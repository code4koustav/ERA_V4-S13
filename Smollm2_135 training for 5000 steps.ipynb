{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Y-t2thLe-S4",
        "outputId": "f75a86e2-7b1f-49b1-e3b6-b25584532af8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: CUDA (Tesla T4), Mixed precision: True, dtype: torch.bfloat16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (341094 > 8192). Running this sequence through the model will result in indexing errors\n",
            "\n",
            "Training:   0%|          | 0/5000 [00:00<?, ?it/s]\u001b[A\n",
            "Training:   0%|          | 1/5000 [00:02<3:12:28,  2.31s/it]\u001b[A\n",
            "Training:   0%|          | 1/5000 [00:02<3:12:28,  2.31s/it, loss=11.2908]\u001b[A\n",
            "Training:   0%|          | 2/5000 [00:05<3:35:19,  2.58s/it, loss=11.2908]\u001b[A\n",
            "Training:   0%|          | 2/5000 [00:05<3:35:19,  2.58s/it, loss=10.2112]\u001b[A\n",
            "Training:   0%|          | 3/5000 [00:07<3:27:40,  2.49s/it, loss=10.2112]\u001b[A\n",
            "Training:   0%|          | 3/5000 [00:07<3:27:40,  2.49s/it, loss=10.6612]\u001b[A\n",
            "Training:   0%|          | 4/5000 [00:09<3:20:10,  2.40s/it, loss=10.6612]\u001b[A\n",
            "Training:   0%|          | 4/5000 [00:09<3:20:10,  2.40s/it, loss=9.4684] \u001b[A\n",
            "Training:   0%|          | 5/5000 [00:12<3:16:02,  2.35s/it, loss=9.4684]\u001b[A\n",
            "Training:   0%|          | 5/5000 [00:12<3:16:02,  2.35s/it, loss=9.1282]\u001b[A\n",
            "Training:   0%|          | 6/5000 [00:14<3:13:54,  2.33s/it, loss=9.1282]\u001b[A\n",
            "Training:   0%|          | 6/5000 [00:14<3:13:54,  2.33s/it, loss=8.4909]\u001b[A\n",
            "Training:   0%|          | 7/5000 [00:16<3:23:22,  2.44s/it, loss=8.4909]\u001b[A\n",
            "Training:   0%|          | 7/5000 [00:16<3:23:22,  2.44s/it, loss=8.6745]\u001b[A\n",
            "Training:   0%|          | 8/5000 [00:19<3:24:30,  2.46s/it, loss=8.6745]\u001b[A\n",
            "Training:   0%|          | 8/5000 [00:19<3:24:30,  2.46s/it, loss=7.5096]\u001b[A\n",
            "Training:   0%|          | 9/5000 [00:21<3:19:25,  2.40s/it, loss=7.5096]\u001b[A\n",
            "Training:   0%|          | 9/5000 [00:21<3:19:25,  2.40s/it, loss=8.3980]\u001b[A\n",
            "Training:   0%|          | 10/5000 [00:23<3:15:42,  2.35s/it, loss=8.3980]\u001b[A\n",
            "Training:   0%|          | 10/5000 [00:24<3:15:42,  2.35s/it, loss=7.5016]\u001b[A\n",
            "Training:   0%|          | 11/5000 [00:26<3:13:52,  2.33s/it, loss=7.5016]\u001b[A\n",
            "Training:   0%|          | 11/5000 [00:26<3:13:52,  2.33s/it, loss=7.3611]\u001b[A\n",
            "Training:   0%|          | 12/5000 [00:28<3:23:01,  2.44s/it, loss=7.3611]\u001b[A\n",
            "Training:   0%|          | 12/5000 [00:28<3:23:01,  2.44s/it, loss=6.8155]\u001b[A\n",
            "Training:   0%|          | 13/5000 [00:31<3:23:27,  2.45s/it, loss=6.8155]\u001b[A\n",
            "Training:   0%|          | 13/5000 [00:31<3:23:27,  2.45s/it, loss=7.0027]\u001b[A\n",
            "Training:   0%|          | 14/5000 [00:33<3:19:54,  2.41s/it, loss=7.0027]\u001b[A\n",
            "Training:   0%|          | 14/5000 [00:33<3:19:54,  2.41s/it, loss=6.3858]\u001b[A\n",
            "Training:   0%|          | 15/5000 [00:36<3:17:19,  2.37s/it, loss=6.3858]\u001b[A\n",
            "Training:   0%|          | 15/5000 [00:36<3:17:19,  2.37s/it, loss=6.0739]\u001b[A\n",
            "Training:   0%|          | 16/5000 [00:38<3:14:50,  2.35s/it, loss=6.0739]\u001b[A\n",
            "Training:   0%|          | 16/5000 [00:38<3:14:50,  2.35s/it, loss=6.4157]\u001b[A\n",
            "Training:   0%|          | 17/5000 [00:40<3:22:18,  2.44s/it, loss=6.4157]\u001b[A\n",
            "Training:   0%|          | 17/5000 [00:40<3:22:18,  2.44s/it, loss=6.1418]\u001b[A\n",
            "Training:   0%|          | 18/5000 [00:43<3:23:43,  2.45s/it, loss=6.1418]\u001b[A\n",
            "Training:   0%|          | 18/5000 [00:43<3:23:43,  2.45s/it, loss=6.1646]\u001b[A\n",
            "Training:   0%|          | 19/5000 [00:45<3:19:12,  2.40s/it, loss=6.1646]\u001b[A\n",
            "Training:   0%|          | 19/5000 [00:45<3:19:12,  2.40s/it, loss=6.8638]\u001b[A\n",
            "Training:   0%|          | 20/5000 [00:47<3:15:55,  2.36s/it, loss=6.8638]\u001b[A\n",
            "Training:   0%|          | 20/5000 [00:48<3:15:55,  2.36s/it, loss=6.0299]\u001b[A\n",
            "Training:   0%|          | 21/5000 [00:50<3:14:58,  2.35s/it, loss=6.0299]\u001b[A\n",
            "Training:   0%|          | 21/5000 [00:50<3:14:58,  2.35s/it, loss=7.2147]\u001b[A\n",
            "Training:   0%|          | 22/5000 [00:52<3:22:42,  2.44s/it, loss=7.2147]\u001b[A\n",
            "Training:   0%|          | 22/5000 [00:52<3:22:42,  2.44s/it, loss=6.9461]\u001b[A\n",
            "Training:   0%|          | 23/5000 [00:55<3:22:45,  2.44s/it, loss=6.9461]\u001b[A\n",
            "Training:   0%|          | 23/5000 [00:55<3:22:45,  2.44s/it, loss=6.9304]\u001b[A\n",
            "Training:   0%|          | 24/5000 [00:57<3:17:52,  2.39s/it, loss=6.9304]\u001b[A\n",
            "Training:   0%|          | 24/5000 [00:57<3:17:52,  2.39s/it, loss=7.1395]\u001b[A\n",
            "Training:   0%|          | 25/5000 [00:59<3:15:17,  2.36s/it, loss=7.1395]\u001b[A\n",
            "Training:   0%|          | 25/5000 [00:59<3:15:17,  2.36s/it, loss=7.4960]\u001b[A\n",
            "Training:   1%|          | 26/5000 [01:02<3:13:41,  2.34s/it, loss=7.4960]\u001b[A\n",
            "Training:   1%|          | 26/5000 [01:02<3:13:41,  2.34s/it, loss=7.1224]\u001b[A\n",
            "Training:   1%|          | 27/5000 [01:04<3:20:07,  2.41s/it, loss=7.1224]\u001b[A\n",
            "Training:   1%|          | 27/5000 [01:04<3:20:07,  2.41s/it, loss=7.0142]\u001b[A\n",
            "Training:   1%|          | 28/5000 [01:07<3:22:20,  2.44s/it, loss=7.0142]\u001b[A\n",
            "Training:   1%|          | 28/5000 [01:07<3:22:20,  2.44s/it, loss=6.9433]\u001b[A\n",
            "Training:   1%|          | 29/5000 [01:09<3:17:56,  2.39s/it, loss=6.9433]\u001b[A\n",
            "Training:   1%|          | 29/5000 [01:09<3:17:56,  2.39s/it, loss=7.2387]\u001b[A\n",
            "Training:   1%|          | 30/5000 [01:11<3:14:59,  2.35s/it, loss=7.2387]\u001b[A\n",
            "Training:   1%|          | 30/5000 [01:11<3:14:59,  2.35s/it, loss=6.8518]\u001b[A\n",
            "Training:   1%|          | 31/5000 [01:14<3:12:37,  2.33s/it, loss=6.8518]\u001b[A\n",
            "Training:   1%|          | 31/5000 [01:14<3:12:37,  2.33s/it, loss=6.8357]\u001b[A\n",
            "Training:   1%|          | 32/5000 [01:16<3:18:38,  2.40s/it, loss=6.8357]\u001b[A\n",
            "Training:   1%|          | 32/5000 [01:16<3:18:38,  2.40s/it, loss=7.1794]\u001b[A\n",
            "Training:   1%|          | 33/5000 [01:19<3:22:54,  2.45s/it, loss=7.1794]\u001b[A\n",
            "Training:   1%|          | 33/5000 [01:19<3:22:54,  2.45s/it, loss=6.9119]\u001b[A\n",
            "Training:   1%|          | 34/5000 [01:21<3:18:54,  2.40s/it, loss=6.9119]\u001b[A\n",
            "Training:   1%|          | 34/5000 [01:21<3:18:54,  2.40s/it, loss=6.4550]\u001b[A\n",
            "Training:   1%|          | 35/5000 [01:23<3:15:38,  2.36s/it, loss=6.4550]\u001b[A\n",
            "Training:   1%|          | 35/5000 [01:23<3:15:38,  2.36s/it, loss=6.5427]\u001b[A\n",
            "Training:   1%|          | 36/5000 [01:26<3:13:19,  2.34s/it, loss=6.5427]\u001b[A\n",
            "Training:   1%|          | 36/5000 [01:26<3:13:19,  2.34s/it, loss=6.3030]\u001b[A\n",
            "Training:   1%|          | 37/5000 [01:28<3:18:29,  2.40s/it, loss=6.3030]\u001b[A\n",
            "Training:   1%|          | 37/5000 [01:28<3:18:29,  2.40s/it, loss=6.1538]\u001b[A\n",
            "Training:   1%|          | 38/5000 [01:31<3:22:37,  2.45s/it, loss=6.1538]\u001b[A\n",
            "Training:   1%|          | 38/5000 [01:31<3:22:37,  2.45s/it, loss=6.5247]\u001b[A\n",
            "Training:   1%|          | 39/5000 [01:33<3:18:58,  2.41s/it, loss=6.5247]\u001b[A\n",
            "Training:   1%|          | 39/5000 [01:33<3:18:58,  2.41s/it, loss=6.1868]\u001b[A\n",
            "Training:   1%|          | 40/5000 [01:35<3:15:01,  2.36s/it, loss=6.1868]\u001b[A\n",
            "Training:   1%|          | 40/5000 [01:35<3:15:01,  2.36s/it, loss=6.9728]\u001b[A\n",
            "Training:   1%|          | 41/5000 [01:38<3:12:48,  2.33s/it, loss=6.9728]\u001b[A\n",
            "Training:   1%|          | 41/5000 [01:38<3:12:48,  2.33s/it, loss=7.0399]\u001b[A\n",
            "Training:   1%|          | 42/5000 [01:40<3:17:22,  2.39s/it, loss=7.0399]\u001b[A\n",
            "Training:   1%|          | 42/5000 [01:40<3:17:22,  2.39s/it, loss=6.4810]\u001b[A\n",
            "Training:   1%|          | 43/5000 [01:43<3:22:39,  2.45s/it, loss=6.4810]\u001b[A\n",
            "Training:   1%|          | 43/5000 [01:43<3:22:39,  2.45s/it, loss=6.5451]\u001b[A\n",
            "Training:   1%|          | 44/5000 [01:45<3:18:35,  2.40s/it, loss=6.5451]\u001b[A\n",
            "Training:   1%|          | 44/5000 [01:45<3:18:35,  2.40s/it, loss=6.8122]\u001b[A\n",
            "Training:   1%|          | 45/5000 [01:47<3:14:31,  2.36s/it, loss=6.8122]\u001b[A\n",
            "Training:   1%|          | 45/5000 [01:47<3:14:31,  2.36s/it, loss=6.6107]\u001b[A\n",
            "Training:   1%|          | 46/5000 [01:50<3:13:15,  2.34s/it, loss=6.6107]\u001b[A\n",
            "Training:   1%|          | 46/5000 [01:50<3:13:15,  2.34s/it, loss=6.9030]\u001b[A\n",
            "Training:   1%|          | 47/5000 [01:52<3:17:34,  2.39s/it, loss=6.9030]\u001b[A\n",
            "Training:   1%|          | 47/5000 [01:52<3:17:34,  2.39s/it, loss=5.7931]\u001b[A\n",
            "Training:   1%|          | 48/5000 [01:55<3:23:04,  2.46s/it, loss=5.7931]\u001b[A\n",
            "Training:   1%|          | 48/5000 [01:55<3:23:04,  2.46s/it, loss=6.0547]\u001b[A\n",
            "Training:   1%|          | 49/5000 [01:57<3:17:52,  2.40s/it, loss=6.0547]\u001b[A\n",
            "Training:   1%|          | 49/5000 [01:57<3:17:52,  2.40s/it, loss=6.6396]\u001b[A\n",
            "Training:   1%|          | 50/5000 [01:59<3:14:14,  2.35s/it, loss=6.6396]\u001b[A\n",
            "Training:   1%|          | 50/5000 [01:59<3:14:14,  2.35s/it, loss=6.5151]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 50 ---\n",
            "Prompt: 'The '\n",
            "The \n",
            " must: death thy my,st despair\n",
            " in andB inAnd and of, learn\n",
            " lord OF: your's, to and's: and,,Or\n",
            "ENARDESS\n",
            ", thereofTh,ge love, storyLong to,,\n",
            "'s,I: is\n",
            " again jealous her in and and, in:ates my the she\n",
            " dear danger, to rough\n",
            "est in a:\n",
            "\n",
            "blown\n",
            " no: the to here\n",
            " children my soul desireI thy with.\n",
            "Prompt: 'In '\n",
            "In \n",
            "AB: IING am of,,R.\n",
            "ICH\n",
            "ICH\n",
            " R: shall, daily:If toSoThat no,, II thy, the,'s I: meAMAM\n",
            " to Ifor,,, qu, go hath mayful to's, to of when.\n",
            " leads gro their,: wrong thy, let hast of,, then and in,,ING's and with my me. Richard, thou;, every never ChristAB us, resign,\n",
            "Prompt: 'To '\n",
            "To \n",
            " to in the;: what and and close\n",
            " thyV there;!\n",
            "ING have and is\n",
            " my the the untoHow, GodThe a and is, I; a make will to in\n",
            ":: humour\n",
            "--ity in, coward here, is my royal now walls\n",
            " not and,, on my and\n",
            "ful of would with bes the I.\n",
            " R in isfort, by not\n",
            " R this I bless, I loveill\n",
            "EN'sR-: my his\n",
            "Prompt: 'A '\n",
            "A  is\n",
            ", to live tid fame,, ap conscience theirsent law\n",
            "ily a say:ICH\n",
            " shallitor coward toallEST\n",
            " for:al ent isius name, in,No royalou have my the, I\n",
            "ING hollow: for return in the,QUEI shallow not\n",
            "ICH\n",
            " springtime'sest or are\n",
            " sovereigngovern so honour,, to in and's to the speak\n",
            "AN\n",
            " cannot and purposeake and I how\n",
            "IZ world I's ofAB.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:   1%|          | 51/5000 [02:14<8:29:12,  6.17s/it, loss=6.5151]\u001b[A\n",
            "Training:   1%|          | 51/5000 [02:14<8:29:12,  6.17s/it, loss=6.6871]\u001b[A\n",
            "Training:   1%|          | 52/5000 [02:17<7:03:46,  5.14s/it, loss=6.6871]\u001b[A\n",
            "Training:   1%|          | 52/5000 [02:17<7:03:46,  5.14s/it, loss=5.7061]\u001b[A\n",
            "Training:   1%|          | 53/5000 [02:19<5:55:05,  4.31s/it, loss=5.7061]\u001b[A\n",
            "Training:   1%|          | 53/5000 [02:19<5:55:05,  4.31s/it, loss=6.5593]\u001b[A\n",
            "Training:   1%|          | 54/5000 [02:22<5:04:34,  3.69s/it, loss=6.5593]\u001b[A\n",
            "Training:   1%|          | 54/5000 [02:22<5:04:34,  3.69s/it, loss=6.1754]\u001b[A\n",
            "Training:   1%|          | 55/5000 [02:24<4:28:49,  3.26s/it, loss=6.1754]\u001b[A\n",
            "Training:   1%|          | 55/5000 [02:24<4:28:49,  3.26s/it, loss=6.0320]\u001b[A\n",
            "Training:   1%|          | 56/5000 [02:26<4:03:46,  2.96s/it, loss=6.0320]\u001b[A\n",
            "Training:   1%|          | 56/5000 [02:26<4:03:46,  2.96s/it, loss=6.4104]\u001b[A\n",
            "Training:   1%|          | 57/5000 [02:29<3:55:49,  2.86s/it, loss=6.4104]\u001b[A\n",
            "Training:   1%|          | 57/5000 [02:29<3:55:49,  2.86s/it, loss=7.0998]\u001b[A\n",
            "Training:   1%|          | 58/5000 [02:31<3:45:13,  2.73s/it, loss=7.0998]\u001b[A\n",
            "Training:   1%|          | 58/5000 [02:31<3:45:13,  2.73s/it, loss=6.7616]\u001b[A\n",
            "Training:   1%|          | 59/5000 [02:33<3:33:32,  2.59s/it, loss=6.7616]\u001b[A\n",
            "Training:   1%|          | 59/5000 [02:33<3:33:32,  2.59s/it, loss=7.1542]\u001b[A\n",
            "Training:   1%|          | 60/5000 [02:36<3:26:39,  2.51s/it, loss=7.1542]\u001b[A\n",
            "Training:   1%|          | 60/5000 [02:36<3:26:39,  2.51s/it, loss=6.3580]\u001b[A\n",
            "Training:   1%|          | 61/5000 [02:38<3:20:24,  2.43s/it, loss=6.3580]\u001b[A\n",
            "Training:   1%|          | 61/5000 [02:38<3:20:24,  2.43s/it, loss=6.0704]\u001b[A\n",
            "Training:   1%|          | 62/5000 [02:41<3:24:24,  2.48s/it, loss=6.0704]\u001b[A\n",
            "Training:   1%|          | 62/5000 [02:41<3:24:24,  2.48s/it, loss=5.9680]\u001b[A\n",
            "Training:   1%|▏         | 63/5000 [02:43<3:25:57,  2.50s/it, loss=5.9680]\u001b[A\n",
            "Training:   1%|▏         | 63/5000 [02:43<3:25:57,  2.50s/it, loss=5.9023]\u001b[A\n",
            "Training:   1%|▏         | 64/5000 [02:45<3:20:07,  2.43s/it, loss=5.9023]\u001b[A\n",
            "Training:   1%|▏         | 64/5000 [02:45<3:20:07,  2.43s/it, loss=6.0547]\u001b[A\n",
            "Training:   1%|▏         | 65/5000 [02:48<3:15:58,  2.38s/it, loss=6.0547]\u001b[A\n",
            "Training:   1%|▏         | 65/5000 [02:48<3:15:58,  2.38s/it, loss=6.8018]\u001b[A\n",
            "Training:   1%|▏         | 66/5000 [02:50<3:13:49,  2.36s/it, loss=6.8018]\u001b[A\n",
            "Training:   1%|▏         | 66/5000 [02:50<3:13:49,  2.36s/it, loss=7.3277]\u001b[A\n",
            "Training:   1%|▏         | 67/5000 [02:53<3:18:16,  2.41s/it, loss=7.3277]\u001b[A\n",
            "Training:   1%|▏         | 67/5000 [02:53<3:18:16,  2.41s/it, loss=6.5963]\u001b[A\n",
            "Training:   1%|▏         | 68/5000 [02:55<3:20:49,  2.44s/it, loss=6.5963]\u001b[A\n",
            "Training:   1%|▏         | 68/5000 [02:55<3:20:49,  2.44s/it, loss=6.8211]\u001b[A\n",
            "Training:   1%|▏         | 69/5000 [02:57<3:15:50,  2.38s/it, loss=6.8211]\u001b[A\n",
            "Training:   1%|▏         | 69/5000 [02:57<3:15:50,  2.38s/it, loss=7.4051]\u001b[A\n",
            "Training:   1%|▏         | 70/5000 [03:00<3:12:32,  2.34s/it, loss=7.4051]\u001b[A\n",
            "Training:   1%|▏         | 70/5000 [03:00<3:12:32,  2.34s/it, loss=5.8094]\u001b[A\n",
            "Training:   1%|▏         | 71/5000 [03:02<3:10:00,  2.31s/it, loss=5.8094]\u001b[A\n",
            "Training:   1%|▏         | 71/5000 [03:02<3:10:00,  2.31s/it, loss=5.8762]\u001b[A\n",
            "Training:   1%|▏         | 72/5000 [03:04<3:13:04,  2.35s/it, loss=5.8762]\u001b[A\n",
            "Training:   1%|▏         | 72/5000 [03:04<3:13:04,  2.35s/it, loss=7.5108]\u001b[A\n",
            "Training:   1%|▏         | 73/5000 [03:07<3:19:29,  2.43s/it, loss=7.5108]\u001b[A\n",
            "Training:   1%|▏         | 73/5000 [03:07<3:19:29,  2.43s/it, loss=6.3650]\u001b[A\n",
            "Training:   1%|▏         | 74/5000 [03:09<3:14:52,  2.37s/it, loss=6.3650]\u001b[A\n",
            "Training:   1%|▏         | 74/5000 [03:09<3:14:52,  2.37s/it, loss=6.3709]\u001b[A\n",
            "Training:   2%|▏         | 75/5000 [03:11<3:11:47,  2.34s/it, loss=6.3709]\u001b[A\n",
            "Training:   2%|▏         | 75/5000 [03:11<3:11:47,  2.34s/it, loss=6.2347]\u001b[A\n",
            "Training:   2%|▏         | 76/5000 [03:14<3:10:07,  2.32s/it, loss=6.2347]\u001b[A\n",
            "Training:   2%|▏         | 76/5000 [03:14<3:10:07,  2.32s/it, loss=6.7640]\u001b[A\n",
            "Training:   2%|▏         | 77/5000 [03:16<3:12:13,  2.34s/it, loss=6.7640]\u001b[A\n",
            "Training:   2%|▏         | 77/5000 [03:16<3:12:13,  2.34s/it, loss=5.9852]\u001b[A\n",
            "Training:   2%|▏         | 78/5000 [03:19<3:19:24,  2.43s/it, loss=5.9852]\u001b[A\n",
            "Training:   2%|▏         | 78/5000 [03:19<3:19:24,  2.43s/it, loss=6.6887]\u001b[A\n",
            "Training:   2%|▏         | 79/5000 [03:21<3:15:47,  2.39s/it, loss=6.6887]\u001b[A\n",
            "Training:   2%|▏         | 79/5000 [03:21<3:15:47,  2.39s/it, loss=5.4589]\u001b[A\n",
            "Training:   2%|▏         | 80/5000 [03:23<3:12:04,  2.34s/it, loss=5.4589]\u001b[A\n",
            "Training:   2%|▏         | 80/5000 [03:23<3:12:04,  2.34s/it, loss=5.6836]\u001b[A\n",
            "Training:   2%|▏         | 81/5000 [03:25<3:10:05,  2.32s/it, loss=5.6836]\u001b[A\n",
            "Training:   2%|▏         | 81/5000 [03:25<3:10:05,  2.32s/it, loss=6.0585]\u001b[A\n",
            "Training:   2%|▏         | 82/5000 [03:28<3:10:33,  2.32s/it, loss=6.0585]\u001b[A\n",
            "Training:   2%|▏         | 82/5000 [03:28<3:10:33,  2.32s/it, loss=6.2636]\u001b[A\n",
            "Training:   2%|▏         | 83/5000 [03:30<3:19:45,  2.44s/it, loss=6.2636]\u001b[A\n",
            "Training:   2%|▏         | 83/5000 [03:30<3:19:45,  2.44s/it, loss=6.3161]\u001b[A\n",
            "Training:   2%|▏         | 84/5000 [03:33<3:15:24,  2.38s/it, loss=6.3161]\u001b[A\n",
            "Training:   2%|▏         | 84/5000 [03:33<3:15:24,  2.38s/it, loss=5.9070]\u001b[A\n",
            "Training:   2%|▏         | 85/5000 [03:35<3:12:27,  2.35s/it, loss=5.9070]\u001b[A\n",
            "Training:   2%|▏         | 85/5000 [03:35<3:12:27,  2.35s/it, loss=6.2734]\u001b[A\n",
            "Training:   2%|▏         | 86/5000 [03:37<3:10:00,  2.32s/it, loss=6.2734]\u001b[A\n",
            "Training:   2%|▏         | 86/5000 [03:37<3:10:00,  2.32s/it, loss=6.0815]\u001b[A\n",
            "Training:   2%|▏         | 87/5000 [03:39<3:08:05,  2.30s/it, loss=6.0815]\u001b[A\n",
            "Training:   2%|▏         | 87/5000 [03:40<3:08:05,  2.30s/it, loss=6.4928]\u001b[A\n",
            "Training:   2%|▏         | 88/5000 [03:42<3:22:21,  2.47s/it, loss=6.4928]\u001b[A\n",
            "Training:   2%|▏         | 88/5000 [03:42<3:22:21,  2.47s/it, loss=6.3283]\u001b[A\n",
            "Training:   2%|▏         | 89/5000 [03:45<3:17:16,  2.41s/it, loss=6.3283]\u001b[A\n",
            "Training:   2%|▏         | 89/5000 [03:45<3:17:16,  2.41s/it, loss=6.3307]\u001b[A\n",
            "Training:   2%|▏         | 90/5000 [03:47<3:13:34,  2.37s/it, loss=6.3307]\u001b[A\n",
            "Training:   2%|▏         | 90/5000 [03:47<3:13:34,  2.37s/it, loss=6.5264]\u001b[A\n",
            "Training:   2%|▏         | 91/5000 [03:49<3:11:00,  2.33s/it, loss=6.5264]\u001b[A\n",
            "Training:   2%|▏         | 91/5000 [03:49<3:11:00,  2.33s/it, loss=5.8966]\u001b[A\n",
            "Training:   2%|▏         | 92/5000 [03:51<3:09:47,  2.32s/it, loss=5.8966]\u001b[A\n",
            "Training:   2%|▏         | 92/5000 [03:51<3:09:47,  2.32s/it, loss=6.3659]\u001b[A\n",
            "Training:   2%|▏         | 93/5000 [03:54<3:21:55,  2.47s/it, loss=6.3659]\u001b[A\n",
            "Training:   2%|▏         | 93/5000 [03:54<3:21:55,  2.47s/it, loss=6.7435]\u001b[A\n",
            "Training:   2%|▏         | 94/5000 [03:57<3:16:45,  2.41s/it, loss=6.7435]\u001b[A\n",
            "Training:   2%|▏         | 94/5000 [03:57<3:16:45,  2.41s/it, loss=6.2074]\u001b[A\n",
            "Training:   2%|▏         | 95/5000 [03:59<3:12:34,  2.36s/it, loss=6.2074]\u001b[A\n",
            "Training:   2%|▏         | 95/5000 [03:59<3:12:34,  2.36s/it, loss=6.2187]\u001b[A\n",
            "Training:   2%|▏         | 96/5000 [04:01<3:10:03,  2.33s/it, loss=6.2187]\u001b[A\n",
            "Training:   2%|▏         | 96/5000 [04:01<3:10:03,  2.33s/it, loss=6.1419]\u001b[A\n",
            "Training:   2%|▏         | 97/5000 [04:03<3:07:52,  2.30s/it, loss=6.1419]\u001b[A\n",
            "Training:   2%|▏         | 97/5000 [04:03<3:07:52,  2.30s/it, loss=5.7977]\u001b[A\n",
            "Training:   2%|▏         | 98/5000 [04:06<3:20:49,  2.46s/it, loss=5.7977]\u001b[A\n",
            "Training:   2%|▏         | 98/5000 [04:06<3:20:49,  2.46s/it, loss=6.0042]\u001b[A\n",
            "Training:   2%|▏         | 99/5000 [04:08<3:15:24,  2.39s/it, loss=6.0042]\u001b[A\n",
            "Training:   2%|▏         | 99/5000 [04:08<3:15:24,  2.39s/it, loss=6.0370]\u001b[A\n",
            "Training:   2%|▏         | 100/5000 [04:11<3:11:40,  2.35s/it, loss=6.0370]\u001b[A\n",
            "Training:   2%|▏         | 100/5000 [04:11<3:11:40,  2.35s/it, loss=5.3908]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 100 ---\n",
            "Prompt: 'The '\n",
            "The  how move and,And can,AndAnd breath\n",
            " that by my they in crown\n",
            " so common.\n",
            "IFD a tears were and strong, the w\n",
            " from's and the and and, me give with\n",
            "'sAD cannot prison black:And his to.\n",
            "INGICH\n",
            ",'s yielding and.\n",
            "W, I ste:But's to,That for for by.\n",
            "INGKKINGINGINGINGINGWARD\n",
            "KNALadeAR:\n",
            " me can both will\n",
            "Prompt: 'In '\n",
            "In  sl,For child comfort come\n",
            " words toHave, I love an thou's light\n",
            " I have not like hungry with and be,Which?\n",
            "KESTGAR: is watch and, thy father howAndAndAndAndFor\n",
            " that this father, thou's I.\n",
            "KINGKW:Too a thy stand,With,Stay in stay.\n",
            "KW passages that thy God.\n",
            "KINGWARD:And; fiery wilt with,Andine I end thy.\n",
            "\n",
            "Prompt: 'To '\n",
            "To  to thousand his to save,AndAndAnd,And,AndAnd entrance speakFivele.\n",
            "W words'smbling,, we through for tongue,Hold\n",
            " in if one I him in conference\n",
            "s my and his a away?That\n",
            "KWARD and thy to promise me his\n",
            " murder forless your brother that their my\n",
            ", hoursan endar I's with and,Is thy a aded my!\n",
            "KKou bo usland tillp silver lives and,But\n",
            "Prompt: 'A '\n",
            "A  to a.\n",
            "WARD:So sorrow be, if thy of loveHow\n",
            " down that or of and of him,And,Here does\n",
            "OR as to and mis menOur. thee,But,And;My,W thee to shall his\n",
            " up I'd aim'd sin his so give of and bed.\n",
            "KINGINGW:That,, leave age?,That than,And for, from and of toThere now done\n",
            "KINGINGKWARD\n",
            " hope\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:   2%|▏         | 101/5000 [04:25<8:15:47,  6.07s/it, loss=5.3908]\u001b[A\n",
            "Training:   2%|▏         | 101/5000 [04:25<8:15:47,  6.07s/it, loss=5.8144]\u001b[A\n",
            "Training:   2%|▏         | 102/5000 [04:28<6:43:33,  4.94s/it, loss=5.8144]\u001b[A\n",
            "Training:   2%|▏         | 102/5000 [04:28<6:43:33,  4.94s/it, loss=4.8139]\u001b[A\n",
            "Training:   2%|▏         | 103/5000 [04:30<5:50:24,  4.29s/it, loss=4.8139]\u001b[A\n",
            "Training:   2%|▏         | 103/5000 [04:30<5:50:24,  4.29s/it, loss=6.1816]\u001b[A\n",
            "Training:   2%|▏         | 104/5000 [04:33<5:01:03,  3.69s/it, loss=6.1816]\u001b[A\n",
            "Training:   2%|▏         | 104/5000 [04:33<5:01:03,  3.69s/it, loss=5.9803]\u001b[A\n",
            "Training:   2%|▏         | 105/5000 [04:35<4:25:21,  3.25s/it, loss=5.9803]\u001b[A\n",
            "Training:   2%|▏         | 105/5000 [04:35<4:25:21,  3.25s/it, loss=5.8818]\u001b[A\n",
            "Training:   2%|▏         | 106/5000 [04:37<4:01:11,  2.96s/it, loss=5.8818]\u001b[A\n",
            "Training:   2%|▏         | 106/5000 [04:37<4:01:11,  2.96s/it, loss=7.1533]\u001b[A\n",
            "Training:   2%|▏         | 107/5000 [04:39<3:44:12,  2.75s/it, loss=7.1533]\u001b[A\n",
            "Training:   2%|▏         | 107/5000 [04:39<3:44:12,  2.75s/it, loss=7.0091]\u001b[A\n",
            "Training:   2%|▏         | 108/5000 [04:42<3:46:02,  2.77s/it, loss=7.0091]\u001b[A\n",
            "Training:   2%|▏         | 108/5000 [04:42<3:46:02,  2.77s/it, loss=6.2964]\u001b[A\n",
            "Training:   2%|▏         | 109/5000 [04:45<3:33:20,  2.62s/it, loss=6.2964]\u001b[A\n",
            "Training:   2%|▏         | 109/5000 [04:45<3:33:20,  2.62s/it, loss=5.9980]\u001b[A\n",
            "Training:   2%|▏         | 110/5000 [04:47<3:24:20,  2.51s/it, loss=5.9980]\u001b[A\n",
            "Training:   2%|▏         | 110/5000 [04:47<3:24:20,  2.51s/it, loss=6.2738]\u001b[A\n",
            "Training:   2%|▏         | 111/5000 [04:49<3:18:39,  2.44s/it, loss=6.2738]\u001b[A\n",
            "Training:   2%|▏         | 111/5000 [04:49<3:18:39,  2.44s/it, loss=6.1163]\u001b[A\n",
            "Training:   2%|▏         | 112/5000 [04:51<3:15:17,  2.40s/it, loss=6.1163]\u001b[A\n",
            "Training:   2%|▏         | 112/5000 [04:51<3:15:17,  2.40s/it, loss=6.5843]\u001b[A\n",
            "Training:   2%|▏         | 113/5000 [04:54<3:25:20,  2.52s/it, loss=6.5843]\u001b[A\n",
            "Training:   2%|▏         | 113/5000 [04:54<3:25:20,  2.52s/it, loss=6.8324]\u001b[A\n",
            "Training:   2%|▏         | 114/5000 [04:56<3:18:27,  2.44s/it, loss=6.8324]\u001b[A\n",
            "Training:   2%|▏         | 114/5000 [04:56<3:18:27,  2.44s/it, loss=7.2962]\u001b[A\n",
            "Training:   2%|▏         | 115/5000 [04:59<3:14:23,  2.39s/it, loss=7.2962]\u001b[A\n",
            "Training:   2%|▏         | 115/5000 [04:59<3:14:23,  2.39s/it, loss=7.6958]\u001b[A\n",
            "Training:   2%|▏         | 116/5000 [05:01<3:11:09,  2.35s/it, loss=7.6958]\u001b[A\n",
            "Training:   2%|▏         | 116/5000 [05:01<3:11:09,  2.35s/it, loss=6.7004]\u001b[A\n",
            "Training:   2%|▏         | 117/5000 [05:03<3:08:26,  2.32s/it, loss=6.7004]\u001b[A\n",
            "Training:   2%|▏         | 117/5000 [05:03<3:08:26,  2.32s/it, loss=6.7036]\u001b[A\n",
            "Training:   2%|▏         | 118/5000 [05:06<3:20:45,  2.47s/it, loss=6.7036]\u001b[A\n",
            "Training:   2%|▏         | 118/5000 [05:06<3:20:45,  2.47s/it, loss=6.9150]\u001b[A\n",
            "Training:   2%|▏         | 119/5000 [05:08<3:15:45,  2.41s/it, loss=6.9150]\u001b[A\n",
            "Training:   2%|▏         | 119/5000 [05:08<3:15:45,  2.41s/it, loss=6.4563]\u001b[A\n",
            "Training:   2%|▏         | 120/5000 [05:11<3:11:56,  2.36s/it, loss=6.4563]\u001b[A\n",
            "Training:   2%|▏         | 120/5000 [05:11<3:11:56,  2.36s/it, loss=5.7222]\u001b[A\n",
            "Training:   2%|▏         | 121/5000 [05:13<3:09:59,  2.34s/it, loss=5.7222]\u001b[A\n",
            "Training:   2%|▏         | 121/5000 [05:13<3:09:59,  2.34s/it, loss=6.9674]\u001b[A\n",
            "Training:   2%|▏         | 122/5000 [05:15<3:08:34,  2.32s/it, loss=6.9674]\u001b[A\n",
            "Training:   2%|▏         | 122/5000 [05:15<3:08:34,  2.32s/it, loss=6.3111]\u001b[A\n",
            "Training:   2%|▏         | 123/5000 [05:18<3:20:29,  2.47s/it, loss=6.3111]\u001b[A\n",
            "Training:   2%|▏         | 123/5000 [05:18<3:20:29,  2.47s/it, loss=6.8427]\u001b[A\n",
            "Training:   2%|▏         | 124/5000 [05:20<3:15:55,  2.41s/it, loss=6.8427]\u001b[A\n",
            "Training:   2%|▏         | 124/5000 [05:20<3:15:55,  2.41s/it, loss=5.6094]\u001b[A\n",
            "Training:   2%|▎         | 125/5000 [05:22<3:13:29,  2.38s/it, loss=5.6094]\u001b[A\n",
            "Training:   2%|▎         | 125/5000 [05:23<3:13:29,  2.38s/it, loss=6.4943]\u001b[A\n",
            "Training:   3%|▎         | 126/5000 [05:25<3:10:16,  2.34s/it, loss=6.4943]\u001b[A\n",
            "Training:   3%|▎         | 126/5000 [05:25<3:10:16,  2.34s/it, loss=6.3037]\u001b[A\n",
            "Training:   3%|▎         | 127/5000 [05:27<3:08:10,  2.32s/it, loss=6.3037]\u001b[A\n",
            "Training:   3%|▎         | 127/5000 [05:27<3:08:10,  2.32s/it, loss=6.8294]\u001b[A\n",
            "Training:   3%|▎         | 128/5000 [05:30<3:20:45,  2.47s/it, loss=6.8294]\u001b[A\n",
            "Training:   3%|▎         | 128/5000 [05:30<3:20:45,  2.47s/it, loss=5.8993]\u001b[A\n",
            "Training:   3%|▎         | 129/5000 [05:32<3:15:31,  2.41s/it, loss=5.8993]\u001b[A\n",
            "Training:   3%|▎         | 129/5000 [05:32<3:15:31,  2.41s/it, loss=6.5932]\u001b[A\n",
            "Training:   3%|▎         | 130/5000 [05:34<3:11:22,  2.36s/it, loss=6.5932]\u001b[A\n",
            "Training:   3%|▎         | 130/5000 [05:34<3:11:22,  2.36s/it, loss=5.8501]\u001b[A\n",
            "Training:   3%|▎         | 131/5000 [05:37<3:08:24,  2.32s/it, loss=5.8501]\u001b[A\n",
            "Training:   3%|▎         | 131/5000 [05:37<3:08:24,  2.32s/it, loss=5.8623]\u001b[A\n",
            "Training:   3%|▎         | 132/5000 [05:39<3:06:40,  2.30s/it, loss=5.8623]\u001b[A\n",
            "Training:   3%|▎         | 132/5000 [05:39<3:06:40,  2.30s/it, loss=5.7610]\u001b[A\n",
            "Training:   3%|▎         | 133/5000 [05:42<3:20:45,  2.47s/it, loss=5.7610]\u001b[A\n",
            "Training:   3%|▎         | 133/5000 [05:42<3:20:45,  2.47s/it, loss=6.4238]\u001b[A\n",
            "Training:   3%|▎         | 134/5000 [05:44<3:15:19,  2.41s/it, loss=6.4238]\u001b[A\n",
            "Training:   3%|▎         | 134/5000 [05:44<3:15:19,  2.41s/it, loss=6.2652]\u001b[A\n",
            "Training:   3%|▎         | 135/5000 [05:46<3:11:13,  2.36s/it, loss=6.2652]\u001b[A\n",
            "Training:   3%|▎         | 135/5000 [05:46<3:11:13,  2.36s/it, loss=5.9229]\u001b[A\n",
            "Training:   3%|▎         | 136/5000 [05:48<3:08:41,  2.33s/it, loss=5.9229]\u001b[A\n",
            "Training:   3%|▎         | 136/5000 [05:48<3:08:41,  2.33s/it, loss=6.5193]\u001b[A\n",
            "Training:   3%|▎         | 137/5000 [05:51<3:07:12,  2.31s/it, loss=6.5193]\u001b[A\n",
            "Training:   3%|▎         | 137/5000 [05:51<3:07:12,  2.31s/it, loss=6.2188]\u001b[A\n",
            "Training:   3%|▎         | 138/5000 [05:54<3:18:55,  2.45s/it, loss=6.2188]\u001b[A\n",
            "Training:   3%|▎         | 138/5000 [05:54<3:18:55,  2.45s/it, loss=7.1122]\u001b[A\n",
            "Training:   3%|▎         | 139/5000 [05:56<3:15:13,  2.41s/it, loss=7.1122]\u001b[A\n",
            "Training:   3%|▎         | 139/5000 [05:56<3:15:13,  2.41s/it, loss=6.1709]\u001b[A\n",
            "Training:   3%|▎         | 140/5000 [05:58<3:10:40,  2.35s/it, loss=6.1709]\u001b[A\n",
            "Training:   3%|▎         | 140/5000 [05:58<3:10:40,  2.35s/it, loss=5.4386]\u001b[A\n",
            "Training:   3%|▎         | 141/5000 [06:00<3:07:36,  2.32s/it, loss=5.4386]\u001b[A\n",
            "Training:   3%|▎         | 141/5000 [06:00<3:07:36,  2.32s/it, loss=5.1082]\u001b[A\n",
            "Training:   3%|▎         | 142/5000 [06:03<3:05:54,  2.30s/it, loss=5.1082]\u001b[A\n",
            "Training:   3%|▎         | 142/5000 [06:03<3:05:54,  2.30s/it, loss=4.6365]\u001b[A\n",
            "Training:   3%|▎         | 143/5000 [06:05<3:14:06,  2.40s/it, loss=4.6365]\u001b[A\n",
            "Training:   3%|▎         | 143/5000 [06:05<3:14:06,  2.40s/it, loss=4.8885]\u001b[A\n",
            "Training:   3%|▎         | 144/5000 [06:08<3:14:32,  2.40s/it, loss=4.8885]\u001b[A\n",
            "Training:   3%|▎         | 144/5000 [06:08<3:14:32,  2.40s/it, loss=6.5120]\u001b[A\n",
            "Training:   3%|▎         | 145/5000 [06:10<3:10:26,  2.35s/it, loss=6.5120]\u001b[A\n",
            "Training:   3%|▎         | 145/5000 [06:10<3:10:26,  2.35s/it, loss=6.2694]\u001b[A\n",
            "Training:   3%|▎         | 146/5000 [06:12<3:08:15,  2.33s/it, loss=6.2694]\u001b[A\n",
            "Training:   3%|▎         | 146/5000 [06:12<3:08:15,  2.33s/it, loss=7.0324]\u001b[A\n",
            "Training:   3%|▎         | 147/5000 [06:14<3:06:30,  2.31s/it, loss=7.0324]\u001b[A\n",
            "Training:   3%|▎         | 147/5000 [06:14<3:06:30,  2.31s/it, loss=7.1782]\u001b[A\n",
            "Training:   3%|▎         | 148/5000 [06:17<3:11:43,  2.37s/it, loss=7.1782]\u001b[A\n",
            "Training:   3%|▎         | 148/5000 [06:17<3:11:43,  2.37s/it, loss=5.8968]\u001b[A\n",
            "Training:   3%|▎         | 149/5000 [06:19<3:14:51,  2.41s/it, loss=5.8968]\u001b[A\n",
            "Training:   3%|▎         | 149/5000 [06:19<3:14:51,  2.41s/it, loss=6.3038]\u001b[A\n",
            "Training:   3%|▎         | 150/5000 [06:22<3:11:55,  2.37s/it, loss=6.3038]\u001b[A\n",
            "Training:   3%|▎         | 150/5000 [06:22<3:11:55,  2.37s/it, loss=6.6940]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 150 ---\n",
            "Prompt: 'The '\n",
            "The : verynew sheer touchio\n",
            ", your! I andd,, him,I\n",
            ",, I andfrom it I ofTo,SoHe\n",
            " ta hath you Angel sir eyes, he, not and,And eye!\n",
            "Together she,,asting purchase the, Iar to,And for!\n",
            "LIOWhat thouman inTo excellent!\n",
            "BKE\n",
            " matter to su sir nor hope,Whfully,, youio, me,Her, you you other for\n",
            "Prompt: 'In '\n",
            "In \n",
            " Happy,'ll's, entertainment the on,Who\n",
            ", pleasant me knew as The to'd,And,And,To\n",
            " grace I the!'s andio did now\n",
            " possession pilgrimage youred myself andawio himself,By,And,I\n",
            " thou pray you f many and\n",
            " know. with.\n",
            "ost dies,'ll, remembrance heart with,I;For!\n",
            " pass himself have.\n",
            "ProvIO\n",
            " heard of my\n",
            ", you,sh,, life, well\n",
            "Prompt: 'To '\n",
            "To  a t hand times have\n",
            " youry sir couple brother?\n",
            "LIO\n",
            ", things thy, you?\n",
            " whitIO\n",
            " her, IMaster- to.\n",
            "LIO\n",
            " lord: yourew think, me,'s, henceAd yourself, friends\n",
            "ose to,T close to in pen, horrow then,', gentleman.\n",
            "ProvIO\n",
            ", she Iky serve me?\n",
            "ostENTIO\n",
            " hath lack and, women the and: he.H, you,\n",
            "Prompt: 'A '\n",
            "A  the stands the\n",
            " estate I your, woman,ie death, it the,Andarts\n",
            "Her journey father a\n",
            " you's seen have.\n",
            "Hceived, from: priest,,, you,,She your of,But\n",
            " Then not the that I does gy.\n",
            "LIO\n",
            ", fender,ance.\n",
            "L:I thou and: he ra for mine with! there,I peace unhappy my;tis fri here, thou.\n",
            " precious, for,, lord\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:   3%|▎         | 151/5000 [06:36<8:13:01,  6.10s/it, loss=6.6940]\u001b[A\n",
            "Training:   3%|▎         | 151/5000 [06:36<8:13:01,  6.10s/it, loss=6.0270]\u001b[A\n",
            "Training:   3%|▎         | 152/5000 [06:39<6:39:25,  4.94s/it, loss=6.0270]\u001b[A\n",
            "Training:   3%|▎         | 152/5000 [06:39<6:39:25,  4.94s/it, loss=5.8910]\u001b[A\n",
            "Training:   3%|▎         | 153/5000 [06:41<5:46:04,  4.28s/it, loss=5.8910]\u001b[A\n",
            "Training:   3%|▎         | 153/5000 [06:41<5:46:04,  4.28s/it, loss=5.2659]\u001b[A\n",
            "Training:   3%|▎         | 154/5000 [06:44<5:00:54,  3.73s/it, loss=5.2659]\u001b[A\n",
            "Training:   3%|▎         | 154/5000 [06:44<5:00:54,  3.73s/it, loss=6.3872]\u001b[A\n",
            "Training:   3%|▎         | 155/5000 [06:46<4:24:47,  3.28s/it, loss=6.3872]\u001b[A\n",
            "Training:   3%|▎         | 155/5000 [06:46<4:24:47,  3.28s/it, loss=6.1402]\u001b[A\n",
            "Training:   3%|▎         | 156/5000 [06:48<3:59:44,  2.97s/it, loss=6.1402]\u001b[A\n",
            "Training:   3%|▎         | 156/5000 [06:48<3:59:44,  2.97s/it, loss=5.7004]\u001b[A\n",
            "Training:   3%|▎         | 157/5000 [06:51<3:42:21,  2.75s/it, loss=5.7004]\u001b[A\n",
            "Training:   3%|▎         | 157/5000 [06:51<3:42:21,  2.75s/it, loss=5.9029]\u001b[A\n",
            "Training:   3%|▎         | 158/5000 [06:53<3:39:32,  2.72s/it, loss=5.9029]\u001b[A\n",
            "Training:   3%|▎         | 158/5000 [06:53<3:39:32,  2.72s/it, loss=5.2890]\u001b[A\n",
            "Training:   3%|▎         | 159/5000 [06:56<3:34:29,  2.66s/it, loss=5.2890]\u001b[A\n",
            "Training:   3%|▎         | 159/5000 [06:56<3:34:29,  2.66s/it, loss=5.8343]\u001b[A\n",
            "Training:   3%|▎         | 160/5000 [06:58<3:27:59,  2.58s/it, loss=5.8343]\u001b[A\n",
            "Training:   3%|▎         | 160/5000 [06:58<3:27:59,  2.58s/it, loss=5.3435]\u001b[A\n",
            "Training:   3%|▎         | 161/5000 [07:01<3:22:38,  2.51s/it, loss=5.3435]\u001b[A\n",
            "Training:   3%|▎         | 161/5000 [07:01<3:22:38,  2.51s/it, loss=6.5817]\u001b[A\n",
            "Training:   3%|▎         | 162/5000 [07:03<3:18:11,  2.46s/it, loss=6.5817]\u001b[A\n",
            "Training:   3%|▎         | 162/5000 [07:03<3:18:11,  2.46s/it, loss=6.3731]\u001b[A\n",
            "Training:   3%|▎         | 163/5000 [07:06<3:26:50,  2.57s/it, loss=6.3731]\u001b[A\n",
            "Training:   3%|▎         | 163/5000 [07:06<3:26:50,  2.57s/it, loss=6.8814]\u001b[A\n",
            "Training:   3%|▎         | 164/5000 [07:08<3:23:18,  2.52s/it, loss=6.8814]\u001b[A\n",
            "Training:   3%|▎         | 164/5000 [07:08<3:23:18,  2.52s/it, loss=6.7801]\u001b[A\n",
            "Training:   3%|▎         | 165/5000 [07:10<3:19:00,  2.47s/it, loss=6.7801]\u001b[A\n",
            "Training:   3%|▎         | 165/5000 [07:10<3:19:00,  2.47s/it, loss=6.2701]\u001b[A\n",
            "Training:   3%|▎         | 166/5000 [07:13<3:13:45,  2.40s/it, loss=6.2701]\u001b[A\n",
            "Training:   3%|▎         | 166/5000 [07:13<3:13:45,  2.40s/it, loss=5.9460]\u001b[A\n",
            "Training:   3%|▎         | 167/5000 [07:15<3:09:48,  2.36s/it, loss=5.9460]\u001b[A\n",
            "Training:   3%|▎         | 167/5000 [07:15<3:09:48,  2.36s/it, loss=7.1994]\u001b[A\n",
            "Training:   3%|▎         | 168/5000 [07:18<3:17:20,  2.45s/it, loss=7.1994]\u001b[A\n",
            "Training:   3%|▎         | 168/5000 [07:18<3:17:20,  2.45s/it, loss=5.8361]\u001b[A\n",
            "Training:   3%|▎         | 169/5000 [07:20<3:14:48,  2.42s/it, loss=5.8361]\u001b[A\n",
            "Training:   3%|▎         | 169/5000 [07:20<3:14:48,  2.42s/it, loss=6.0872]\u001b[A\n",
            "Training:   3%|▎         | 170/5000 [07:22<3:09:57,  2.36s/it, loss=6.0872]\u001b[A\n",
            "Training:   3%|▎         | 170/5000 [07:22<3:09:57,  2.36s/it, loss=6.5203]\u001b[A\n",
            "Training:   3%|▎         | 171/5000 [07:24<3:08:20,  2.34s/it, loss=6.5203]\u001b[A\n",
            "Training:   3%|▎         | 171/5000 [07:24<3:08:20,  2.34s/it, loss=5.7489]\u001b[A\n",
            "Training:   3%|▎         | 172/5000 [07:27<3:05:59,  2.31s/it, loss=5.7489]\u001b[A\n",
            "Training:   3%|▎         | 172/5000 [07:27<3:05:59,  2.31s/it, loss=6.2108]\u001b[A\n",
            "Training:   3%|▎         | 173/5000 [07:29<3:12:50,  2.40s/it, loss=6.2108]\u001b[A\n",
            "Training:   3%|▎         | 173/5000 [07:29<3:12:50,  2.40s/it, loss=5.2998]\u001b[A\n",
            "Training:   3%|▎         | 174/5000 [07:32<3:14:32,  2.42s/it, loss=5.2998]\u001b[A\n",
            "Training:   3%|▎         | 174/5000 [07:32<3:14:32,  2.42s/it, loss=5.6986]\u001b[A\n",
            "Training:   4%|▎         | 175/5000 [07:34<3:10:39,  2.37s/it, loss=5.6986]\u001b[A\n",
            "Training:   4%|▎         | 175/5000 [07:34<3:10:39,  2.37s/it, loss=5.6215]\u001b[A\n",
            "Training:   4%|▎         | 176/5000 [07:36<3:07:59,  2.34s/it, loss=5.6215]\u001b[A\n",
            "Training:   4%|▎         | 176/5000 [07:36<3:07:59,  2.34s/it, loss=6.0778]\u001b[A\n",
            "Training:   4%|▎         | 177/5000 [07:39<3:05:56,  2.31s/it, loss=6.0778]\u001b[A\n",
            "Training:   4%|▎         | 177/5000 [07:39<3:05:56,  2.31s/it, loss=6.0238]\u001b[A\n",
            "Training:   4%|▎         | 178/5000 [07:41<3:11:40,  2.38s/it, loss=6.0238]\u001b[A\n",
            "Training:   4%|▎         | 178/5000 [07:41<3:11:40,  2.38s/it, loss=4.8072]\u001b[A\n",
            "Training:   4%|▎         | 179/5000 [07:44<3:15:33,  2.43s/it, loss=4.8072]\u001b[A\n",
            "Training:   4%|▎         | 179/5000 [07:44<3:15:33,  2.43s/it, loss=5.3057]\u001b[A\n",
            "Training:   4%|▎         | 180/5000 [07:46<3:11:37,  2.39s/it, loss=5.3057]\u001b[A\n",
            "Training:   4%|▎         | 180/5000 [07:46<3:11:37,  2.39s/it, loss=4.8352]\u001b[A\n",
            "Training:   4%|▎         | 181/5000 [07:48<3:08:25,  2.35s/it, loss=4.8352]\u001b[A\n",
            "Training:   4%|▎         | 181/5000 [07:48<3:08:25,  2.35s/it, loss=5.7254]\u001b[A\n",
            "Training:   4%|▎         | 182/5000 [07:50<3:05:22,  2.31s/it, loss=5.7254]\u001b[A\n",
            "Training:   4%|▎         | 182/5000 [07:50<3:05:22,  2.31s/it, loss=6.3998]\u001b[A\n",
            "Training:   4%|▎         | 183/5000 [07:53<3:10:19,  2.37s/it, loss=6.3998]\u001b[A\n",
            "Training:   4%|▎         | 183/5000 [07:53<3:10:19,  2.37s/it, loss=6.4462]\u001b[A\n",
            "Training:   4%|▎         | 184/5000 [07:55<3:15:17,  2.43s/it, loss=6.4462]\u001b[A\n",
            "Training:   4%|▎         | 184/5000 [07:56<3:15:17,  2.43s/it, loss=5.6576]\u001b[A\n",
            "Training:   4%|▎         | 185/5000 [07:58<3:10:40,  2.38s/it, loss=5.6576]\u001b[A\n",
            "Training:   4%|▎         | 185/5000 [07:58<3:10:40,  2.38s/it, loss=6.0542]\u001b[A\n",
            "Training:   4%|▎         | 186/5000 [08:00<3:07:00,  2.33s/it, loss=6.0542]\u001b[A\n",
            "Training:   4%|▎         | 186/5000 [08:00<3:07:00,  2.33s/it, loss=4.4949]\u001b[A\n",
            "Training:   4%|▎         | 187/5000 [08:02<3:05:02,  2.31s/it, loss=4.4949]\u001b[A\n",
            "Training:   4%|▎         | 187/5000 [08:02<3:05:02,  2.31s/it, loss=6.6141]\u001b[A\n",
            "Training:   4%|▍         | 188/5000 [08:05<3:07:38,  2.34s/it, loss=6.6141]\u001b[A\n",
            "Training:   4%|▍         | 188/5000 [08:05<3:07:38,  2.34s/it, loss=5.5364]\u001b[A\n",
            "Training:   4%|▍         | 189/5000 [08:07<3:15:00,  2.43s/it, loss=5.5364]\u001b[A\n",
            "Training:   4%|▍         | 189/5000 [08:07<3:15:00,  2.43s/it, loss=5.9708]\u001b[A\n",
            "Training:   4%|▍         | 190/5000 [08:10<3:11:12,  2.39s/it, loss=5.9708]\u001b[A\n",
            "Training:   4%|▍         | 190/5000 [08:10<3:11:12,  2.39s/it, loss=6.4091]\u001b[A\n",
            "Training:   4%|▍         | 191/5000 [08:12<3:07:51,  2.34s/it, loss=6.4091]\u001b[A\n",
            "Training:   4%|▍         | 191/5000 [08:12<3:07:51,  2.34s/it, loss=6.5023]\u001b[A\n",
            "Training:   4%|▍         | 192/5000 [08:14<3:05:11,  2.31s/it, loss=6.5023]\u001b[A\n",
            "Training:   4%|▍         | 192/5000 [08:14<3:05:11,  2.31s/it, loss=6.4780]\u001b[A\n",
            "Training:   4%|▍         | 193/5000 [08:16<3:05:12,  2.31s/it, loss=6.4780]\u001b[A\n",
            "Training:   4%|▍         | 193/5000 [08:16<3:05:12,  2.31s/it, loss=6.6198]\u001b[A\n",
            "Training:   4%|▍         | 194/5000 [08:19<3:15:14,  2.44s/it, loss=6.6198]\u001b[A\n",
            "Training:   4%|▍         | 194/5000 [08:19<3:15:14,  2.44s/it, loss=6.3090]\u001b[A\n",
            "Training:   4%|▍         | 195/5000 [08:21<3:10:18,  2.38s/it, loss=6.3090]\u001b[A\n",
            "Training:   4%|▍         | 195/5000 [08:21<3:10:18,  2.38s/it, loss=6.1818]\u001b[A\n",
            "Training:   4%|▍         | 196/5000 [08:24<3:08:02,  2.35s/it, loss=6.1818]\u001b[A\n",
            "Training:   4%|▍         | 196/5000 [08:24<3:08:02,  2.35s/it, loss=6.4015]\u001b[A\n",
            "Training:   4%|▍         | 197/5000 [08:26<3:05:15,  2.31s/it, loss=6.4015]\u001b[A\n",
            "Training:   4%|▍         | 197/5000 [08:26<3:05:15,  2.31s/it, loss=5.3227]\u001b[A\n",
            "Training:   4%|▍         | 198/5000 [08:28<3:03:44,  2.30s/it, loss=5.3227]\u001b[A\n",
            "Training:   4%|▍         | 198/5000 [08:28<3:03:44,  2.30s/it, loss=5.6875]\u001b[A\n",
            "Training:   4%|▍         | 199/5000 [08:31<3:16:15,  2.45s/it, loss=5.6875]\u001b[A\n",
            "Training:   4%|▍         | 199/5000 [08:31<3:16:15,  2.45s/it, loss=5.2136]\u001b[A\n",
            "Training:   4%|▍         | 200/5000 [08:33<3:11:16,  2.39s/it, loss=5.2136]\u001b[A\n",
            "Training:   4%|▍         | 200/5000 [08:33<3:11:16,  2.39s/it, loss=5.3279]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 200 ---\n",
            "Prompt: 'The '\n",
            "The  and run my, the; there\n",
            ",, Gloucester thyies life and the son\n",
            "ath toler, my of long and by.\n",
            "GUC,, himself a and to,!!O\n",
            "LO heaven, not not shall his, hate, have, ' to, may was's mistrust him\n",
            " my time my that whom you, have by crown, it my!\n",
            "GET\n",
            "UCER\n",
            "UC:No,,,, can be, heir my of; I grace\n",
            "Prompt: 'In '\n",
            "In  me he, it hands\n",
            "orrow, thy to the queeniles doom\n",
            " thou mild buter the,,,-, it\n",
            " my where the to battle answer is, shall thees\n",
            " for- gods and up send a of,, I my?\n",
            "GUC shalt thee\n",
            ", you be my with, ins.\n",
            "Secondsemb pure; '!' we;,And it in that sheuck more,, you for wrong\n",
            " he master and die the and, I, thou\n",
            "Prompt: 'To '\n",
            "To , my and; fee, I\n",
            " you live to grave nor for! by truth they, thou, I you is me\n",
            " was to Edwardess a to it the thee;W,As is, with enough and\n",
            " my, many, ancient the, my before murd:I many her, so my safe nurse arms children!\n",
            "Gman lords begins\n",
            ", MAR to were slainest a,our here\n",
            " have in faint'd modest, hath thee!MyG\n",
            "LO placed, my\n",
            "Prompt: 'A '\n",
            "A \n",
            "ESTESS should to and, you, you\n",
            " al so peace me but lamp, any be poor\n",
            " that for no our; I the's, will deny?\n",
            "GLOOL MAR:Why the my!\n",
            "QUE shall one deserves be bigger,!\n",
            "GUCLOUC:D Duke!\n",
            "R the!\n",
            "LO, I gone, do frame the, thoughtant\n",
            "o I unfold defend you me, had thy, they, my is,, you,; I of\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:   4%|▍         | 201/5000 [08:48<8:09:23,  6.12s/it, loss=5.3279]\u001b[A\n",
            "Training:   4%|▍         | 201/5000 [08:48<8:09:23,  6.12s/it, loss=6.0871]\u001b[A\n",
            "Training:   4%|▍         | 202/5000 [08:50<6:36:31,  4.96s/it, loss=6.0871]\u001b[A\n",
            "Training:   4%|▍         | 202/5000 [08:50<6:36:31,  4.96s/it, loss=5.3539]\u001b[A\n",
            "Training:   4%|▍         | 203/5000 [08:53<5:34:00,  4.18s/it, loss=5.3539]\u001b[A\n",
            "Training:   4%|▍         | 203/5000 [08:53<5:34:00,  4.18s/it, loss=5.9295]\u001b[A\n",
            "Training:   4%|▍         | 204/5000 [08:55<4:58:44,  3.74s/it, loss=5.9295]\u001b[A\n",
            "Training:   4%|▍         | 204/5000 [08:55<4:58:44,  3.74s/it, loss=5.8568]\u001b[A\n",
            "Training:   4%|▍         | 205/5000 [08:58<4:22:51,  3.29s/it, loss=5.8568]\u001b[A\n",
            "Training:   4%|▍         | 205/5000 [08:58<4:22:51,  3.29s/it, loss=6.3968]\u001b[A\n",
            "Training:   4%|▍         | 206/5000 [09:00<3:57:17,  2.97s/it, loss=6.3968]\u001b[A\n",
            "Training:   4%|▍         | 206/5000 [09:00<3:57:17,  2.97s/it, loss=5.2535]\u001b[A\n",
            "Training:   4%|▍         | 207/5000 [09:02<3:39:56,  2.75s/it, loss=5.2535]\u001b[A\n",
            "Training:   4%|▍         | 207/5000 [09:02<3:39:56,  2.75s/it, loss=5.1096]\u001b[A\n",
            "Training:   4%|▍         | 208/5000 [09:04<3:28:49,  2.61s/it, loss=5.1096]\u001b[A\n",
            "Training:   4%|▍         | 208/5000 [09:04<3:28:49,  2.61s/it, loss=6.1970]\u001b[A\n",
            "Training:   4%|▍         | 209/5000 [09:07<3:32:06,  2.66s/it, loss=6.1970]\u001b[A\n",
            "Training:   4%|▍         | 209/5000 [09:07<3:32:06,  2.66s/it, loss=6.3690]\u001b[A\n",
            "Training:   4%|▍         | 210/5000 [09:09<3:22:22,  2.53s/it, loss=6.3690]\u001b[A\n",
            "Training:   4%|▍         | 210/5000 [09:09<3:22:22,  2.53s/it, loss=4.6696]\u001b[A\n",
            "Training:   4%|▍         | 211/5000 [09:12<3:16:22,  2.46s/it, loss=4.6696]\u001b[A\n",
            "Training:   4%|▍         | 211/5000 [09:12<3:16:22,  2.46s/it, loss=5.8045]\u001b[A\n",
            "Training:   4%|▍         | 212/5000 [09:14<3:11:16,  2.40s/it, loss=5.8045]\u001b[A\n",
            "Training:   4%|▍         | 212/5000 [09:14<3:11:16,  2.40s/it, loss=5.8349]\u001b[A\n",
            "Training:   4%|▍         | 213/5000 [09:16<3:07:12,  2.35s/it, loss=5.8349]\u001b[A\n",
            "Training:   4%|▍         | 213/5000 [09:16<3:07:12,  2.35s/it, loss=6.1616]\u001b[A\n",
            "Training:   4%|▍         | 214/5000 [09:19<3:18:43,  2.49s/it, loss=6.1616]\u001b[A\n",
            "Training:   4%|▍         | 214/5000 [09:19<3:18:43,  2.49s/it, loss=6.0289]\u001b[A\n",
            "Training:   4%|▍         | 215/5000 [09:21<3:12:18,  2.41s/it, loss=6.0289]\u001b[A\n",
            "Training:   4%|▍         | 215/5000 [09:21<3:12:18,  2.41s/it, loss=5.9520]\u001b[A\n",
            "Training:   4%|▍         | 216/5000 [09:23<3:08:56,  2.37s/it, loss=5.9520]\u001b[A\n",
            "Training:   4%|▍         | 216/5000 [09:23<3:08:56,  2.37s/it, loss=5.9488]\u001b[A\n",
            "Training:   4%|▍         | 217/5000 [09:26<3:06:38,  2.34s/it, loss=5.9488]\u001b[A\n",
            "Training:   4%|▍         | 217/5000 [09:26<3:06:38,  2.34s/it, loss=5.5097]\u001b[A\n",
            "Training:   4%|▍         | 218/5000 [09:28<3:04:46,  2.32s/it, loss=5.5097]\u001b[A\n",
            "Training:   4%|▍         | 218/5000 [09:28<3:04:46,  2.32s/it, loss=5.8208]\u001b[A\n",
            "Training:   4%|▍         | 219/5000 [09:31<3:16:24,  2.46s/it, loss=5.8208]\u001b[A\n",
            "Training:   4%|▍         | 219/5000 [09:31<3:16:24,  2.46s/it, loss=6.4009]\u001b[A\n",
            "Training:   4%|▍         | 220/5000 [09:33<3:11:52,  2.41s/it, loss=6.4009]\u001b[A\n",
            "Training:   4%|▍         | 220/5000 [09:33<3:11:52,  2.41s/it, loss=6.2831]\u001b[A\n",
            "Training:   4%|▍         | 221/5000 [09:35<3:07:38,  2.36s/it, loss=6.2831]\u001b[A\n",
            "Training:   4%|▍         | 221/5000 [09:35<3:07:38,  2.36s/it, loss=5.8294]\u001b[A\n",
            "Training:   4%|▍         | 222/5000 [09:37<3:04:44,  2.32s/it, loss=5.8294]\u001b[A\n",
            "Training:   4%|▍         | 222/5000 [09:37<3:04:44,  2.32s/it, loss=5.6196]\u001b[A\n",
            "Training:   4%|▍         | 223/5000 [09:40<3:03:04,  2.30s/it, loss=5.6196]\u001b[A\n",
            "Training:   4%|▍         | 223/5000 [09:40<3:03:04,  2.30s/it, loss=5.4851]\u001b[A\n",
            "Training:   4%|▍         | 224/5000 [09:43<3:16:35,  2.47s/it, loss=5.4851]\u001b[A\n",
            "Training:   4%|▍         | 224/5000 [09:43<3:16:35,  2.47s/it, loss=5.0198]\u001b[A\n",
            "Training:   4%|▍         | 225/5000 [09:45<3:11:32,  2.41s/it, loss=5.0198]\u001b[A\n",
            "Training:   4%|▍         | 225/5000 [09:45<3:11:32,  2.41s/it, loss=5.5144]\u001b[A\n",
            "Training:   5%|▍         | 226/5000 [09:47<3:08:03,  2.36s/it, loss=5.5144]\u001b[A\n",
            "Training:   5%|▍         | 226/5000 [09:47<3:08:03,  2.36s/it, loss=5.7003]\u001b[A\n",
            "Training:   5%|▍         | 227/5000 [09:49<3:05:07,  2.33s/it, loss=5.7003]\u001b[A\n",
            "Training:   5%|▍         | 227/5000 [09:49<3:05:07,  2.33s/it, loss=6.2666]\u001b[A\n",
            "Training:   5%|▍         | 228/5000 [09:52<3:02:51,  2.30s/it, loss=6.2666]\u001b[A\n",
            "Training:   5%|▍         | 228/5000 [09:52<3:02:51,  2.30s/it, loss=5.0750]\u001b[A\n",
            "Training:   5%|▍         | 229/5000 [09:54<3:16:39,  2.47s/it, loss=5.0750]\u001b[A\n",
            "Training:   5%|▍         | 229/5000 [09:54<3:16:39,  2.47s/it, loss=5.8102]\u001b[A\n",
            "Training:   5%|▍         | 230/5000 [09:57<3:11:21,  2.41s/it, loss=5.8102]\u001b[A\n",
            "Training:   5%|▍         | 230/5000 [09:57<3:11:21,  2.41s/it, loss=4.8554]\u001b[A\n",
            "Training:   5%|▍         | 231/5000 [09:59<3:07:29,  2.36s/it, loss=4.8554]\u001b[A\n",
            "Training:   5%|▍         | 231/5000 [09:59<3:07:29,  2.36s/it, loss=6.0258]\u001b[A\n",
            "Training:   5%|▍         | 232/5000 [10:01<3:04:28,  2.32s/it, loss=6.0258]\u001b[A\n",
            "Training:   5%|▍         | 232/5000 [10:01<3:04:28,  2.32s/it, loss=6.4755]\u001b[A\n",
            "Training:   5%|▍         | 233/5000 [10:03<3:02:37,  2.30s/it, loss=6.4755]\u001b[A\n",
            "Training:   5%|▍         | 233/5000 [10:03<3:02:37,  2.30s/it, loss=5.4129]\u001b[A\n",
            "Training:   5%|▍         | 234/5000 [10:06<3:13:02,  2.43s/it, loss=5.4129]\u001b[A\n",
            "Training:   5%|▍         | 234/5000 [10:06<3:13:02,  2.43s/it, loss=5.3991]\u001b[A\n",
            "Training:   5%|▍         | 235/5000 [10:08<3:09:28,  2.39s/it, loss=5.3991]\u001b[A\n",
            "Training:   5%|▍         | 235/5000 [10:08<3:09:28,  2.39s/it, loss=5.7541]\u001b[A\n",
            "Training:   5%|▍         | 236/5000 [10:11<3:06:14,  2.35s/it, loss=5.7541]\u001b[A\n",
            "Training:   5%|▍         | 236/5000 [10:11<3:06:14,  2.35s/it, loss=5.9056]\u001b[A\n",
            "Training:   5%|▍         | 237/5000 [10:13<3:04:03,  2.32s/it, loss=5.9056]\u001b[A\n",
            "Training:   5%|▍         | 237/5000 [10:13<3:04:03,  2.32s/it, loss=5.9506]\u001b[A\n",
            "Training:   5%|▍         | 238/5000 [10:15<3:02:49,  2.30s/it, loss=5.9506]\u001b[A\n",
            "Training:   5%|▍         | 238/5000 [10:15<3:02:49,  2.30s/it, loss=5.4329]\u001b[A\n",
            "Training:   5%|▍         | 239/5000 [10:18<3:11:47,  2.42s/it, loss=5.4329]\u001b[A\n",
            "Training:   5%|▍         | 239/5000 [10:18<3:11:47,  2.42s/it, loss=5.2993]\u001b[A\n",
            "Training:   5%|▍         | 240/5000 [10:20<3:11:15,  2.41s/it, loss=5.2993]\u001b[A\n",
            "Training:   5%|▍         | 240/5000 [10:20<3:11:15,  2.41s/it, loss=5.4217]\u001b[A\n",
            "Training:   5%|▍         | 241/5000 [10:23<3:07:23,  2.36s/it, loss=5.4217]\u001b[A\n",
            "Training:   5%|▍         | 241/5000 [10:23<3:07:23,  2.36s/it, loss=5.6135]\u001b[A\n",
            "Training:   5%|▍         | 242/5000 [10:25<3:06:03,  2.35s/it, loss=5.6135]\u001b[A\n",
            "Training:   5%|▍         | 242/5000 [10:25<3:06:03,  2.35s/it, loss=6.0284]\u001b[A\n",
            "Training:   5%|▍         | 243/5000 [10:27<3:04:57,  2.33s/it, loss=6.0284]\u001b[A\n",
            "Training:   5%|▍         | 243/5000 [10:27<3:04:57,  2.33s/it, loss=5.9010]\u001b[A\n",
            "Training:   5%|▍         | 244/5000 [10:30<3:12:59,  2.43s/it, loss=5.9010]\u001b[A\n",
            "Training:   5%|▍         | 244/5000 [10:30<3:12:59,  2.43s/it, loss=5.3778]\u001b[A\n",
            "Training:   5%|▍         | 245/5000 [10:32<3:13:12,  2.44s/it, loss=5.3778]\u001b[A\n",
            "Training:   5%|▍         | 245/5000 [10:32<3:13:12,  2.44s/it, loss=5.5693]\u001b[A\n",
            "Training:   5%|▍         | 246/5000 [10:35<3:09:06,  2.39s/it, loss=5.5693]\u001b[A\n",
            "Training:   5%|▍         | 246/5000 [10:35<3:09:06,  2.39s/it, loss=5.3931]\u001b[A\n",
            "Training:   5%|▍         | 247/5000 [10:37<3:05:45,  2.35s/it, loss=5.3931]\u001b[A\n",
            "Training:   5%|▍         | 247/5000 [10:37<3:05:45,  2.35s/it, loss=4.8048]\u001b[A\n",
            "Training:   5%|▍         | 248/5000 [10:39<3:03:15,  2.31s/it, loss=4.8048]\u001b[A\n",
            "Training:   5%|▍         | 248/5000 [10:39<3:03:15,  2.31s/it, loss=5.2192]\u001b[A\n",
            "Training:   5%|▍         | 249/5000 [10:42<3:09:09,  2.39s/it, loss=5.2192]\u001b[A\n",
            "Training:   5%|▍         | 249/5000 [10:42<3:09:09,  2.39s/it, loss=5.9067]\u001b[A\n",
            "Training:   5%|▌         | 250/5000 [10:44<3:12:41,  2.43s/it, loss=5.9067]\u001b[A\n",
            "Training:   5%|▌         | 250/5000 [10:44<3:12:41,  2.43s/it, loss=5.7543]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 250 ---\n",
            "Prompt: 'The '\n",
            "The  my.\n",
            "JI it to, thou old lights\n",
            ",'ll to blood not, come the, isats.'\n",
            " is you so any come turn I my to's,For the love\n",
            "ere; mere's to is the that you will, whatost the,?\n",
            " the of?,is; fat, best and do with's.M will.\n",
            ", art, I no, for be shall love\n",
            ",At my love do to as I I Ty;\n",
            "Prompt: 'In '\n",
            "In ET\n",
            " word thy, have,'ll he justice cannot\n",
            " this to love, breath passage external.\n",
            " he a, an out what be\n",
            "'ll love not! thou highch, the,!\n",
            ", thouir this poison,, pray for not sir\n",
            " what act and;S her\n",
            ", my, merow my of; love own not find do hand\n",
            " fret thy Edward.\n",
            "J,,; kill young is she I me\n",
            " her her that sun you a be be but\n",
            "Prompt: 'To '\n",
            "To  so his;W: what Ben;Which,AndThis,Where white are\n",
            " the of she be, me be wedding\n",
            "ath of more itio thee withble\n",
            " hast of thou plague and sweet that, all in;And I.\n",
            " that thou wit, we's stay the, now,And\n",
            ",tis: may you,Y, my,- ago I vanity,And fool\n",
            " hath are.Th you her to, verycl withh,, I her, to\n",
            "\n",
            "Prompt: 'A '\n",
            "A  a to my, would and a,For,Which\n",
            " asoth am by the is Romeo are Juliet:I\n",
            " it I d Juliet for this make\n",
            " thou was how!\n",
            ", thou it one' you but, shall thy,And, my,It this liv I the of!\n",
            ",ou will I;' those me my, the, he not it\n",
            " you is the with to again my, my,Go,\n",
            " had upon,, he action love shall gone\n",
            " is\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:   5%|▌         | 251/5000 [10:59<8:03:57,  6.11s/it, loss=5.7543]\u001b[A\n",
            "Training:   5%|▌         | 251/5000 [10:59<8:03:57,  6.11s/it, loss=5.1694]\u001b[A\n",
            "Training:   5%|▌         | 252/5000 [11:01<6:31:54,  4.95s/it, loss=5.1694]\u001b[A\n",
            "Training:   5%|▌         | 252/5000 [11:01<6:31:54,  4.95s/it, loss=5.2101]\u001b[A\n",
            "Training:   5%|▌         | 253/5000 [11:03<5:27:39,  4.14s/it, loss=5.2101]\u001b[A\n",
            "Training:   5%|▌         | 253/5000 [11:03<5:27:39,  4.14s/it, loss=5.8063]\u001b[A\n",
            "Training:   5%|▌         | 254/5000 [11:06<4:53:16,  3.71s/it, loss=5.8063]\u001b[A\n",
            "Training:   5%|▌         | 254/5000 [11:06<4:53:16,  3.71s/it, loss=6.3138]\u001b[A\n",
            "Training:   5%|▌         | 255/5000 [11:08<4:21:37,  3.31s/it, loss=6.3138]\u001b[A\n",
            "Training:   5%|▌         | 255/5000 [11:08<4:21:37,  3.31s/it, loss=5.7742]\u001b[A\n",
            "Training:   5%|▌         | 256/5000 [11:11<3:56:18,  2.99s/it, loss=5.7742]\u001b[A\n",
            "Training:   5%|▌         | 256/5000 [11:11<3:56:18,  2.99s/it, loss=6.2406]\u001b[A\n",
            "Training:   5%|▌         | 257/5000 [11:13<3:38:53,  2.77s/it, loss=6.2406]\u001b[A\n",
            "Training:   5%|▌         | 257/5000 [11:13<3:38:53,  2.77s/it, loss=6.4101]\u001b[A\n",
            "Training:   5%|▌         | 258/5000 [11:15<3:26:01,  2.61s/it, loss=6.4101]\u001b[A\n",
            "Training:   5%|▌         | 258/5000 [11:15<3:26:01,  2.61s/it, loss=4.7552]\u001b[A\n",
            "Training:   5%|▌         | 259/5000 [11:18<3:25:45,  2.60s/it, loss=4.7552]\u001b[A\n",
            "Training:   5%|▌         | 259/5000 [11:18<3:25:45,  2.60s/it, loss=5.6268]\u001b[A\n",
            "Training:   5%|▌         | 260/5000 [11:20<3:22:42,  2.57s/it, loss=5.6268]\u001b[A\n",
            "Training:   5%|▌         | 260/5000 [11:20<3:22:42,  2.57s/it, loss=5.8682]\u001b[A\n",
            "Training:   5%|▌         | 261/5000 [11:22<3:14:50,  2.47s/it, loss=5.8682]\u001b[A\n",
            "Training:   5%|▌         | 261/5000 [11:22<3:14:50,  2.47s/it, loss=5.5485]\u001b[A\n",
            "Training:   5%|▌         | 262/5000 [11:25<3:09:33,  2.40s/it, loss=5.5485]\u001b[A\n",
            "Training:   5%|▌         | 262/5000 [11:25<3:09:33,  2.40s/it, loss=5.0523]\u001b[A\n",
            "Training:   5%|▌         | 263/5000 [11:27<3:06:31,  2.36s/it, loss=5.0523]\u001b[A\n",
            "Training:   5%|▌         | 263/5000 [11:27<3:06:31,  2.36s/it, loss=5.6353]\u001b[A\n",
            "Training:   5%|▌         | 264/5000 [11:30<3:11:35,  2.43s/it, loss=5.6353]\u001b[A\n",
            "Training:   5%|▌         | 264/5000 [11:30<3:11:35,  2.43s/it, loss=6.1166]\u001b[A\n",
            "Training:   5%|▌         | 265/5000 [11:32<3:13:59,  2.46s/it, loss=6.1166]\u001b[A\n",
            "Training:   5%|▌         | 265/5000 [11:32<3:13:59,  2.46s/it, loss=5.4107]\u001b[A\n",
            "Training:   5%|▌         | 266/5000 [11:34<3:08:43,  2.39s/it, loss=5.4107]\u001b[A\n",
            "Training:   5%|▌         | 266/5000 [11:34<3:08:43,  2.39s/it, loss=5.5753]\u001b[A\n",
            "Training:   5%|▌         | 267/5000 [11:37<3:04:37,  2.34s/it, loss=5.5753]\u001b[A\n",
            "Training:   5%|▌         | 267/5000 [11:37<3:04:37,  2.34s/it, loss=5.3446]\u001b[A\n",
            "Training:   5%|▌         | 268/5000 [11:39<3:03:32,  2.33s/it, loss=5.3446]\u001b[A\n",
            "Training:   5%|▌         | 268/5000 [11:39<3:03:32,  2.33s/it, loss=4.8216]\u001b[A\n",
            "Training:   5%|▌         | 269/5000 [11:41<3:06:45,  2.37s/it, loss=4.8216]\u001b[A\n",
            "Training:   5%|▌         | 269/5000 [11:41<3:06:45,  2.37s/it, loss=4.4380]\u001b[A\n",
            "Training:   5%|▌         | 270/5000 [11:44<3:11:55,  2.43s/it, loss=4.4380]\u001b[A\n",
            "Training:   5%|▌         | 270/5000 [11:44<3:11:55,  2.43s/it, loss=5.5604]\u001b[A\n",
            "Training:   5%|▌         | 271/5000 [11:46<3:07:24,  2.38s/it, loss=5.5604]\u001b[A\n",
            "Training:   5%|▌         | 271/5000 [11:46<3:07:24,  2.38s/it, loss=4.8564]\u001b[A\n",
            "Training:   5%|▌         | 272/5000 [11:48<3:04:54,  2.35s/it, loss=4.8564]\u001b[A\n",
            "Training:   5%|▌         | 272/5000 [11:48<3:04:54,  2.35s/it, loss=6.4671]\u001b[A\n",
            "Training:   5%|▌         | 273/5000 [11:51<3:02:13,  2.31s/it, loss=6.4671]\u001b[A\n",
            "Training:   5%|▌         | 273/5000 [11:51<3:02:13,  2.31s/it, loss=6.8565]\u001b[A\n",
            "Training:   5%|▌         | 274/5000 [11:53<3:04:16,  2.34s/it, loss=6.8565]\u001b[A\n",
            "Training:   5%|▌         | 274/5000 [11:53<3:04:16,  2.34s/it, loss=6.3847]\u001b[A\n",
            "Training:   6%|▌         | 275/5000 [11:56<3:11:27,  2.43s/it, loss=6.3847]\u001b[A\n",
            "Training:   6%|▌         | 275/5000 [11:56<3:11:27,  2.43s/it, loss=6.0317]\u001b[A\n",
            "Training:   6%|▌         | 276/5000 [11:58<3:07:32,  2.38s/it, loss=6.0317]\u001b[A\n",
            "Training:   6%|▌         | 276/5000 [11:58<3:07:32,  2.38s/it, loss=5.5450]\u001b[A\n",
            "Training:   6%|▌         | 277/5000 [12:00<3:04:29,  2.34s/it, loss=5.5450]\u001b[A\n",
            "Training:   6%|▌         | 277/5000 [12:00<3:04:29,  2.34s/it, loss=6.1426]\u001b[A\n",
            "Training:   6%|▌         | 278/5000 [12:02<3:01:55,  2.31s/it, loss=6.1426]\u001b[A\n",
            "Training:   6%|▌         | 278/5000 [12:02<3:01:55,  2.31s/it, loss=6.2475]\u001b[A\n",
            "Training:   6%|▌         | 279/5000 [12:05<3:02:50,  2.32s/it, loss=6.2475]\u001b[A\n",
            "Training:   6%|▌         | 279/5000 [12:05<3:02:50,  2.32s/it, loss=6.5068]\u001b[A\n",
            "Training:   6%|▌         | 280/5000 [12:07<3:11:31,  2.43s/it, loss=6.5068]\u001b[A\n",
            "Training:   6%|▌         | 280/5000 [12:08<3:11:31,  2.43s/it, loss=6.0752]\u001b[A\n",
            "Training:   6%|▌         | 281/5000 [12:10<3:07:16,  2.38s/it, loss=6.0752]\u001b[A\n",
            "Training:   6%|▌         | 281/5000 [12:10<3:07:16,  2.38s/it, loss=6.1793]\u001b[A\n",
            "Training:   6%|▌         | 282/5000 [12:12<3:04:17,  2.34s/it, loss=6.1793]\u001b[A\n",
            "Training:   6%|▌         | 282/5000 [12:12<3:04:17,  2.34s/it, loss=6.5686]\u001b[A\n",
            "Training:   6%|▌         | 283/5000 [12:14<3:01:26,  2.31s/it, loss=6.5686]\u001b[A\n",
            "Training:   6%|▌         | 283/5000 [12:14<3:01:26,  2.31s/it, loss=5.8383]\u001b[A\n",
            "Training:   6%|▌         | 284/5000 [12:16<2:58:44,  2.27s/it, loss=5.8383]\u001b[A\n",
            "Training:   6%|▌         | 284/5000 [12:16<2:58:44,  2.27s/it, loss=6.2347]\u001b[A\n",
            "Training:   6%|▌         | 285/5000 [12:19<3:11:19,  2.43s/it, loss=6.2347]\u001b[A\n",
            "Training:   6%|▌         | 285/5000 [12:19<3:11:19,  2.43s/it, loss=5.4572]\u001b[A\n",
            "Training:   6%|▌         | 286/5000 [12:21<3:07:07,  2.38s/it, loss=5.4572]\u001b[A\n",
            "Training:   6%|▌         | 286/5000 [12:22<3:07:07,  2.38s/it, loss=6.0745]\u001b[A\n",
            "Training:   6%|▌         | 287/5000 [12:24<3:02:59,  2.33s/it, loss=6.0745]\u001b[A\n",
            "Training:   6%|▌         | 287/5000 [12:24<3:02:59,  2.33s/it, loss=5.8825]\u001b[A\n",
            "Training:   6%|▌         | 288/5000 [12:26<3:00:44,  2.30s/it, loss=5.8825]\u001b[A\n",
            "Training:   6%|▌         | 288/5000 [12:26<3:00:44,  2.30s/it, loss=5.9231]\u001b[A\n",
            "Training:   6%|▌         | 289/5000 [12:28<3:00:05,  2.29s/it, loss=5.9231]\u001b[A\n",
            "Training:   6%|▌         | 289/5000 [12:28<3:00:05,  2.29s/it, loss=5.9932]\u001b[A\n",
            "Training:   6%|▌         | 290/5000 [12:31<3:13:25,  2.46s/it, loss=5.9932]\u001b[A\n",
            "Training:   6%|▌         | 290/5000 [12:31<3:13:25,  2.46s/it, loss=6.6177]\u001b[A\n",
            "Training:   6%|▌         | 291/5000 [12:33<3:08:27,  2.40s/it, loss=6.6177]\u001b[A\n",
            "Training:   6%|▌         | 291/5000 [12:33<3:08:27,  2.40s/it, loss=5.5503]\u001b[A\n",
            "Training:   6%|▌         | 292/5000 [12:36<3:04:37,  2.35s/it, loss=5.5503]\u001b[A\n",
            "Training:   6%|▌         | 292/5000 [12:36<3:04:37,  2.35s/it, loss=5.2199]\u001b[A\n",
            "Training:   6%|▌         | 293/5000 [12:38<3:02:08,  2.32s/it, loss=5.2199]\u001b[A\n",
            "Training:   6%|▌         | 293/5000 [12:38<3:02:08,  2.32s/it, loss=5.2976]\u001b[A\n",
            "Training:   6%|▌         | 294/5000 [12:40<3:00:19,  2.30s/it, loss=5.2976]\u001b[A\n",
            "Training:   6%|▌         | 294/5000 [12:40<3:00:19,  2.30s/it, loss=5.6378]\u001b[A\n",
            "Training:   6%|▌         | 295/5000 [12:43<3:13:24,  2.47s/it, loss=5.6378]\u001b[A\n",
            "Training:   6%|▌         | 295/5000 [12:43<3:13:24,  2.47s/it, loss=5.5159]\u001b[A\n",
            "Training:   6%|▌         | 296/5000 [12:45<3:08:50,  2.41s/it, loss=5.5159]\u001b[A\n",
            "Training:   6%|▌         | 296/5000 [12:45<3:08:50,  2.41s/it, loss=5.9096]\u001b[A\n",
            "Training:   6%|▌         | 297/5000 [12:47<3:04:42,  2.36s/it, loss=5.9096]\u001b[A\n",
            "Training:   6%|▌         | 297/5000 [12:47<3:04:42,  2.36s/it, loss=6.4911]\u001b[A\n",
            "Training:   6%|▌         | 298/5000 [12:50<3:01:54,  2.32s/it, loss=6.4911]\u001b[A\n",
            "Training:   6%|▌         | 298/5000 [12:50<3:01:54,  2.32s/it, loss=5.2836]\u001b[A\n",
            "Training:   6%|▌         | 299/5000 [12:52<3:00:45,  2.31s/it, loss=5.2836]\u001b[A\n",
            "Training:   6%|▌         | 299/5000 [12:52<3:00:45,  2.31s/it, loss=5.8061]\u001b[A\n",
            "Training:   6%|▌         | 300/5000 [12:55<3:12:39,  2.46s/it, loss=5.8061]\u001b[A\n",
            "Training:   6%|▌         | 300/5000 [12:55<3:12:39,  2.46s/it, loss=5.0347]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 300 ---\n",
            "Prompt: 'The '\n",
            "The .\n",
            "L, you you this\n",
            "MAR:She my's to?\n",
            "FLman\n",
            "EL:We many?\n",
            "ABEL:Here\n",
            ", how the, you joy a of stone\n",
            "C safe flesh wear what like?\n",
            "AB eyes that her am?\n",
            "CAM\n",
            "AL:I? that little?\n",
            "EL:\n",
            " sought furnish the be,,, to you theest I that.\n",
            "ELIO\n",
            "DLA\n",
            "EL:\n",
            "EL:You good would the, was\n",
            "Prompt: 'In '\n",
            "In LAEL:Yes?\n",
            "CinerEL:Your when in.\n",
            "CeOL:But thisIS not driven; sw Iis life\n",
            "C me hour revolman\n",
            "A you dead of, you world if you,n\n",
            " would you you as is stand the?\n",
            "SecondYC:I thing\n",
            " read, my,; that the of.\n",
            "EL:\n",
            ", his,?\n",
            "ALINA\n",
            "ISEL:A\n",
            "AELno with,A it\n",
            " let to?\n",
            "Prompt: 'To '\n",
            "To  not.\n",
            "CpherdIO\n",
            "OL:If, the of, not her.\n",
            " ashamed as dead\n",
            " of is?\n",
            "ONAIO\n",
            " you the wayoth?\n",
            "ISEL:\n",
            "?\n",
            ":Al?\n",
            " Thou,, to?\n",
            "DEL:I it?\n",
            "L kingBRIO\n",
            " neither make?\n",
            "EL then.But business thinkAd to; but my that notione your worthy; man.\n",
            "AL:O\n",
            "pherd\n",
            "AB word:Theream\n",
            "Prompt: 'A '\n",
            "A  we.\n",
            "EL:That follow broken I tost\n",
            " wasw's you to, the. ups.\n",
            "CEL:I,?\n",
            "CEL:The an'smanBut you.\n",
            "UTOLELman\n",
            "LUS\n",
            "CAM:I be for.\n",
            "EL:If give do?ce; you i are law Think you?\n",
            "ost I, is the of;And,, is?\n",
            "EL I speakink?,, were saint e that?\n",
            "A\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:   6%|▌         | 301/5000 [13:09<7:57:36,  6.10s/it, loss=5.0347]\u001b[A\n",
            "Training:   6%|▌         | 301/5000 [13:09<7:57:36,  6.10s/it, loss=5.5418]\u001b[A\n",
            "Training:   6%|▌         | 302/5000 [13:12<6:27:00,  4.94s/it, loss=5.5418]\u001b[A\n",
            "Training:   6%|▌         | 302/5000 [13:12<6:27:00,  4.94s/it, loss=5.0062]\u001b[A\n",
            "Training:   6%|▌         | 303/5000 [13:14<5:23:28,  4.13s/it, loss=5.0062]\u001b[A\n",
            "Training:   6%|▌         | 303/5000 [13:14<5:23:28,  4.13s/it, loss=4.4023]\u001b[A\n",
            "Training:   6%|▌         | 304/5000 [13:16<4:39:04,  3.57s/it, loss=4.4023]\u001b[A\n",
            "Training:   6%|▌         | 304/5000 [13:16<4:39:04,  3.57s/it, loss=5.3205]\u001b[A\n",
            "Training:   6%|▌         | 305/5000 [13:19<4:21:31,  3.34s/it, loss=5.3205]\u001b[A\n",
            "Training:   6%|▌         | 305/5000 [13:19<4:21:31,  3.34s/it, loss=5.0200]\u001b[A\n",
            "Training:   6%|▌         | 306/5000 [13:21<3:55:06,  3.01s/it, loss=5.0200]\u001b[A\n",
            "Training:   6%|▌         | 306/5000 [13:21<3:55:06,  3.01s/it, loss=5.7855]\u001b[A\n",
            "Training:   6%|▌         | 307/5000 [13:23<3:37:07,  2.78s/it, loss=5.7855]\u001b[A\n",
            "Training:   6%|▌         | 307/5000 [13:23<3:37:07,  2.78s/it, loss=6.0935]\u001b[A\n",
            "Training:   6%|▌         | 308/5000 [13:26<3:25:07,  2.62s/it, loss=6.0935]\u001b[A\n",
            "Training:   6%|▌         | 308/5000 [13:26<3:25:07,  2.62s/it, loss=5.9701]\u001b[A\n",
            "Training:   6%|▌         | 309/5000 [13:28<3:15:57,  2.51s/it, loss=5.9701]\u001b[A\n",
            "Training:   6%|▌         | 309/5000 [13:28<3:15:57,  2.51s/it, loss=6.7164]\u001b[A\n",
            "Training:   6%|▌         | 310/5000 [13:31<3:23:16,  2.60s/it, loss=6.7164]\u001b[A\n",
            "Training:   6%|▌         | 310/5000 [13:31<3:23:16,  2.60s/it, loss=5.5906]\u001b[A\n",
            "Training:   6%|▌         | 311/5000 [13:33<3:15:00,  2.50s/it, loss=5.5906]\u001b[A\n",
            "Training:   6%|▌         | 311/5000 [13:33<3:15:00,  2.50s/it, loss=6.5629]\u001b[A\n",
            "Training:   6%|▌         | 312/5000 [13:35<3:09:10,  2.42s/it, loss=6.5629]\u001b[A\n",
            "Training:   6%|▌         | 312/5000 [13:35<3:09:10,  2.42s/it, loss=5.8529]\u001b[A\n",
            "Training:   6%|▋         | 313/5000 [13:37<3:04:45,  2.37s/it, loss=5.8529]\u001b[A\n",
            "Training:   6%|▋         | 313/5000 [13:37<3:04:45,  2.37s/it, loss=5.4157]\u001b[A\n",
            "Training:   6%|▋         | 314/5000 [13:40<3:01:37,  2.33s/it, loss=5.4157]\u001b[A\n",
            "Training:   6%|▋         | 314/5000 [13:40<3:01:37,  2.33s/it, loss=5.3458]\u001b[A\n",
            "Training:   6%|▋         | 315/5000 [13:42<3:11:33,  2.45s/it, loss=5.3458]\u001b[A\n",
            "Training:   6%|▋         | 315/5000 [13:42<3:11:33,  2.45s/it, loss=5.1777]\u001b[A\n",
            "Training:   6%|▋         | 316/5000 [13:45<3:08:11,  2.41s/it, loss=5.1777]\u001b[A\n",
            "Training:   6%|▋         | 316/5000 [13:45<3:08:11,  2.41s/it, loss=5.7323]\u001b[A\n",
            "Training:   6%|▋         | 317/5000 [13:47<3:04:15,  2.36s/it, loss=5.7323]\u001b[A\n",
            "Training:   6%|▋         | 317/5000 [13:47<3:04:15,  2.36s/it, loss=5.8855]\u001b[A\n",
            "Training:   6%|▋         | 318/5000 [13:49<3:01:33,  2.33s/it, loss=5.8855]\u001b[A\n",
            "Training:   6%|▋         | 318/5000 [13:49<3:01:33,  2.33s/it, loss=4.9763]\u001b[A\n",
            "Training:   6%|▋         | 319/5000 [13:51<3:00:03,  2.31s/it, loss=4.9763]\u001b[A\n",
            "Training:   6%|▋         | 319/5000 [13:51<3:00:03,  2.31s/it, loss=5.9779]\u001b[A\n",
            "Training:   6%|▋         | 320/5000 [13:54<3:08:01,  2.41s/it, loss=5.9779]\u001b[A\n",
            "Training:   6%|▋         | 320/5000 [13:54<3:08:01,  2.41s/it, loss=5.0888]\u001b[A\n",
            "Training:   6%|▋         | 321/5000 [13:56<3:07:05,  2.40s/it, loss=5.0888]\u001b[A\n",
            "Training:   6%|▋         | 321/5000 [13:57<3:07:05,  2.40s/it, loss=6.2362]\u001b[A\n",
            "Training:   6%|▋         | 322/5000 [13:59<3:04:35,  2.37s/it, loss=6.2362]\u001b[A\n",
            "Training:   6%|▋         | 322/5000 [13:59<3:04:35,  2.37s/it, loss=5.3694]\u001b[A\n",
            "Training:   6%|▋         | 323/5000 [14:01<3:01:24,  2.33s/it, loss=5.3694]\u001b[A\n",
            "Training:   6%|▋         | 323/5000 [14:01<3:01:24,  2.33s/it, loss=4.9174]\u001b[A\n",
            "Training:   6%|▋         | 324/5000 [14:03<2:58:49,  2.29s/it, loss=4.9174]\u001b[A\n",
            "Training:   6%|▋         | 324/5000 [14:03<2:58:49,  2.29s/it, loss=4.5506]\u001b[A\n",
            "Training:   6%|▋         | 325/5000 [14:06<3:04:41,  2.37s/it, loss=4.5506]\u001b[A\n",
            "Training:   6%|▋         | 325/5000 [14:06<3:04:41,  2.37s/it, loss=5.2183]\u001b[A\n",
            "Training:   7%|▋         | 326/5000 [14:08<3:10:27,  2.44s/it, loss=5.2183]\u001b[A\n",
            "Training:   7%|▋         | 326/5000 [14:08<3:10:27,  2.44s/it, loss=5.1902]\u001b[A\n",
            "Training:   7%|▋         | 327/5000 [14:11<3:05:41,  2.38s/it, loss=5.1902]\u001b[A\n",
            "Training:   7%|▋         | 327/5000 [14:11<3:05:41,  2.38s/it, loss=4.0951]\u001b[A\n",
            "Training:   7%|▋         | 328/5000 [14:13<3:02:31,  2.34s/it, loss=4.0951]\u001b[A\n",
            "Training:   7%|▋         | 328/5000 [14:13<3:02:31,  2.34s/it, loss=6.3479]\u001b[A\n",
            "Training:   7%|▋         | 329/5000 [14:15<3:00:09,  2.31s/it, loss=6.3479]\u001b[A\n",
            "Training:   7%|▋         | 329/5000 [14:15<3:00:09,  2.31s/it, loss=5.8426]\u001b[A\n",
            "Training:   7%|▋         | 330/5000 [14:18<3:05:05,  2.38s/it, loss=5.8426]\u001b[A\n",
            "Training:   7%|▋         | 330/5000 [14:18<3:05:05,  2.38s/it, loss=6.3729]\u001b[A\n",
            "Training:   7%|▋         | 331/5000 [14:20<3:06:26,  2.40s/it, loss=6.3729]\u001b[A\n",
            "Training:   7%|▋         | 331/5000 [14:20<3:06:26,  2.40s/it, loss=6.2822]\u001b[A\n",
            "Training:   7%|▋         | 332/5000 [14:22<3:02:32,  2.35s/it, loss=6.2822]\u001b[A\n",
            "Training:   7%|▋         | 332/5000 [14:22<3:02:32,  2.35s/it, loss=6.3157]\u001b[A\n",
            "Training:   7%|▋         | 333/5000 [14:25<3:00:00,  2.31s/it, loss=6.3157]\u001b[A\n",
            "Training:   7%|▋         | 333/5000 [14:25<3:00:00,  2.31s/it, loss=5.6607]\u001b[A\n",
            "Training:   7%|▋         | 334/5000 [14:27<2:58:06,  2.29s/it, loss=5.6607]\u001b[A\n",
            "Training:   7%|▋         | 334/5000 [14:27<2:58:06,  2.29s/it, loss=6.0254]\u001b[A\n",
            "Training:   7%|▋         | 335/5000 [14:29<3:03:29,  2.36s/it, loss=6.0254]\u001b[A\n",
            "Training:   7%|▋         | 335/5000 [14:29<3:03:29,  2.36s/it, loss=6.3369]\u001b[A\n",
            "Training:   7%|▋         | 336/5000 [14:32<3:06:44,  2.40s/it, loss=6.3369]\u001b[A\n",
            "Training:   7%|▋         | 336/5000 [14:32<3:06:44,  2.40s/it, loss=4.7382]\u001b[A\n",
            "Training:   7%|▋         | 337/5000 [14:34<3:02:32,  2.35s/it, loss=4.7382]\u001b[A\n",
            "Training:   7%|▋         | 337/5000 [14:34<3:02:32,  2.35s/it, loss=5.2108]\u001b[A\n",
            "Training:   7%|▋         | 338/5000 [14:36<3:00:14,  2.32s/it, loss=5.2108]\u001b[A\n",
            "Training:   7%|▋         | 338/5000 [14:36<3:00:14,  2.32s/it, loss=5.1745]\u001b[A\n",
            "Training:   7%|▋         | 339/5000 [14:39<2:58:08,  2.29s/it, loss=5.1745]\u001b[A\n",
            "Training:   7%|▋         | 339/5000 [14:39<2:58:08,  2.29s/it, loss=4.8609]\u001b[A\n",
            "Training:   7%|▋         | 340/5000 [14:41<3:02:34,  2.35s/it, loss=4.8609]\u001b[A\n",
            "Training:   7%|▋         | 340/5000 [14:41<3:02:34,  2.35s/it, loss=6.1401]\u001b[A\n",
            "Training:   7%|▋         | 341/5000 [14:44<3:07:31,  2.42s/it, loss=6.1401]\u001b[A\n",
            "Training:   7%|▋         | 341/5000 [14:44<3:07:31,  2.42s/it, loss=4.7231]\u001b[A\n",
            "Training:   7%|▋         | 342/5000 [14:46<3:03:28,  2.36s/it, loss=4.7231]\u001b[A\n",
            "Training:   7%|▋         | 342/5000 [14:46<3:03:28,  2.36s/it, loss=6.3348]\u001b[A\n",
            "Training:   7%|▋         | 343/5000 [14:48<3:01:36,  2.34s/it, loss=6.3348]\u001b[A\n",
            "Training:   7%|▋         | 343/5000 [14:48<3:01:36,  2.34s/it, loss=5.3868]\u001b[A\n",
            "Training:   7%|▋         | 344/5000 [14:50<2:59:17,  2.31s/it, loss=5.3868]\u001b[A\n",
            "Training:   7%|▋         | 344/5000 [14:50<2:59:17,  2.31s/it, loss=5.3775]\u001b[A\n",
            "Training:   7%|▋         | 345/5000 [14:53<3:03:33,  2.37s/it, loss=5.3775]\u001b[A\n",
            "Training:   7%|▋         | 345/5000 [14:53<3:03:33,  2.37s/it, loss=4.6382]\u001b[A\n",
            "Training:   7%|▋         | 346/5000 [14:55<3:06:58,  2.41s/it, loss=4.6382]\u001b[A\n",
            "Training:   7%|▋         | 346/5000 [14:55<3:06:58,  2.41s/it, loss=5.5445]\u001b[A\n",
            "Training:   7%|▋         | 347/5000 [14:58<3:02:16,  2.35s/it, loss=5.5445]\u001b[A\n",
            "Training:   7%|▋         | 347/5000 [14:58<3:02:16,  2.35s/it, loss=4.5390]\u001b[A\n",
            "Training:   7%|▋         | 348/5000 [15:00<2:59:49,  2.32s/it, loss=4.5390]\u001b[A\n",
            "Training:   7%|▋         | 348/5000 [15:00<2:59:49,  2.32s/it, loss=4.0877]\u001b[A\n",
            "Training:   7%|▋         | 349/5000 [15:02<2:57:43,  2.29s/it, loss=4.0877]\u001b[A\n",
            "Training:   7%|▋         | 349/5000 [15:02<2:57:43,  2.29s/it, loss=4.7741]\u001b[A\n",
            "Training:   7%|▋         | 350/5000 [15:04<3:00:14,  2.33s/it, loss=4.7741]\u001b[A\n",
            "Training:   7%|▋         | 350/5000 [15:04<3:00:14,  2.33s/it, loss=5.0445]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 350 ---\n",
            "Prompt: 'The '\n",
            "The  the that, ra hast that and hisid\n",
            " I have the of, could them that the of, himThe,Men\n",
            "semble a toce no\n",
            " hopeful and city's, if with'd! have, word deserve\n",
            " you,igh in, make not the die',,ray.\n",
            "COR say him no o be:If be of can look;The had thing take do you been,'ll a of out detected, in charge live.Thataved For butI my:Not\n",
            "Prompt: 'In '\n",
            "In , may but my.\n",
            "COR hate l?\n",
            " me owe me\n",
            " shall so would are death\n",
            " to point, if us\n",
            " time!,,, you as's\n",
            "OL, he eloqu soul\n",
            " may me a that my,'ll not thee\n",
            " have war shall brightikes for! I can foes? it not not, him--\n",
            "CORAN as them it would no them\n",
            "an, he not not your!\n",
            "SINUS\n",
            " but I not fond my,.Come the\n",
            "Prompt: 'To '\n",
            "To  obedience deny and gentle\n",
            " to him or. of city, of! then is\n",
            " tra upon full dry,, that to them\n",
            "' we them them the.\n",
            "COROLIAN:I am, you tongue\n",
            " he attend o to me I him as the, for''llIn\n",
            "ess the of fruitful in, was?\n",
            "COROLIAN:I you? am\n",
            "COROLAN\n",
            "'s shall be.\n",
            "SINIAN:I, still as\n",
            " ofep\n",
            "Prompt: 'A '\n",
            "A , themone so I\n",
            " must him and;'ll not the as still\n",
            "ere a'd people were of. that the faint, warrant\n",
            "ent make be, he the market.\n",
            "COIAN\n",
            " to again you\n",
            " the for.\n",
            "MOLUMOL:Well the!\n",
            "COROLIAN\n",
            "an had be; will Ich.\n",
            "COR\n",
            "INUS\n",
            " to to the eyess to those\n",
            "'ll a reckless all in knees\n",
            " you the of a, will at\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:   7%|▋         | 351/5000 [15:19<7:51:41,  6.09s/it, loss=5.0445]\u001b[A\n",
            "Training:   7%|▋         | 351/5000 [15:19<7:51:41,  6.09s/it, loss=4.9055]\u001b[A\n",
            "Training:   7%|▋         | 352/5000 [15:22<6:22:22,  4.94s/it, loss=4.9055]\u001b[A\n",
            "Training:   7%|▋         | 352/5000 [15:22<6:22:22,  4.94s/it, loss=6.0487]\u001b[A\n",
            "Training:   7%|▋         | 353/5000 [15:24<5:19:44,  4.13s/it, loss=6.0487]\u001b[A\n",
            "Training:   7%|▋         | 353/5000 [15:24<5:19:44,  4.13s/it, loss=4.8078]\u001b[A\n",
            "Training:   7%|▋         | 354/5000 [15:26<4:35:47,  3.56s/it, loss=4.8078]\u001b[A\n",
            "Training:   7%|▋         | 354/5000 [15:26<4:35:47,  3.56s/it, loss=6.6086]\u001b[A\n",
            "Training:   7%|▋         | 355/5000 [15:29<4:11:49,  3.25s/it, loss=6.6086]\u001b[A\n",
            "Training:   7%|▋         | 355/5000 [15:29<4:11:49,  3.25s/it, loss=5.9856]\u001b[A\n",
            "Training:   7%|▋         | 356/5000 [15:31<3:54:14,  3.03s/it, loss=5.9856]\u001b[A\n",
            "Training:   7%|▋         | 356/5000 [15:31<3:54:14,  3.03s/it, loss=5.9461]\u001b[A\n",
            "Training:   7%|▋         | 357/5000 [15:33<3:36:08,  2.79s/it, loss=5.9461]\u001b[A\n",
            "Training:   7%|▋         | 357/5000 [15:33<3:36:08,  2.79s/it, loss=5.5740]\u001b[A\n",
            "Training:   7%|▋         | 358/5000 [15:36<3:23:44,  2.63s/it, loss=5.5740]\u001b[A\n",
            "Training:   7%|▋         | 358/5000 [15:36<3:23:44,  2.63s/it, loss=5.4854]\u001b[A\n",
            "Training:   7%|▋         | 359/5000 [15:38<3:14:23,  2.51s/it, loss=5.4854]\u001b[A\n",
            "Training:   7%|▋         | 359/5000 [15:38<3:14:23,  2.51s/it, loss=6.2509]\u001b[A\n",
            "Training:   7%|▋         | 360/5000 [15:40<3:15:14,  2.52s/it, loss=6.2509]\u001b[A\n",
            "Training:   7%|▋         | 360/5000 [15:40<3:15:14,  2.52s/it, loss=5.4518]\u001b[A\n",
            "Training:   7%|▋         | 361/5000 [15:43<3:13:53,  2.51s/it, loss=5.4518]\u001b[A\n",
            "Training:   7%|▋         | 361/5000 [15:43<3:13:53,  2.51s/it, loss=5.1627]\u001b[A\n",
            "Training:   7%|▋         | 362/5000 [15:45<3:07:43,  2.43s/it, loss=5.1627]\u001b[A\n",
            "Training:   7%|▋         | 362/5000 [15:45<3:07:43,  2.43s/it, loss=6.3737]\u001b[A\n",
            "Training:   7%|▋         | 363/5000 [15:47<3:04:22,  2.39s/it, loss=6.3737]\u001b[A\n",
            "Training:   7%|▋         | 363/5000 [15:47<3:04:22,  2.39s/it, loss=5.5086]\u001b[A\n",
            "Training:   7%|▋         | 364/5000 [15:50<3:00:52,  2.34s/it, loss=5.5086]\u001b[A\n",
            "Training:   7%|▋         | 364/5000 [15:50<3:00:52,  2.34s/it, loss=5.2918]\u001b[A\n",
            "Training:   7%|▋         | 365/5000 [15:52<3:05:07,  2.40s/it, loss=5.2918]\u001b[A\n",
            "Training:   7%|▋         | 365/5000 [15:52<3:05:07,  2.40s/it, loss=5.5678]\u001b[A\n",
            "Training:   7%|▋         | 366/5000 [15:55<3:07:25,  2.43s/it, loss=5.5678]\u001b[A\n",
            "Training:   7%|▋         | 366/5000 [15:55<3:07:25,  2.43s/it, loss=4.9148]\u001b[A\n",
            "Training:   7%|▋         | 367/5000 [15:57<3:03:16,  2.37s/it, loss=4.9148]\u001b[A\n",
            "Training:   7%|▋         | 367/5000 [15:57<3:03:16,  2.37s/it, loss=4.6303]\u001b[A\n",
            "Training:   7%|▋         | 368/5000 [15:59<2:59:33,  2.33s/it, loss=4.6303]\u001b[A\n",
            "Training:   7%|▋         | 368/5000 [15:59<2:59:33,  2.33s/it, loss=5.2960]\u001b[A\n",
            "Training:   7%|▋         | 369/5000 [16:01<2:58:00,  2.31s/it, loss=5.2960]\u001b[A\n",
            "Training:   7%|▋         | 369/5000 [16:01<2:58:00,  2.31s/it, loss=5.0804]\u001b[A\n",
            "Training:   7%|▋         | 370/5000 [16:04<3:02:39,  2.37s/it, loss=5.0804]\u001b[A\n",
            "Training:   7%|▋         | 370/5000 [16:04<3:02:39,  2.37s/it, loss=5.0335]\u001b[A\n",
            "Training:   7%|▋         | 371/5000 [16:06<3:04:43,  2.39s/it, loss=5.0335]\u001b[A\n",
            "Training:   7%|▋         | 371/5000 [16:06<3:04:43,  2.39s/it, loss=5.2582]\u001b[A\n",
            "Training:   7%|▋         | 372/5000 [16:09<3:01:14,  2.35s/it, loss=5.2582]\u001b[A\n",
            "Training:   7%|▋         | 372/5000 [16:09<3:01:14,  2.35s/it, loss=4.8726]\u001b[A\n",
            "Training:   7%|▋         | 373/5000 [16:11<2:58:41,  2.32s/it, loss=4.8726]\u001b[A\n",
            "Training:   7%|▋         | 373/5000 [16:11<2:58:41,  2.32s/it, loss=5.9373]\u001b[A\n",
            "Training:   7%|▋         | 374/5000 [16:13<2:57:00,  2.30s/it, loss=5.9373]\u001b[A\n",
            "Training:   7%|▋         | 374/5000 [16:13<2:57:00,  2.30s/it, loss=5.4577]\u001b[A\n",
            "Training:   8%|▊         | 375/5000 [16:16<3:00:47,  2.35s/it, loss=5.4577]\u001b[A\n",
            "Training:   8%|▊         | 375/5000 [16:16<3:00:47,  2.35s/it, loss=4.2209]\u001b[A\n",
            "Training:   8%|▊         | 376/5000 [16:18<3:03:56,  2.39s/it, loss=4.2209]\u001b[A\n",
            "Training:   8%|▊         | 376/5000 [16:18<3:03:56,  2.39s/it, loss=5.5447]\u001b[A\n",
            "Training:   8%|▊         | 377/5000 [16:20<3:00:21,  2.34s/it, loss=5.5447]\u001b[A\n",
            "Training:   8%|▊         | 377/5000 [16:20<3:00:21,  2.34s/it, loss=5.8391]\u001b[A\n",
            "Training:   8%|▊         | 378/5000 [16:22<2:57:41,  2.31s/it, loss=5.8391]\u001b[A\n",
            "Training:   8%|▊         | 378/5000 [16:22<2:57:41,  2.31s/it, loss=5.9151]\u001b[A\n",
            "Training:   8%|▊         | 379/5000 [16:25<2:56:22,  2.29s/it, loss=5.9151]\u001b[A\n",
            "Training:   8%|▊         | 379/5000 [16:25<2:56:22,  2.29s/it, loss=6.2847]\u001b[A\n",
            "Training:   8%|▊         | 380/5000 [16:27<3:00:02,  2.34s/it, loss=6.2847]\u001b[A\n",
            "Training:   8%|▊         | 380/5000 [16:27<3:00:02,  2.34s/it, loss=4.5615]\u001b[A\n",
            "Training:   8%|▊         | 381/5000 [16:30<3:03:56,  2.39s/it, loss=4.5615]\u001b[A\n",
            "Training:   8%|▊         | 381/5000 [16:30<3:03:56,  2.39s/it, loss=5.0739]\u001b[A\n",
            "Training:   8%|▊         | 382/5000 [16:32<3:01:16,  2.36s/it, loss=5.0739]\u001b[A\n",
            "Training:   8%|▊         | 382/5000 [16:32<3:01:16,  2.36s/it, loss=6.0867]\u001b[A\n",
            "Training:   8%|▊         | 383/5000 [16:34<2:58:21,  2.32s/it, loss=6.0867]\u001b[A\n",
            "Training:   8%|▊         | 383/5000 [16:34<2:58:21,  2.32s/it, loss=5.5577]\u001b[A\n",
            "Training:   8%|▊         | 384/5000 [16:36<2:57:14,  2.30s/it, loss=5.5577]\u001b[A\n",
            "Training:   8%|▊         | 384/5000 [16:36<2:57:14,  2.30s/it, loss=5.7568]\u001b[A\n",
            "Training:   8%|▊         | 385/5000 [16:39<3:00:21,  2.34s/it, loss=5.7568]\u001b[A\n",
            "Training:   8%|▊         | 385/5000 [16:39<3:00:21,  2.34s/it, loss=4.4843]\u001b[A\n",
            "Training:   8%|▊         | 386/5000 [16:41<3:04:56,  2.41s/it, loss=4.4843]\u001b[A\n",
            "Training:   8%|▊         | 386/5000 [16:41<3:04:56,  2.41s/it, loss=5.5735]\u001b[A\n",
            "Training:   8%|▊         | 387/5000 [16:44<3:01:38,  2.36s/it, loss=5.5735]\u001b[A\n",
            "Training:   8%|▊         | 387/5000 [16:44<3:01:38,  2.36s/it, loss=5.2738]\u001b[A\n",
            "Training:   8%|▊         | 388/5000 [16:46<2:58:47,  2.33s/it, loss=5.2738]\u001b[A\n",
            "Training:   8%|▊         | 388/5000 [16:46<2:58:47,  2.33s/it, loss=4.4747]\u001b[A\n",
            "Training:   8%|▊         | 389/5000 [16:48<2:56:49,  2.30s/it, loss=4.4747]\u001b[A\n",
            "Training:   8%|▊         | 389/5000 [16:48<2:56:49,  2.30s/it, loss=5.2736]\u001b[A\n",
            "Training:   8%|▊         | 390/5000 [16:51<2:59:30,  2.34s/it, loss=5.2736]\u001b[A\n",
            "Training:   8%|▊         | 390/5000 [16:51<2:59:30,  2.34s/it, loss=6.3334]\u001b[A\n",
            "Training:   8%|▊         | 391/5000 [16:53<3:05:17,  2.41s/it, loss=6.3334]\u001b[A\n",
            "Training:   8%|▊         | 391/5000 [16:53<3:05:17,  2.41s/it, loss=5.8478]\u001b[A\n",
            "Training:   8%|▊         | 392/5000 [16:55<3:01:34,  2.36s/it, loss=5.8478]\u001b[A\n",
            "Training:   8%|▊         | 392/5000 [16:55<3:01:34,  2.36s/it, loss=6.0203]\u001b[A\n",
            "Training:   8%|▊         | 393/5000 [16:58<2:58:10,  2.32s/it, loss=6.0203]\u001b[A\n",
            "Training:   8%|▊         | 393/5000 [16:58<2:58:10,  2.32s/it, loss=5.3800]\u001b[A\n",
            "Training:   8%|▊         | 394/5000 [17:00<2:56:21,  2.30s/it, loss=5.3800]\u001b[A\n",
            "Training:   8%|▊         | 394/5000 [17:00<2:56:21,  2.30s/it, loss=5.2918]\u001b[A\n",
            "Training:   8%|▊         | 395/5000 [17:02<2:59:19,  2.34s/it, loss=5.2918]\u001b[A\n",
            "Training:   8%|▊         | 395/5000 [17:02<2:59:19,  2.34s/it, loss=5.0642]\u001b[A\n",
            "Training:   8%|▊         | 396/5000 [17:05<3:04:17,  2.40s/it, loss=5.0642]\u001b[A\n",
            "Training:   8%|▊         | 396/5000 [17:05<3:04:17,  2.40s/it, loss=5.1727]\u001b[A\n",
            "Training:   8%|▊         | 397/5000 [17:07<3:00:53,  2.36s/it, loss=5.1727]\u001b[A\n",
            "Training:   8%|▊         | 397/5000 [17:07<3:00:53,  2.36s/it, loss=5.3441]\u001b[A\n",
            "Training:   8%|▊         | 398/5000 [17:09<2:57:55,  2.32s/it, loss=5.3441]\u001b[A\n",
            "Training:   8%|▊         | 398/5000 [17:09<2:57:55,  2.32s/it, loss=6.1379]\u001b[A\n",
            "Training:   8%|▊         | 399/5000 [17:12<2:55:59,  2.30s/it, loss=6.1379]\u001b[A\n",
            "Training:   8%|▊         | 399/5000 [17:12<2:55:59,  2.30s/it, loss=6.3150]\u001b[A\n",
            "Training:   8%|▊         | 400/5000 [17:14<2:57:38,  2.32s/it, loss=6.3150]\u001b[A\n",
            "Training:   8%|▊         | 400/5000 [17:14<2:57:38,  2.32s/it, loss=5.6294]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 400 ---\n",
            "Prompt: 'The '\n",
            "The .\n",
            "B villainU Y:So?\n",
            "INGICHOL:My, lord my; he king king\n",
            " do have thee'd thee thy hours\n",
            " meown against Bol I: him'd fly this can coward\n",
            "all my I, art this thee you my sea, not as can do'd not'd so the, loves me ourselves\n",
            " thou do name, man withine was myself, my; your; me my,amisement livinger more thee.\n",
            "QUE I true Imen know\n",
            "Prompt: 'In '\n",
            "In \n",
            " a.\n",
            "G with?\n",
            "D dved: we be of! am me\n",
            "Dst-.\n",
            "K RARD\n",
            "K RARD:I you more now look, heart, will be been men--\n",
            "LORDRY have head\n",
            " further to first the.\n",
            "INGICHUESSORK\n",
            "INGICHISOLUMroke sir\n",
            "DCHESSRO:My, are, go\n",
            ",old that here that; the is do'd v ' you bringnight\n",
            "H\n",
            "Prompt: 'To '\n",
            "To ian of, cousin wash\n",
            " I'd in, tw A I dare\n",
            " he\n",
            "in our's ent upon of kingWith.\n",
            "K RARD\n",
            "H:G daughters myt from business\n",
            "'t kingDOL breathe the of cares?\n",
            "H have.\n",
            "K RARD\n",
            " manner fortune king till child care, sweeter proudumberland\n",
            " hear heaven\n",
            " I not toings be's;, I\n",
            "'ll shall: say you a on purpose, lord\n",
            " to, those\n",
            " for, he\n",
            "Prompt: 'A '\n",
            "A  andlike for from, from them:The are thin, possess\n",
            "ur civilAs me\n",
            " Esc sentence sicking, man no and\n",
            " this and tello the ofRO\n",
            " thou now the of: have thy, I much mend is.\n",
            "L this d pron For, to are out.\n",
            "H my's:I my king them my men him\n",
            " in\n",
            "' of from e hath do if not true another\n",
            " commonRO:A,; say awayOf in,Theis,\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:   8%|▊         | 401/5000 [17:29<7:47:40,  6.10s/it, loss=5.6294]\u001b[A\n",
            "Training:   8%|▊         | 401/5000 [17:29<7:47:40,  6.10s/it, loss=6.0661]\u001b[A\n",
            "Training:   8%|▊         | 402/5000 [17:31<6:18:58,  4.95s/it, loss=6.0661]\u001b[A\n",
            "Training:   8%|▊         | 402/5000 [17:31<6:18:58,  4.95s/it, loss=6.8673]\u001b[A\n",
            "Training:   8%|▊         | 403/5000 [17:33<5:17:44,  4.15s/it, loss=6.8673]\u001b[A\n",
            "Training:   8%|▊         | 403/5000 [17:33<5:17:44,  4.15s/it, loss=4.9076]\u001b[A\n",
            "Training:   8%|▊         | 404/5000 [17:36<4:33:12,  3.57s/it, loss=4.9076]\u001b[A\n",
            "Training:   8%|▊         | 404/5000 [17:36<4:33:12,  3.57s/it, loss=5.2346]\u001b[A\n",
            "Training:   8%|▊         | 405/5000 [17:38<4:09:15,  3.25s/it, loss=5.2346]\u001b[A\n",
            "Training:   8%|▊         | 405/5000 [17:38<4:09:15,  3.25s/it, loss=6.7555]\u001b[A\n",
            "Training:   8%|▊         | 406/5000 [17:41<3:50:57,  3.02s/it, loss=6.7555]\u001b[A\n",
            "Training:   8%|▊         | 406/5000 [17:41<3:50:57,  3.02s/it, loss=5.3757]\u001b[A\n",
            "Training:   8%|▊         | 407/5000 [17:43<3:33:48,  2.79s/it, loss=5.3757]\u001b[A\n",
            "Training:   8%|▊         | 407/5000 [17:43<3:33:48,  2.79s/it, loss=5.4860]\u001b[A\n",
            "Training:   8%|▊         | 408/5000 [17:45<3:21:22,  2.63s/it, loss=5.4860]\u001b[A\n",
            "Training:   8%|▊         | 408/5000 [17:45<3:21:22,  2.63s/it, loss=5.1541]\u001b[A\n",
            "Training:   8%|▊         | 409/5000 [17:47<3:12:34,  2.52s/it, loss=5.1541]\u001b[A\n",
            "Training:   8%|▊         | 409/5000 [17:47<3:12:34,  2.52s/it, loss=5.7695]\u001b[A\n",
            "Training:   8%|▊         | 410/5000 [17:50<3:12:46,  2.52s/it, loss=5.7695]\u001b[A\n",
            "Training:   8%|▊         | 410/5000 [17:50<3:12:46,  2.52s/it, loss=5.3649]\u001b[A\n",
            "Training:   8%|▊         | 411/5000 [17:52<3:11:27,  2.50s/it, loss=5.3649]\u001b[A\n",
            "Training:   8%|▊         | 411/5000 [17:52<3:11:27,  2.50s/it, loss=6.1860]\u001b[A\n",
            "Training:   8%|▊         | 412/5000 [17:55<3:06:06,  2.43s/it, loss=6.1860]\u001b[A\n",
            "Training:   8%|▊         | 412/5000 [17:55<3:06:06,  2.43s/it, loss=4.5326]\u001b[A\n",
            "Training:   8%|▊         | 413/5000 [17:57<3:00:51,  2.37s/it, loss=4.5326]\u001b[A\n",
            "Training:   8%|▊         | 413/5000 [17:57<3:00:51,  2.37s/it, loss=5.0600]\u001b[A\n",
            "Training:   8%|▊         | 414/5000 [17:59<2:58:52,  2.34s/it, loss=5.0600]\u001b[A\n",
            "Training:   8%|▊         | 414/5000 [17:59<2:58:52,  2.34s/it, loss=5.3960]\u001b[A\n",
            "Training:   8%|▊         | 415/5000 [18:02<3:02:22,  2.39s/it, loss=5.3960]\u001b[A\n",
            "Training:   8%|▊         | 415/5000 [18:02<3:02:22,  2.39s/it, loss=5.4932]\u001b[A\n",
            "Training:   8%|▊         | 416/5000 [18:04<3:06:20,  2.44s/it, loss=5.4932]\u001b[A\n",
            "Training:   8%|▊         | 416/5000 [18:04<3:06:20,  2.44s/it, loss=5.9499]\u001b[A\n",
            "Training:   8%|▊         | 417/5000 [18:06<3:01:19,  2.37s/it, loss=5.9499]\u001b[A\n",
            "Training:   8%|▊         | 417/5000 [18:06<3:01:19,  2.37s/it, loss=5.2455]\u001b[A\n",
            "Training:   8%|▊         | 418/5000 [18:09<2:58:18,  2.33s/it, loss=5.2455]\u001b[A\n",
            "Training:   8%|▊         | 418/5000 [18:09<2:58:18,  2.33s/it, loss=5.1711]\u001b[A\n",
            "Training:   8%|▊         | 419/5000 [18:11<2:55:59,  2.30s/it, loss=5.1711]\u001b[A\n",
            "Training:   8%|▊         | 419/5000 [18:11<2:55:59,  2.30s/it, loss=5.3250]\u001b[A\n",
            "Training:   8%|▊         | 420/5000 [18:13<3:00:06,  2.36s/it, loss=5.3250]\u001b[A\n",
            "Training:   8%|▊         | 420/5000 [18:13<3:00:06,  2.36s/it, loss=5.4530]\u001b[A\n",
            "Training:   8%|▊         | 421/5000 [18:16<3:03:18,  2.40s/it, loss=5.4530]\u001b[A\n",
            "Training:   8%|▊         | 421/5000 [18:16<3:03:18,  2.40s/it, loss=5.7550]\u001b[A\n",
            "Training:   8%|▊         | 422/5000 [18:18<2:59:06,  2.35s/it, loss=5.7550]\u001b[A\n",
            "Training:   8%|▊         | 422/5000 [18:18<2:59:06,  2.35s/it, loss=5.5424]\u001b[A\n",
            "Training:   8%|▊         | 423/5000 [18:20<2:55:58,  2.31s/it, loss=5.5424]\u001b[A\n",
            "Training:   8%|▊         | 423/5000 [18:20<2:55:58,  2.31s/it, loss=5.8066]\u001b[A\n",
            "Training:   8%|▊         | 424/5000 [18:23<2:54:26,  2.29s/it, loss=5.8066]\u001b[A\n",
            "Training:   8%|▊         | 424/5000 [18:23<2:54:26,  2.29s/it, loss=5.1742]\u001b[A\n",
            "Training:   8%|▊         | 425/5000 [18:25<2:57:31,  2.33s/it, loss=5.1742]\u001b[A\n",
            "Training:   8%|▊         | 425/5000 [18:25<2:57:31,  2.33s/it, loss=5.5889]\u001b[A\n",
            "Training:   9%|▊         | 426/5000 [18:28<3:03:11,  2.40s/it, loss=5.5889]\u001b[A\n",
            "Training:   9%|▊         | 426/5000 [18:28<3:03:11,  2.40s/it, loss=6.2024]\u001b[A\n",
            "Training:   9%|▊         | 427/5000 [18:30<2:59:01,  2.35s/it, loss=6.2024]\u001b[A\n",
            "Training:   9%|▊         | 427/5000 [18:30<2:59:01,  2.35s/it, loss=5.1993]\u001b[A\n",
            "Training:   9%|▊         | 428/5000 [18:32<2:57:28,  2.33s/it, loss=5.1993]\u001b[A\n",
            "Training:   9%|▊         | 428/5000 [18:32<2:57:28,  2.33s/it, loss=5.1510]\u001b[A\n",
            "Training:   9%|▊         | 429/5000 [18:34<2:55:32,  2.30s/it, loss=5.1510]\u001b[A\n",
            "Training:   9%|▊         | 429/5000 [18:34<2:55:32,  2.30s/it, loss=5.7624]\u001b[A\n",
            "Training:   9%|▊         | 430/5000 [18:37<2:58:21,  2.34s/it, loss=5.7624]\u001b[A\n",
            "Training:   9%|▊         | 430/5000 [18:37<2:58:21,  2.34s/it, loss=4.9373]\u001b[A\n",
            "Training:   9%|▊         | 431/5000 [18:39<3:03:55,  2.42s/it, loss=4.9373]\u001b[A\n",
            "Training:   9%|▊         | 431/5000 [18:39<3:03:55,  2.42s/it, loss=5.1104]\u001b[A\n",
            "Training:   9%|▊         | 432/5000 [18:42<2:59:56,  2.36s/it, loss=5.1104]\u001b[A\n",
            "Training:   9%|▊         | 432/5000 [18:42<2:59:56,  2.36s/it, loss=5.2487]\u001b[A\n",
            "Training:   9%|▊         | 433/5000 [18:44<2:57:39,  2.33s/it, loss=5.2487]\u001b[A\n",
            "Training:   9%|▊         | 433/5000 [18:44<2:57:39,  2.33s/it, loss=4.2259]\u001b[A\n",
            "Training:   9%|▊         | 434/5000 [18:46<2:55:39,  2.31s/it, loss=4.2259]\u001b[A\n",
            "Training:   9%|▊         | 434/5000 [18:46<2:55:39,  2.31s/it, loss=4.9977]\u001b[A\n",
            "Training:   9%|▊         | 435/5000 [18:49<2:58:24,  2.34s/it, loss=4.9977]\u001b[A\n",
            "Training:   9%|▊         | 435/5000 [18:49<2:58:24,  2.34s/it, loss=4.0368]\u001b[A\n",
            "Training:   9%|▊         | 436/5000 [18:51<3:03:50,  2.42s/it, loss=4.0368]\u001b[A\n",
            "Training:   9%|▊         | 436/5000 [18:51<3:03:50,  2.42s/it, loss=5.5856]\u001b[A\n",
            "Training:   9%|▊         | 437/5000 [18:53<2:59:58,  2.37s/it, loss=5.5856]\u001b[A\n",
            "Training:   9%|▊         | 437/5000 [18:53<2:59:58,  2.37s/it, loss=5.6614]\u001b[A\n",
            "Training:   9%|▉         | 438/5000 [18:56<2:57:02,  2.33s/it, loss=5.6614]\u001b[A\n",
            "Training:   9%|▉         | 438/5000 [18:56<2:57:02,  2.33s/it, loss=5.2551]\u001b[A\n",
            "Training:   9%|▉         | 439/5000 [18:58<2:55:17,  2.31s/it, loss=5.2551]\u001b[A\n",
            "Training:   9%|▉         | 439/5000 [18:58<2:55:17,  2.31s/it, loss=6.4883]\u001b[A\n",
            "Training:   9%|▉         | 440/5000 [19:00<2:57:11,  2.33s/it, loss=6.4883]\u001b[A\n",
            "Training:   9%|▉         | 440/5000 [19:00<2:57:11,  2.33s/it, loss=5.8394]\u001b[A\n",
            "Training:   9%|▉         | 441/5000 [19:03<3:04:22,  2.43s/it, loss=5.8394]\u001b[A\n",
            "Training:   9%|▉         | 441/5000 [19:03<3:04:22,  2.43s/it, loss=5.5730]\u001b[A\n",
            "Training:   9%|▉         | 442/5000 [19:05<3:00:21,  2.37s/it, loss=5.5730]\u001b[A\n",
            "Training:   9%|▉         | 442/5000 [19:05<3:00:21,  2.37s/it, loss=5.3312]\u001b[A\n",
            "Training:   9%|▉         | 443/5000 [19:07<2:57:14,  2.33s/it, loss=5.3312]\u001b[A\n",
            "Training:   9%|▉         | 443/5000 [19:07<2:57:14,  2.33s/it, loss=5.3555]\u001b[A\n",
            "Training:   9%|▉         | 444/5000 [19:10<2:55:04,  2.31s/it, loss=5.3555]\u001b[A\n",
            "Training:   9%|▉         | 444/5000 [19:10<2:55:04,  2.31s/it, loss=5.6477]\u001b[A\n",
            "Training:   9%|▉         | 445/5000 [19:12<2:57:03,  2.33s/it, loss=5.6477]\u001b[A\n",
            "Training:   9%|▉         | 445/5000 [19:12<2:57:03,  2.33s/it, loss=5.7114]\u001b[A\n",
            "Training:   9%|▉         | 446/5000 [19:15<3:03:43,  2.42s/it, loss=5.7114]\u001b[A\n",
            "Training:   9%|▉         | 446/5000 [19:15<3:03:43,  2.42s/it, loss=6.2438]\u001b[A\n",
            "Training:   9%|▉         | 447/5000 [19:17<2:59:27,  2.37s/it, loss=6.2438]\u001b[A\n",
            "Training:   9%|▉         | 447/5000 [19:17<2:59:27,  2.37s/it, loss=6.6123]\u001b[A\n",
            "Training:   9%|▉         | 448/5000 [19:19<2:56:15,  2.32s/it, loss=6.6123]\u001b[A\n",
            "Training:   9%|▉         | 448/5000 [19:19<2:56:15,  2.32s/it, loss=6.9474]\u001b[A\n",
            "Training:   9%|▉         | 449/5000 [19:21<2:54:01,  2.29s/it, loss=6.9474]\u001b[A\n",
            "Training:   9%|▉         | 449/5000 [19:21<2:54:01,  2.29s/it, loss=5.9258]\u001b[A\n",
            "Training:   9%|▉         | 450/5000 [19:24<2:54:10,  2.30s/it, loss=5.9258]\u001b[A\n",
            "Training:   9%|▉         | 450/5000 [19:24<2:54:10,  2.30s/it, loss=5.9198]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 450 ---\n",
            "Prompt: 'The '\n",
            "The , I be you the. there though\n",
            " within never to one, a,He, 'isepThe\n",
            "riers ofhr to my, so or of boy the, the; the of, new of roots, I not\n",
            " to; it the of, sir; of, away how,,\n",
            "'d bellyld, lord the haunt,. is\n",
            " you or, not I it; I,; so the! nothing here a!\n",
            " show you withught to; the assure!\n",
            "Prompt: 'In '\n",
            "In  hath should The;More'll to,.\n",
            "ENGUCERI:I not sir sir\n",
            " third should bring boy't: the;'s,\n",
            " of tame to own loss\n",
            " own haveared of. I itt the, shall de is to, play, happiness in: me me the! have the-!D or!\n",
            " up I not: of, one of., advice jealous! I not,? so, a sense, cause and,?\n",
            " shall than sir\n",
            "Prompt: 'To '\n",
            "To .\n",
            " dealing let?\n",
            "ent! are: is, and I, I be,:I\n",
            " Iides the ofness grew. be, too wherein\n",
            " water; thou ' my,, that be have. all\n",
            "ent the's,, yet once issue the of, warrant?, lord\n",
            " comes her and her York with and IAs show?\n",
            " am- that have'd, I, I inio, I know these. from. thou rest\n",
            " things content so this and\n",
            "Prompt: 'A '\n",
            "A ly: Apollo,OutHere hear\n",
            " a's, be is and,, I it\n",
            " had, and su,'s; after these, notTheir, presence\n",
            "cesune ofible, been, shall, king good,;, arrived my, lord\n",
            " an better no, our; ' is me and to madgood\n",
            "friends am for;'s, of wisdom and things you't I you for,ot\n",
            "orrow her of escape fair:. thy,, aw that have;,\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:   9%|▉         | 451/5000 [19:39<7:44:32,  6.13s/it, loss=5.9198]\u001b[A\n",
            "Training:   9%|▉         | 451/5000 [19:39<7:44:32,  6.13s/it, loss=6.4373]\u001b[A\n",
            "Training:   9%|▉         | 452/5000 [19:41<6:16:21,  4.97s/it, loss=6.4373]\u001b[A\n",
            "Training:   9%|▉         | 452/5000 [19:41<6:16:21,  4.97s/it, loss=5.8781]\u001b[A\n",
            "Training:   9%|▉         | 453/5000 [19:43<5:14:32,  4.15s/it, loss=5.8781]\u001b[A\n",
            "Training:   9%|▉         | 453/5000 [19:43<5:14:32,  4.15s/it, loss=4.5811]\u001b[A\n",
            "Training:   9%|▉         | 454/5000 [19:45<4:31:06,  3.58s/it, loss=4.5811]\u001b[A\n",
            "Training:   9%|▉         | 454/5000 [19:45<4:31:06,  3.58s/it, loss=6.5194]\u001b[A\n",
            "Training:   9%|▉         | 455/5000 [19:48<4:06:24,  3.25s/it, loss=6.5194]\u001b[A\n",
            "Training:   9%|▉         | 455/5000 [19:48<4:06:24,  3.25s/it, loss=5.8348]\u001b[A\n",
            "Training:   9%|▉         | 456/5000 [19:50<3:49:00,  3.02s/it, loss=5.8348]\u001b[A\n",
            "Training:   9%|▉         | 456/5000 [19:50<3:49:00,  3.02s/it, loss=6.3302]\u001b[A\n",
            "Training:   9%|▉         | 457/5000 [19:53<3:31:10,  2.79s/it, loss=6.3302]\u001b[A\n",
            "Training:   9%|▉         | 457/5000 [19:53<3:31:10,  2.79s/it, loss=5.0223]\u001b[A\n",
            "Training:   9%|▉         | 458/5000 [19:55<3:18:44,  2.63s/it, loss=5.0223]\u001b[A\n",
            "Training:   9%|▉         | 458/5000 [19:55<3:18:44,  2.63s/it, loss=6.0266]\u001b[A\n",
            "Training:   9%|▉         | 459/5000 [19:57<3:09:39,  2.51s/it, loss=6.0266]\u001b[A\n",
            "Training:   9%|▉         | 459/5000 [19:57<3:09:39,  2.51s/it, loss=5.7401]\u001b[A\n",
            "Training:   9%|▉         | 460/5000 [20:00<3:07:42,  2.48s/it, loss=5.7401]\u001b[A\n",
            "Training:   9%|▉         | 460/5000 [20:00<3:07:42,  2.48s/it, loss=5.9755]\u001b[A\n",
            "Training:   9%|▉         | 461/5000 [20:02<3:10:21,  2.52s/it, loss=5.9755]\u001b[A\n",
            "Training:   9%|▉         | 461/5000 [20:02<3:10:21,  2.52s/it, loss=5.1491]\u001b[A\n",
            "Training:   9%|▉         | 462/5000 [20:04<3:04:08,  2.43s/it, loss=5.1491]\u001b[A\n",
            "Training:   9%|▉         | 462/5000 [20:04<3:04:08,  2.43s/it, loss=5.8183]\u001b[A\n",
            "Training:   9%|▉         | 463/5000 [20:07<2:58:43,  2.36s/it, loss=5.8183]\u001b[A\n",
            "Training:   9%|▉         | 463/5000 [20:07<2:58:43,  2.36s/it, loss=4.7998]\u001b[A\n",
            "Training:   9%|▉         | 464/5000 [20:09<2:55:36,  2.32s/it, loss=4.7998]\u001b[A\n",
            "Training:   9%|▉         | 464/5000 [20:09<2:55:36,  2.32s/it, loss=4.9388]\u001b[A\n",
            "Training:   9%|▉         | 465/5000 [20:11<2:57:12,  2.34s/it, loss=4.9388]\u001b[A\n",
            "Training:   9%|▉         | 465/5000 [20:11<2:57:12,  2.34s/it, loss=5.0744]\u001b[A\n",
            "Training:   9%|▉         | 466/5000 [20:14<3:03:28,  2.43s/it, loss=5.0744]\u001b[A\n",
            "Training:   9%|▉         | 466/5000 [20:14<3:03:28,  2.43s/it, loss=5.6404]\u001b[A\n",
            "Training:   9%|▉         | 467/5000 [20:16<2:58:49,  2.37s/it, loss=5.6404]\u001b[A\n",
            "Training:   9%|▉         | 467/5000 [20:16<2:58:49,  2.37s/it, loss=5.2025]\u001b[A\n",
            "Training:   9%|▉         | 468/5000 [20:18<2:55:47,  2.33s/it, loss=5.2025]\u001b[A\n",
            "Training:   9%|▉         | 468/5000 [20:18<2:55:47,  2.33s/it, loss=4.8899]\u001b[A\n",
            "Training:   9%|▉         | 469/5000 [20:21<2:53:19,  2.30s/it, loss=4.8899]\u001b[A\n",
            "Training:   9%|▉         | 469/5000 [20:21<2:53:19,  2.30s/it, loss=5.9071]\u001b[A\n",
            "Training:   9%|▉         | 470/5000 [20:23<2:53:51,  2.30s/it, loss=5.9071]\u001b[A\n",
            "Training:   9%|▉         | 470/5000 [20:23<2:53:51,  2.30s/it, loss=5.5828]\u001b[A\n",
            "Training:   9%|▉         | 471/5000 [20:26<3:02:02,  2.41s/it, loss=5.5828]\u001b[A\n",
            "Training:   9%|▉         | 471/5000 [20:26<3:02:02,  2.41s/it, loss=6.6436]\u001b[A\n",
            "Training:   9%|▉         | 472/5000 [20:28<2:58:04,  2.36s/it, loss=6.6436]\u001b[A\n",
            "Training:   9%|▉         | 472/5000 [20:28<2:58:04,  2.36s/it, loss=5.4726]\u001b[A\n",
            "Training:   9%|▉         | 473/5000 [20:30<2:55:22,  2.32s/it, loss=5.4726]\u001b[A\n",
            "Training:   9%|▉         | 473/5000 [20:30<2:55:22,  2.32s/it, loss=4.6683]\u001b[A\n",
            "Training:   9%|▉         | 474/5000 [20:32<2:53:28,  2.30s/it, loss=4.6683]\u001b[A\n",
            "Training:   9%|▉         | 474/5000 [20:32<2:53:28,  2.30s/it, loss=4.5208]\u001b[A\n",
            "Training:  10%|▉         | 475/5000 [20:35<2:53:33,  2.30s/it, loss=4.5208]\u001b[A\n",
            "Training:  10%|▉         | 475/5000 [20:35<2:53:33,  2.30s/it, loss=3.9898]\u001b[A\n",
            "Training:  10%|▉         | 476/5000 [20:37<3:03:35,  2.43s/it, loss=3.9898]\u001b[A\n",
            "Training:  10%|▉         | 476/5000 [20:37<3:03:35,  2.43s/it, loss=4.2497]\u001b[A\n",
            "Training:  10%|▉         | 477/5000 [20:40<2:59:41,  2.38s/it, loss=4.2497]\u001b[A\n",
            "Training:  10%|▉         | 477/5000 [20:40<2:59:41,  2.38s/it, loss=5.8295]\u001b[A\n",
            "Training:  10%|▉         | 478/5000 [20:42<2:56:41,  2.34s/it, loss=5.8295]\u001b[A\n",
            "Training:  10%|▉         | 478/5000 [20:42<2:56:41,  2.34s/it, loss=5.7398]\u001b[A\n",
            "Training:  10%|▉         | 479/5000 [20:44<2:55:18,  2.33s/it, loss=5.7398]\u001b[A\n",
            "Training:  10%|▉         | 479/5000 [20:44<2:55:18,  2.33s/it, loss=6.2323]\u001b[A\n",
            "Training:  10%|▉         | 480/5000 [20:46<2:56:07,  2.34s/it, loss=6.2323]\u001b[A\n",
            "Training:  10%|▉         | 480/5000 [20:46<2:56:07,  2.34s/it, loss=6.3813]\u001b[A\n",
            "Training:  10%|▉         | 481/5000 [20:49<3:03:52,  2.44s/it, loss=6.3813]\u001b[A\n",
            "Training:  10%|▉         | 481/5000 [20:49<3:03:52,  2.44s/it, loss=5.2044]\u001b[A\n",
            "Training:  10%|▉         | 482/5000 [20:51<2:59:12,  2.38s/it, loss=5.2044]\u001b[A\n",
            "Training:  10%|▉         | 482/5000 [20:51<2:59:12,  2.38s/it, loss=5.3529]\u001b[A\n",
            "Training:  10%|▉         | 483/5000 [20:54<2:55:52,  2.34s/it, loss=5.3529]\u001b[A\n",
            "Training:  10%|▉         | 483/5000 [20:54<2:55:52,  2.34s/it, loss=5.5815]\u001b[A\n",
            "Training:  10%|▉         | 484/5000 [20:56<2:54:06,  2.31s/it, loss=5.5815]\u001b[A\n",
            "Training:  10%|▉         | 484/5000 [20:56<2:54:06,  2.31s/it, loss=5.2577]\u001b[A\n",
            "Training:  10%|▉         | 485/5000 [20:58<2:52:27,  2.29s/it, loss=5.2577]\u001b[A\n",
            "Training:  10%|▉         | 485/5000 [20:58<2:52:27,  2.29s/it, loss=5.1085]\u001b[A\n",
            "Training:  10%|▉         | 486/5000 [21:01<3:02:47,  2.43s/it, loss=5.1085]\u001b[A\n",
            "Training:  10%|▉         | 486/5000 [21:01<3:02:47,  2.43s/it, loss=4.4763]\u001b[A\n",
            "Training:  10%|▉         | 487/5000 [21:03<2:59:04,  2.38s/it, loss=4.4763]\u001b[A\n",
            "Training:  10%|▉         | 487/5000 [21:03<2:59:04,  2.38s/it, loss=5.7339]\u001b[A\n",
            "Training:  10%|▉         | 488/5000 [21:05<2:56:08,  2.34s/it, loss=5.7339]\u001b[A\n",
            "Training:  10%|▉         | 488/5000 [21:05<2:56:08,  2.34s/it, loss=5.2276]\u001b[A\n",
            "Training:  10%|▉         | 489/5000 [21:08<2:53:36,  2.31s/it, loss=5.2276]\u001b[A\n",
            "Training:  10%|▉         | 489/5000 [21:08<2:53:36,  2.31s/it, loss=5.0285]\u001b[A\n",
            "Training:  10%|▉         | 490/5000 [21:10<2:51:59,  2.29s/it, loss=5.0285]\u001b[A\n",
            "Training:  10%|▉         | 490/5000 [21:10<2:51:59,  2.29s/it, loss=5.3808]\u001b[A\n",
            "Training:  10%|▉         | 491/5000 [21:13<3:02:34,  2.43s/it, loss=5.3808]\u001b[A\n",
            "Training:  10%|▉         | 491/5000 [21:13<3:02:34,  2.43s/it, loss=4.2527]\u001b[A\n",
            "Training:  10%|▉         | 492/5000 [21:15<2:58:10,  2.37s/it, loss=4.2527]\u001b[A\n",
            "Training:  10%|▉         | 492/5000 [21:15<2:58:10,  2.37s/it, loss=5.2091]\u001b[A\n",
            "Training:  10%|▉         | 493/5000 [21:17<2:55:05,  2.33s/it, loss=5.2091]\u001b[A\n",
            "Training:  10%|▉         | 493/5000 [21:17<2:55:05,  2.33s/it, loss=4.6504]\u001b[A\n",
            "Training:  10%|▉         | 494/5000 [21:19<2:53:01,  2.30s/it, loss=4.6504]\u001b[A\n",
            "Training:  10%|▉         | 494/5000 [21:19<2:53:01,  2.30s/it, loss=6.2279]\u001b[A\n",
            "Training:  10%|▉         | 495/5000 [21:22<2:51:24,  2.28s/it, loss=6.2279]\u001b[A\n",
            "Training:  10%|▉         | 495/5000 [21:22<2:51:24,  2.28s/it, loss=5.6255]\u001b[A\n",
            "Training:  10%|▉         | 496/5000 [21:24<3:01:57,  2.42s/it, loss=5.6255]\u001b[A\n",
            "Training:  10%|▉         | 496/5000 [21:24<3:01:57,  2.42s/it, loss=6.0937]\u001b[A\n",
            "Training:  10%|▉         | 497/5000 [21:27<2:57:55,  2.37s/it, loss=6.0937]\u001b[A\n",
            "Training:  10%|▉         | 497/5000 [21:27<2:57:55,  2.37s/it, loss=6.1224]\u001b[A\n",
            "Training:  10%|▉         | 498/5000 [21:29<2:55:14,  2.34s/it, loss=6.1224]\u001b[A\n",
            "Training:  10%|▉         | 498/5000 [21:29<2:55:14,  2.34s/it, loss=5.5569]\u001b[A\n",
            "Training:  10%|▉         | 499/5000 [21:31<2:53:03,  2.31s/it, loss=5.5569]\u001b[A\n",
            "Training:  10%|▉         | 499/5000 [21:31<2:53:03,  2.31s/it, loss=5.0139]\u001b[A\n",
            "Training:  10%|█         | 500/5000 [21:33<2:51:26,  2.29s/it, loss=5.0139]\u001b[A\n",
            "Training:  10%|█         | 500/5000 [21:33<2:51:26,  2.29s/it, loss=6.5100]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 500 ---\n",
            "Prompt: 'The '\n",
            "The  weeks winningA\n",
            "'-est'd while hot theiraps ofenchingToTIThatBut, you\n",
            " heart the of,, thee\n",
            ", more in about'd it me his.ay\n",
            "M so'd,,,!\n",
            " iser Harry\n",
            " ist fromouns\n",
            " boots;, we\n",
            " I off with the in, in and any he\n",
            "iss with, we happiness daughter my to home our is the,Have hath to.Sir!\n",
            ",!man had\n",
            ",!\n",
            "Prompt: 'In '\n",
            "In  action be: wasily 'est tot\n",
            ", alleth mad mine w all\n",
            "nt's.\n",
            "Second\n",
            "CAMA\n",
            "\n",
            "an I a but\n",
            ".\n",
            "UR,,!\n",
            " green't that and,!, a!\n",
            "EL, upon, we goesor\n",
            " hours\n",
            "SP sister\n",
            "'s, subjects scarce\n",
            " Mont.\n",
            "Dou seem it soft my?\n",
            "ANTTI:A\n",
            "PET,! and?\n",
            ",!\n",
            "IONca\n",
            "Mem of I\n",
            "Prompt: 'To '\n",
            "To atter to.\n",
            "ANTERO old:What\n",
            "orse thou at, my!\n",
            "M baruck at.\n",
            ", hedgeunesR\n",
            "an is-- tone a!\n",
            "More ground, lord butplease city\n",
            " l!, begin: meanst father\n",
            " curse made what did\n",
            " news that,, mine!\n",
            " souls Lady of to fellows it\n",
            " is, you bear, bride\n",
            "apt Sh the,tis,,'d the is'd ever nor the and me heir The on mad\n",
            "Prompt: 'A '\n",
            "A  my!\n",
            "G,,!\n",
            ",,!, thee kn!\n",
            " shines and!\n",
            " work falseerer\n",
            " in ready or?\n",
            "EL,,!\n",
            "M beg!\n",
            " the of kind too,un!onworth theest,!\n",
            "ANTIO\n",
            "PAA\n",
            " special,!\n",
            "ANTIO\n",
            "Third\n",
            " paradise\n",
            "ELattering,!\n",
            "ESCCHp\n",
            " this of.\n",
            "PRO thou G,amb, master uponbrother my, bes cro, is o\n",
            "PET\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "✓ Checkpoint saved: checkpoints/checkpoint_step_500.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  10%|█         | 501/5000 [22:18<18:49:27, 15.06s/it, loss=6.5100]\u001b[A\n",
            "Training:  10%|█         | 501/5000 [22:18<18:49:27, 15.06s/it, loss=5.3863]\u001b[A\n",
            "Training:  10%|█         | 502/5000 [22:21<14:08:03, 11.31s/it, loss=5.3863]\u001b[A\n",
            "Training:  10%|█         | 502/5000 [22:21<14:08:03, 11.31s/it, loss=5.2713]\u001b[A\n",
            "Training:  10%|█         | 503/5000 [22:23<10:52:57,  8.71s/it, loss=5.2713]\u001b[A\n",
            "Training:  10%|█         | 503/5000 [22:23<10:52:57,  8.71s/it, loss=6.0751]\u001b[A\n",
            "Training:  10%|█         | 504/5000 [22:26<8:29:24,  6.80s/it, loss=6.0751] \u001b[A\n",
            "Training:  10%|█         | 504/5000 [22:26<8:29:24,  6.80s/it, loss=5.2764]\u001b[A\n",
            "Training:  10%|█         | 505/5000 [22:28<6:49:09,  5.46s/it, loss=5.2764]\u001b[A\n",
            "Training:  10%|█         | 505/5000 [22:28<6:49:09,  5.46s/it, loss=5.7256]\u001b[A\n",
            "Training:  10%|█         | 506/5000 [22:30<5:39:09,  4.53s/it, loss=5.7256]\u001b[A\n",
            "Training:  10%|█         | 506/5000 [22:30<5:39:09,  4.53s/it, loss=4.5974]\u001b[A\n",
            "Training:  10%|█         | 507/5000 [22:33<5:00:01,  4.01s/it, loss=4.5974]\u001b[A\n",
            "Training:  10%|█         | 507/5000 [22:33<5:00:01,  4.01s/it, loss=5.2600]\u001b[A\n",
            "Training:  10%|█         | 508/5000 [22:36<4:27:57,  3.58s/it, loss=5.2600]\u001b[A\n",
            "Training:  10%|█         | 508/5000 [22:36<4:27:57,  3.58s/it, loss=4.9431]\u001b[A\n",
            "Training:  10%|█         | 509/5000 [22:38<4:01:22,  3.22s/it, loss=4.9431]\u001b[A\n",
            "Training:  10%|█         | 509/5000 [22:38<4:01:22,  3.22s/it, loss=5.5618]\u001b[A\n",
            "Training:  10%|█         | 510/5000 [22:41<3:43:16,  2.98s/it, loss=5.5618]\u001b[A\n",
            "Training:  10%|█         | 510/5000 [22:41<3:43:16,  2.98s/it, loss=5.6123]\u001b[A\n",
            "Training:  10%|█         | 511/5000 [22:43<3:30:16,  2.81s/it, loss=5.6123]\u001b[A\n",
            "Training:  10%|█         | 511/5000 [22:43<3:30:16,  2.81s/it, loss=4.2288]\u001b[A\n",
            "Training:  10%|█         | 512/5000 [22:46<3:33:56,  2.86s/it, loss=4.2288]\u001b[A\n",
            "Training:  10%|█         | 512/5000 [22:46<3:33:56,  2.86s/it, loss=4.8889]\u001b[A\n",
            "Training:  10%|█         | 513/5000 [22:48<3:23:27,  2.72s/it, loss=4.8889]\u001b[A\n",
            "Training:  10%|█         | 513/5000 [22:48<3:23:27,  2.72s/it, loss=4.1719]\u001b[A\n",
            "Training:  10%|█         | 514/5000 [22:51<3:16:31,  2.63s/it, loss=4.1719]\u001b[A\n",
            "Training:  10%|█         | 514/5000 [22:51<3:16:31,  2.63s/it, loss=5.2829]\u001b[A\n",
            "Training:  10%|█         | 515/5000 [22:53<3:11:20,  2.56s/it, loss=5.2829]\u001b[A\n",
            "Training:  10%|█         | 515/5000 [22:53<3:11:20,  2.56s/it, loss=5.9721]\u001b[A\n",
            "Training:  10%|█         | 516/5000 [22:56<3:11:58,  2.57s/it, loss=5.9721]\u001b[A\n",
            "Training:  10%|█         | 516/5000 [22:56<3:11:58,  2.57s/it, loss=6.1433]\u001b[A\n",
            "Training:  10%|█         | 517/5000 [22:59<3:16:27,  2.63s/it, loss=6.1433]\u001b[A\n",
            "Training:  10%|█         | 517/5000 [22:59<3:16:27,  2.63s/it, loss=5.3257]\u001b[A\n",
            "Training:  10%|█         | 518/5000 [23:01<3:10:41,  2.55s/it, loss=5.3257]\u001b[A\n",
            "Training:  10%|█         | 518/5000 [23:01<3:10:41,  2.55s/it, loss=5.5736]\u001b[A\n",
            "Training:  10%|█         | 519/5000 [23:03<3:06:07,  2.49s/it, loss=5.5736]\u001b[A\n",
            "Training:  10%|█         | 519/5000 [23:03<3:06:07,  2.49s/it, loss=4.0018]\u001b[A\n",
            "Training:  10%|█         | 520/5000 [23:06<3:04:25,  2.47s/it, loss=4.0018]\u001b[A\n",
            "Training:  10%|█         | 520/5000 [23:06<3:04:25,  2.47s/it, loss=6.2411]\u001b[A\n",
            "Training:  10%|█         | 521/5000 [23:08<3:07:31,  2.51s/it, loss=6.2411]\u001b[A\n",
            "Training:  10%|█         | 521/5000 [23:08<3:07:31,  2.51s/it, loss=5.0719]\u001b[A\n",
            "Training:  10%|█         | 522/5000 [23:11<3:12:08,  2.57s/it, loss=5.0719]\u001b[A\n",
            "Training:  10%|█         | 522/5000 [23:11<3:12:08,  2.57s/it, loss=5.5654]\u001b[A\n",
            "Training:  10%|█         | 523/5000 [23:13<3:08:12,  2.52s/it, loss=5.5654]\u001b[A\n",
            "Training:  10%|█         | 523/5000 [23:13<3:08:12,  2.52s/it, loss=5.6667]\u001b[A\n",
            "Training:  10%|█         | 524/5000 [23:16<3:05:23,  2.49s/it, loss=5.6667]\u001b[A\n",
            "Training:  10%|█         | 524/5000 [23:16<3:05:23,  2.49s/it, loss=5.7798]\u001b[A\n",
            "Training:  10%|█         | 525/5000 [23:18<3:02:26,  2.45s/it, loss=5.7798]\u001b[A\n",
            "Training:  10%|█         | 525/5000 [23:18<3:02:26,  2.45s/it, loss=6.0632]\u001b[A\n",
            "Training:  11%|█         | 526/5000 [23:21<3:08:22,  2.53s/it, loss=6.0632]\u001b[A\n",
            "Training:  11%|█         | 526/5000 [23:21<3:08:22,  2.53s/it, loss=6.1375]\u001b[A\n",
            "Training:  11%|█         | 527/5000 [23:23<3:09:05,  2.54s/it, loss=6.1375]\u001b[A\n",
            "Training:  11%|█         | 527/5000 [23:23<3:09:05,  2.54s/it, loss=5.7959]\u001b[A\n",
            "Training:  11%|█         | 528/5000 [23:26<3:05:59,  2.50s/it, loss=5.7959]\u001b[A\n",
            "Training:  11%|█         | 528/5000 [23:26<3:05:59,  2.50s/it, loss=5.6118]\u001b[A\n",
            "Training:  11%|█         | 529/5000 [23:28<3:03:03,  2.46s/it, loss=5.6118]\u001b[A\n",
            "Training:  11%|█         | 529/5000 [23:28<3:03:03,  2.46s/it, loss=5.8989]\u001b[A\n",
            "Training:  11%|█         | 530/5000 [23:31<3:01:41,  2.44s/it, loss=5.8989]\u001b[A\n",
            "Training:  11%|█         | 530/5000 [23:31<3:01:41,  2.44s/it, loss=4.7568]\u001b[A\n",
            "Training:  11%|█         | 531/5000 [23:34<3:12:20,  2.58s/it, loss=4.7568]\u001b[A\n",
            "Training:  11%|█         | 531/5000 [23:34<3:12:20,  2.58s/it, loss=5.2716]\u001b[A\n",
            "Training:  11%|█         | 532/5000 [23:36<3:08:04,  2.53s/it, loss=5.2716]\u001b[A\n",
            "Training:  11%|█         | 532/5000 [23:36<3:08:04,  2.53s/it, loss=4.8386]\u001b[A\n",
            "Training:  11%|█         | 533/5000 [23:38<3:05:06,  2.49s/it, loss=4.8386]\u001b[A\n",
            "Training:  11%|█         | 533/5000 [23:38<3:05:06,  2.49s/it, loss=4.7377]\u001b[A\n",
            "Training:  11%|█         | 534/5000 [23:41<3:02:49,  2.46s/it, loss=4.7377]\u001b[A\n",
            "Training:  11%|█         | 534/5000 [23:41<3:02:49,  2.46s/it, loss=5.5501]\u001b[A\n",
            "Training:  11%|█         | 535/5000 [23:43<3:00:57,  2.43s/it, loss=5.5501]\u001b[A\n",
            "Training:  11%|█         | 535/5000 [23:43<3:00:57,  2.43s/it, loss=4.8426]\u001b[A\n",
            "Training:  11%|█         | 536/5000 [23:46<3:11:49,  2.58s/it, loss=4.8426]\u001b[A\n",
            "Training:  11%|█         | 536/5000 [23:46<3:11:49,  2.58s/it, loss=5.5732]\u001b[A\n",
            "Training:  11%|█         | 537/5000 [23:48<3:07:56,  2.53s/it, loss=5.5732]\u001b[A\n",
            "Training:  11%|█         | 537/5000 [23:48<3:07:56,  2.53s/it, loss=5.4548]\u001b[A\n",
            "Training:  11%|█         | 538/5000 [23:51<3:04:49,  2.49s/it, loss=5.4548]\u001b[A\n",
            "Training:  11%|█         | 538/5000 [23:51<3:04:49,  2.49s/it, loss=6.0618]\u001b[A\n",
            "Training:  11%|█         | 539/5000 [23:53<3:02:41,  2.46s/it, loss=6.0618]\u001b[A\n",
            "Training:  11%|█         | 539/5000 [23:53<3:02:41,  2.46s/it, loss=4.4424]\u001b[A\n",
            "Training:  11%|█         | 540/5000 [23:56<3:03:21,  2.47s/it, loss=4.4424]\u001b[A\n",
            "Training:  11%|█         | 540/5000 [23:56<3:03:21,  2.47s/it, loss=4.6720]\u001b[A\n",
            "Training:  11%|█         | 541/5000 [23:58<3:11:08,  2.57s/it, loss=4.6720]\u001b[A\n",
            "Training:  11%|█         | 541/5000 [23:59<3:11:08,  2.57s/it, loss=5.8304]\u001b[A\n",
            "Training:  11%|█         | 542/5000 [24:01<3:06:50,  2.51s/it, loss=5.8304]\u001b[A\n",
            "Training:  11%|█         | 542/5000 [24:01<3:06:50,  2.51s/it, loss=6.1071]\u001b[A\n",
            "Training:  11%|█         | 543/5000 [24:03<3:04:05,  2.48s/it, loss=6.1071]\u001b[A\n",
            "Training:  11%|█         | 543/5000 [24:03<3:04:05,  2.48s/it, loss=3.8162]\u001b[A\n",
            "Training:  11%|█         | 544/5000 [24:06<3:02:37,  2.46s/it, loss=3.8162]\u001b[A\n",
            "Training:  11%|█         | 544/5000 [24:06<3:02:37,  2.46s/it, loss=5.3037]\u001b[A\n",
            "Training:  11%|█         | 545/5000 [24:08<3:07:22,  2.52s/it, loss=5.3037]\u001b[A\n",
            "Training:  11%|█         | 545/5000 [24:08<3:07:22,  2.52s/it, loss=5.5948]\u001b[A\n",
            "Training:  11%|█         | 546/5000 [24:11<3:10:32,  2.57s/it, loss=5.5948]\u001b[A\n",
            "Training:  11%|█         | 546/5000 [24:11<3:10:32,  2.57s/it, loss=5.8750]\u001b[A\n",
            "Training:  11%|█         | 547/5000 [24:13<3:06:23,  2.51s/it, loss=5.8750]\u001b[A\n",
            "Training:  11%|█         | 547/5000 [24:13<3:06:23,  2.51s/it, loss=5.3341]\u001b[A\n",
            "Training:  11%|█         | 548/5000 [24:16<3:03:07,  2.47s/it, loss=5.3341]\u001b[A\n",
            "Training:  11%|█         | 548/5000 [24:16<3:03:07,  2.47s/it, loss=5.3268]\u001b[A\n",
            "Training:  11%|█         | 549/5000 [24:18<3:00:52,  2.44s/it, loss=5.3268]\u001b[A\n",
            "Training:  11%|█         | 549/5000 [24:18<3:00:52,  2.44s/it, loss=5.6183]\u001b[A\n",
            "Training:  11%|█         | 550/5000 [24:21<3:08:25,  2.54s/it, loss=5.6183]\u001b[A\n",
            "Training:  11%|█         | 550/5000 [24:21<3:08:25,  2.54s/it, loss=5.0210]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 550 ---\n",
            "Prompt: 'The '\n",
            "The , head this; not upon land death\n",
            "Too that will w England in distress the\n",
            " answer love\n",
            "est our company him this gitor hell\n",
            " not in\n",
            " hate, in rip toroke thou peace\n",
            " I, imprisonment her, faith the, Lord heavy.Give the brown: thouall contrary hear me\n",
            " oneels hath by youth gar red here in fair!God you were I, is repro Richard house\n",
            " thou's, to\n",
            " look in, would with is,,, you with\n",
            "Prompt: 'In '\n",
            "In , is pains of!\n",
            "K RARD:C news\n",
            " sights, Richmond ens\n",
            " in of despair\n",
            " me my, faith most neck, aitor\n",
            " scept,-,reat my isness too\n",
            " kingdom, gracious; both let friends bed Court,Then.MQUE EL EL ELerer\n",
            "LE wear met the of sailor, with advice some lifeW:\n",
            " shall myorrow conf for consequence post thanks stay I thou! I not,ute coming lie is, keep;Th, to\n",
            "Prompt: 'To '\n",
            "To  Here a. duke to been, met'd?The.\n",
            " near my, me their and courtesy\n",
            " subject-orrowhere that theingedWith!N,And been sweet;Then should hard'd tender,ves painted,That by.\n",
            " triumph thy; I be'd in post\n",
            " towards liberty who our meaning but gar'd nightAff, epit of, would were died worldFrom fool the, his\n",
            " thou-orrow bear is is, f? my soul may, is sovereign and not\n",
            "Prompt: 'A '\n",
            "A ly else ten peers and's I out it\n",
            " buckle theORK\n",
            "QUEates for again things fast grave\n",
            " friends the, suggestion'd\n",
            "dition some, a'd sing aining him\n",
            " my-orrow consequence and purpose: love.\n",
            "QUE God a, what, myment who come burns\n",
            " princ my hath, the isitor e omin; shall reeds Vaugh way\n",
            " be to, will the of yet a bed offord my: it not, tra cousin so my; cryAy\n",
            "able\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  11%|█         | 551/5000 [24:36<7:58:19,  6.45s/it, loss=5.0210]\u001b[A\n",
            "Training:  11%|█         | 551/5000 [24:37<7:58:19,  6.45s/it, loss=5.3870]\u001b[A\n",
            "Training:  11%|█         | 552/5000 [24:39<6:27:29,  5.23s/it, loss=5.3870]\u001b[A\n",
            "Training:  11%|█         | 552/5000 [24:39<6:27:29,  5.23s/it, loss=5.9750]\u001b[A\n",
            "Training:  11%|█         | 553/5000 [24:41<5:24:42,  4.38s/it, loss=5.9750]\u001b[A\n",
            "Training:  11%|█         | 553/5000 [24:41<5:24:42,  4.38s/it, loss=5.8946]\u001b[A\n",
            "Training:  11%|█         | 554/5000 [24:44<4:44:36,  3.84s/it, loss=5.8946]\u001b[A\n",
            "Training:  11%|█         | 554/5000 [24:44<4:44:36,  3.84s/it, loss=4.9941]\u001b[A\n",
            "Training:  11%|█         | 555/5000 [24:47<4:20:49,  3.52s/it, loss=4.9941]\u001b[A\n",
            "Training:  11%|█         | 555/5000 [24:47<4:20:49,  3.52s/it, loss=4.7870]\u001b[A\n",
            "Training:  11%|█         | 556/5000 [24:49<3:55:31,  3.18s/it, loss=4.7870]\u001b[A\n",
            "Training:  11%|█         | 556/5000 [24:49<3:55:31,  3.18s/it, loss=4.9614]\u001b[A\n",
            "Training:  11%|█         | 557/5000 [24:51<3:37:45,  2.94s/it, loss=4.9614]\u001b[A\n",
            "Training:  11%|█         | 557/5000 [24:51<3:37:45,  2.94s/it, loss=4.3314]\u001b[A\n",
            "Training:  11%|█         | 558/5000 [24:54<3:25:35,  2.78s/it, loss=4.3314]\u001b[A\n",
            "Training:  11%|█         | 558/5000 [24:54<3:25:35,  2.78s/it, loss=4.8876]\u001b[A\n",
            "Training:  11%|█         | 559/5000 [24:57<3:24:20,  2.76s/it, loss=4.8876]\u001b[A\n",
            "Training:  11%|█         | 559/5000 [24:57<3:24:20,  2.76s/it, loss=5.3025]\u001b[A\n",
            "Training:  11%|█         | 560/5000 [24:59<3:21:14,  2.72s/it, loss=5.3025]\u001b[A\n",
            "Training:  11%|█         | 560/5000 [24:59<3:21:14,  2.72s/it, loss=5.9662]\u001b[A\n",
            "Training:  11%|█         | 561/5000 [25:02<3:14:14,  2.63s/it, loss=5.9662]\u001b[A\n",
            "Training:  11%|█         | 561/5000 [25:02<3:14:14,  2.63s/it, loss=4.5364]\u001b[A\n",
            "Training:  11%|█         | 562/5000 [25:04<3:08:57,  2.55s/it, loss=4.5364]\u001b[A\n",
            "Training:  11%|█         | 562/5000 [25:04<3:08:57,  2.55s/it, loss=5.5387]\u001b[A\n",
            "Training:  11%|█▏        | 563/5000 [25:06<3:05:50,  2.51s/it, loss=5.5387]\u001b[A\n",
            "Training:  11%|█▏        | 563/5000 [25:06<3:05:50,  2.51s/it, loss=4.0864]\u001b[A\n",
            "Training:  11%|█▏        | 564/5000 [25:09<3:15:03,  2.64s/it, loss=4.0864]\u001b[A\n",
            "Training:  11%|█▏        | 564/5000 [25:09<3:15:03,  2.64s/it, loss=5.7049]\u001b[A\n",
            "Training:  11%|█▏        | 565/5000 [25:12<3:10:28,  2.58s/it, loss=5.7049]\u001b[A\n",
            "Training:  11%|█▏        | 565/5000 [25:12<3:10:28,  2.58s/it, loss=5.8401]\u001b[A\n",
            "Training:  11%|█▏        | 566/5000 [25:14<3:05:42,  2.51s/it, loss=5.8401]\u001b[A\n",
            "Training:  11%|█▏        | 566/5000 [25:14<3:05:42,  2.51s/it, loss=4.9291]\u001b[A\n",
            "Training:  11%|█▏        | 567/5000 [25:16<3:02:42,  2.47s/it, loss=4.9291]\u001b[A\n",
            "Training:  11%|█▏        | 567/5000 [25:16<3:02:42,  2.47s/it, loss=4.7591]\u001b[A\n",
            "Training:  11%|█▏        | 568/5000 [25:19<2:59:37,  2.43s/it, loss=4.7591]\u001b[A\n",
            "Training:  11%|█▏        | 568/5000 [25:19<2:59:37,  2.43s/it, loss=5.1461]\u001b[A\n",
            "Training:  11%|█▏        | 569/5000 [25:22<3:08:42,  2.56s/it, loss=5.1461]\u001b[A\n",
            "Training:  11%|█▏        | 569/5000 [25:22<3:08:42,  2.56s/it, loss=5.3746]\u001b[A\n",
            "Training:  11%|█▏        | 570/5000 [25:24<3:03:42,  2.49s/it, loss=5.3746]\u001b[A\n",
            "Training:  11%|█▏        | 570/5000 [25:24<3:03:42,  2.49s/it, loss=5.4443]\u001b[A\n",
            "Training:  11%|█▏        | 571/5000 [25:26<2:59:51,  2.44s/it, loss=5.4443]\u001b[A\n",
            "Training:  11%|█▏        | 571/5000 [25:26<2:59:51,  2.44s/it, loss=4.9750]\u001b[A\n",
            "Training:  11%|█▏        | 572/5000 [25:29<2:56:45,  2.40s/it, loss=4.9750]\u001b[A\n",
            "Training:  11%|█▏        | 572/5000 [25:29<2:56:45,  2.40s/it, loss=4.5722]\u001b[A\n",
            "Training:  11%|█▏        | 573/5000 [25:31<2:54:32,  2.37s/it, loss=4.5722]\u001b[A\n",
            "Training:  11%|█▏        | 573/5000 [25:31<2:54:32,  2.37s/it, loss=5.0535]\u001b[A\n",
            "Training:  11%|█▏        | 574/5000 [25:34<3:05:53,  2.52s/it, loss=5.0535]\u001b[A\n",
            "Training:  11%|█▏        | 574/5000 [25:34<3:05:53,  2.52s/it, loss=5.2729]\u001b[A\n",
            "Training:  12%|█▏        | 575/5000 [25:36<3:01:42,  2.46s/it, loss=5.2729]\u001b[A\n",
            "Training:  12%|█▏        | 575/5000 [25:36<3:01:42,  2.46s/it, loss=5.5423]\u001b[A\n",
            "Training:  12%|█▏        | 576/5000 [25:38<2:59:02,  2.43s/it, loss=5.5423]\u001b[A\n",
            "Training:  12%|█▏        | 576/5000 [25:38<2:59:02,  2.43s/it, loss=5.6489]\u001b[A\n",
            "Training:  12%|█▏        | 577/5000 [25:41<2:57:03,  2.40s/it, loss=5.6489]\u001b[A\n",
            "Training:  12%|█▏        | 577/5000 [25:41<2:57:03,  2.40s/it, loss=4.6944]\u001b[A\n",
            "Training:  12%|█▏        | 578/5000 [25:43<2:57:57,  2.41s/it, loss=4.6944]\u001b[A\n",
            "Training:  12%|█▏        | 578/5000 [25:43<2:57:57,  2.41s/it, loss=5.1015]\u001b[A\n",
            "Training:  12%|█▏        | 579/5000 [25:46<3:04:50,  2.51s/it, loss=5.1015]\u001b[A\n",
            "Training:  12%|█▏        | 579/5000 [25:46<3:04:50,  2.51s/it, loss=4.8614]\u001b[A\n",
            "Training:  12%|█▏        | 580/5000 [25:48<3:01:21,  2.46s/it, loss=4.8614]\u001b[A\n",
            "Training:  12%|█▏        | 580/5000 [25:48<3:01:21,  2.46s/it, loss=4.3006]\u001b[A\n",
            "Training:  12%|█▏        | 581/5000 [25:51<2:57:24,  2.41s/it, loss=4.3006]\u001b[A\n",
            "Training:  12%|█▏        | 581/5000 [25:51<2:57:24,  2.41s/it, loss=4.7416]\u001b[A\n",
            "Training:  12%|█▏        | 582/5000 [25:53<2:53:22,  2.35s/it, loss=4.7416]\u001b[A\n",
            "Training:  12%|█▏        | 582/5000 [25:53<2:53:22,  2.35s/it, loss=5.4750]\u001b[A\n",
            "Training:  12%|█▏        | 583/5000 [25:55<2:53:29,  2.36s/it, loss=5.4750]\u001b[A\n",
            "Training:  12%|█▏        | 583/5000 [25:55<2:53:29,  2.36s/it, loss=5.3138]\u001b[A\n",
            "Training:  12%|█▏        | 584/5000 [25:58<3:00:21,  2.45s/it, loss=5.3138]\u001b[A\n",
            "Training:  12%|█▏        | 584/5000 [25:58<3:00:21,  2.45s/it, loss=4.7031]\u001b[A\n",
            "Training:  12%|█▏        | 585/5000 [26:00<2:55:42,  2.39s/it, loss=4.7031]\u001b[A\n",
            "Training:  12%|█▏        | 585/5000 [26:00<2:55:42,  2.39s/it, loss=4.8167]\u001b[A\n",
            "Training:  12%|█▏        | 586/5000 [26:02<2:53:00,  2.35s/it, loss=4.8167]\u001b[A\n",
            "Training:  12%|█▏        | 586/5000 [26:02<2:53:00,  2.35s/it, loss=5.5209]\u001b[A\n",
            "Training:  12%|█▏        | 587/5000 [26:05<2:50:51,  2.32s/it, loss=5.5209]\u001b[A\n",
            "Training:  12%|█▏        | 587/5000 [26:05<2:50:51,  2.32s/it, loss=5.9762]\u001b[A\n",
            "Training:  12%|█▏        | 588/5000 [26:07<2:52:18,  2.34s/it, loss=5.9762]\u001b[A\n",
            "Training:  12%|█▏        | 588/5000 [26:07<2:52:18,  2.34s/it, loss=5.5935]\u001b[A\n",
            "Training:  12%|█▏        | 589/5000 [26:10<2:59:04,  2.44s/it, loss=5.5935]\u001b[A\n",
            "Training:  12%|█▏        | 589/5000 [26:10<2:59:04,  2.44s/it, loss=5.9961]\u001b[A\n",
            "Training:  12%|█▏        | 590/5000 [26:12<2:55:20,  2.39s/it, loss=5.9961]\u001b[A\n",
            "Training:  12%|█▏        | 590/5000 [26:12<2:55:20,  2.39s/it, loss=5.9118]\u001b[A\n",
            "Training:  12%|█▏        | 591/5000 [26:14<2:52:35,  2.35s/it, loss=5.9118]\u001b[A\n",
            "Training:  12%|█▏        | 591/5000 [26:14<2:52:35,  2.35s/it, loss=4.0132]\u001b[A\n",
            "Training:  12%|█▏        | 592/5000 [26:16<2:49:42,  2.31s/it, loss=4.0132]\u001b[A\n",
            "Training:  12%|█▏        | 592/5000 [26:16<2:49:42,  2.31s/it, loss=5.3830]\u001b[A\n",
            "Training:  12%|█▏        | 593/5000 [26:19<2:50:09,  2.32s/it, loss=5.3830]\u001b[A\n",
            "Training:  12%|█▏        | 593/5000 [26:19<2:50:09,  2.32s/it, loss=5.5956]\u001b[A\n",
            "Training:  12%|█▏        | 594/5000 [26:21<2:57:43,  2.42s/it, loss=5.5956]\u001b[A\n",
            "Training:  12%|█▏        | 594/5000 [26:21<2:57:43,  2.42s/it, loss=5.1894]\u001b[A\n",
            "Training:  12%|█▏        | 595/5000 [26:24<2:53:46,  2.37s/it, loss=5.1894]\u001b[A\n",
            "Training:  12%|█▏        | 595/5000 [26:24<2:53:46,  2.37s/it, loss=4.4617]\u001b[A\n",
            "Training:  12%|█▏        | 596/5000 [26:26<2:50:59,  2.33s/it, loss=4.4617]\u001b[A\n",
            "Training:  12%|█▏        | 596/5000 [26:26<2:50:59,  2.33s/it, loss=5.2021]\u001b[A\n",
            "Training:  12%|█▏        | 597/5000 [26:28<2:49:12,  2.31s/it, loss=5.2021]\u001b[A\n",
            "Training:  12%|█▏        | 597/5000 [26:28<2:49:12,  2.31s/it, loss=5.7296]\u001b[A\n",
            "Training:  12%|█▏        | 598/5000 [26:30<2:48:05,  2.29s/it, loss=5.7296]\u001b[A\n",
            "Training:  12%|█▏        | 598/5000 [26:30<2:48:05,  2.29s/it, loss=5.1096]\u001b[A\n",
            "Training:  12%|█▏        | 599/5000 [26:33<2:57:49,  2.42s/it, loss=5.1096]\u001b[A\n",
            "Training:  12%|█▏        | 599/5000 [26:33<2:57:49,  2.42s/it, loss=5.1800]\u001b[A\n",
            "Training:  12%|█▏        | 600/5000 [26:35<2:54:07,  2.37s/it, loss=5.1800]\u001b[A\n",
            "Training:  12%|█▏        | 600/5000 [26:35<2:54:07,  2.37s/it, loss=4.9507]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 600 ---\n",
            "Prompt: 'The '\n",
            "The  is aip.\n",
            "WAR, do,, a,,'d wh,, p shalt' seen'd?\n",
            "T Warwick in in mighty and: Warwick not from, used' follow.\n",
            "WARICK\n",
            "AND me:\n",
            " things, am, Clifford that be VI\n",
            ",Theing witness ne thy's hither my fromague\n",
            "am pardon,,, I not,, am, thou thy to mine he day hast leave the beed his be\n",
            " calls of af his than you,\n",
            "Prompt: 'In '\n",
            "In , come will bred to.\n",
            "WARICK\n",
            "WARER:The of, hefore none the.\n",
            "CLENCE\n",
            "QUE MARAR:Iee my,, will itHave thee past.\n",
            "NB clear!, I queen but virtue let I, in e say I world March\n",
            "K EDARD\n",
            "Having,,, me the lord\n",
            "RARD\n",
            "First you y's lord what I it;, me not thatst thy than:My is may be which\n",
            "WAR his\n",
            "Prompt: 'To '\n",
            "To 'dud he or father?\n",
            "Kinks crown a to, a of lord\n",
            " as be to me at to 'as she such.\n",
            "WARICK\n",
            "WARICK\n",
            "RARD\n",
            "K EDARD\n",
            "WARICK\n",
            " KRYORD\n",
            "WARICK\n",
            "Y:' shalt shall so to you me?\n",
            "WARICK\n",
            " wind:Your I this and, my is words\n",
            ", it leave untoix to thus resolved;,, am my son death andeliff well such,!,\n",
            "Prompt: 'A '\n",
            "A  ofour my to shepherd\n",
            " all world his and; a therein\n",
            " hehers stay thou thesear thy;, think l\n",
            " princ was mine for queen for war and.\n",
            "K EDARD\n",
            "GUCER:Call my's let stay,'s, hast.\n",
            "ou's's be or, up must and the's what's and'd cause your soul thy to way your.\n",
            "WARICK\n",
            "WARICK\n",
            "WAR what cease mother the lives myful deceit Come are your's my's\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  12%|█▏        | 601/5000 [26:50<7:24:39,  6.06s/it, loss=4.9507]\u001b[A\n",
            "Training:  12%|█▏        | 601/5000 [26:50<7:24:39,  6.06s/it, loss=4.3292]\u001b[A\n",
            "Training:  12%|█▏        | 602/5000 [26:52<6:00:18,  4.92s/it, loss=4.3292]\u001b[A\n",
            "Training:  12%|█▏        | 602/5000 [26:52<6:00:18,  4.92s/it, loss=3.9060]\u001b[A\n",
            "Training:  12%|█▏        | 603/5000 [26:55<5:05:58,  4.18s/it, loss=3.9060]\u001b[A\n",
            "Training:  12%|█▏        | 603/5000 [26:55<5:05:58,  4.18s/it, loss=5.1196]\u001b[A\n",
            "Training:  12%|█▏        | 604/5000 [26:57<4:30:32,  3.69s/it, loss=5.1196]\u001b[A\n",
            "Training:  12%|█▏        | 604/5000 [26:57<4:30:32,  3.69s/it, loss=4.2891]\u001b[A\n",
            "Training:  12%|█▏        | 605/5000 [27:00<3:58:10,  3.25s/it, loss=4.2891]\u001b[A\n",
            "Training:  12%|█▏        | 605/5000 [27:00<3:58:10,  3.25s/it, loss=5.8955]\u001b[A\n",
            "Training:  12%|█▏        | 606/5000 [27:02<3:35:43,  2.95s/it, loss=5.8955]\u001b[A\n",
            "Training:  12%|█▏        | 606/5000 [27:02<3:35:43,  2.95s/it, loss=6.4807]\u001b[A\n",
            "Training:  12%|█▏        | 607/5000 [27:04<3:20:06,  2.73s/it, loss=6.4807]\u001b[A\n",
            "Training:  12%|█▏        | 607/5000 [27:04<3:20:06,  2.73s/it, loss=5.7882]\u001b[A\n",
            "Training:  12%|█▏        | 608/5000 [27:06<3:11:52,  2.62s/it, loss=5.7882]\u001b[A\n",
            "Training:  12%|█▏        | 608/5000 [27:06<3:11:52,  2.62s/it, loss=5.6745]\u001b[A\n",
            "Training:  12%|█▏        | 609/5000 [27:09<3:12:04,  2.62s/it, loss=5.6745]\u001b[A\n",
            "Training:  12%|█▏        | 609/5000 [27:09<3:12:04,  2.62s/it, loss=5.3152]\u001b[A\n",
            "Training:  12%|█▏        | 610/5000 [27:11<3:03:12,  2.50s/it, loss=5.3152]\u001b[A\n",
            "Training:  12%|█▏        | 610/5000 [27:11<3:03:12,  2.50s/it, loss=5.7427]\u001b[A\n",
            "Training:  12%|█▏        | 611/5000 [27:13<2:57:30,  2.43s/it, loss=5.7427]\u001b[A\n",
            "Training:  12%|█▏        | 611/5000 [27:13<2:57:30,  2.43s/it, loss=5.5463]\u001b[A\n",
            "Training:  12%|█▏        | 612/5000 [27:16<2:53:55,  2.38s/it, loss=5.5463]\u001b[A\n",
            "Training:  12%|█▏        | 612/5000 [27:16<2:53:55,  2.38s/it, loss=6.1720]\u001b[A\n",
            "Training:  12%|█▏        | 613/5000 [27:18<2:52:48,  2.36s/it, loss=6.1720]\u001b[A\n",
            "Training:  12%|█▏        | 613/5000 [27:18<2:52:48,  2.36s/it, loss=5.6161]\u001b[A\n",
            "Training:  12%|█▏        | 614/5000 [27:21<2:58:43,  2.44s/it, loss=5.6161]\u001b[A\n",
            "Training:  12%|█▏        | 614/5000 [27:21<2:58:43,  2.44s/it, loss=5.7448]\u001b[A\n",
            "Training:  12%|█▏        | 615/5000 [27:23<2:54:39,  2.39s/it, loss=5.7448]\u001b[A\n",
            "Training:  12%|█▏        | 615/5000 [27:23<2:54:39,  2.39s/it, loss=5.8921]\u001b[A\n",
            "Training:  12%|█▏        | 616/5000 [27:25<2:51:24,  2.35s/it, loss=5.8921]\u001b[A\n",
            "Training:  12%|█▏        | 616/5000 [27:25<2:51:24,  2.35s/it, loss=5.4061]\u001b[A\n",
            "Training:  12%|█▏        | 617/5000 [27:27<2:48:54,  2.31s/it, loss=5.4061]\u001b[A\n",
            "Training:  12%|█▏        | 617/5000 [27:27<2:48:54,  2.31s/it, loss=5.5923]\u001b[A\n",
            "Training:  12%|█▏        | 618/5000 [27:30<2:48:31,  2.31s/it, loss=5.5923]\u001b[A\n",
            "Training:  12%|█▏        | 618/5000 [27:30<2:48:31,  2.31s/it, loss=4.9906]\u001b[A\n",
            "Training:  12%|█▏        | 619/5000 [27:32<2:56:58,  2.42s/it, loss=4.9906]\u001b[A\n",
            "Training:  12%|█▏        | 619/5000 [27:32<2:56:58,  2.42s/it, loss=5.7214]\u001b[A\n",
            "Training:  12%|█▏        | 620/5000 [27:35<2:53:11,  2.37s/it, loss=5.7214]\u001b[A\n",
            "Training:  12%|█▏        | 620/5000 [27:35<2:53:11,  2.37s/it, loss=5.3885]\u001b[A\n",
            "Training:  12%|█▏        | 621/5000 [27:37<2:49:50,  2.33s/it, loss=5.3885]\u001b[A\n",
            "Training:  12%|█▏        | 621/5000 [27:37<2:49:50,  2.33s/it, loss=5.7708]\u001b[A\n",
            "Training:  12%|█▏        | 622/5000 [27:39<2:48:47,  2.31s/it, loss=5.7708]\u001b[A\n",
            "Training:  12%|█▏        | 622/5000 [27:39<2:48:47,  2.31s/it, loss=5.7031]\u001b[A\n",
            "Training:  12%|█▏        | 623/5000 [27:41<2:48:39,  2.31s/it, loss=5.7031]\u001b[A\n",
            "Training:  12%|█▏        | 623/5000 [27:42<2:48:39,  2.31s/it, loss=6.3750]\u001b[A\n",
            "Training:  12%|█▏        | 624/5000 [27:44<2:58:11,  2.44s/it, loss=6.3750]\u001b[A\n",
            "Training:  12%|█▏        | 624/5000 [27:44<2:58:11,  2.44s/it, loss=5.2296]\u001b[A\n",
            "Training:  12%|█▎        | 625/5000 [27:46<2:53:39,  2.38s/it, loss=5.2296]\u001b[A\n",
            "Training:  12%|█▎        | 625/5000 [27:46<2:53:39,  2.38s/it, loss=4.9037]\u001b[A\n",
            "Training:  13%|█▎        | 626/5000 [27:49<2:50:39,  2.34s/it, loss=4.9037]\u001b[A\n",
            "Training:  13%|█▎        | 626/5000 [27:49<2:50:39,  2.34s/it, loss=5.0437]\u001b[A\n",
            "Training:  13%|█▎        | 627/5000 [27:51<2:48:52,  2.32s/it, loss=5.0437]\u001b[A\n",
            "Training:  13%|█▎        | 627/5000 [27:51<2:48:52,  2.32s/it, loss=5.3662]\u001b[A\n",
            "Training:  13%|█▎        | 628/5000 [27:53<2:46:46,  2.29s/it, loss=5.3662]\u001b[A\n",
            "Training:  13%|█▎        | 628/5000 [27:53<2:46:46,  2.29s/it, loss=4.9352]\u001b[A\n",
            "Training:  13%|█▎        | 629/5000 [27:56<2:57:11,  2.43s/it, loss=4.9352]\u001b[A\n",
            "Training:  13%|█▎        | 629/5000 [27:56<2:57:11,  2.43s/it, loss=5.4356]\u001b[A\n",
            "Training:  13%|█▎        | 630/5000 [27:58<2:52:41,  2.37s/it, loss=5.4356]\u001b[A\n",
            "Training:  13%|█▎        | 630/5000 [27:58<2:52:41,  2.37s/it, loss=6.0522]\u001b[A\n",
            "Training:  13%|█▎        | 631/5000 [28:00<2:49:49,  2.33s/it, loss=6.0522]\u001b[A\n",
            "Training:  13%|█▎        | 631/5000 [28:00<2:49:49,  2.33s/it, loss=4.7844]\u001b[A\n",
            "Training:  13%|█▎        | 632/5000 [28:03<2:47:26,  2.30s/it, loss=4.7844]\u001b[A\n",
            "Training:  13%|█▎        | 632/5000 [28:03<2:47:26,  2.30s/it, loss=5.3876]\u001b[A\n",
            "Training:  13%|█▎        | 633/5000 [28:05<2:46:02,  2.28s/it, loss=5.3876]\u001b[A\n",
            "Training:  13%|█▎        | 633/5000 [28:05<2:46:02,  2.28s/it, loss=4.1359]\u001b[A\n",
            "Training:  13%|█▎        | 634/5000 [28:08<2:56:55,  2.43s/it, loss=4.1359]\u001b[A\n",
            "Training:  13%|█▎        | 634/5000 [28:08<2:56:55,  2.43s/it, loss=4.9486]\u001b[A\n",
            "Training:  13%|█▎        | 635/5000 [28:10<2:53:06,  2.38s/it, loss=4.9486]\u001b[A\n",
            "Training:  13%|█▎        | 635/5000 [28:10<2:53:06,  2.38s/it, loss=4.3442]\u001b[A\n",
            "Training:  13%|█▎        | 636/5000 [28:12<2:49:46,  2.33s/it, loss=4.3442]\u001b[A\n",
            "Training:  13%|█▎        | 636/5000 [28:12<2:49:46,  2.33s/it, loss=3.8596]\u001b[A\n",
            "Training:  13%|█▎        | 637/5000 [28:14<2:47:52,  2.31s/it, loss=3.8596]\u001b[A\n",
            "Training:  13%|█▎        | 637/5000 [28:14<2:47:52,  2.31s/it, loss=4.9561]\u001b[A\n",
            "Training:  13%|█▎        | 638/5000 [28:17<2:47:26,  2.30s/it, loss=4.9561]\u001b[A\n",
            "Training:  13%|█▎        | 638/5000 [28:17<2:47:26,  2.30s/it, loss=4.7233]\u001b[A\n",
            "Training:  13%|█▎        | 639/5000 [28:19<2:57:09,  2.44s/it, loss=4.7233]\u001b[A\n",
            "Training:  13%|█▎        | 639/5000 [28:19<2:57:09,  2.44s/it, loss=5.5587]\u001b[A\n",
            "Training:  13%|█▎        | 640/5000 [28:22<2:52:43,  2.38s/it, loss=5.5587]\u001b[A\n",
            "Training:  13%|█▎        | 640/5000 [28:22<2:52:43,  2.38s/it, loss=5.5534]\u001b[A\n",
            "Training:  13%|█▎        | 641/5000 [28:24<2:49:50,  2.34s/it, loss=5.5534]\u001b[A\n",
            "Training:  13%|█▎        | 641/5000 [28:24<2:49:50,  2.34s/it, loss=5.7013]\u001b[A\n",
            "Training:  13%|█▎        | 642/5000 [28:26<2:48:00,  2.31s/it, loss=5.7013]\u001b[A\n",
            "Training:  13%|█▎        | 642/5000 [28:26<2:48:00,  2.31s/it, loss=6.1879]\u001b[A\n",
            "Training:  13%|█▎        | 643/5000 [28:28<2:46:12,  2.29s/it, loss=6.1879]\u001b[A\n",
            "Training:  13%|█▎        | 643/5000 [28:28<2:46:12,  2.29s/it, loss=5.2232]\u001b[A\n",
            "Training:  13%|█▎        | 644/5000 [28:31<2:56:18,  2.43s/it, loss=5.2232]\u001b[A\n",
            "Training:  13%|█▎        | 644/5000 [28:31<2:56:18,  2.43s/it, loss=6.2482]\u001b[A\n",
            "Training:  13%|█▎        | 645/5000 [28:33<2:51:37,  2.36s/it, loss=6.2482]\u001b[A\n",
            "Training:  13%|█▎        | 645/5000 [28:33<2:51:37,  2.36s/it, loss=5.4329]\u001b[A\n",
            "Training:  13%|█▎        | 646/5000 [28:36<2:48:28,  2.32s/it, loss=5.4329]\u001b[A\n",
            "Training:  13%|█▎        | 646/5000 [28:36<2:48:28,  2.32s/it, loss=5.1144]\u001b[A\n",
            "Training:  13%|█▎        | 647/5000 [28:38<2:46:03,  2.29s/it, loss=5.1144]\u001b[A\n",
            "Training:  13%|█▎        | 647/5000 [28:38<2:46:03,  2.29s/it, loss=4.7771]\u001b[A\n",
            "Training:  13%|█▎        | 648/5000 [28:40<2:45:39,  2.28s/it, loss=4.7771]\u001b[A\n",
            "Training:  13%|█▎        | 648/5000 [28:40<2:45:39,  2.28s/it, loss=4.6212]\u001b[A\n",
            "Training:  13%|█▎        | 649/5000 [28:43<2:56:06,  2.43s/it, loss=4.6212]\u001b[A\n",
            "Training:  13%|█▎        | 649/5000 [28:43<2:56:06,  2.43s/it, loss=5.1692]\u001b[A\n",
            "Training:  13%|█▎        | 650/5000 [28:45<2:52:25,  2.38s/it, loss=5.1692]\u001b[A\n",
            "Training:  13%|█▎        | 650/5000 [28:45<2:52:25,  2.38s/it, loss=5.4149]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 650 ---\n",
            "Prompt: 'The '\n",
            "The , will not, this, am\n",
            " friends be, we; he, here you a.What he come you\n",
            ", you contrary youay your,, come, you, look out\n",
            ",, my, your, I, being, is right\n",
            " I w death Kath of get,, pray\n",
            " art to to; you her; I tell one and,A\n",
            "ir more mying un are to, me to,, is,'s mad as, I you well,,,\n",
            "Prompt: 'In '\n",
            "In  shall toAD\n",
            "PONA dispatch my: I do it let\n",
            " here, secret for, you warm,ay you sir\n",
            " this it so me of duty: shall,,, remedy\n",
            " you me my.\n",
            "Prov:\n",
            " what visit, to, will good well, I hear me did you be for.\n",
            "TRIO\n",
            " motion,,rah no I know to come I you.\n",
            ", not my.\n",
            "KARI:Be a is book the.\n",
            "L how the\n",
            "\n",
            "Prompt: 'To '\n",
            "To  can debt mine when of, to,ior:'s\n",
            " twenty, eyes I my,, by father,.\n",
            "A you, fair,ark,You wh I: it\n",
            ", lord or to contrary\n",
            " I more until her., you are her, the, I so: to my?\n",
            "TRIO\n",
            " all, lord I gate still it my, I,, he.\n",
            " brother comfort that a, am, me, bes not off thee not, go then.\n",
            ",\n",
            "Prompt: 'A '\n",
            "A ,tis toian, thy is'd\n",
            " you asingale I,,, I,!\n",
            "UM,,, Esc, you aboutio sir\n",
            " isNA the's.\n",
            "F, lord much:O I no, word not my.\n",
            " say crave my,'s, you,, know is mind the\n",
            " I' a, me I you, wood Kath you, for strange,!\n",
            "R,, I,'ll you murder,rum,,, this's, am,\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  13%|█▎        | 651/5000 [29:00<7:18:17,  6.05s/it, loss=5.4149]\u001b[A\n",
            "Training:  13%|█▎        | 651/5000 [29:00<7:18:17,  6.05s/it, loss=4.4856]\u001b[A\n",
            "Training:  13%|█▎        | 652/5000 [29:02<5:55:23,  4.90s/it, loss=4.4856]\u001b[A\n",
            "Training:  13%|█▎        | 652/5000 [29:02<5:55:23,  4.90s/it, loss=5.1898]\u001b[A\n",
            "Training:  13%|█▎        | 653/5000 [29:04<4:57:59,  4.11s/it, loss=5.1898]\u001b[A\n",
            "Training:  13%|█▎        | 653/5000 [29:04<4:57:59,  4.11s/it, loss=4.5597]\u001b[A\n",
            "Training:  13%|█▎        | 654/5000 [29:07<4:27:31,  3.69s/it, loss=4.5597]\u001b[A\n",
            "Training:  13%|█▎        | 654/5000 [29:07<4:27:31,  3.69s/it, loss=5.8290]\u001b[A\n",
            "Training:  13%|█▎        | 655/5000 [29:09<3:56:50,  3.27s/it, loss=5.8290]\u001b[A\n",
            "Training:  13%|█▎        | 655/5000 [29:09<3:56:50,  3.27s/it, loss=4.9677]\u001b[A\n",
            "Training:  13%|█▎        | 656/5000 [29:11<3:33:57,  2.96s/it, loss=4.9677]\u001b[A\n",
            "Training:  13%|█▎        | 656/5000 [29:11<3:33:57,  2.96s/it, loss=4.5575]\u001b[A\n",
            "Training:  13%|█▎        | 657/5000 [29:14<3:18:54,  2.75s/it, loss=4.5575]\u001b[A\n",
            "Training:  13%|█▎        | 657/5000 [29:14<3:18:54,  2.75s/it, loss=4.0301]\u001b[A\n",
            "Training:  13%|█▎        | 658/5000 [29:16<3:08:04,  2.60s/it, loss=4.0301]\u001b[A\n",
            "Training:  13%|█▎        | 658/5000 [29:16<3:08:04,  2.60s/it, loss=4.9147]\u001b[A\n",
            "Training:  13%|█▎        | 659/5000 [29:19<3:12:03,  2.65s/it, loss=4.9147]\u001b[A\n",
            "Training:  13%|█▎        | 659/5000 [29:19<3:12:03,  2.65s/it, loss=4.5889]\u001b[A\n",
            "Training:  13%|█▎        | 660/5000 [29:21<3:02:50,  2.53s/it, loss=4.5889]\u001b[A\n",
            "Training:  13%|█▎        | 660/5000 [29:21<3:02:50,  2.53s/it, loss=3.8164]\u001b[A\n",
            "Training:  13%|█▎        | 661/5000 [29:23<2:56:01,  2.43s/it, loss=3.8164]\u001b[A\n",
            "Training:  13%|█▎        | 661/5000 [29:23<2:56:01,  2.43s/it, loss=5.8136]\u001b[A\n",
            "Training:  13%|█▎        | 662/5000 [29:25<2:51:44,  2.38s/it, loss=5.8136]\u001b[A\n",
            "Training:  13%|█▎        | 662/5000 [29:25<2:51:44,  2.38s/it, loss=5.2226]\u001b[A\n",
            "Training:  13%|█▎        | 663/5000 [29:28<2:48:43,  2.33s/it, loss=5.2226]\u001b[A\n",
            "Training:  13%|█▎        | 663/5000 [29:28<2:48:43,  2.33s/it, loss=5.6771]\u001b[A\n",
            "Training:  13%|█▎        | 664/5000 [29:30<2:58:04,  2.46s/it, loss=5.6771]\u001b[A\n",
            "Training:  13%|█▎        | 664/5000 [29:30<2:58:04,  2.46s/it, loss=5.6205]\u001b[A\n",
            "Training:  13%|█▎        | 665/5000 [29:33<2:53:20,  2.40s/it, loss=5.6205]\u001b[A\n",
            "Training:  13%|█▎        | 665/5000 [29:33<2:53:20,  2.40s/it, loss=5.6562]\u001b[A\n",
            "Training:  13%|█▎        | 666/5000 [29:35<2:49:47,  2.35s/it, loss=5.6562]\u001b[A\n",
            "Training:  13%|█▎        | 666/5000 [29:35<2:49:47,  2.35s/it, loss=5.1322]\u001b[A\n",
            "Training:  13%|█▎        | 667/5000 [29:37<2:47:06,  2.31s/it, loss=5.1322]\u001b[A\n",
            "Training:  13%|█▎        | 667/5000 [29:37<2:47:06,  2.31s/it, loss=5.5834]\u001b[A\n",
            "Training:  13%|█▎        | 668/5000 [29:39<2:46:33,  2.31s/it, loss=5.5834]\u001b[A\n",
            "Training:  13%|█▎        | 668/5000 [29:39<2:46:33,  2.31s/it, loss=5.9518]\u001b[A\n",
            "Training:  13%|█▎        | 669/5000 [29:42<2:56:26,  2.44s/it, loss=5.9518]\u001b[A\n",
            "Training:  13%|█▎        | 669/5000 [29:42<2:56:26,  2.44s/it, loss=4.2250]\u001b[A\n",
            "Training:  13%|█▎        | 670/5000 [29:44<2:51:47,  2.38s/it, loss=4.2250]\u001b[A\n",
            "Training:  13%|█▎        | 670/5000 [29:44<2:51:47,  2.38s/it, loss=4.6451]\u001b[A\n",
            "Training:  13%|█▎        | 671/5000 [29:47<2:48:48,  2.34s/it, loss=4.6451]\u001b[A\n",
            "Training:  13%|█▎        | 671/5000 [29:47<2:48:48,  2.34s/it, loss=4.5755]\u001b[A\n",
            "Training:  13%|█▎        | 672/5000 [29:49<2:46:46,  2.31s/it, loss=4.5755]\u001b[A\n",
            "Training:  13%|█▎        | 672/5000 [29:49<2:46:46,  2.31s/it, loss=4.3406]\u001b[A\n",
            "Training:  13%|█▎        | 673/5000 [29:51<2:45:28,  2.29s/it, loss=4.3406]\u001b[A\n",
            "Training:  13%|█▎        | 673/5000 [29:51<2:45:28,  2.29s/it, loss=5.6915]\u001b[A\n",
            "Training:  13%|█▎        | 674/5000 [29:54<2:55:25,  2.43s/it, loss=5.6915]\u001b[A\n",
            "Training:  13%|█▎        | 674/5000 [29:54<2:55:25,  2.43s/it, loss=4.1841]\u001b[A\n",
            "Training:  14%|█▎        | 675/5000 [29:56<2:51:06,  2.37s/it, loss=4.1841]\u001b[A\n",
            "Training:  14%|█▎        | 675/5000 [29:56<2:51:06,  2.37s/it, loss=5.9858]\u001b[A\n",
            "Training:  14%|█▎        | 676/5000 [29:58<2:48:09,  2.33s/it, loss=5.9858]\u001b[A\n",
            "Training:  14%|█▎        | 676/5000 [29:58<2:48:09,  2.33s/it, loss=4.8339]\u001b[A\n",
            "Training:  14%|█▎        | 677/5000 [30:01<2:46:20,  2.31s/it, loss=4.8339]\u001b[A\n",
            "Training:  14%|█▎        | 677/5000 [30:01<2:46:20,  2.31s/it, loss=5.0534]\u001b[A\n",
            "Training:  14%|█▎        | 678/5000 [30:03<2:44:54,  2.29s/it, loss=5.0534]\u001b[A\n",
            "Training:  14%|█▎        | 678/5000 [30:03<2:44:54,  2.29s/it, loss=4.3331]\u001b[A\n",
            "Training:  14%|█▎        | 679/5000 [30:06<2:55:08,  2.43s/it, loss=4.3331]\u001b[A\n",
            "Training:  14%|█▎        | 679/5000 [30:06<2:55:08,  2.43s/it, loss=5.1773]\u001b[A\n",
            "Training:  14%|█▎        | 680/5000 [30:08<2:51:06,  2.38s/it, loss=5.1773]\u001b[A\n",
            "Training:  14%|█▎        | 680/5000 [30:08<2:51:06,  2.38s/it, loss=4.1914]\u001b[A\n",
            "Training:  14%|█▎        | 681/5000 [30:10<2:49:04,  2.35s/it, loss=4.1914]\u001b[A\n",
            "Training:  14%|█▎        | 681/5000 [30:10<2:49:04,  2.35s/it, loss=3.7606]\u001b[A\n",
            "Training:  14%|█▎        | 682/5000 [30:12<2:46:43,  2.32s/it, loss=3.7606]\u001b[A\n",
            "Training:  14%|█▎        | 682/5000 [30:12<2:46:43,  2.32s/it, loss=4.3892]\u001b[A\n",
            "Training:  14%|█▎        | 683/5000 [30:15<2:45:12,  2.30s/it, loss=4.3892]\u001b[A\n",
            "Training:  14%|█▎        | 683/5000 [30:15<2:45:12,  2.30s/it, loss=4.4866]\u001b[A\n",
            "Training:  14%|█▎        | 684/5000 [30:17<2:54:53,  2.43s/it, loss=4.4866]\u001b[A\n",
            "Training:  14%|█▎        | 684/5000 [30:17<2:54:53,  2.43s/it, loss=4.5261]\u001b[A\n",
            "Training:  14%|█▎        | 685/5000 [30:20<2:51:10,  2.38s/it, loss=4.5261]\u001b[A\n",
            "Training:  14%|█▎        | 685/5000 [30:20<2:51:10,  2.38s/it, loss=5.6628]\u001b[A\n",
            "Training:  14%|█▎        | 686/5000 [30:22<2:49:07,  2.35s/it, loss=5.6628]\u001b[A\n",
            "Training:  14%|█▎        | 686/5000 [30:22<2:49:07,  2.35s/it, loss=4.4628]\u001b[A\n",
            "Training:  14%|█▎        | 687/5000 [30:24<2:46:25,  2.32s/it, loss=4.4628]\u001b[A\n",
            "Training:  14%|█▎        | 687/5000 [30:24<2:46:25,  2.32s/it, loss=6.2665]\u001b[A\n",
            "Training:  14%|█▍        | 688/5000 [30:26<2:44:49,  2.29s/it, loss=6.2665]\u001b[A\n",
            "Training:  14%|█▍        | 688/5000 [30:27<2:44:49,  2.29s/it, loss=5.5964]\u001b[A\n",
            "Training:  14%|█▍        | 689/5000 [30:29<2:54:55,  2.43s/it, loss=5.5964]\u001b[A\n",
            "Training:  14%|█▍        | 689/5000 [30:29<2:54:55,  2.43s/it, loss=5.4995]\u001b[A\n",
            "Training:  14%|█▍        | 690/5000 [30:31<2:50:41,  2.38s/it, loss=5.4995]\u001b[A\n",
            "Training:  14%|█▍        | 690/5000 [30:32<2:50:41,  2.38s/it, loss=4.8691]\u001b[A\n",
            "Training:  14%|█▍        | 691/5000 [30:34<2:47:37,  2.33s/it, loss=4.8691]\u001b[A\n",
            "Training:  14%|█▍        | 691/5000 [30:34<2:47:37,  2.33s/it, loss=4.6324]\u001b[A\n",
            "Training:  14%|█▍        | 692/5000 [30:36<2:47:13,  2.33s/it, loss=4.6324]\u001b[A\n",
            "Training:  14%|█▍        | 692/5000 [30:36<2:47:13,  2.33s/it, loss=5.7881]\u001b[A\n",
            "Training:  14%|█▍        | 693/5000 [30:38<2:45:10,  2.30s/it, loss=5.7881]\u001b[A\n",
            "Training:  14%|█▍        | 693/5000 [30:38<2:45:10,  2.30s/it, loss=4.9054]\u001b[A\n",
            "Training:  14%|█▍        | 694/5000 [30:41<2:56:19,  2.46s/it, loss=4.9054]\u001b[A\n",
            "Training:  14%|█▍        | 694/5000 [30:41<2:56:19,  2.46s/it, loss=4.6944]\u001b[A\n",
            "Training:  14%|█▍        | 695/5000 [30:43<2:51:57,  2.40s/it, loss=4.6944]\u001b[A\n",
            "Training:  14%|█▍        | 695/5000 [30:43<2:51:57,  2.40s/it, loss=5.9092]\u001b[A\n",
            "Training:  14%|█▍        | 696/5000 [30:46<2:48:18,  2.35s/it, loss=5.9092]\u001b[A\n",
            "Training:  14%|█▍        | 696/5000 [30:46<2:48:18,  2.35s/it, loss=4.8640]\u001b[A\n",
            "Training:  14%|█▍        | 697/5000 [30:48<2:46:24,  2.32s/it, loss=4.8640]\u001b[A\n",
            "Training:  14%|█▍        | 697/5000 [30:48<2:46:24,  2.32s/it, loss=4.7904]\u001b[A\n",
            "Training:  14%|█▍        | 698/5000 [30:50<2:44:38,  2.30s/it, loss=4.7904]\u001b[A\n",
            "Training:  14%|█▍        | 698/5000 [30:50<2:44:38,  2.30s/it, loss=5.0825]\u001b[A\n",
            "Training:  14%|█▍        | 699/5000 [30:53<2:55:01,  2.44s/it, loss=5.0825]\u001b[A\n",
            "Training:  14%|█▍        | 699/5000 [30:53<2:55:01,  2.44s/it, loss=4.2586]\u001b[A\n",
            "Training:  14%|█▍        | 700/5000 [30:55<2:51:06,  2.39s/it, loss=4.2586]\u001b[A\n",
            "Training:  14%|█▍        | 700/5000 [30:55<2:51:06,  2.39s/it, loss=3.6379]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 700 ---\n",
            "Prompt: 'The '\n",
            "The , sorrow it bleed!?\n",
            "CLENCE\n",
            "LY\n",
            "K EDARD\n",
            "HINGS\n",
            "BK ED:It thou a, lord\n",
            " it it andar is mine a whip\n",
            "QUE MARARurd death\n",
            "BiorINETH your l my's?\n",
            "Second have now thoust and plaint you be'doth w'dINGAMO thou that have'd me and yearsute\n",
            "Such'dWINGW VI\n",
            "HERENCE France\n",
            "QUEKENE But with young father,ake\n",
            "Prompt: 'In '\n",
            "In  with my father!\n",
            "Firsturd:O well it all?What he heartH\n",
            " that did see how should the of?'sazed\n",
            "BOLlowH: you not remembrance, melancholy\n",
            "B d se provoked my, you go good.\n",
            "enger my, you thing me you will Derby one dream\n",
            " Lord, you al, will no yout it Here suit-,!'est\n",
            "INGW:But and,!O again why with?\n",
            "B let live now that were\n",
            "Prompt: 'To '\n",
            "To  byord your, young, Iites\n",
            " you me to theeILL me the.\n",
            "Firsturd:F, you who your?\n",
            "B IBY\n",
            "D not, is foul, are shallu:First it it thee.\n",
            ", will this wonder my,am and much thouest, you, thy, seem, my;And this.\n",
            " wrink,,, you pawn what it in cause\n",
            " M now I not have in presence you my.\n",
            " ' last n with, lord\n",
            "Prompt: 'A '\n",
            "A , friends in, you and for.\n",
            "LYNEYNEYNE\n",
            "BK, your, never not and feel itFor.\n",
            "BK EDARARD\n",
            "K RARD\n",
            "Fwell tellt all is, say not them next\n",
            "'s lord this Hastings and beg and love I it it 'ixt thatowINGWICHst, are isMother\n",
            "K EDARD\n",
            "B the thatK are sl and'll my in-:And were will be, I be.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  14%|█▍        | 701/5000 [31:10<7:14:07,  6.06s/it, loss=3.6379]\u001b[A\n",
            "Training:  14%|█▍        | 701/5000 [31:10<7:14:07,  6.06s/it, loss=4.6666]\u001b[A\n",
            "Training:  14%|█▍        | 702/5000 [31:12<5:52:55,  4.93s/it, loss=4.6666]\u001b[A\n",
            "Training:  14%|█▍        | 702/5000 [31:12<5:52:55,  4.93s/it, loss=4.5831]\u001b[A\n",
            "Training:  14%|█▍        | 703/5000 [31:14<4:55:03,  4.12s/it, loss=4.5831]\u001b[A\n",
            "Training:  14%|█▍        | 703/5000 [31:14<4:55:03,  4.12s/it, loss=4.5385]\u001b[A\n",
            "Training:  14%|█▍        | 704/5000 [31:17<4:25:39,  3.71s/it, loss=4.5385]\u001b[A\n",
            "Training:  14%|█▍        | 704/5000 [31:17<4:25:39,  3.71s/it, loss=4.6656]\u001b[A\n",
            "Training:  14%|█▍        | 705/5000 [31:19<3:53:53,  3.27s/it, loss=4.6656]\u001b[A\n",
            "Training:  14%|█▍        | 705/5000 [31:19<3:53:53,  3.27s/it, loss=4.3008]\u001b[A\n",
            "Training:  14%|█▍        | 706/5000 [31:21<3:31:40,  2.96s/it, loss=4.3008]\u001b[A\n",
            "Training:  14%|█▍        | 706/5000 [31:22<3:31:40,  2.96s/it, loss=5.6248]\u001b[A\n",
            "Training:  14%|█▍        | 707/5000 [31:24<3:16:25,  2.75s/it, loss=5.6248]\u001b[A\n",
            "Training:  14%|█▍        | 707/5000 [31:24<3:16:25,  2.75s/it, loss=4.9726]\u001b[A\n",
            "Training:  14%|█▍        | 708/5000 [31:26<3:05:42,  2.60s/it, loss=4.9726]\u001b[A\n",
            "Training:  14%|█▍        | 708/5000 [31:26<3:05:42,  2.60s/it, loss=3.4920]\u001b[A\n",
            "Training:  14%|█▍        | 709/5000 [31:29<3:08:51,  2.64s/it, loss=3.4920]\u001b[A\n",
            "Training:  14%|█▍        | 709/5000 [31:29<3:08:51,  2.64s/it, loss=5.1108]\u001b[A\n",
            "Training:  14%|█▍        | 710/5000 [31:31<2:59:53,  2.52s/it, loss=5.1108]\u001b[A\n",
            "Training:  14%|█▍        | 710/5000 [31:31<2:59:53,  2.52s/it, loss=5.1878]\u001b[A\n",
            "Training:  14%|█▍        | 711/5000 [31:33<2:53:30,  2.43s/it, loss=5.1878]\u001b[A\n",
            "Training:  14%|█▍        | 711/5000 [31:33<2:53:30,  2.43s/it, loss=5.4718]\u001b[A\n",
            "Training:  14%|█▍        | 712/5000 [31:35<2:49:31,  2.37s/it, loss=5.4718]\u001b[A\n",
            "Training:  14%|█▍        | 712/5000 [31:35<2:49:31,  2.37s/it, loss=5.6117]\u001b[A\n",
            "Training:  14%|█▍        | 713/5000 [31:38<2:46:15,  2.33s/it, loss=5.6117]\u001b[A\n",
            "Training:  14%|█▍        | 713/5000 [31:38<2:46:15,  2.33s/it, loss=4.1835]\u001b[A\n",
            "Training:  14%|█▍        | 714/5000 [31:40<2:55:34,  2.46s/it, loss=4.1835]\u001b[A\n",
            "Training:  14%|█▍        | 714/5000 [31:40<2:55:34,  2.46s/it, loss=4.6613]\u001b[A\n",
            "Training:  14%|█▍        | 715/5000 [31:43<2:52:01,  2.41s/it, loss=4.6613]\u001b[A\n",
            "Training:  14%|█▍        | 715/5000 [31:43<2:52:01,  2.41s/it, loss=5.7535]\u001b[A\n",
            "Training:  14%|█▍        | 716/5000 [31:45<2:48:31,  2.36s/it, loss=5.7535]\u001b[A\n",
            "Training:  14%|█▍        | 716/5000 [31:45<2:48:31,  2.36s/it, loss=5.1902]\u001b[A\n",
            "Training:  14%|█▍        | 717/5000 [31:47<2:46:19,  2.33s/it, loss=5.1902]\u001b[A\n",
            "Training:  14%|█▍        | 717/5000 [31:47<2:46:19,  2.33s/it, loss=5.1658]\u001b[A\n",
            "Training:  14%|█▍        | 718/5000 [31:49<2:44:32,  2.31s/it, loss=5.1658]\u001b[A\n",
            "Training:  14%|█▍        | 718/5000 [31:49<2:44:32,  2.31s/it, loss=4.0936]\u001b[A\n",
            "Training:  14%|█▍        | 719/5000 [31:52<2:54:25,  2.44s/it, loss=4.0936]\u001b[A\n",
            "Training:  14%|█▍        | 719/5000 [31:52<2:54:25,  2.44s/it, loss=5.0560]\u001b[A\n",
            "Training:  14%|█▍        | 720/5000 [31:54<2:50:02,  2.38s/it, loss=5.0560]\u001b[A\n",
            "Training:  14%|█▍        | 720/5000 [31:54<2:50:02,  2.38s/it, loss=4.8636]\u001b[A\n",
            "Training:  14%|█▍        | 721/5000 [31:57<2:48:57,  2.37s/it, loss=4.8636]\u001b[A\n",
            "Training:  14%|█▍        | 721/5000 [31:57<2:48:57,  2.37s/it, loss=3.7770]\u001b[A\n",
            "Training:  14%|█▍        | 722/5000 [31:59<2:46:04,  2.33s/it, loss=3.7770]\u001b[A\n",
            "Training:  14%|█▍        | 722/5000 [31:59<2:46:04,  2.33s/it, loss=4.8632]\u001b[A\n",
            "Training:  14%|█▍        | 723/5000 [32:01<2:44:08,  2.30s/it, loss=4.8632]\u001b[A\n",
            "Training:  14%|█▍        | 723/5000 [32:01<2:44:08,  2.30s/it, loss=5.8497]\u001b[A\n",
            "Training:  14%|█▍        | 724/5000 [32:04<2:53:45,  2.44s/it, loss=5.8497]\u001b[A\n",
            "Training:  14%|█▍        | 724/5000 [32:04<2:53:45,  2.44s/it, loss=5.3330]\u001b[A\n",
            "Training:  14%|█▍        | 725/5000 [32:06<2:49:23,  2.38s/it, loss=5.3330]\u001b[A\n",
            "Training:  14%|█▍        | 725/5000 [32:06<2:49:23,  2.38s/it, loss=5.4781]\u001b[A\n",
            "Training:  15%|█▍        | 726/5000 [32:09<2:46:39,  2.34s/it, loss=5.4781]\u001b[A\n",
            "Training:  15%|█▍        | 726/5000 [32:09<2:46:39,  2.34s/it, loss=4.8286]\u001b[A\n",
            "Training:  15%|█▍        | 727/5000 [32:11<2:44:05,  2.30s/it, loss=4.8286]\u001b[A\n",
            "Training:  15%|█▍        | 727/5000 [32:11<2:44:05,  2.30s/it, loss=4.8029]\u001b[A\n",
            "Training:  15%|█▍        | 728/5000 [32:13<2:43:15,  2.29s/it, loss=4.8029]\u001b[A\n",
            "Training:  15%|█▍        | 728/5000 [32:13<2:43:15,  2.29s/it, loss=4.6858]\u001b[A\n",
            "Training:  15%|█▍        | 729/5000 [32:16<2:52:47,  2.43s/it, loss=4.6858]\u001b[A\n",
            "Training:  15%|█▍        | 729/5000 [32:16<2:52:47,  2.43s/it, loss=4.8950]\u001b[A\n",
            "Training:  15%|█▍        | 730/5000 [32:18<2:49:29,  2.38s/it, loss=4.8950]\u001b[A\n",
            "Training:  15%|█▍        | 730/5000 [32:18<2:49:29,  2.38s/it, loss=5.0516]\u001b[A\n",
            "Training:  15%|█▍        | 731/5000 [32:20<2:46:15,  2.34s/it, loss=5.0516]\u001b[A\n",
            "Training:  15%|█▍        | 731/5000 [32:20<2:46:15,  2.34s/it, loss=5.7070]\u001b[A\n",
            "Training:  15%|█▍        | 732/5000 [32:22<2:43:38,  2.30s/it, loss=5.7070]\u001b[A\n",
            "Training:  15%|█▍        | 732/5000 [32:22<2:43:38,  2.30s/it, loss=5.9371]\u001b[A\n",
            "Training:  15%|█▍        | 733/5000 [32:25<2:42:30,  2.29s/it, loss=5.9371]\u001b[A\n",
            "Training:  15%|█▍        | 733/5000 [32:25<2:42:30,  2.29s/it, loss=5.0293]\u001b[A\n",
            "Training:  15%|█▍        | 734/5000 [32:27<2:52:28,  2.43s/it, loss=5.0293]\u001b[A\n",
            "Training:  15%|█▍        | 734/5000 [32:27<2:52:28,  2.43s/it, loss=5.4605]\u001b[A\n",
            "Training:  15%|█▍        | 735/5000 [32:30<2:48:17,  2.37s/it, loss=5.4605]\u001b[A\n",
            "Training:  15%|█▍        | 735/5000 [32:30<2:48:17,  2.37s/it, loss=6.2144]\u001b[A\n",
            "Training:  15%|█▍        | 736/5000 [32:32<2:45:44,  2.33s/it, loss=6.2144]\u001b[A\n",
            "Training:  15%|█▍        | 736/5000 [32:32<2:45:44,  2.33s/it, loss=4.4724]\u001b[A\n",
            "Training:  15%|█▍        | 737/5000 [32:34<2:43:30,  2.30s/it, loss=4.4724]\u001b[A\n",
            "Training:  15%|█▍        | 737/5000 [32:34<2:43:30,  2.30s/it, loss=4.9363]\u001b[A\n",
            "Training:  15%|█▍        | 738/5000 [32:36<2:42:12,  2.28s/it, loss=4.9363]\u001b[A\n",
            "Training:  15%|█▍        | 738/5000 [32:36<2:42:12,  2.28s/it, loss=6.2884]\u001b[A\n",
            "Training:  15%|█▍        | 739/5000 [32:39<2:51:48,  2.42s/it, loss=6.2884]\u001b[A\n",
            "Training:  15%|█▍        | 739/5000 [32:39<2:51:48,  2.42s/it, loss=4.8344]\u001b[A\n",
            "Training:  15%|█▍        | 740/5000 [32:41<2:48:56,  2.38s/it, loss=4.8344]\u001b[A\n",
            "Training:  15%|█▍        | 740/5000 [32:41<2:48:56,  2.38s/it, loss=5.0418]\u001b[A\n",
            "Training:  15%|█▍        | 741/5000 [32:44<2:46:53,  2.35s/it, loss=5.0418]\u001b[A\n",
            "Training:  15%|█▍        | 741/5000 [32:44<2:46:53,  2.35s/it, loss=4.5569]\u001b[A\n",
            "Training:  15%|█▍        | 742/5000 [32:46<2:44:23,  2.32s/it, loss=4.5569]\u001b[A\n",
            "Training:  15%|█▍        | 742/5000 [32:46<2:44:23,  2.32s/it, loss=5.2491]\u001b[A\n",
            "Training:  15%|█▍        | 743/5000 [32:48<2:43:00,  2.30s/it, loss=5.2491]\u001b[A\n",
            "Training:  15%|█▍        | 743/5000 [32:48<2:43:00,  2.30s/it, loss=4.9249]\u001b[A\n",
            "Training:  15%|█▍        | 744/5000 [32:51<2:52:43,  2.44s/it, loss=4.9249]\u001b[A\n",
            "Training:  15%|█▍        | 744/5000 [32:51<2:52:43,  2.44s/it, loss=5.6643]\u001b[A\n",
            "Training:  15%|█▍        | 745/5000 [32:53<2:48:48,  2.38s/it, loss=5.6643]\u001b[A\n",
            "Training:  15%|█▍        | 745/5000 [32:53<2:48:48,  2.38s/it, loss=3.8663]\u001b[A\n",
            "Training:  15%|█▍        | 746/5000 [32:55<2:45:46,  2.34s/it, loss=3.8663]\u001b[A\n",
            "Training:  15%|█▍        | 746/5000 [32:55<2:45:46,  2.34s/it, loss=4.6633]\u001b[A\n",
            "Training:  15%|█▍        | 747/5000 [32:58<2:44:08,  2.32s/it, loss=4.6633]\u001b[A\n",
            "Training:  15%|█▍        | 747/5000 [32:58<2:44:08,  2.32s/it, loss=5.0963]\u001b[A\n",
            "Training:  15%|█▍        | 748/5000 [33:00<2:42:54,  2.30s/it, loss=5.0963]\u001b[A\n",
            "Training:  15%|█▍        | 748/5000 [33:00<2:42:54,  2.30s/it, loss=5.1914]\u001b[A\n",
            "Training:  15%|█▍        | 749/5000 [33:03<2:52:49,  2.44s/it, loss=5.1914]\u001b[A\n",
            "Training:  15%|█▍        | 749/5000 [33:03<2:52:49,  2.44s/it, loss=5.5856]\u001b[A\n",
            "Training:  15%|█▌        | 750/5000 [33:05<2:48:17,  2.38s/it, loss=5.5856]\u001b[A\n",
            "Training:  15%|█▌        | 750/5000 [33:05<2:48:17,  2.38s/it, loss=4.9021]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 750 ---\n",
            "Prompt: 'The '\n",
            "The e a lady of bind the.\n",
            "INGROO: B'd thouost:O what so\n",
            " vowt where in city burden:,,,, you\n",
            " foria as hear say death\n",
            "MT and, mother came mad; father give be.\n",
            "CAPET:N,'s then you Merc music and striketst, lord\n",
            " theal of and,, my: you think thy;'ll him Romeot nurse him snow; thou promise such and love, go, be\n",
            "Prompt: 'In '\n",
            "In , wedding, lady with face\n",
            " villain\n",
            "UL:We the ofesty the to father.\n",
            "CAPET\n",
            " CAPET\n",
            "eps my.\n",
            "MT they;tis, not; then hence;tis and be;In's,,.\n",
            "MUT:O the soul tell, my,; is not so bedy.,,; now in sweet;We for by pilot in,, will morese be'd in qu slaint thelf but thingtt indeed my,\n",
            "Prompt: 'To '\n",
            "To ale, hour be.\n",
            "PET:O\n",
            ", you not tom.\n",
            "CAPET\n",
            " CAPET\n",
            "\n",
            " CAPET.\n",
            "JI thee the with cruel our; secret,, you.\n",
            " shownrell with;,; you know, and's lady.\n",
            "PET:There him; now, welcome\n",
            "ME:,; am,, fri. behind to good, myge\n",
            "ULET\n",
            "ULET\n",
            "urse why I:,,, give.\n",
            ",,-\n",
            "Prompt: 'A '\n",
            "A  in penaming quite death h; Romeo\n",
            " they theirlow to inesty to in:Thereforet\n",
            " Tyt g form and, heaven Ty, speak brotherful:If'des, good, tom,,,,; would slain, once go,,,.\n",
            " un monthly strokes fair, father, thou's think hath find like:But's soul\n",
            "UT: I me then and thisitpt in bys love me and, O death the;,,, will\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  15%|█▌        | 751/5000 [33:20<7:07:39,  6.04s/it, loss=4.9021]\u001b[A\n",
            "Training:  15%|█▌        | 751/5000 [33:20<7:07:39,  6.04s/it, loss=4.8123]\u001b[A\n",
            "Training:  15%|█▌        | 752/5000 [33:22<5:46:33,  4.89s/it, loss=4.8123]\u001b[A\n",
            "Training:  15%|█▌        | 752/5000 [33:22<5:46:33,  4.89s/it, loss=4.8233]\u001b[A\n",
            "Training:  15%|█▌        | 753/5000 [33:24<4:49:57,  4.10s/it, loss=4.8233]\u001b[A\n",
            "Training:  15%|█▌        | 753/5000 [33:24<4:49:57,  4.10s/it, loss=4.9350]\u001b[A\n",
            "Training:  15%|█▌        | 754/5000 [33:27<4:21:34,  3.70s/it, loss=4.9350]\u001b[A\n",
            "Training:  15%|█▌        | 754/5000 [33:27<4:21:34,  3.70s/it, loss=5.4979]\u001b[A\n",
            "Training:  15%|█▌        | 755/5000 [33:29<3:50:32,  3.26s/it, loss=5.4979]\u001b[A\n",
            "Training:  15%|█▌        | 755/5000 [33:29<3:50:32,  3.26s/it, loss=4.8593]\u001b[A\n",
            "Training:  15%|█▌        | 756/5000 [33:31<3:28:31,  2.95s/it, loss=4.8593]\u001b[A\n",
            "Training:  15%|█▌        | 756/5000 [33:31<3:28:31,  2.95s/it, loss=5.4859]\u001b[A\n",
            "Training:  15%|█▌        | 757/5000 [33:33<3:13:30,  2.74s/it, loss=5.4859]\u001b[A\n",
            "Training:  15%|█▌        | 757/5000 [33:34<3:13:30,  2.74s/it, loss=4.6729]\u001b[A\n",
            "Training:  15%|█▌        | 758/5000 [33:36<3:02:41,  2.58s/it, loss=4.6729]\u001b[A\n",
            "Training:  15%|█▌        | 758/5000 [33:36<3:02:41,  2.58s/it, loss=5.1763]\u001b[A\n",
            "Training:  15%|█▌        | 759/5000 [33:38<3:05:48,  2.63s/it, loss=5.1763]\u001b[A\n",
            "Training:  15%|█▌        | 759/5000 [33:38<3:05:48,  2.63s/it, loss=5.8060]\u001b[A\n",
            "Training:  15%|█▌        | 760/5000 [33:41<2:57:32,  2.51s/it, loss=5.8060]\u001b[A\n",
            "Training:  15%|█▌        | 760/5000 [33:41<2:57:32,  2.51s/it, loss=4.7633]\u001b[A\n",
            "Training:  15%|█▌        | 761/5000 [33:43<2:52:17,  2.44s/it, loss=4.7633]\u001b[A\n",
            "Training:  15%|█▌        | 761/5000 [33:43<2:52:17,  2.44s/it, loss=4.8626]\u001b[A\n",
            "Training:  15%|█▌        | 762/5000 [33:45<2:47:28,  2.37s/it, loss=4.8626]\u001b[A\n",
            "Training:  15%|█▌        | 762/5000 [33:45<2:47:28,  2.37s/it, loss=5.5678]\u001b[A\n",
            "Training:  15%|█▌        | 763/5000 [33:47<2:44:22,  2.33s/it, loss=5.5678]\u001b[A\n",
            "Training:  15%|█▌        | 763/5000 [33:47<2:44:22,  2.33s/it, loss=4.4083]\u001b[A\n",
            "Training:  15%|█▌        | 764/5000 [33:50<2:53:23,  2.46s/it, loss=4.4083]\u001b[A\n",
            "Training:  15%|█▌        | 764/5000 [33:50<2:53:23,  2.46s/it, loss=4.7327]\u001b[A\n",
            "Training:  15%|█▌        | 765/5000 [33:52<2:49:04,  2.40s/it, loss=4.7327]\u001b[A\n",
            "Training:  15%|█▌        | 765/5000 [33:52<2:49:04,  2.40s/it, loss=4.9595]\u001b[A\n",
            "Training:  15%|█▌        | 766/5000 [33:55<2:45:45,  2.35s/it, loss=4.9595]\u001b[A\n",
            "Training:  15%|█▌        | 766/5000 [33:55<2:45:45,  2.35s/it, loss=3.8326]\u001b[A\n",
            "Training:  15%|█▌        | 767/5000 [33:57<2:43:10,  2.31s/it, loss=3.8326]\u001b[A\n",
            "Training:  15%|█▌        | 767/5000 [33:57<2:43:10,  2.31s/it, loss=4.4821]\u001b[A\n",
            "Training:  15%|█▌        | 768/5000 [33:59<2:41:22,  2.29s/it, loss=4.4821]\u001b[A\n",
            "Training:  15%|█▌        | 768/5000 [33:59<2:41:22,  2.29s/it, loss=3.7551]\u001b[A\n",
            "Training:  15%|█▌        | 769/5000 [34:02<2:50:36,  2.42s/it, loss=3.7551]\u001b[A\n",
            "Training:  15%|█▌        | 769/5000 [34:02<2:50:36,  2.42s/it, loss=5.0933]\u001b[A\n",
            "Training:  15%|█▌        | 770/5000 [34:04<2:46:40,  2.36s/it, loss=5.0933]\u001b[A\n",
            "Training:  15%|█▌        | 770/5000 [34:04<2:46:40,  2.36s/it, loss=5.3849]\u001b[A\n",
            "Training:  15%|█▌        | 771/5000 [34:06<2:43:30,  2.32s/it, loss=5.3849]\u001b[A\n",
            "Training:  15%|█▌        | 771/5000 [34:06<2:43:30,  2.32s/it, loss=4.8702]\u001b[A\n",
            "Training:  15%|█▌        | 772/5000 [34:09<2:41:46,  2.30s/it, loss=4.8702]\u001b[A\n",
            "Training:  15%|█▌        | 772/5000 [34:09<2:41:46,  2.30s/it, loss=5.8267]\u001b[A\n",
            "Training:  15%|█▌        | 773/5000 [34:11<2:40:34,  2.28s/it, loss=5.8267]\u001b[A\n",
            "Training:  15%|█▌        | 773/5000 [34:11<2:40:34,  2.28s/it, loss=5.2386]\u001b[A\n",
            "Training:  15%|█▌        | 774/5000 [34:14<2:51:20,  2.43s/it, loss=5.2386]\u001b[A\n",
            "Training:  15%|█▌        | 774/5000 [34:14<2:51:20,  2.43s/it, loss=5.1325]\u001b[A\n",
            "Training:  16%|█▌        | 775/5000 [34:16<2:46:41,  2.37s/it, loss=5.1325]\u001b[A\n",
            "Training:  16%|█▌        | 775/5000 [34:16<2:46:41,  2.37s/it, loss=4.7561]\u001b[A\n",
            "Training:  16%|█▌        | 776/5000 [34:18<2:44:11,  2.33s/it, loss=4.7561]\u001b[A\n",
            "Training:  16%|█▌        | 776/5000 [34:18<2:44:11,  2.33s/it, loss=4.7372]\u001b[A\n",
            "Training:  16%|█▌        | 777/5000 [34:20<2:41:54,  2.30s/it, loss=4.7372]\u001b[A\n",
            "Training:  16%|█▌        | 777/5000 [34:20<2:41:54,  2.30s/it, loss=5.1133]\u001b[A\n",
            "Training:  16%|█▌        | 778/5000 [34:22<2:40:02,  2.27s/it, loss=5.1133]\u001b[A\n",
            "Training:  16%|█▌        | 778/5000 [34:22<2:40:02,  2.27s/it, loss=5.1947]\u001b[A\n",
            "Training:  16%|█▌        | 779/5000 [34:25<2:49:38,  2.41s/it, loss=5.1947]\u001b[A\n",
            "Training:  16%|█▌        | 779/5000 [34:25<2:49:38,  2.41s/it, loss=5.8486]\u001b[A\n",
            "Training:  16%|█▌        | 780/5000 [34:27<2:47:04,  2.38s/it, loss=5.8486]\u001b[A\n",
            "Training:  16%|█▌        | 780/5000 [34:28<2:47:04,  2.38s/it, loss=6.1714]\u001b[A\n",
            "Training:  16%|█▌        | 781/5000 [34:30<2:43:33,  2.33s/it, loss=6.1714]\u001b[A\n",
            "Training:  16%|█▌        | 781/5000 [34:30<2:43:33,  2.33s/it, loss=6.5241]\u001b[A\n",
            "Training:  16%|█▌        | 782/5000 [34:32<2:41:29,  2.30s/it, loss=6.5241]\u001b[A\n",
            "Training:  16%|█▌        | 782/5000 [34:32<2:41:29,  2.30s/it, loss=5.5144]\u001b[A\n",
            "Training:  16%|█▌        | 783/5000 [34:34<2:39:48,  2.27s/it, loss=5.5144]\u001b[A\n",
            "Training:  16%|█▌        | 783/5000 [34:34<2:39:48,  2.27s/it, loss=5.5632]\u001b[A\n",
            "Training:  16%|█▌        | 784/5000 [34:37<2:49:26,  2.41s/it, loss=5.5632]\u001b[A\n",
            "Training:  16%|█▌        | 784/5000 [34:37<2:49:26,  2.41s/it, loss=6.1463]\u001b[A\n",
            "Training:  16%|█▌        | 785/5000 [34:39<2:45:54,  2.36s/it, loss=6.1463]\u001b[A\n",
            "Training:  16%|█▌        | 785/5000 [34:39<2:45:54,  2.36s/it, loss=5.6555]\u001b[A\n",
            "Training:  16%|█▌        | 786/5000 [34:41<2:43:10,  2.32s/it, loss=5.6555]\u001b[A\n",
            "Training:  16%|█▌        | 786/5000 [34:41<2:43:10,  2.32s/it, loss=3.9451]\u001b[A\n",
            "Training:  16%|█▌        | 787/5000 [34:44<2:41:44,  2.30s/it, loss=3.9451]\u001b[A\n",
            "Training:  16%|█▌        | 787/5000 [34:44<2:41:44,  2.30s/it, loss=6.1965]\u001b[A\n",
            "Training:  16%|█▌        | 788/5000 [34:46<2:40:45,  2.29s/it, loss=6.1965]\u001b[A\n",
            "Training:  16%|█▌        | 788/5000 [34:46<2:40:45,  2.29s/it, loss=5.4565]\u001b[A\n",
            "Training:  16%|█▌        | 789/5000 [34:49<2:50:18,  2.43s/it, loss=5.4565]\u001b[A\n",
            "Training:  16%|█▌        | 789/5000 [34:49<2:50:18,  2.43s/it, loss=5.9282]\u001b[A\n",
            "Training:  16%|█▌        | 790/5000 [34:51<2:46:28,  2.37s/it, loss=5.9282]\u001b[A\n",
            "Training:  16%|█▌        | 790/5000 [34:51<2:46:28,  2.37s/it, loss=4.5876]\u001b[A\n",
            "Training:  16%|█▌        | 791/5000 [34:53<2:43:50,  2.34s/it, loss=4.5876]\u001b[A\n",
            "Training:  16%|█▌        | 791/5000 [34:53<2:43:50,  2.34s/it, loss=5.6082]\u001b[A\n",
            "Training:  16%|█▌        | 792/5000 [34:55<2:41:25,  2.30s/it, loss=5.6082]\u001b[A\n",
            "Training:  16%|█▌        | 792/5000 [34:55<2:41:25,  2.30s/it, loss=5.3466]\u001b[A\n",
            "Training:  16%|█▌        | 793/5000 [34:58<2:39:52,  2.28s/it, loss=5.3466]\u001b[A\n",
            "Training:  16%|█▌        | 793/5000 [34:58<2:39:52,  2.28s/it, loss=5.4769]\u001b[A\n",
            "Training:  16%|█▌        | 794/5000 [35:00<2:50:05,  2.43s/it, loss=5.4769]\u001b[A\n",
            "Training:  16%|█▌        | 794/5000 [35:00<2:50:05,  2.43s/it, loss=4.7657]\u001b[A\n",
            "Training:  16%|█▌        | 795/5000 [35:03<2:46:00,  2.37s/it, loss=4.7657]\u001b[A\n",
            "Training:  16%|█▌        | 795/5000 [35:03<2:46:00,  2.37s/it, loss=5.3318]\u001b[A\n",
            "Training:  16%|█▌        | 796/5000 [35:05<2:43:02,  2.33s/it, loss=5.3318]\u001b[A\n",
            "Training:  16%|█▌        | 796/5000 [35:05<2:43:02,  2.33s/it, loss=4.2847]\u001b[A\n",
            "Training:  16%|█▌        | 797/5000 [35:07<2:40:53,  2.30s/it, loss=4.2847]\u001b[A\n",
            "Training:  16%|█▌        | 797/5000 [35:07<2:40:53,  2.30s/it, loss=4.4683]\u001b[A\n",
            "Training:  16%|█▌        | 798/5000 [35:09<2:39:25,  2.28s/it, loss=4.4683]\u001b[A\n",
            "Training:  16%|█▌        | 798/5000 [35:09<2:39:25,  2.28s/it, loss=4.6071]\u001b[A\n",
            "Training:  16%|█▌        | 799/5000 [35:12<2:48:44,  2.41s/it, loss=4.6071]\u001b[A\n",
            "Training:  16%|█▌        | 799/5000 [35:12<2:48:44,  2.41s/it, loss=5.2161]\u001b[A\n",
            "Training:  16%|█▌        | 800/5000 [35:14<2:45:38,  2.37s/it, loss=5.2161]\u001b[A\n",
            "Training:  16%|█▌        | 800/5000 [35:14<2:45:38,  2.37s/it, loss=4.8175]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 800 ---\n",
            "Prompt: 'The '\n",
            "The  to you as as as knot\n",
            "ath to sense.\n",
            "ANGO:Y ever,.\n",
            "ANGO\n",
            "LA\n",
            "LAC:Go, would notable\n",
            " a shall to blow\n",
            " odds\n",
            "FLEL:\n",
            "ieve, theo Mist thy father?\n",
            "ISEL:' fool an\n",
            "LA\n",
            "--\n",
            "ANGO\n",
            "ANGO?\n",
            "ABABLA\n",
            "LAD.\n",
            "ISEL!\n",
            "ANGO\n",
            "Prov:Well your loss what the? waits one neck the?\n",
            "Prompt: 'In '\n",
            "In  her in grace\n",
            "raw, she that selfy law, it in\n",
            "aining noble.\n",
            "Prov:Good's,ina thy dove\n",
            " she to grave p head and you remedy\n",
            " both pleasant j in: are bitter and\n",
            "ANGO contents I\n",
            ", love the with dark she you in grief you., you:Most\n",
            " of father; ever, I might no never-orrow\n",
            " the ofress\n",
            " e bare, come\n",
            " Isabel and not the of wrong\n",
            " willingly,, comfort you\n",
            "Prompt: 'To '\n",
            "To  the nu the forors that the\n",
            "thence for of This excuse\n",
            "ath the rich OD thievesEL,\n",
            "Remember desire the be me the earthThat do\n",
            " cannot that wear?\n",
            "ISEL:Five how she\n",
            " me art one; I, I back me earth would you and\n",
            " you her'd for.\n",
            "D:What think think, my?\n",
            "ANGO\n",
            "LA OD you of; the whattw be in gentlemen, my, brother\n",
            " hour daughters it you,\n",
            "Prompt: 'A '\n",
            "A  or his:, your is in\n",
            " axe year instruct!\n",
            "ANGO\n",
            "LA\n",
            "LAIO\n",
            "Dclock\n",
            "R OD:O the my, sir I do\n",
            " of was to herard the of, Ild heard\n",
            " honour all losing\n",
            "LAIO\n",
            "POELEL OD:, do my? you be,y?\n",
            "ISELEL:We I you be in and, not the\n",
            ", we none the see the ofua upon grace\n",
            " toy rot\n",
            " liberty\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  16%|█▌        | 801/5000 [35:29<7:01:49,  6.03s/it, loss=4.8175]\u001b[A\n",
            "Training:  16%|█▌        | 801/5000 [35:29<7:01:49,  6.03s/it, loss=4.4564]\u001b[A\n",
            "Training:  16%|█▌        | 802/5000 [35:31<5:41:48,  4.89s/it, loss=4.4564]\u001b[A\n",
            "Training:  16%|█▌        | 802/5000 [35:31<5:41:48,  4.89s/it, loss=5.3609]\u001b[A\n",
            "Training:  16%|█▌        | 803/5000 [35:33<4:46:18,  4.09s/it, loss=5.3609]\u001b[A\n",
            "Training:  16%|█▌        | 803/5000 [35:33<4:46:18,  4.09s/it, loss=5.0547]\u001b[A\n",
            "Training:  16%|█▌        | 804/5000 [35:36<4:17:29,  3.68s/it, loss=5.0547]\u001b[A\n",
            "Training:  16%|█▌        | 804/5000 [35:36<4:17:29,  3.68s/it, loss=6.1624]\u001b[A\n",
            "Training:  16%|█▌        | 805/5000 [35:38<3:47:06,  3.25s/it, loss=6.1624]\u001b[A\n",
            "Training:  16%|█▌        | 805/5000 [35:38<3:47:06,  3.25s/it, loss=5.1107]\u001b[A\n",
            "Training:  16%|█▌        | 806/5000 [35:40<3:25:54,  2.95s/it, loss=5.1107]\u001b[A\n",
            "Training:  16%|█▌        | 806/5000 [35:41<3:25:54,  2.95s/it, loss=4.3186]\u001b[A\n",
            "Training:  16%|█▌        | 807/5000 [35:43<3:11:24,  2.74s/it, loss=4.3186]\u001b[A\n",
            "Training:  16%|█▌        | 807/5000 [35:43<3:11:24,  2.74s/it, loss=4.1535]\u001b[A\n",
            "Training:  16%|█▌        | 808/5000 [35:45<3:01:39,  2.60s/it, loss=4.1535]\u001b[A\n",
            "Training:  16%|█▌        | 808/5000 [35:45<3:01:39,  2.60s/it, loss=3.6519]\u001b[A\n",
            "Training:  16%|█▌        | 809/5000 [35:48<3:04:19,  2.64s/it, loss=3.6519]\u001b[A\n",
            "Training:  16%|█▌        | 809/5000 [35:48<3:04:19,  2.64s/it, loss=3.8934]\u001b[A\n",
            "Training:  16%|█▌        | 810/5000 [35:50<2:56:26,  2.53s/it, loss=3.8934]\u001b[A\n",
            "Training:  16%|█▌        | 810/5000 [35:50<2:56:26,  2.53s/it, loss=5.3888]\u001b[A\n",
            "Training:  16%|█▌        | 811/5000 [35:52<2:50:12,  2.44s/it, loss=5.3888]\u001b[A\n",
            "Training:  16%|█▌        | 811/5000 [35:52<2:50:12,  2.44s/it, loss=5.2582]\u001b[A\n",
            "Training:  16%|█▌        | 812/5000 [35:54<2:45:49,  2.38s/it, loss=5.2582]\u001b[A\n",
            "Training:  16%|█▌        | 812/5000 [35:54<2:45:49,  2.38s/it, loss=5.6453]\u001b[A\n",
            "Training:  16%|█▋        | 813/5000 [35:57<2:43:06,  2.34s/it, loss=5.6453]\u001b[A\n",
            "Training:  16%|█▋        | 813/5000 [35:57<2:43:06,  2.34s/it, loss=5.7116]\u001b[A\n",
            "Training:  16%|█▋        | 814/5000 [35:59<2:52:10,  2.47s/it, loss=5.7116]\u001b[A\n",
            "Training:  16%|█▋        | 814/5000 [36:00<2:52:10,  2.47s/it, loss=4.8078]\u001b[A\n",
            "Training:  16%|█▋        | 815/5000 [36:02<2:47:07,  2.40s/it, loss=4.8078]\u001b[A\n",
            "Training:  16%|█▋        | 815/5000 [36:02<2:47:07,  2.40s/it, loss=4.6560]\u001b[A\n",
            "Training:  16%|█▋        | 816/5000 [36:04<2:43:39,  2.35s/it, loss=4.6560]\u001b[A\n",
            "Training:  16%|█▋        | 816/5000 [36:04<2:43:39,  2.35s/it, loss=4.9781]\u001b[A\n",
            "Training:  16%|█▋        | 817/5000 [36:06<2:40:58,  2.31s/it, loss=4.9781]\u001b[A\n",
            "Training:  16%|█▋        | 817/5000 [36:06<2:40:58,  2.31s/it, loss=4.7676]\u001b[A\n",
            "Training:  16%|█▋        | 818/5000 [36:08<2:39:42,  2.29s/it, loss=4.7676]\u001b[A\n",
            "Training:  16%|█▋        | 818/5000 [36:08<2:39:42,  2.29s/it, loss=4.6058]\u001b[A\n",
            "Training:  16%|█▋        | 819/5000 [36:11<2:50:18,  2.44s/it, loss=4.6058]\u001b[A\n",
            "Training:  16%|█▋        | 819/5000 [36:11<2:50:18,  2.44s/it, loss=4.1646]\u001b[A\n",
            "Training:  16%|█▋        | 820/5000 [36:14<2:47:08,  2.40s/it, loss=4.1646]\u001b[A\n",
            "Training:  16%|█▋        | 820/5000 [36:14<2:47:08,  2.40s/it, loss=5.0667]\u001b[A\n",
            "Training:  16%|█▋        | 821/5000 [36:16<2:44:46,  2.37s/it, loss=5.0667]\u001b[A\n",
            "Training:  16%|█▋        | 821/5000 [36:16<2:44:46,  2.37s/it, loss=4.8571]\u001b[A\n",
            "Training:  16%|█▋        | 822/5000 [36:18<2:43:18,  2.35s/it, loss=4.8571]\u001b[A\n",
            "Training:  16%|█▋        | 822/5000 [36:18<2:43:18,  2.35s/it, loss=4.5261]\u001b[A\n",
            "Training:  16%|█▋        | 823/5000 [36:20<2:41:07,  2.31s/it, loss=4.5261]\u001b[A\n",
            "Training:  16%|█▋        | 823/5000 [36:20<2:41:07,  2.31s/it, loss=4.9377]\u001b[A\n",
            "Training:  16%|█▋        | 824/5000 [36:23<2:50:19,  2.45s/it, loss=4.9377]\u001b[A\n",
            "Training:  16%|█▋        | 824/5000 [36:23<2:50:19,  2.45s/it, loss=3.6957]\u001b[A\n",
            "Training:  16%|█▋        | 825/5000 [36:25<2:45:39,  2.38s/it, loss=3.6957]\u001b[A\n",
            "Training:  16%|█▋        | 825/5000 [36:25<2:45:39,  2.38s/it, loss=4.5978]\u001b[A\n",
            "Training:  17%|█▋        | 826/5000 [36:28<2:42:44,  2.34s/it, loss=4.5978]\u001b[A\n",
            "Training:  17%|█▋        | 826/5000 [36:28<2:42:44,  2.34s/it, loss=4.4352]\u001b[A\n",
            "Training:  17%|█▋        | 827/5000 [36:30<2:40:35,  2.31s/it, loss=4.4352]\u001b[A\n",
            "Training:  17%|█▋        | 827/5000 [36:30<2:40:35,  2.31s/it, loss=5.6857]\u001b[A\n",
            "Training:  17%|█▋        | 828/5000 [36:32<2:39:37,  2.30s/it, loss=5.6857]\u001b[A\n",
            "Training:  17%|█▋        | 828/5000 [36:32<2:39:37,  2.30s/it, loss=4.9903]\u001b[A\n",
            "Training:  17%|█▋        | 829/5000 [36:35<2:48:51,  2.43s/it, loss=4.9903]\u001b[A\n",
            "Training:  17%|█▋        | 829/5000 [36:35<2:48:51,  2.43s/it, loss=5.3845]\u001b[A\n",
            "Training:  17%|█▋        | 830/5000 [36:37<2:44:55,  2.37s/it, loss=5.3845]\u001b[A\n",
            "Training:  17%|█▋        | 830/5000 [36:37<2:44:55,  2.37s/it, loss=5.6260]\u001b[A\n",
            "Training:  17%|█▋        | 831/5000 [36:39<2:41:54,  2.33s/it, loss=5.6260]\u001b[A\n",
            "Training:  17%|█▋        | 831/5000 [36:39<2:41:54,  2.33s/it, loss=5.0703]\u001b[A\n",
            "Training:  17%|█▋        | 832/5000 [36:42<2:40:26,  2.31s/it, loss=5.0703]\u001b[A\n",
            "Training:  17%|█▋        | 832/5000 [36:42<2:40:26,  2.31s/it, loss=4.1008]\u001b[A\n",
            "Training:  17%|█▋        | 833/5000 [36:44<2:39:28,  2.30s/it, loss=4.1008]\u001b[A\n",
            "Training:  17%|█▋        | 833/5000 [36:44<2:39:28,  2.30s/it, loss=5.9112]\u001b[A\n",
            "Training:  17%|█▋        | 834/5000 [36:47<2:49:11,  2.44s/it, loss=5.9112]\u001b[A\n",
            "Training:  17%|█▋        | 834/5000 [36:47<2:49:11,  2.44s/it, loss=4.7506]\u001b[A\n",
            "Training:  17%|█▋        | 835/5000 [36:49<2:45:08,  2.38s/it, loss=4.7506]\u001b[A\n",
            "Training:  17%|█▋        | 835/5000 [36:49<2:45:08,  2.38s/it, loss=4.6292]\u001b[A\n",
            "Training:  17%|█▋        | 836/5000 [36:51<2:42:05,  2.34s/it, loss=4.6292]\u001b[A\n",
            "Training:  17%|█▋        | 836/5000 [36:51<2:42:05,  2.34s/it, loss=5.7286]\u001b[A\n",
            "Training:  17%|█▋        | 837/5000 [36:53<2:40:09,  2.31s/it, loss=5.7286]\u001b[A\n",
            "Training:  17%|█▋        | 837/5000 [36:53<2:40:09,  2.31s/it, loss=4.9930]\u001b[A\n",
            "Training:  17%|█▋        | 838/5000 [36:56<2:38:07,  2.28s/it, loss=4.9930]\u001b[A\n",
            "Training:  17%|█▋        | 838/5000 [36:56<2:38:07,  2.28s/it, loss=5.2578]\u001b[A\n",
            "Training:  17%|█▋        | 839/5000 [36:58<2:47:43,  2.42s/it, loss=5.2578]\u001b[A\n",
            "Training:  17%|█▋        | 839/5000 [36:58<2:47:43,  2.42s/it, loss=4.1417]\u001b[A\n",
            "Training:  17%|█▋        | 840/5000 [37:00<2:43:54,  2.36s/it, loss=4.1417]\u001b[A\n",
            "Training:  17%|█▋        | 840/5000 [37:01<2:43:54,  2.36s/it, loss=4.8356]\u001b[A\n",
            "Training:  17%|█▋        | 841/5000 [37:03<2:41:20,  2.33s/it, loss=4.8356]\u001b[A\n",
            "Training:  17%|█▋        | 841/5000 [37:03<2:41:20,  2.33s/it, loss=4.5826]\u001b[A\n",
            "Training:  17%|█▋        | 842/5000 [37:05<2:39:33,  2.30s/it, loss=4.5826]\u001b[A\n",
            "Training:  17%|█▋        | 842/5000 [37:05<2:39:33,  2.30s/it, loss=5.2669]\u001b[A\n",
            "Training:  17%|█▋        | 843/5000 [37:07<2:37:55,  2.28s/it, loss=5.2669]\u001b[A\n",
            "Training:  17%|█▋        | 843/5000 [37:07<2:37:55,  2.28s/it, loss=5.2621]\u001b[A\n",
            "Training:  17%|█▋        | 844/5000 [37:10<2:47:44,  2.42s/it, loss=5.2621]\u001b[A\n",
            "Training:  17%|█▋        | 844/5000 [37:10<2:47:44,  2.42s/it, loss=3.8198]\u001b[A\n",
            "Training:  17%|█▋        | 845/5000 [37:12<2:44:04,  2.37s/it, loss=3.8198]\u001b[A\n",
            "Training:  17%|█▋        | 845/5000 [37:12<2:44:04,  2.37s/it, loss=4.5362]\u001b[A\n",
            "Training:  17%|█▋        | 846/5000 [37:14<2:41:24,  2.33s/it, loss=4.5362]\u001b[A\n",
            "Training:  17%|█▋        | 846/5000 [37:14<2:41:24,  2.33s/it, loss=3.8210]\u001b[A\n",
            "Training:  17%|█▋        | 847/5000 [37:17<2:39:52,  2.31s/it, loss=3.8210]\u001b[A\n",
            "Training:  17%|█▋        | 847/5000 [37:17<2:39:52,  2.31s/it, loss=4.9204]\u001b[A\n",
            "Training:  17%|█▋        | 848/5000 [37:19<2:38:17,  2.29s/it, loss=4.9204]\u001b[A\n",
            "Training:  17%|█▋        | 848/5000 [37:19<2:38:17,  2.29s/it, loss=5.6074]\u001b[A\n",
            "Training:  17%|█▋        | 849/5000 [37:22<2:46:39,  2.41s/it, loss=5.6074]\u001b[A\n",
            "Training:  17%|█▋        | 849/5000 [37:22<2:46:39,  2.41s/it, loss=5.8511]\u001b[A\n",
            "Training:  17%|█▋        | 850/5000 [37:24<2:44:05,  2.37s/it, loss=5.8511]\u001b[A\n",
            "Training:  17%|█▋        | 850/5000 [37:24<2:44:05,  2.37s/it, loss=4.8965]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 850 ---\n",
            "Prompt: 'The '\n",
            "The  fort the in delaying,Sh tell and\n",
            "aked fat ofelf the from war the's, should as\n",
            " former waterar you not\n",
            " things but the of heavy?\n",
            "Second:Norarth you to him as is\n",
            " may put,'s than thouate' speak not in devil\n",
            " is to true you this's; therefore the on way I?\n",
            "MBRUS\n",
            " is man\n",
            " patile is.\n",
            "COROLN beg and you thest well let no?\n",
            "MG\n",
            "Prompt: 'In '\n",
            "In , hurt is, have'd the, the say\n",
            " save softied un'd so to a, any, other\n",
            ", thy's, stop, and to, you keep, thank.\n",
            "COROLUSIAN:In of good- was!\n",
            "Sires he them the to his;, cannot them.\n",
            "SINUSI: Necess,;, the-- thus; was good, shall\n",
            " am; thank, them be, you let two fellow your: your is even with\n",
            "Prompt: 'To '\n",
            "To , heart has full; being, they to\n",
            " three in spiders deadced to breasts before\n",
            "w dis sack an than, they hence\n",
            " much to him inits. now you daughters good,And\n",
            " valaction you the of, justice your!Think content him ears you' city\n",
            "an with here here speak in time and webre have made to, thee no'd a's?\n",
            "Seconding yetIA you be'd so; if us here out to him this, my true and.\n",
            "Prompt: 'A '\n",
            "A , noble, they;, a\n",
            "ere on thy and nobles in arms\n",
            " rich your dismer streets by; they not, take\n",
            "ear and in power and plague and to him day wity\n",
            " ground make a andide them a of arms my, I it\n",
            " trouuck; I to wisdom I you is to.\n",
            "MENIch:I it hear, me. your is? me you comes\n",
            " did them the, your! that I show to no, you and more\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  17%|█▋        | 851/5000 [37:39<6:57:55,  6.04s/it, loss=4.8965]\u001b[A\n",
            "Training:  17%|█▋        | 851/5000 [37:39<6:57:55,  6.04s/it, loss=5.1046]\u001b[A\n",
            "Training:  17%|█▋        | 852/5000 [37:41<5:39:40,  4.91s/it, loss=5.1046]\u001b[A\n",
            "Training:  17%|█▋        | 852/5000 [37:41<5:39:40,  4.91s/it, loss=3.7068]\u001b[A\n",
            "Training:  17%|█▋        | 853/5000 [37:43<4:44:29,  4.12s/it, loss=3.7068]\u001b[A\n",
            "Training:  17%|█▋        | 853/5000 [37:43<4:44:29,  4.12s/it, loss=5.7346]\u001b[A\n",
            "Training:  17%|█▋        | 854/5000 [37:46<4:17:17,  3.72s/it, loss=5.7346]\u001b[A\n",
            "Training:  17%|█▋        | 854/5000 [37:46<4:17:17,  3.72s/it, loss=4.6942]\u001b[A\n",
            "Training:  17%|█▋        | 855/5000 [37:48<3:46:51,  3.28s/it, loss=4.6942]\u001b[A\n",
            "Training:  17%|█▋        | 855/5000 [37:48<3:46:51,  3.28s/it, loss=5.0818]\u001b[A\n",
            "Training:  17%|█▋        | 856/5000 [37:50<3:25:19,  2.97s/it, loss=5.0818]\u001b[A\n",
            "Training:  17%|█▋        | 856/5000 [37:50<3:25:19,  2.97s/it, loss=5.1316]\u001b[A\n",
            "Training:  17%|█▋        | 857/5000 [37:53<3:09:47,  2.75s/it, loss=5.1316]\u001b[A\n",
            "Training:  17%|█▋        | 857/5000 [37:53<3:09:47,  2.75s/it, loss=4.9666]\u001b[A\n",
            "Training:  17%|█▋        | 858/5000 [37:55<2:58:50,  2.59s/it, loss=4.9666]\u001b[A\n",
            "Training:  17%|█▋        | 858/5000 [37:55<2:58:50,  2.59s/it, loss=5.5718]\u001b[A\n",
            "Training:  17%|█▋        | 859/5000 [37:58<3:02:43,  2.65s/it, loss=5.5718]\u001b[A\n",
            "Training:  17%|█▋        | 859/5000 [37:58<3:02:43,  2.65s/it, loss=5.5836]\u001b[A\n",
            "Training:  17%|█▋        | 860/5000 [38:00<2:54:00,  2.52s/it, loss=5.5836]\u001b[A\n",
            "Training:  17%|█▋        | 860/5000 [38:00<2:54:00,  2.52s/it, loss=5.4591]\u001b[A\n",
            "Training:  17%|█▋        | 861/5000 [38:02<2:48:05,  2.44s/it, loss=5.4591]\u001b[A\n",
            "Training:  17%|█▋        | 861/5000 [38:02<2:48:05,  2.44s/it, loss=4.9870]\u001b[A\n",
            "Training:  17%|█▋        | 862/5000 [38:04<2:43:44,  2.37s/it, loss=4.9870]\u001b[A\n",
            "Training:  17%|█▋        | 862/5000 [38:04<2:43:44,  2.37s/it, loss=5.3900]\u001b[A\n",
            "Training:  17%|█▋        | 863/5000 [38:07<2:40:57,  2.33s/it, loss=5.3900]\u001b[A\n",
            "Training:  17%|█▋        | 863/5000 [38:07<2:40:57,  2.33s/it, loss=4.3855]\u001b[A\n",
            "Training:  17%|█▋        | 864/5000 [38:09<2:49:49,  2.46s/it, loss=4.3855]\u001b[A\n",
            "Training:  17%|█▋        | 864/5000 [38:09<2:49:49,  2.46s/it, loss=4.7230]\u001b[A\n",
            "Training:  17%|█▋        | 865/5000 [38:12<2:45:07,  2.40s/it, loss=4.7230]\u001b[A\n",
            "Training:  17%|█▋        | 865/5000 [38:12<2:45:07,  2.40s/it, loss=4.5324]\u001b[A\n",
            "Training:  17%|█▋        | 866/5000 [38:14<2:41:58,  2.35s/it, loss=4.5324]\u001b[A\n",
            "Training:  17%|█▋        | 866/5000 [38:14<2:41:58,  2.35s/it, loss=4.1343]\u001b[A\n",
            "Training:  17%|█▋        | 867/5000 [38:16<2:40:05,  2.32s/it, loss=4.1343]\u001b[A\n",
            "Training:  17%|█▋        | 867/5000 [38:16<2:40:05,  2.32s/it, loss=4.9516]\u001b[A\n",
            "Training:  17%|█▋        | 868/5000 [38:18<2:38:26,  2.30s/it, loss=4.9516]\u001b[A\n",
            "Training:  17%|█▋        | 868/5000 [38:18<2:38:26,  2.30s/it, loss=4.3704]\u001b[A\n",
            "Training:  17%|█▋        | 869/5000 [38:21<2:47:14,  2.43s/it, loss=4.3704]\u001b[A\n",
            "Training:  17%|█▋        | 869/5000 [38:21<2:47:14,  2.43s/it, loss=4.8646]\u001b[A\n",
            "Training:  17%|█▋        | 870/5000 [38:23<2:43:25,  2.37s/it, loss=4.8646]\u001b[A\n",
            "Training:  17%|█▋        | 870/5000 [38:23<2:43:25,  2.37s/it, loss=5.0444]\u001b[A\n",
            "Training:  17%|█▋        | 871/5000 [38:25<2:40:13,  2.33s/it, loss=5.0444]\u001b[A\n",
            "Training:  17%|█▋        | 871/5000 [38:26<2:40:13,  2.33s/it, loss=5.4095]\u001b[A\n",
            "Training:  17%|█▋        | 872/5000 [38:28<2:38:41,  2.31s/it, loss=5.4095]\u001b[A\n",
            "Training:  17%|█▋        | 872/5000 [38:28<2:38:41,  2.31s/it, loss=4.0668]\u001b[A\n",
            "Training:  17%|█▋        | 873/5000 [38:30<2:36:51,  2.28s/it, loss=4.0668]\u001b[A\n",
            "Training:  17%|█▋        | 873/5000 [38:30<2:36:51,  2.28s/it, loss=4.3883]\u001b[A\n",
            "Training:  17%|█▋        | 874/5000 [38:33<2:46:40,  2.42s/it, loss=4.3883]\u001b[A\n",
            "Training:  17%|█▋        | 874/5000 [38:33<2:46:40,  2.42s/it, loss=5.3311]\u001b[A\n",
            "Training:  18%|█▊        | 875/5000 [38:35<2:42:43,  2.37s/it, loss=5.3311]\u001b[A\n",
            "Training:  18%|█▊        | 875/5000 [38:35<2:42:43,  2.37s/it, loss=5.5590]\u001b[A\n",
            "Training:  18%|█▊        | 876/5000 [38:37<2:39:50,  2.33s/it, loss=5.5590]\u001b[A\n",
            "Training:  18%|█▊        | 876/5000 [38:37<2:39:50,  2.33s/it, loss=3.3256]\u001b[A\n",
            "Training:  18%|█▊        | 877/5000 [38:39<2:38:02,  2.30s/it, loss=3.3256]\u001b[A\n",
            "Training:  18%|█▊        | 877/5000 [38:39<2:38:02,  2.30s/it, loss=4.8824]\u001b[A\n",
            "Training:  18%|█▊        | 878/5000 [38:42<2:36:54,  2.28s/it, loss=4.8824]\u001b[A\n",
            "Training:  18%|█▊        | 878/5000 [38:42<2:36:54,  2.28s/it, loss=4.9830]\u001b[A\n",
            "Training:  18%|█▊        | 879/5000 [38:44<2:46:39,  2.43s/it, loss=4.9830]\u001b[A\n",
            "Training:  18%|█▊        | 879/5000 [38:44<2:46:39,  2.43s/it, loss=5.5176]\u001b[A\n",
            "Training:  18%|█▊        | 880/5000 [38:47<2:44:01,  2.39s/it, loss=5.5176]\u001b[A\n",
            "Training:  18%|█▊        | 880/5000 [38:47<2:44:01,  2.39s/it, loss=4.7550]\u001b[A\n",
            "Training:  18%|█▊        | 881/5000 [38:49<2:41:09,  2.35s/it, loss=4.7550]\u001b[A\n",
            "Training:  18%|█▊        | 881/5000 [38:49<2:41:09,  2.35s/it, loss=4.7491]\u001b[A\n",
            "Training:  18%|█▊        | 882/5000 [38:51<2:39:16,  2.32s/it, loss=4.7491]\u001b[A\n",
            "Training:  18%|█▊        | 882/5000 [38:51<2:39:16,  2.32s/it, loss=5.2416]\u001b[A\n",
            "Training:  18%|█▊        | 883/5000 [38:53<2:37:31,  2.30s/it, loss=5.2416]\u001b[A\n",
            "Training:  18%|█▊        | 883/5000 [38:54<2:37:31,  2.30s/it, loss=4.5798]\u001b[A\n",
            "Training:  18%|█▊        | 884/5000 [38:56<2:46:10,  2.42s/it, loss=4.5798]\u001b[A\n",
            "Training:  18%|█▊        | 884/5000 [38:56<2:46:10,  2.42s/it, loss=4.7385]\u001b[A\n",
            "Training:  18%|█▊        | 885/5000 [38:58<2:43:08,  2.38s/it, loss=4.7385]\u001b[A\n",
            "Training:  18%|█▊        | 885/5000 [38:59<2:43:08,  2.38s/it, loss=5.5211]\u001b[A\n",
            "Training:  18%|█▊        | 886/5000 [39:01<2:40:28,  2.34s/it, loss=5.5211]\u001b[A\n",
            "Training:  18%|█▊        | 886/5000 [39:01<2:40:28,  2.34s/it, loss=5.5826]\u001b[A\n",
            "Training:  18%|█▊        | 887/5000 [39:03<2:38:09,  2.31s/it, loss=5.5826]\u001b[A\n",
            "Training:  18%|█▊        | 887/5000 [39:03<2:38:09,  2.31s/it, loss=4.5136]\u001b[A\n",
            "Training:  18%|█▊        | 888/5000 [39:05<2:36:18,  2.28s/it, loss=4.5136]\u001b[A\n",
            "Training:  18%|█▊        | 888/5000 [39:05<2:36:18,  2.28s/it, loss=4.3908]\u001b[A\n",
            "Training:  18%|█▊        | 889/5000 [39:08<2:42:53,  2.38s/it, loss=4.3908]\u001b[A\n",
            "Training:  18%|█▊        | 889/5000 [39:08<2:42:53,  2.38s/it, loss=4.5970]\u001b[A\n",
            "Training:  18%|█▊        | 890/5000 [39:10<2:42:46,  2.38s/it, loss=4.5970]\u001b[A\n",
            "Training:  18%|█▊        | 890/5000 [39:10<2:42:46,  2.38s/it, loss=3.8673]\u001b[A\n",
            "Training:  18%|█▊        | 891/5000 [39:12<2:39:57,  2.34s/it, loss=3.8673]\u001b[A\n",
            "Training:  18%|█▊        | 891/5000 [39:12<2:39:57,  2.34s/it, loss=4.3637]\u001b[A\n",
            "Training:  18%|█▊        | 892/5000 [39:15<2:37:37,  2.30s/it, loss=4.3637]\u001b[A\n",
            "Training:  18%|█▊        | 892/5000 [39:15<2:37:37,  2.30s/it, loss=4.6971]\u001b[A\n",
            "Training:  18%|█▊        | 893/5000 [39:17<2:36:18,  2.28s/it, loss=4.6971]\u001b[A\n",
            "Training:  18%|█▊        | 893/5000 [39:17<2:36:18,  2.28s/it, loss=5.5020]\u001b[A\n",
            "Training:  18%|█▊        | 894/5000 [39:19<2:43:11,  2.38s/it, loss=5.5020]\u001b[A\n",
            "Training:  18%|█▊        | 894/5000 [39:20<2:43:11,  2.38s/it, loss=4.1456]\u001b[A\n",
            "Training:  18%|█▊        | 895/5000 [39:22<2:43:57,  2.40s/it, loss=4.1456]\u001b[A\n",
            "Training:  18%|█▊        | 895/5000 [39:22<2:43:57,  2.40s/it, loss=4.9794]\u001b[A\n",
            "Training:  18%|█▊        | 896/5000 [39:24<2:40:50,  2.35s/it, loss=4.9794]\u001b[A\n",
            "Training:  18%|█▊        | 896/5000 [39:24<2:40:50,  2.35s/it, loss=3.7127]\u001b[A\n",
            "Training:  18%|█▊        | 897/5000 [39:26<2:38:49,  2.32s/it, loss=3.7127]\u001b[A\n",
            "Training:  18%|█▊        | 897/5000 [39:26<2:38:49,  2.32s/it, loss=5.3068]\u001b[A\n",
            "Training:  18%|█▊        | 898/5000 [39:29<2:37:08,  2.30s/it, loss=5.3068]\u001b[A\n",
            "Training:  18%|█▊        | 898/5000 [39:29<2:37:08,  2.30s/it, loss=5.2449]\u001b[A\n",
            "Training:  18%|█▊        | 899/5000 [39:31<2:41:48,  2.37s/it, loss=5.2449]\u001b[A\n",
            "Training:  18%|█▊        | 899/5000 [39:31<2:41:48,  2.37s/it, loss=4.3953]\u001b[A\n",
            "Training:  18%|█▊        | 900/5000 [39:34<2:43:56,  2.40s/it, loss=4.3953]\u001b[A\n",
            "Training:  18%|█▊        | 900/5000 [39:34<2:43:56,  2.40s/it, loss=4.1839]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 900 ---\n",
            "Prompt: 'The '\n",
            "The  man a of sham\n",
            " weighs at state wall\n",
            "- l.\n",
            "Hily thouest the,ague fol of confer\n",
            "ra?\n",
            "GCAPARD\n",
            "LORK\n",
            "HRYCY\n",
            " talk woman fury the: so is so\n",
            " repl of life then have un'd?\n",
            "Hart the as aert'd dayrown, would be king crown WarwickThisous'soth\n",
            "ure but comes with have here gentle,,! monument than-, that name it my, much of own\n",
            "Prompt: 'In '\n",
            "In  is with heart his' and ransom\n",
            "'sasteconstant we, that might himself O.\n",
            "D not then woman and?\n",
            "D thou no thou thy was?\n",
            " shall boundThrough for heart I sir\n",
            " you at men, gracious: but one as as as world\n",
            "O, I be king and?\n",
            "Hwell king gro many to it\n",
            "N, me ' I my love, yet have you:The were my be.I not last?\n",
            "D thoust not upon counsel my\n",
            "Prompt: 'To '\n",
            "To , per un in bed lesser thou.\n",
            "ant, not itut me if be dead wouldt,And come\n",
            " much than have here youyou, thee you.\n",
            "Hwell b,,, IWh die or to.\n",
            "H thouert said you, good; being thouert not:Look I not this\n",
            " byr be, and shall unto world I live\n",
            " I to.\n",
            "L title cam gentlemen I not,; is gone make not.\n",
            "K tedious me latest better\n",
            "Prompt: 'A '\n",
            "A .\n",
            "N,\n",
            " your, me aboutcer\n",
            " name thrown sweet;tis\n",
            " p: you well to them what it, know, this\n",
            " seem to it\n",
            " one at brothers the used Sir point I now\n",
            "; the ofREG with.\n",
            "LY\n",
            "HRY of time and\n",
            " R\n",
            ", far, besch, at judge\n",
            " blow blade and, I thee what have so here\n",
            " body for life death ever.\n",
            "H.\n",
            " foe and for own by by sweet,\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  18%|█▊        | 901/5000 [39:48<6:54:55,  6.07s/it, loss=4.1839]\u001b[A\n",
            "Training:  18%|█▊        | 901/5000 [39:48<6:54:55,  6.07s/it, loss=4.4622]\u001b[A\n",
            "Training:  18%|█▊        | 902/5000 [39:51<5:36:26,  4.93s/it, loss=4.4622]\u001b[A\n",
            "Training:  18%|█▊        | 902/5000 [39:51<5:36:26,  4.93s/it, loss=4.9149]\u001b[A\n",
            "Training:  18%|█▊        | 903/5000 [39:53<4:41:32,  4.12s/it, loss=4.9149]\u001b[A\n",
            "Training:  18%|█▊        | 903/5000 [39:53<4:41:32,  4.12s/it, loss=4.8120]\u001b[A\n",
            "Training:  18%|█▊        | 904/5000 [39:56<4:13:51,  3.72s/it, loss=4.8120]\u001b[A\n",
            "Training:  18%|█▊        | 904/5000 [39:56<4:13:51,  3.72s/it, loss=4.6668]\u001b[A\n",
            "Training:  18%|█▊        | 905/5000 [39:58<3:43:31,  3.28s/it, loss=4.6668]\u001b[A\n",
            "Training:  18%|█▊        | 905/5000 [39:58<3:43:31,  3.28s/it, loss=3.9927]\u001b[A\n",
            "Training:  18%|█▊        | 906/5000 [40:00<3:21:53,  2.96s/it, loss=3.9927]\u001b[A\n",
            "Training:  18%|█▊        | 906/5000 [40:00<3:21:53,  2.96s/it, loss=4.6320]\u001b[A\n",
            "Training:  18%|█▊        | 907/5000 [40:02<3:07:30,  2.75s/it, loss=4.6320]\u001b[A\n",
            "Training:  18%|█▊        | 907/5000 [40:02<3:07:30,  2.75s/it, loss=4.8975]\u001b[A\n",
            "Training:  18%|█▊        | 908/5000 [40:05<2:56:55,  2.59s/it, loss=4.8975]\u001b[A\n",
            "Training:  18%|█▊        | 908/5000 [40:05<2:56:55,  2.59s/it, loss=5.0222]\u001b[A\n",
            "Training:  18%|█▊        | 909/5000 [40:07<2:59:46,  2.64s/it, loss=5.0222]\u001b[A\n",
            "Training:  18%|█▊        | 909/5000 [40:07<2:59:46,  2.64s/it, loss=5.1947]\u001b[A\n",
            "Training:  18%|█▊        | 910/5000 [40:10<2:51:55,  2.52s/it, loss=5.1947]\u001b[A\n",
            "Training:  18%|█▊        | 910/5000 [40:10<2:51:55,  2.52s/it, loss=4.2341]\u001b[A\n",
            "Training:  18%|█▊        | 911/5000 [40:12<2:46:25,  2.44s/it, loss=4.2341]\u001b[A\n",
            "Training:  18%|█▊        | 911/5000 [40:12<2:46:25,  2.44s/it, loss=4.7014]\u001b[A\n",
            "Training:  18%|█▊        | 912/5000 [40:14<2:42:44,  2.39s/it, loss=4.7014]\u001b[A\n",
            "Training:  18%|█▊        | 912/5000 [40:14<2:42:44,  2.39s/it, loss=4.5504]\u001b[A\n",
            "Training:  18%|█▊        | 913/5000 [40:16<2:38:53,  2.33s/it, loss=4.5504]\u001b[A\n",
            "Training:  18%|█▊        | 913/5000 [40:16<2:38:53,  2.33s/it, loss=3.9700]\u001b[A\n",
            "Training:  18%|█▊        | 914/5000 [40:19<2:45:44,  2.43s/it, loss=3.9700]\u001b[A\n",
            "Training:  18%|█▊        | 914/5000 [40:19<2:45:44,  2.43s/it, loss=4.5005]\u001b[A\n",
            "Training:  18%|█▊        | 915/5000 [40:21<2:44:00,  2.41s/it, loss=4.5005]\u001b[A\n",
            "Training:  18%|█▊        | 915/5000 [40:21<2:44:00,  2.41s/it, loss=5.1091]\u001b[A\n",
            "Training:  18%|█▊        | 916/5000 [40:23<2:40:31,  2.36s/it, loss=5.1091]\u001b[A\n",
            "Training:  18%|█▊        | 916/5000 [40:24<2:40:31,  2.36s/it, loss=4.7563]\u001b[A\n",
            "Training:  18%|█▊        | 917/5000 [40:26<2:37:42,  2.32s/it, loss=4.7563]\u001b[A\n",
            "Training:  18%|█▊        | 917/5000 [40:26<2:37:42,  2.32s/it, loss=4.2097]\u001b[A\n",
            "Training:  18%|█▊        | 918/5000 [40:28<2:36:20,  2.30s/it, loss=4.2097]\u001b[A\n",
            "Training:  18%|█▊        | 918/5000 [40:28<2:36:20,  2.30s/it, loss=4.5463]\u001b[A\n",
            "Training:  18%|█▊        | 919/5000 [40:31<2:41:52,  2.38s/it, loss=4.5463]\u001b[A\n",
            "Training:  18%|█▊        | 919/5000 [40:31<2:41:52,  2.38s/it, loss=4.5716]\u001b[A\n",
            "Training:  18%|█▊        | 920/5000 [40:33<2:42:54,  2.40s/it, loss=4.5716]\u001b[A\n",
            "Training:  18%|█▊        | 920/5000 [40:33<2:42:54,  2.40s/it, loss=5.5215]\u001b[A\n",
            "Training:  18%|█▊        | 921/5000 [40:35<2:39:04,  2.34s/it, loss=5.5215]\u001b[A\n",
            "Training:  18%|█▊        | 921/5000 [40:35<2:39:04,  2.34s/it, loss=5.0487]\u001b[A\n",
            "Training:  18%|█▊        | 922/5000 [40:37<2:37:04,  2.31s/it, loss=5.0487]\u001b[A\n",
            "Training:  18%|█▊        | 922/5000 [40:37<2:37:04,  2.31s/it, loss=5.4493]\u001b[A\n",
            "Training:  18%|█▊        | 923/5000 [40:40<2:35:48,  2.29s/it, loss=5.4493]\u001b[A\n",
            "Training:  18%|█▊        | 923/5000 [40:40<2:35:48,  2.29s/it, loss=5.3824]\u001b[A\n",
            "Training:  18%|█▊        | 924/5000 [40:42<2:41:10,  2.37s/it, loss=5.3824]\u001b[A\n",
            "Training:  18%|█▊        | 924/5000 [40:42<2:41:10,  2.37s/it, loss=3.5297]\u001b[A\n",
            "Training:  18%|█▊        | 925/5000 [40:45<2:43:11,  2.40s/it, loss=3.5297]\u001b[A\n",
            "Training:  18%|█▊        | 925/5000 [40:45<2:43:11,  2.40s/it, loss=4.9051]\u001b[A\n",
            "Training:  19%|█▊        | 926/5000 [40:47<2:39:46,  2.35s/it, loss=4.9051]\u001b[A\n",
            "Training:  19%|█▊        | 926/5000 [40:47<2:39:46,  2.35s/it, loss=4.9205]\u001b[A\n",
            "Training:  19%|█▊        | 927/5000 [40:49<2:38:41,  2.34s/it, loss=4.9205]\u001b[A\n",
            "Training:  19%|█▊        | 927/5000 [40:49<2:38:41,  2.34s/it, loss=4.6333]\u001b[A\n",
            "Training:  19%|█▊        | 928/5000 [40:51<2:36:27,  2.31s/it, loss=4.6333]\u001b[A\n",
            "Training:  19%|█▊        | 928/5000 [40:52<2:36:27,  2.31s/it, loss=4.1773]\u001b[A\n",
            "Training:  19%|█▊        | 929/5000 [40:54<2:40:48,  2.37s/it, loss=4.1773]\u001b[A\n",
            "Training:  19%|█▊        | 929/5000 [40:54<2:40:48,  2.37s/it, loss=4.8372]\u001b[A\n",
            "Training:  19%|█▊        | 930/5000 [40:56<2:42:51,  2.40s/it, loss=4.8372]\u001b[A\n",
            "Training:  19%|█▊        | 930/5000 [40:56<2:42:51,  2.40s/it, loss=5.2796]\u001b[A\n",
            "Training:  19%|█▊        | 931/5000 [40:59<2:40:00,  2.36s/it, loss=5.2796]\u001b[A\n",
            "Training:  19%|█▊        | 931/5000 [40:59<2:40:00,  2.36s/it, loss=4.5199]\u001b[A\n",
            "Training:  19%|█▊        | 932/5000 [41:01<2:37:17,  2.32s/it, loss=4.5199]\u001b[A\n",
            "Training:  19%|█▊        | 932/5000 [41:01<2:37:17,  2.32s/it, loss=4.5264]\u001b[A\n",
            "Training:  19%|█▊        | 933/5000 [41:03<2:36:13,  2.30s/it, loss=4.5264]\u001b[A\n",
            "Training:  19%|█▊        | 933/5000 [41:03<2:36:13,  2.30s/it, loss=4.5195]\u001b[A\n",
            "Training:  19%|█▊        | 934/5000 [41:06<2:39:44,  2.36s/it, loss=4.5195]\u001b[A\n",
            "Training:  19%|█▊        | 934/5000 [41:06<2:39:44,  2.36s/it, loss=3.9101]\u001b[A\n",
            "Training:  19%|█▊        | 935/5000 [41:08<2:43:01,  2.41s/it, loss=3.9101]\u001b[A\n",
            "Training:  19%|█▊        | 935/5000 [41:08<2:43:01,  2.41s/it, loss=3.5502]\u001b[A\n",
            "Training:  19%|█▊        | 936/5000 [41:10<2:39:34,  2.36s/it, loss=3.5502]\u001b[A\n",
            "Training:  19%|█▊        | 936/5000 [41:10<2:39:34,  2.36s/it, loss=4.7182]\u001b[A\n",
            "Training:  19%|█▊        | 937/5000 [41:13<2:37:33,  2.33s/it, loss=4.7182]\u001b[A\n",
            "Training:  19%|█▊        | 937/5000 [41:13<2:37:33,  2.33s/it, loss=3.9266]\u001b[A\n",
            "Training:  19%|█▉        | 938/5000 [41:15<2:35:42,  2.30s/it, loss=3.9266]\u001b[A\n",
            "Training:  19%|█▉        | 938/5000 [41:15<2:35:42,  2.30s/it, loss=5.3698]\u001b[A\n",
            "Training:  19%|█▉        | 939/5000 [41:17<2:39:14,  2.35s/it, loss=5.3698]\u001b[A\n",
            "Training:  19%|█▉        | 939/5000 [41:17<2:39:14,  2.35s/it, loss=5.9333]\u001b[A\n",
            "Training:  19%|█▉        | 940/5000 [41:20<2:43:20,  2.41s/it, loss=5.9333]\u001b[A\n",
            "Training:  19%|█▉        | 940/5000 [41:20<2:43:20,  2.41s/it, loss=5.3283]\u001b[A\n",
            "Training:  19%|█▉        | 941/5000 [41:22<2:39:56,  2.36s/it, loss=5.3283]\u001b[A\n",
            "Training:  19%|█▉        | 941/5000 [41:22<2:39:56,  2.36s/it, loss=5.1064]\u001b[A\n",
            "Training:  19%|█▉        | 942/5000 [41:25<2:37:57,  2.34s/it, loss=5.1064]\u001b[A\n",
            "Training:  19%|█▉        | 942/5000 [41:25<2:37:57,  2.34s/it, loss=4.8456]\u001b[A\n",
            "Training:  19%|█▉        | 943/5000 [41:27<2:36:17,  2.31s/it, loss=4.8456]\u001b[A\n",
            "Training:  19%|█▉        | 943/5000 [41:27<2:36:17,  2.31s/it, loss=5.3681]\u001b[A\n",
            "Training:  19%|█▉        | 944/5000 [41:29<2:40:05,  2.37s/it, loss=5.3681]\u001b[A\n",
            "Training:  19%|█▉        | 944/5000 [41:29<2:40:05,  2.37s/it, loss=5.0282]\u001b[A\n",
            "Training:  19%|█▉        | 945/5000 [41:32<2:44:23,  2.43s/it, loss=5.0282]\u001b[A\n",
            "Training:  19%|█▉        | 945/5000 [41:32<2:44:23,  2.43s/it, loss=5.6238]\u001b[A\n",
            "Training:  19%|█▉        | 946/5000 [41:34<2:40:38,  2.38s/it, loss=5.6238]\u001b[A\n",
            "Training:  19%|█▉        | 946/5000 [41:34<2:40:38,  2.38s/it, loss=5.1288]\u001b[A\n",
            "Training:  19%|█▉        | 947/5000 [41:36<2:37:33,  2.33s/it, loss=5.1288]\u001b[A\n",
            "Training:  19%|█▉        | 947/5000 [41:36<2:37:33,  2.33s/it, loss=5.2978]\u001b[A\n",
            "Training:  19%|█▉        | 948/5000 [41:39<2:35:48,  2.31s/it, loss=5.2978]\u001b[A\n",
            "Training:  19%|█▉        | 948/5000 [41:39<2:35:48,  2.31s/it, loss=5.4115]\u001b[A\n",
            "Training:  19%|█▉        | 949/5000 [41:41<2:38:56,  2.35s/it, loss=5.4115]\u001b[A\n",
            "Training:  19%|█▉        | 949/5000 [41:41<2:38:56,  2.35s/it, loss=4.9683]\u001b[A\n",
            "Training:  19%|█▉        | 950/5000 [41:44<2:43:42,  2.43s/it, loss=4.9683]\u001b[A\n",
            "Training:  19%|█▉        | 950/5000 [41:44<2:43:42,  2.43s/it, loss=5.0575]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 950 ---\n",
            "Prompt: 'The '\n",
            "The  of, be,, and, had eyes\n",
            " virtuous the of sil, here and the my yours\n",
            "u to the and of oft rest.\n",
            "PERAOLUS\n",
            " king what a,illo make! light murd,, have\n",
            ", bear way maid's, gulf word would haveProper by\n",
            "elt of is and may\n",
            " the of own and with behind than the of,,, wild-ath in for is ever the of,, see night what your, my, envy this I\n",
            "Prompt: 'In '\n",
            "In  my-,'d for's, and,SheWhichOr',That,You not wrong enough't have more.\n",
            "MILLINA\n",
            "ison to,,; sure thou, me the of of,uck,:,,, lord\n",
            " the- dreams with, had and's oerest the call, here\n",
            " the is of,Th art of a, a- and you! any,,,tis how the of!o's and, my,\n",
            " know, good,\n",
            "Prompt: 'To '\n",
            "To 's, a hom cause you my,You,How Le the\n",
            " kept of,, Iot; it sir' found\n",
            "ogs is. is that vast the do would a, much\n",
            "all courtly.\n",
            "'s said less the have to with greater, follows\n",
            " her enough th at condemn with, I; you yours\n",
            " light me't when are,, you to, any:Go the point all where aman; there I dead need then\n",
            " time well sir these were, life\n",
            "Prompt: 'A '\n",
            "A  to will them take't\n",
            " him me than were thr thouest\n",
            " stain not these, I,re best will.\n",
            "Serv:'ll\n",
            "oust thy, lord\n",
            " have prove.\n",
            "io nothing't\n",
            "all will the of lord\n",
            " most's,enger\n",
            ", meine of, come see,,, sir\n",
            "end very but touch.\n",
            "First with!\n",
            "Cn answer,, that my- you this a ofs a, very,S,? thou had;,\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  19%|█▉        | 951/5000 [41:58<6:51:02,  6.09s/it, loss=5.0575]\u001b[A\n",
            "Training:  19%|█▉        | 951/5000 [41:58<6:51:02,  6.09s/it, loss=4.5375]\u001b[A\n",
            "Training:  19%|█▉        | 952/5000 [42:01<5:32:42,  4.93s/it, loss=4.5375]\u001b[A\n",
            "Training:  19%|█▉        | 952/5000 [42:01<5:32:42,  4.93s/it, loss=5.3785]\u001b[A\n",
            "Training:  19%|█▉        | 953/5000 [42:03<4:38:15,  4.13s/it, loss=5.3785]\u001b[A\n",
            "Training:  19%|█▉        | 953/5000 [42:03<4:38:15,  4.13s/it, loss=4.9921]\u001b[A\n",
            "Training:  19%|█▉        | 954/5000 [42:05<4:07:14,  3.67s/it, loss=4.9921]\u001b[A\n",
            "Training:  19%|█▉        | 954/5000 [42:05<4:07:14,  3.67s/it, loss=5.2827]\u001b[A\n",
            "Training:  19%|█▉        | 955/5000 [42:08<3:42:03,  3.29s/it, loss=5.2827]\u001b[A\n",
            "Training:  19%|█▉        | 955/5000 [42:08<3:42:03,  3.29s/it, loss=5.3081]\u001b[A\n",
            "Training:  19%|█▉        | 956/5000 [42:10<3:20:47,  2.98s/it, loss=5.3081]\u001b[A\n",
            "Training:  19%|█▉        | 956/5000 [42:10<3:20:47,  2.98s/it, loss=5.8681]\u001b[A\n",
            "Training:  19%|█▉        | 957/5000 [42:12<3:06:02,  2.76s/it, loss=5.8681]\u001b[A\n",
            "Training:  19%|█▉        | 957/5000 [42:12<3:06:02,  2.76s/it, loss=4.7391]\u001b[A\n",
            "Training:  19%|█▉        | 958/5000 [42:15<2:55:35,  2.61s/it, loss=4.7391]\u001b[A\n",
            "Training:  19%|█▉        | 958/5000 [42:15<2:55:35,  2.61s/it, loss=4.4706]\u001b[A\n",
            "Training:  19%|█▉        | 959/5000 [42:17<2:53:28,  2.58s/it, loss=4.4706]\u001b[A\n",
            "Training:  19%|█▉        | 959/5000 [42:17<2:53:28,  2.58s/it, loss=4.5602]\u001b[A\n",
            "Training:  19%|█▉        | 960/5000 [42:20<2:52:11,  2.56s/it, loss=4.5602]\u001b[A\n",
            "Training:  19%|█▉        | 960/5000 [42:20<2:52:11,  2.56s/it, loss=4.8103]\u001b[A\n",
            "Training:  19%|█▉        | 961/5000 [42:22<2:45:25,  2.46s/it, loss=4.8103]\u001b[A\n",
            "Training:  19%|█▉        | 961/5000 [42:22<2:45:25,  2.46s/it, loss=4.3978]\u001b[A\n",
            "Training:  19%|█▉        | 962/5000 [42:24<2:40:49,  2.39s/it, loss=4.3978]\u001b[A\n",
            "Training:  19%|█▉        | 962/5000 [42:24<2:40:49,  2.39s/it, loss=4.7491]\u001b[A\n",
            "Training:  19%|█▉        | 963/5000 [42:26<2:37:31,  2.34s/it, loss=4.7491]\u001b[A\n",
            "Training:  19%|█▉        | 963/5000 [42:26<2:37:31,  2.34s/it, loss=5.4766]\u001b[A\n",
            "Training:  19%|█▉        | 964/5000 [42:29<2:40:55,  2.39s/it, loss=5.4766]\u001b[A\n",
            "Training:  19%|█▉        | 964/5000 [42:29<2:40:55,  2.39s/it, loss=4.2490]\u001b[A\n",
            "Training:  19%|█▉        | 965/5000 [42:31<2:43:01,  2.42s/it, loss=4.2490]\u001b[A\n",
            "Training:  19%|█▉        | 965/5000 [42:31<2:43:01,  2.42s/it, loss=4.7299]\u001b[A\n",
            "Training:  19%|█▉        | 966/5000 [42:33<2:39:17,  2.37s/it, loss=4.7299]\u001b[A\n",
            "Training:  19%|█▉        | 966/5000 [42:33<2:39:17,  2.37s/it, loss=3.7062]\u001b[A\n",
            "Training:  19%|█▉        | 967/5000 [42:36<2:37:10,  2.34s/it, loss=3.7062]\u001b[A\n",
            "Training:  19%|█▉        | 967/5000 [42:36<2:37:10,  2.34s/it, loss=4.5434]\u001b[A\n",
            "Training:  19%|█▉        | 968/5000 [42:38<2:35:27,  2.31s/it, loss=4.5434]\u001b[A\n",
            "Training:  19%|█▉        | 968/5000 [42:38<2:35:27,  2.31s/it, loss=3.9203]\u001b[A\n",
            "Training:  19%|█▉        | 969/5000 [42:40<2:39:11,  2.37s/it, loss=3.9203]\u001b[A\n",
            "Training:  19%|█▉        | 969/5000 [42:41<2:39:11,  2.37s/it, loss=3.4356]\u001b[A\n",
            "Training:  19%|█▉        | 970/5000 [42:43<2:42:05,  2.41s/it, loss=3.4356]\u001b[A\n",
            "Training:  19%|█▉        | 970/5000 [42:43<2:42:05,  2.41s/it, loss=4.6209]\u001b[A\n",
            "Training:  19%|█▉        | 971/5000 [42:45<2:39:01,  2.37s/it, loss=4.6209]\u001b[A\n",
            "Training:  19%|█▉        | 971/5000 [42:45<2:39:01,  2.37s/it, loss=4.1945]\u001b[A\n",
            "Training:  19%|█▉        | 972/5000 [42:48<2:36:22,  2.33s/it, loss=4.1945]\u001b[A\n",
            "Training:  19%|█▉        | 972/5000 [42:48<2:36:22,  2.33s/it, loss=5.0030]\u001b[A\n",
            "Training:  19%|█▉        | 973/5000 [42:50<2:34:35,  2.30s/it, loss=5.0030]\u001b[A\n",
            "Training:  19%|█▉        | 973/5000 [42:50<2:34:35,  2.30s/it, loss=4.9316]\u001b[A\n",
            "Training:  19%|█▉        | 974/5000 [42:52<2:38:00,  2.35s/it, loss=4.9316]\u001b[A\n",
            "Training:  19%|█▉        | 974/5000 [42:52<2:38:00,  2.35s/it, loss=5.1075]\u001b[A\n",
            "Training:  20%|█▉        | 975/5000 [42:55<2:41:40,  2.41s/it, loss=5.1075]\u001b[A\n",
            "Training:  20%|█▉        | 975/5000 [42:55<2:41:40,  2.41s/it, loss=5.5018]\u001b[A\n",
            "Training:  20%|█▉        | 976/5000 [42:57<2:37:59,  2.36s/it, loss=5.5018]\u001b[A\n",
            "Training:  20%|█▉        | 976/5000 [42:57<2:37:59,  2.36s/it, loss=4.6219]\u001b[A\n",
            "Training:  20%|█▉        | 977/5000 [42:59<2:35:40,  2.32s/it, loss=4.6219]\u001b[A\n",
            "Training:  20%|█▉        | 977/5000 [42:59<2:35:40,  2.32s/it, loss=5.5221]\u001b[A\n",
            "Training:  20%|█▉        | 978/5000 [43:01<2:33:49,  2.29s/it, loss=5.5221]\u001b[A\n",
            "Training:  20%|█▉        | 978/5000 [43:01<2:33:49,  2.29s/it, loss=4.8995]\u001b[A\n",
            "Training:  20%|█▉        | 979/5000 [43:04<2:36:08,  2.33s/it, loss=4.8995]\u001b[A\n",
            "Training:  20%|█▉        | 979/5000 [43:04<2:36:08,  2.33s/it, loss=4.5490]\u001b[A\n",
            "Training:  20%|█▉        | 980/5000 [43:06<2:40:43,  2.40s/it, loss=4.5490]\u001b[A\n",
            "Training:  20%|█▉        | 980/5000 [43:06<2:40:43,  2.40s/it, loss=4.1748]\u001b[A\n",
            "Training:  20%|█▉        | 981/5000 [43:09<2:37:36,  2.35s/it, loss=4.1748]\u001b[A\n",
            "Training:  20%|█▉        | 981/5000 [43:09<2:37:36,  2.35s/it, loss=4.1140]\u001b[A\n",
            "Training:  20%|█▉        | 982/5000 [43:11<2:35:40,  2.32s/it, loss=4.1140]\u001b[A\n",
            "Training:  20%|█▉        | 982/5000 [43:11<2:35:40,  2.32s/it, loss=4.7178]\u001b[A\n",
            "Training:  20%|█▉        | 983/5000 [43:13<2:34:05,  2.30s/it, loss=4.7178]\u001b[A\n",
            "Training:  20%|█▉        | 983/5000 [43:13<2:34:05,  2.30s/it, loss=5.0313]\u001b[A\n",
            "Training:  20%|█▉        | 984/5000 [43:16<2:35:31,  2.32s/it, loss=5.0313]\u001b[A\n",
            "Training:  20%|█▉        | 984/5000 [43:16<2:35:31,  2.32s/it, loss=4.0598]\u001b[A\n",
            "Training:  20%|█▉        | 985/5000 [43:18<2:41:42,  2.42s/it, loss=4.0598]\u001b[A\n",
            "Training:  20%|█▉        | 985/5000 [43:18<2:41:42,  2.42s/it, loss=4.5303]\u001b[A\n",
            "Training:  20%|█▉        | 986/5000 [43:20<2:38:36,  2.37s/it, loss=4.5303]\u001b[A\n",
            "Training:  20%|█▉        | 986/5000 [43:20<2:38:36,  2.37s/it, loss=4.2310]\u001b[A\n",
            "Training:  20%|█▉        | 987/5000 [43:23<2:35:39,  2.33s/it, loss=4.2310]\u001b[A\n",
            "Training:  20%|█▉        | 987/5000 [43:23<2:35:39,  2.33s/it, loss=5.3015]\u001b[A\n",
            "Training:  20%|█▉        | 988/5000 [43:25<2:33:43,  2.30s/it, loss=5.3015]\u001b[A\n",
            "Training:  20%|█▉        | 988/5000 [43:25<2:33:43,  2.30s/it, loss=4.5598]\u001b[A\n",
            "Training:  20%|█▉        | 989/5000 [43:27<2:33:53,  2.30s/it, loss=4.5598]\u001b[A\n",
            "Training:  20%|█▉        | 989/5000 [43:27<2:33:53,  2.30s/it, loss=4.0767]\u001b[A\n",
            "Training:  20%|█▉        | 990/5000 [43:30<2:41:29,  2.42s/it, loss=4.0767]\u001b[A\n",
            "Training:  20%|█▉        | 990/5000 [43:30<2:41:29,  2.42s/it, loss=3.5737]\u001b[A\n",
            "Training:  20%|█▉        | 991/5000 [43:32<2:37:52,  2.36s/it, loss=3.5737]\u001b[A\n",
            "Training:  20%|█▉        | 991/5000 [43:32<2:37:52,  2.36s/it, loss=4.5066]\u001b[A\n",
            "Training:  20%|█▉        | 992/5000 [43:34<2:35:04,  2.32s/it, loss=4.5066]\u001b[A\n",
            "Training:  20%|█▉        | 992/5000 [43:34<2:35:04,  2.32s/it, loss=4.1042]\u001b[A\n",
            "Training:  20%|█▉        | 993/5000 [43:37<2:33:11,  2.29s/it, loss=4.1042]\u001b[A\n",
            "Training:  20%|█▉        | 993/5000 [43:37<2:33:11,  2.29s/it, loss=3.6142]\u001b[A\n",
            "Training:  20%|█▉        | 994/5000 [43:39<2:32:42,  2.29s/it, loss=3.6142]\u001b[A\n",
            "Training:  20%|█▉        | 994/5000 [43:39<2:32:42,  2.29s/it, loss=5.1301]\u001b[A\n",
            "Training:  20%|█▉        | 995/5000 [43:42<2:42:17,  2.43s/it, loss=5.1301]\u001b[A\n",
            "Training:  20%|█▉        | 995/5000 [43:42<2:42:17,  2.43s/it, loss=4.7716]\u001b[A\n",
            "Training:  20%|█▉        | 996/5000 [43:44<2:39:23,  2.39s/it, loss=4.7716]\u001b[A\n",
            "Training:  20%|█▉        | 996/5000 [43:44<2:39:23,  2.39s/it, loss=4.9804]\u001b[A\n",
            "Training:  20%|█▉        | 997/5000 [43:46<2:36:27,  2.35s/it, loss=4.9804]\u001b[A\n",
            "Training:  20%|█▉        | 997/5000 [43:46<2:36:27,  2.35s/it, loss=5.1998]\u001b[A\n",
            "Training:  20%|█▉        | 998/5000 [43:48<2:34:09,  2.31s/it, loss=5.1998]\u001b[A\n",
            "Training:  20%|█▉        | 998/5000 [43:48<2:34:09,  2.31s/it, loss=4.9573]\u001b[A\n",
            "Training:  20%|█▉        | 999/5000 [43:51<2:34:03,  2.31s/it, loss=4.9573]\u001b[A\n",
            "Training:  20%|█▉        | 999/5000 [43:51<2:34:03,  2.31s/it, loss=4.7076]\u001b[A\n",
            "Training:  20%|██        | 1000/5000 [43:53<2:42:34,  2.44s/it, loss=4.7076]\u001b[A\n",
            "Training:  20%|██        | 1000/5000 [43:53<2:42:34,  2.44s/it, loss=5.1106]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 1000 ---\n",
            "Prompt: 'The '\n",
            "The \n",
            " often their.\n",
            "VCT:Tor that us to't\n",
            " dreadful but enough\n",
            " was become.\n",
            "GZO\n",
            ", of the, all drops andn suit\n",
            "an to, meet lords but honours the.\n",
            "L\n",
            "ENG copy:Where by forth I, you like fire the\n",
            " Iee you ',; might me speak\n",
            " honour ing mercy I, besch.\n",
            "ANTIO\n",
            ", reason\n",
            ", noise your.\n",
            "Firstman\n",
            " would ust\n",
            "Prompt: 'In '\n",
            "In \n",
            " all death not; not ever Rome\n",
            "an oer time o the of town\n",
            " when own the that and.\n",
            " comOf power\n",
            " that had power to: it't good well was at.\n",
            "GZO\n",
            "ull gods\n",
            " present made perform suffer to from great\n",
            " so soldier\n",
            "id than as as as as as as as is is good.\n",
            " thrown those,!\n",
            "GZ per villain\n",
            " the of private\n",
            " fear carbon another\n",
            " sonsames wait.\n",
            "COROLLO\n",
            "Prompt: 'To '\n",
            "To  my is which it.\n",
            "ANTIO\n",
            "OR:I at,,:And you,am\n",
            " power good cry\n",
            " art\n",
            " part us mile The.\n",
            "COROLUS\n",
            " you he,tis faults the of,,That no.\n",
            "ANTIO\n",
            " good,!?My is: such a, bound.\n",
            "Wid:And stomachs\n",
            " would the of a when are desires\n",
            " war people: must not't me these and,That as said my, enemy\n",
            " in my speak grant\n",
            "Prompt: 'A '\n",
            "A  to,\n",
            "anging Rome fragments that Clarence you RomeWhen th,.\n",
            "ANTIO\n",
            "',pert, you,.\n",
            "ARI:No\n",
            " good,illo\n",
            " offer it the may the, you it strong fenAgain\n",
            "yond.\n",
            "ANTIO\n",
            "PROwhat, lord I.\n",
            "SETI:Why it\n",
            ",,tis.\n",
            "SETI:My\n",
            " is,!\n",
            "COROLUS\n",
            "Mess:\n",
            ",, are, your,tis.ost good is it I\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "✓ Checkpoint saved: checkpoints/checkpoint_step_1000.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  20%|██        | 1001/5000 [44:41<17:52:22, 16.09s/it, loss=5.1106]\u001b[A\n",
            "Training:  20%|██        | 1001/5000 [44:41<17:52:22, 16.09s/it, loss=5.3636]\u001b[A\n",
            "Training:  20%|██        | 1002/5000 [44:44<13:16:02, 11.95s/it, loss=5.3636]\u001b[A\n",
            "Training:  20%|██        | 1002/5000 [44:44<13:16:02, 11.95s/it, loss=3.7449]\u001b[A\n",
            "Training:  20%|██        | 1003/5000 [44:46<10:01:29,  9.03s/it, loss=3.7449]\u001b[A\n",
            "Training:  20%|██        | 1003/5000 [44:46<10:01:29,  9.03s/it, loss=4.1068]\u001b[A\n",
            "Training:  20%|██        | 1004/5000 [44:48<7:45:58,  7.00s/it, loss=4.1068] \u001b[A\n",
            "Training:  20%|██        | 1004/5000 [44:48<7:45:58,  7.00s/it, loss=4.2917]\u001b[A\n",
            "Training:  20%|██        | 1005/5000 [44:51<6:22:02,  5.74s/it, loss=4.2917]\u001b[A\n",
            "Training:  20%|██        | 1005/5000 [44:51<6:22:02,  5.74s/it, loss=3.7696]\u001b[A\n",
            "Training:  20%|██        | 1006/5000 [44:53<5:12:35,  4.70s/it, loss=3.7696]\u001b[A\n",
            "Training:  20%|██        | 1006/5000 [44:53<5:12:35,  4.70s/it, loss=5.1267]\u001b[A\n",
            "Training:  20%|██        | 1007/5000 [44:55<4:23:17,  3.96s/it, loss=5.1267]\u001b[A\n",
            "Training:  20%|██        | 1007/5000 [44:55<4:23:17,  3.96s/it, loss=3.8628]\u001b[A\n",
            "Training:  20%|██        | 1008/5000 [44:58<3:50:20,  3.46s/it, loss=3.8628]\u001b[A\n",
            "Training:  20%|██        | 1008/5000 [44:58<3:50:20,  3.46s/it, loss=5.4776]\u001b[A\n",
            "Training:  20%|██        | 1009/5000 [45:00<3:27:26,  3.12s/it, loss=5.4776]\u001b[A\n",
            "Training:  20%|██        | 1009/5000 [45:00<3:27:26,  3.12s/it, loss=4.4057]\u001b[A\n",
            "Training:  20%|██        | 1010/5000 [45:03<3:22:15,  3.04s/it, loss=4.4057]\u001b[A\n",
            "Training:  20%|██        | 1010/5000 [45:03<3:22:15,  3.04s/it, loss=4.5880]\u001b[A\n",
            "Training:  20%|██        | 1011/5000 [45:05<3:07:44,  2.82s/it, loss=4.5880]\u001b[A\n",
            "Training:  20%|██        | 1011/5000 [45:05<3:07:44,  2.82s/it, loss=3.9892]\u001b[A\n",
            "Training:  20%|██        | 1012/5000 [45:08<2:57:02,  2.66s/it, loss=3.9892]\u001b[A\n",
            "Training:  20%|██        | 1012/5000 [45:08<2:57:02,  2.66s/it, loss=4.7950]\u001b[A\n",
            "Training:  20%|██        | 1013/5000 [45:10<2:50:03,  2.56s/it, loss=4.7950]\u001b[A\n",
            "Training:  20%|██        | 1013/5000 [45:10<2:50:03,  2.56s/it, loss=3.8586]\u001b[A\n",
            "Training:  20%|██        | 1014/5000 [45:12<2:45:09,  2.49s/it, loss=3.8586]\u001b[A\n",
            "Training:  20%|██        | 1014/5000 [45:12<2:45:09,  2.49s/it, loss=3.5256]\u001b[A\n",
            "Training:  20%|██        | 1015/5000 [45:15<2:52:14,  2.59s/it, loss=3.5256]\u001b[A\n",
            "Training:  20%|██        | 1015/5000 [45:15<2:52:14,  2.59s/it, loss=3.6391]\u001b[A\n",
            "Training:  20%|██        | 1016/5000 [45:17<2:46:18,  2.50s/it, loss=3.6391]\u001b[A\n",
            "Training:  20%|██        | 1016/5000 [45:17<2:46:18,  2.50s/it, loss=3.7018]\u001b[A\n",
            "Training:  20%|██        | 1017/5000 [45:20<2:42:35,  2.45s/it, loss=3.7018]\u001b[A\n",
            "Training:  20%|██        | 1017/5000 [45:20<2:42:35,  2.45s/it, loss=4.2316]\u001b[A\n",
            "Training:  20%|██        | 1018/5000 [45:22<2:40:38,  2.42s/it, loss=4.2316]\u001b[A\n",
            "Training:  20%|██        | 1018/5000 [45:22<2:40:38,  2.42s/it, loss=5.1580]\u001b[A\n",
            "Training:  20%|██        | 1019/5000 [45:24<2:38:38,  2.39s/it, loss=5.1580]\u001b[A\n",
            "Training:  20%|██        | 1019/5000 [45:24<2:38:38,  2.39s/it, loss=4.1418]\u001b[A\n",
            "Training:  20%|██        | 1020/5000 [45:27<2:47:56,  2.53s/it, loss=4.1418]\u001b[A\n",
            "Training:  20%|██        | 1020/5000 [45:27<2:47:56,  2.53s/it, loss=5.5996]\u001b[A\n",
            "Training:  20%|██        | 1021/5000 [45:29<2:43:44,  2.47s/it, loss=5.5996]\u001b[A\n",
            "Training:  20%|██        | 1021/5000 [45:30<2:43:44,  2.47s/it, loss=4.9550]\u001b[A\n",
            "Training:  20%|██        | 1022/5000 [45:32<2:39:56,  2.41s/it, loss=4.9550]\u001b[A\n",
            "Training:  20%|██        | 1022/5000 [45:32<2:39:56,  2.41s/it, loss=4.8501]\u001b[A\n",
            "Training:  20%|██        | 1023/5000 [45:34<2:37:55,  2.38s/it, loss=4.8501]\u001b[A\n",
            "Training:  20%|██        | 1023/5000 [45:34<2:37:55,  2.38s/it, loss=4.3957]\u001b[A\n",
            "Training:  20%|██        | 1024/5000 [45:36<2:36:56,  2.37s/it, loss=4.3957]\u001b[A\n",
            "Training:  20%|██        | 1024/5000 [45:36<2:36:56,  2.37s/it, loss=4.3741]\u001b[A\n",
            "Training:  20%|██        | 1025/5000 [45:39<2:45:42,  2.50s/it, loss=4.3741]\u001b[A\n",
            "Training:  20%|██        | 1025/5000 [45:39<2:45:42,  2.50s/it, loss=5.3087]\u001b[A\n",
            "Training:  21%|██        | 1026/5000 [45:42<2:41:43,  2.44s/it, loss=5.3087]\u001b[A\n",
            "Training:  21%|██        | 1026/5000 [45:42<2:41:43,  2.44s/it, loss=4.4332]\u001b[A\n",
            "Training:  21%|██        | 1027/5000 [45:44<2:38:56,  2.40s/it, loss=4.4332]\u001b[A\n",
            "Training:  21%|██        | 1027/5000 [45:44<2:38:56,  2.40s/it, loss=4.0985]\u001b[A\n",
            "Training:  21%|██        | 1028/5000 [45:46<2:37:46,  2.38s/it, loss=4.0985]\u001b[A\n",
            "Training:  21%|██        | 1028/5000 [45:46<2:37:46,  2.38s/it, loss=5.2938]\u001b[A\n",
            "Training:  21%|██        | 1029/5000 [45:49<2:37:43,  2.38s/it, loss=5.2938]\u001b[A\n",
            "Training:  21%|██        | 1029/5000 [45:49<2:37:43,  2.38s/it, loss=4.4251]\u001b[A\n",
            "Training:  21%|██        | 1030/5000 [45:51<2:44:11,  2.48s/it, loss=4.4251]\u001b[A\n",
            "Training:  21%|██        | 1030/5000 [45:51<2:44:11,  2.48s/it, loss=4.3551]\u001b[A\n",
            "Training:  21%|██        | 1031/5000 [45:54<2:41:04,  2.44s/it, loss=4.3551]\u001b[A\n",
            "Training:  21%|██        | 1031/5000 [45:54<2:41:04,  2.44s/it, loss=4.4409]\u001b[A\n",
            "Training:  21%|██        | 1032/5000 [45:56<2:39:15,  2.41s/it, loss=4.4409]\u001b[A\n",
            "Training:  21%|██        | 1032/5000 [45:56<2:39:15,  2.41s/it, loss=3.8216]\u001b[A\n",
            "Training:  21%|██        | 1033/5000 [45:58<2:37:02,  2.38s/it, loss=3.8216]\u001b[A\n",
            "Training:  21%|██        | 1033/5000 [45:58<2:37:02,  2.38s/it, loss=3.0756]\u001b[A\n",
            "Training:  21%|██        | 1034/5000 [46:01<2:38:15,  2.39s/it, loss=3.0756]\u001b[A\n",
            "Training:  21%|██        | 1034/5000 [46:01<2:38:15,  2.39s/it, loss=4.3592]\u001b[A\n",
            "Training:  21%|██        | 1035/5000 [46:03<2:44:01,  2.48s/it, loss=4.3592]\u001b[A\n",
            "Training:  21%|██        | 1035/5000 [46:03<2:44:01,  2.48s/it, loss=4.3161]\u001b[A\n",
            "Training:  21%|██        | 1036/5000 [46:06<2:40:35,  2.43s/it, loss=4.3161]\u001b[A\n",
            "Training:  21%|██        | 1036/5000 [46:06<2:40:35,  2.43s/it, loss=4.0949]\u001b[A\n",
            "Training:  21%|██        | 1037/5000 [46:08<2:38:30,  2.40s/it, loss=4.0949]\u001b[A\n",
            "Training:  21%|██        | 1037/5000 [46:08<2:38:30,  2.40s/it, loss=4.1573]\u001b[A\n",
            "Training:  21%|██        | 1038/5000 [46:10<2:36:37,  2.37s/it, loss=4.1573]\u001b[A\n",
            "Training:  21%|██        | 1038/5000 [46:10<2:36:37,  2.37s/it, loss=3.6887]\u001b[A\n",
            "Training:  21%|██        | 1039/5000 [46:13<2:39:54,  2.42s/it, loss=3.6887]\u001b[A\n",
            "Training:  21%|██        | 1039/5000 [46:13<2:39:54,  2.42s/it, loss=5.2107]\u001b[A\n",
            "Training:  21%|██        | 1040/5000 [46:15<2:43:57,  2.48s/it, loss=5.2107]\u001b[A\n",
            "Training:  21%|██        | 1040/5000 [46:16<2:43:57,  2.48s/it, loss=4.4415]\u001b[A\n",
            "Training:  21%|██        | 1041/5000 [46:18<2:40:40,  2.43s/it, loss=4.4415]\u001b[A\n",
            "Training:  21%|██        | 1041/5000 [46:18<2:40:40,  2.43s/it, loss=3.1582]\u001b[A\n",
            "Training:  21%|██        | 1042/5000 [46:20<2:38:11,  2.40s/it, loss=3.1582]\u001b[A\n",
            "Training:  21%|██        | 1042/5000 [46:20<2:38:11,  2.40s/it, loss=4.6842]\u001b[A\n",
            "Training:  21%|██        | 1043/5000 [46:22<2:36:51,  2.38s/it, loss=4.6842]\u001b[A\n",
            "Training:  21%|██        | 1043/5000 [46:22<2:36:51,  2.38s/it, loss=4.4326]\u001b[A\n",
            "Training:  21%|██        | 1044/5000 [46:25<2:40:32,  2.43s/it, loss=4.4326]\u001b[A\n",
            "Training:  21%|██        | 1044/5000 [46:25<2:40:32,  2.43s/it, loss=4.9907]\u001b[A\n",
            "Training:  21%|██        | 1045/5000 [46:28<2:43:29,  2.48s/it, loss=4.9907]\u001b[A\n",
            "Training:  21%|██        | 1045/5000 [46:28<2:43:29,  2.48s/it, loss=4.8390]\u001b[A\n",
            "Training:  21%|██        | 1046/5000 [46:30<2:40:53,  2.44s/it, loss=4.8390]\u001b[A\n",
            "Training:  21%|██        | 1046/5000 [46:30<2:40:53,  2.44s/it, loss=3.6566]\u001b[A\n",
            "Training:  21%|██        | 1047/5000 [46:32<2:38:58,  2.41s/it, loss=3.6566]\u001b[A\n",
            "Training:  21%|██        | 1047/5000 [46:32<2:38:58,  2.41s/it, loss=4.1185]\u001b[A\n",
            "Training:  21%|██        | 1048/5000 [46:35<2:36:50,  2.38s/it, loss=4.1185]\u001b[A\n",
            "Training:  21%|██        | 1048/5000 [46:35<2:36:50,  2.38s/it, loss=5.3799]\u001b[A\n",
            "Training:  21%|██        | 1049/5000 [46:37<2:42:03,  2.46s/it, loss=5.3799]\u001b[A\n",
            "Training:  21%|██        | 1049/5000 [46:37<2:42:03,  2.46s/it, loss=4.6883]\u001b[A\n",
            "Training:  21%|██        | 1050/5000 [46:40<2:43:55,  2.49s/it, loss=4.6883]\u001b[A\n",
            "Training:  21%|██        | 1050/5000 [46:40<2:43:55,  2.49s/it, loss=4.6630]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 1050 ---\n",
            "Prompt: 'The '\n",
            "The , an,s, a, may any, well\n",
            " well: fights on, without and I your's\n",
            " beaged my's,,,, a, myself\n",
            "'d,, a, about,,,!,, thou's thou, grace speak?\n",
            " his is with,,, my; is the is my.\n",
            "HRY upon, God thou words the of, using thus on grief, friend I hither me\n",
            "ave but-orrow must ofMess: ah '\n",
            "Prompt: 'In '\n",
            "In , cl, the fromwinged foototh g\n",
            " sometime, father your and aw'd's, wax me\n",
            "illall again his Ale, two a of life day\n",
            "ame his and, ca, a of'sys,What this it on, ministers, then, the is note to house own,'\n",
            "end the of and by let be mis on eye\n",
            "athest, t, all heart it or away,Be'dish to and and, makes straight dist her--orrow\n",
            "Prompt: 'To '\n",
            "To  to fortune my, dear lie.\n",
            "K RARD:Then:, good, here a thou!Fear is, spott!\n",
            " penet aful so blood were hopes, I the hereblown th?\n",
            "JN, my, full, mother my lie,umer.\n",
            "Y, me how see need name ceremony his in;For will?\n",
            " wouldoth this?\n",
            "PRCEW thou cousin is with, lord I the's thouest, are.N, foot mine;'ll\n",
            "Prompt: 'A '\n",
            "A  of blood to already\n",
            "'s, makes land ste, Duke Norfolk in day\n",
            " thouesttt with arms his kingrun a\n",
            " change recre to home your and, good the is and ': look with form\n",
            " presence and fair, mean miss for to; fault\n",
            "-orrow must, busy, lately and by breast\n",
            " prove\n",
            "ICH and too Heaven my.\n",
            "First strike tell whatDKE ten and, aoler our. loving,ray\n",
            ", my,,, let thouest\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  21%|██        | 1051/5000 [46:55<6:53:25,  6.28s/it, loss=4.6630]\u001b[A\n",
            "Training:  21%|██        | 1051/5000 [46:55<6:53:25,  6.28s/it, loss=3.6357]\u001b[A\n",
            "Training:  21%|██        | 1052/5000 [46:57<5:35:25,  5.10s/it, loss=3.6357]\u001b[A\n",
            "Training:  21%|██        | 1052/5000 [46:57<5:35:25,  5.10s/it, loss=4.3850]\u001b[A\n",
            "Training:  21%|██        | 1053/5000 [47:00<4:40:13,  4.26s/it, loss=4.3850]\u001b[A\n",
            "Training:  21%|██        | 1053/5000 [47:00<4:40:13,  4.26s/it, loss=4.4431]\u001b[A\n",
            "Training:  21%|██        | 1054/5000 [47:02<4:12:55,  3.85s/it, loss=4.4431]\u001b[A\n",
            "Training:  21%|██        | 1054/5000 [47:02<4:12:55,  3.85s/it, loss=3.3852]\u001b[A\n",
            "Training:  21%|██        | 1055/5000 [47:05<3:42:50,  3.39s/it, loss=3.3852]\u001b[A\n",
            "Training:  21%|██        | 1055/5000 [47:05<3:42:50,  3.39s/it, loss=4.4694]\u001b[A\n",
            "Training:  21%|██        | 1056/5000 [47:07<3:21:44,  3.07s/it, loss=4.4694]\u001b[A\n",
            "Training:  21%|██        | 1056/5000 [47:07<3:21:44,  3.07s/it, loss=5.3782]\u001b[A\n",
            "Training:  21%|██        | 1057/5000 [47:09<3:06:08,  2.83s/it, loss=5.3782]\u001b[A\n",
            "Training:  21%|██        | 1057/5000 [47:09<3:06:08,  2.83s/it, loss=4.5509]\u001b[A\n",
            "Training:  21%|██        | 1058/5000 [47:12<2:56:41,  2.69s/it, loss=4.5509]\u001b[A\n",
            "Training:  21%|██        | 1058/5000 [47:12<2:56:41,  2.69s/it, loss=4.6823]\u001b[A\n",
            "Training:  21%|██        | 1059/5000 [47:15<2:58:53,  2.72s/it, loss=4.6823]\u001b[A\n",
            "Training:  21%|██        | 1059/5000 [47:15<2:58:53,  2.72s/it, loss=4.3868]\u001b[A\n",
            "Training:  21%|██        | 1060/5000 [47:17<2:51:11,  2.61s/it, loss=4.3868]\u001b[A\n",
            "Training:  21%|██        | 1060/5000 [47:17<2:51:11,  2.61s/it, loss=4.2142]\u001b[A\n",
            "Training:  21%|██        | 1061/5000 [47:19<2:44:40,  2.51s/it, loss=4.2142]\u001b[A\n",
            "Training:  21%|██        | 1061/5000 [47:19<2:44:40,  2.51s/it, loss=4.2041]\u001b[A\n",
            "Training:  21%|██        | 1062/5000 [47:21<2:40:54,  2.45s/it, loss=4.2041]\u001b[A\n",
            "Training:  21%|██        | 1062/5000 [47:22<2:40:54,  2.45s/it, loss=4.3012]\u001b[A\n",
            "Training:  21%|██▏       | 1063/5000 [47:24<2:41:36,  2.46s/it, loss=4.3012]\u001b[A\n",
            "Training:  21%|██▏       | 1063/5000 [47:24<2:41:36,  2.46s/it, loss=4.4449]\u001b[A\n",
            "Training:  21%|██▏       | 1064/5000 [47:27<2:46:26,  2.54s/it, loss=4.4449]\u001b[A\n",
            "Training:  21%|██▏       | 1064/5000 [47:27<2:46:26,  2.54s/it, loss=5.1162]\u001b[A\n",
            "Training:  21%|██▏       | 1065/5000 [47:29<2:41:56,  2.47s/it, loss=5.1162]\u001b[A\n",
            "Training:  21%|██▏       | 1065/5000 [47:29<2:41:56,  2.47s/it, loss=5.3647]\u001b[A\n",
            "Training:  21%|██▏       | 1066/5000 [47:31<2:38:55,  2.42s/it, loss=5.3647]\u001b[A\n",
            "Training:  21%|██▏       | 1066/5000 [47:31<2:38:55,  2.42s/it, loss=4.6222]\u001b[A\n",
            "Training:  21%|██▏       | 1067/5000 [47:34<2:36:25,  2.39s/it, loss=4.6222]\u001b[A\n",
            "Training:  21%|██▏       | 1067/5000 [47:34<2:36:25,  2.39s/it, loss=4.7153]\u001b[A\n",
            "Training:  21%|██▏       | 1068/5000 [47:36<2:38:55,  2.43s/it, loss=4.7153]\u001b[A\n",
            "Training:  21%|██▏       | 1068/5000 [47:36<2:38:55,  2.43s/it, loss=5.5338]\u001b[A\n",
            "Training:  21%|██▏       | 1069/5000 [47:39<2:43:28,  2.50s/it, loss=5.5338]\u001b[A\n",
            "Training:  21%|██▏       | 1069/5000 [47:39<2:43:28,  2.50s/it, loss=4.0533]\u001b[A\n",
            "Training:  21%|██▏       | 1070/5000 [47:41<2:39:44,  2.44s/it, loss=4.0533]\u001b[A\n",
            "Training:  21%|██▏       | 1070/5000 [47:41<2:39:44,  2.44s/it, loss=4.4638]\u001b[A\n",
            "Training:  21%|██▏       | 1071/5000 [47:43<2:37:23,  2.40s/it, loss=4.4638]\u001b[A\n",
            "Training:  21%|██▏       | 1071/5000 [47:43<2:37:23,  2.40s/it, loss=5.6705]\u001b[A\n",
            "Training:  21%|██▏       | 1072/5000 [47:46<2:35:42,  2.38s/it, loss=5.6705]\u001b[A\n",
            "Training:  21%|██▏       | 1072/5000 [47:46<2:35:42,  2.38s/it, loss=4.1550]\u001b[A\n",
            "Training:  21%|██▏       | 1073/5000 [47:48<2:39:47,  2.44s/it, loss=4.1550]\u001b[A\n",
            "Training:  21%|██▏       | 1073/5000 [47:48<2:39:47,  2.44s/it, loss=4.6001]\u001b[A\n",
            "Training:  21%|██▏       | 1074/5000 [47:51<2:43:10,  2.49s/it, loss=4.6001]\u001b[A\n",
            "Training:  21%|██▏       | 1074/5000 [47:51<2:43:10,  2.49s/it, loss=3.9750]\u001b[A\n",
            "Training:  22%|██▏       | 1075/5000 [47:53<2:39:41,  2.44s/it, loss=3.9750]\u001b[A\n",
            "Training:  22%|██▏       | 1075/5000 [47:53<2:39:41,  2.44s/it, loss=4.7185]\u001b[A\n",
            "Training:  22%|██▏       | 1076/5000 [47:56<2:37:57,  2.42s/it, loss=4.7185]\u001b[A\n",
            "Training:  22%|██▏       | 1076/5000 [47:56<2:37:57,  2.42s/it, loss=4.5223]\u001b[A\n",
            "Training:  22%|██▏       | 1077/5000 [47:58<2:35:54,  2.38s/it, loss=4.5223]\u001b[A\n",
            "Training:  22%|██▏       | 1077/5000 [47:58<2:35:54,  2.38s/it, loss=4.8853]\u001b[A\n",
            "Training:  22%|██▏       | 1078/5000 [48:01<2:41:42,  2.47s/it, loss=4.8853]\u001b[A\n",
            "Training:  22%|██▏       | 1078/5000 [48:01<2:41:42,  2.47s/it, loss=3.5147]\u001b[A\n",
            "Training:  22%|██▏       | 1079/5000 [48:03<2:42:15,  2.48s/it, loss=3.5147]\u001b[A\n",
            "Training:  22%|██▏       | 1079/5000 [48:03<2:42:15,  2.48s/it, loss=4.3615]\u001b[A\n",
            "Training:  22%|██▏       | 1080/5000 [48:05<2:39:25,  2.44s/it, loss=4.3615]\u001b[A\n",
            "Training:  22%|██▏       | 1080/5000 [48:05<2:39:25,  2.44s/it, loss=4.6553]\u001b[A\n",
            "Training:  22%|██▏       | 1081/5000 [48:08<2:37:20,  2.41s/it, loss=4.6553]\u001b[A\n",
            "Training:  22%|██▏       | 1081/5000 [48:08<2:37:20,  2.41s/it, loss=4.5313]\u001b[A\n",
            "Training:  22%|██▏       | 1082/5000 [48:10<2:36:04,  2.39s/it, loss=4.5313]\u001b[A\n",
            "Training:  22%|██▏       | 1082/5000 [48:10<2:36:04,  2.39s/it, loss=5.2569]\u001b[A\n",
            "Training:  22%|██▏       | 1083/5000 [48:13<2:43:43,  2.51s/it, loss=5.2569]\u001b[A\n",
            "Training:  22%|██▏       | 1083/5000 [48:13<2:43:43,  2.51s/it, loss=4.4505]\u001b[A\n",
            "Training:  22%|██▏       | 1084/5000 [48:15<2:40:29,  2.46s/it, loss=4.4505]\u001b[A\n",
            "Training:  22%|██▏       | 1084/5000 [48:15<2:40:29,  2.46s/it, loss=4.4572]\u001b[A\n",
            "Training:  22%|██▏       | 1085/5000 [48:18<2:37:48,  2.42s/it, loss=4.4572]\u001b[A\n",
            "Training:  22%|██▏       | 1085/5000 [48:18<2:37:48,  2.42s/it, loss=4.1453]\u001b[A\n",
            "Training:  22%|██▏       | 1086/5000 [48:20<2:34:11,  2.36s/it, loss=4.1453]\u001b[A\n",
            "Training:  22%|██▏       | 1086/5000 [48:20<2:34:11,  2.36s/it, loss=4.0615]\u001b[A\n",
            "Training:  22%|██▏       | 1087/5000 [48:22<2:31:41,  2.33s/it, loss=4.0615]\u001b[A\n",
            "Training:  22%|██▏       | 1087/5000 [48:22<2:31:41,  2.33s/it, loss=4.9090]\u001b[A\n",
            "Training:  22%|██▏       | 1088/5000 [48:25<2:38:58,  2.44s/it, loss=4.9090]\u001b[A\n",
            "Training:  22%|██▏       | 1088/5000 [48:25<2:38:58,  2.44s/it, loss=4.2543]\u001b[A\n",
            "Training:  22%|██▏       | 1089/5000 [48:27<2:36:46,  2.41s/it, loss=4.2543]\u001b[A\n",
            "Training:  22%|██▏       | 1089/5000 [48:27<2:36:46,  2.41s/it, loss=4.8608]\u001b[A\n",
            "Training:  22%|██▏       | 1090/5000 [48:29<2:33:56,  2.36s/it, loss=4.8608]\u001b[A\n",
            "Training:  22%|██▏       | 1090/5000 [48:29<2:33:56,  2.36s/it, loss=4.1370]\u001b[A\n",
            "Training:  22%|██▏       | 1091/5000 [48:32<2:31:25,  2.32s/it, loss=4.1370]\u001b[A\n",
            "Training:  22%|██▏       | 1091/5000 [48:32<2:31:25,  2.32s/it, loss=4.3580]\u001b[A\n",
            "Training:  22%|██▏       | 1092/5000 [48:34<2:29:38,  2.30s/it, loss=4.3580]\u001b[A\n",
            "Training:  22%|██▏       | 1092/5000 [48:34<2:29:38,  2.30s/it, loss=5.0611]\u001b[A\n",
            "Training:  22%|██▏       | 1093/5000 [48:36<2:36:15,  2.40s/it, loss=5.0611]\u001b[A\n",
            "Training:  22%|██▏       | 1093/5000 [48:36<2:36:15,  2.40s/it, loss=4.1149]\u001b[A\n",
            "Training:  22%|██▏       | 1094/5000 [48:39<2:35:31,  2.39s/it, loss=4.1149]\u001b[A\n",
            "Training:  22%|██▏       | 1094/5000 [48:39<2:35:31,  2.39s/it, loss=4.3337]\u001b[A\n",
            "Training:  22%|██▏       | 1095/5000 [48:41<2:33:18,  2.36s/it, loss=4.3337]\u001b[A\n",
            "Training:  22%|██▏       | 1095/5000 [48:41<2:33:18,  2.36s/it, loss=4.7432]\u001b[A\n",
            "Training:  22%|██▏       | 1096/5000 [48:43<2:31:04,  2.32s/it, loss=4.7432]\u001b[A\n",
            "Training:  22%|██▏       | 1096/5000 [48:43<2:31:04,  2.32s/it, loss=3.7107]\u001b[A\n",
            "Training:  22%|██▏       | 1097/5000 [48:46<2:29:27,  2.30s/it, loss=3.7107]\u001b[A\n",
            "Training:  22%|██▏       | 1097/5000 [48:46<2:29:27,  2.30s/it, loss=4.1251]\u001b[A\n",
            "Training:  22%|██▏       | 1098/5000 [48:48<2:35:10,  2.39s/it, loss=4.1251]\u001b[A\n",
            "Training:  22%|██▏       | 1098/5000 [48:48<2:35:10,  2.39s/it, loss=4.2517]\u001b[A\n",
            "Training:  22%|██▏       | 1099/5000 [48:51<2:36:22,  2.41s/it, loss=4.2517]\u001b[A\n",
            "Training:  22%|██▏       | 1099/5000 [48:51<2:36:22,  2.41s/it, loss=3.2218]\u001b[A\n",
            "Training:  22%|██▏       | 1100/5000 [48:53<2:33:17,  2.36s/it, loss=3.2218]\u001b[A\n",
            "Training:  22%|██▏       | 1100/5000 [48:53<2:33:17,  2.36s/it, loss=3.9355]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 1100 ---\n",
            "Prompt: 'The '\n",
            "The  where, queen the of Edward,Before, either any\n",
            " to removed as as but w,C to forward\n",
            " your execution than; mine,,ee you reason our.\n",
            "WARICK\n",
            "'s!O\n",
            " have to us even,,;! am royal,,; am of,!\n",
            "PAR:And,! now mis kneeerer,ost over now\n",
            " this of, and's,, thy,,, friend to to thy to, us good, thy, with of is\n",
            "Prompt: 'In '\n",
            "In  to sep O but to fortune:IfSt d not,thely his in\n",
            " ever that upon step fellows dangerous.\n",
            "K of,'s,oa to it the of,\n",
            " in'sLike with and must to my;And the to!\n",
            " are at,, Clarence all itself son\n",
            "aw,, this is my of:, will embrace life\n",
            "'s, an and I to this, isp the cross flatm,I him\n",
            " master dignity to my-ids a ofague\n",
            "Prompt: 'To '\n",
            "To  to England him untogone\n",
            "nt my;And, thy, thy and my king\n",
            " any'd loss it me by drunk and.\n",
            "QUE MARAR for;, pier as you, notEven my, sayI my soul thy, it a too king\n",
            " think should my heart ha, do am to, of: me I,, solace my, she, can, but and it, with, you not as and withiful\n",
            " had much son unto less much these best happy,'s\n",
            "Prompt: 'A '\n",
            "A  of j,Thus taen crown\n",
            " to title:,,, she the, while sayAs live too\n",
            " to part that have crown his with andanish their.\n",
            "GUCER\n",
            " intent gaveok;, I thy lord for;For's is hand tearsb, I not, two's is\n",
            " d sir more the un gates high her of.\n",
            " are queen I for!\n",
            "Gle aard\n",
            "Return the are to me the this how I a sparkling for mis him the\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  22%|██▏       | 1101/5000 [49:07<6:31:41,  6.03s/it, loss=3.9355]\u001b[A\n",
            "Training:  22%|██▏       | 1101/5000 [49:07<6:31:41,  6.03s/it, loss=3.3855]\u001b[A\n",
            "Training:  22%|██▏       | 1102/5000 [49:10<5:17:40,  4.89s/it, loss=3.3855]\u001b[A\n",
            "Training:  22%|██▏       | 1102/5000 [49:10<5:17:40,  4.89s/it, loss=4.3439]\u001b[A\n",
            "Training:  22%|██▏       | 1103/5000 [49:12<4:36:12,  4.25s/it, loss=4.3439]\u001b[A\n",
            "Training:  22%|██▏       | 1103/5000 [49:12<4:36:12,  4.25s/it, loss=4.7401]\u001b[A\n",
            "Training:  22%|██▏       | 1104/5000 [49:15<3:57:08,  3.65s/it, loss=4.7401]\u001b[A\n",
            "Training:  22%|██▏       | 1104/5000 [49:15<3:57:08,  3.65s/it, loss=4.2263]\u001b[A\n",
            "Training:  22%|██▏       | 1105/5000 [49:17<3:29:39,  3.23s/it, loss=4.2263]\u001b[A\n",
            "Training:  22%|██▏       | 1105/5000 [49:17<3:29:39,  3.23s/it, loss=5.0275]\u001b[A\n",
            "Training:  22%|██▏       | 1106/5000 [49:19<3:09:57,  2.93s/it, loss=5.0275]\u001b[A\n",
            "Training:  22%|██▏       | 1106/5000 [49:19<3:09:57,  2.93s/it, loss=4.5417]\u001b[A\n",
            "Training:  22%|██▏       | 1107/5000 [49:21<2:56:01,  2.71s/it, loss=4.5417]\u001b[A\n",
            "Training:  22%|██▏       | 1107/5000 [49:21<2:56:01,  2.71s/it, loss=4.5991]\u001b[A\n",
            "Training:  22%|██▏       | 1108/5000 [49:24<2:56:18,  2.72s/it, loss=4.5991]\u001b[A\n",
            "Training:  22%|██▏       | 1108/5000 [49:24<2:56:18,  2.72s/it, loss=4.2130]\u001b[A\n",
            "Training:  22%|██▏       | 1109/5000 [49:26<2:48:33,  2.60s/it, loss=4.2130]\u001b[A\n",
            "Training:  22%|██▏       | 1109/5000 [49:26<2:48:33,  2.60s/it, loss=4.2025]\u001b[A\n",
            "Training:  22%|██▏       | 1110/5000 [49:29<2:41:46,  2.50s/it, loss=4.2025]\u001b[A\n",
            "Training:  22%|██▏       | 1110/5000 [49:29<2:41:46,  2.50s/it, loss=4.4247]\u001b[A\n",
            "Training:  22%|██▏       | 1111/5000 [49:31<2:36:49,  2.42s/it, loss=4.4247]\u001b[A\n",
            "Training:  22%|██▏       | 1111/5000 [49:31<2:36:49,  2.42s/it, loss=4.5393]\u001b[A\n",
            "Training:  22%|██▏       | 1112/5000 [49:33<2:33:05,  2.36s/it, loss=4.5393]\u001b[A\n",
            "Training:  22%|██▏       | 1112/5000 [49:33<2:33:05,  2.36s/it, loss=5.1831]\u001b[A\n",
            "Training:  22%|██▏       | 1113/5000 [49:36<2:38:54,  2.45s/it, loss=5.1831]\u001b[A\n",
            "Training:  22%|██▏       | 1113/5000 [49:36<2:38:54,  2.45s/it, loss=5.3897]\u001b[A\n",
            "Training:  22%|██▏       | 1114/5000 [49:38<2:36:47,  2.42s/it, loss=5.3897]\u001b[A\n",
            "Training:  22%|██▏       | 1114/5000 [49:38<2:36:47,  2.42s/it, loss=5.7013]\u001b[A\n",
            "Training:  22%|██▏       | 1115/5000 [49:40<2:33:08,  2.37s/it, loss=5.7013]\u001b[A\n",
            "Training:  22%|██▏       | 1115/5000 [49:40<2:33:08,  2.37s/it, loss=4.9137]\u001b[A\n",
            "Training:  22%|██▏       | 1116/5000 [49:43<2:30:29,  2.32s/it, loss=4.9137]\u001b[A\n",
            "Training:  22%|██▏       | 1116/5000 [49:43<2:30:29,  2.32s/it, loss=4.9946]\u001b[A\n",
            "Training:  22%|██▏       | 1117/5000 [49:45<2:29:33,  2.31s/it, loss=4.9946]\u001b[A\n",
            "Training:  22%|██▏       | 1117/5000 [49:45<2:29:33,  2.31s/it, loss=5.6012]\u001b[A\n",
            "Training:  22%|██▏       | 1118/5000 [49:48<2:34:55,  2.39s/it, loss=5.6012]\u001b[A\n",
            "Training:  22%|██▏       | 1118/5000 [49:48<2:34:55,  2.39s/it, loss=5.1794]\u001b[A\n",
            "Training:  22%|██▏       | 1119/5000 [49:50<2:35:13,  2.40s/it, loss=5.1794]\u001b[A\n",
            "Training:  22%|██▏       | 1119/5000 [49:50<2:35:13,  2.40s/it, loss=3.4633]\u001b[A\n",
            "Training:  22%|██▏       | 1120/5000 [49:52<2:32:26,  2.36s/it, loss=3.4633]\u001b[A\n",
            "Training:  22%|██▏       | 1120/5000 [49:52<2:32:26,  2.36s/it, loss=5.4327]\u001b[A\n",
            "Training:  22%|██▏       | 1121/5000 [49:54<2:30:13,  2.32s/it, loss=5.4327]\u001b[A\n",
            "Training:  22%|██▏       | 1121/5000 [49:54<2:30:13,  2.32s/it, loss=5.0354]\u001b[A\n",
            "Training:  22%|██▏       | 1122/5000 [49:57<2:29:15,  2.31s/it, loss=5.0354]\u001b[A\n",
            "Training:  22%|██▏       | 1122/5000 [49:57<2:29:15,  2.31s/it, loss=5.3520]\u001b[A\n",
            "Training:  22%|██▏       | 1123/5000 [49:59<2:34:12,  2.39s/it, loss=5.3520]\u001b[A\n",
            "Training:  22%|██▏       | 1123/5000 [49:59<2:34:12,  2.39s/it, loss=4.2038]\u001b[A\n",
            "Training:  22%|██▏       | 1124/5000 [50:02<2:35:19,  2.40s/it, loss=4.2038]\u001b[A\n",
            "Training:  22%|██▏       | 1124/5000 [50:02<2:35:19,  2.40s/it, loss=5.1381]\u001b[A\n",
            "Training:  22%|██▎       | 1125/5000 [50:04<2:32:02,  2.35s/it, loss=5.1381]\u001b[A\n",
            "Training:  22%|██▎       | 1125/5000 [50:04<2:32:02,  2.35s/it, loss=4.8484]\u001b[A\n",
            "Training:  23%|██▎       | 1126/5000 [50:06<2:30:03,  2.32s/it, loss=4.8484]\u001b[A\n",
            "Training:  23%|██▎       | 1126/5000 [50:06<2:30:03,  2.32s/it, loss=5.0342]\u001b[A\n",
            "Training:  23%|██▎       | 1127/5000 [50:08<2:28:09,  2.30s/it, loss=5.0342]\u001b[A\n",
            "Training:  23%|██▎       | 1127/5000 [50:08<2:28:09,  2.30s/it, loss=4.2784]\u001b[A\n",
            "Training:  23%|██▎       | 1128/5000 [50:11<2:32:37,  2.37s/it, loss=4.2784]\u001b[A\n",
            "Training:  23%|██▎       | 1128/5000 [50:11<2:32:37,  2.37s/it, loss=4.6921]\u001b[A\n",
            "Training:  23%|██▎       | 1129/5000 [50:13<2:34:30,  2.39s/it, loss=4.6921]\u001b[A\n",
            "Training:  23%|██▎       | 1129/5000 [50:13<2:34:30,  2.39s/it, loss=3.7524]\u001b[A\n",
            "Training:  23%|██▎       | 1130/5000 [50:16<2:31:30,  2.35s/it, loss=3.7524]\u001b[A\n",
            "Training:  23%|██▎       | 1130/5000 [50:16<2:31:30,  2.35s/it, loss=3.9663]\u001b[A\n",
            "Training:  23%|██▎       | 1131/5000 [50:18<2:29:04,  2.31s/it, loss=3.9663]\u001b[A\n",
            "Training:  23%|██▎       | 1131/5000 [50:18<2:29:04,  2.31s/it, loss=4.0082]\u001b[A\n",
            "Training:  23%|██▎       | 1132/5000 [50:20<2:27:30,  2.29s/it, loss=4.0082]\u001b[A\n",
            "Training:  23%|██▎       | 1132/5000 [50:20<2:27:30,  2.29s/it, loss=4.5212]\u001b[A\n",
            "Training:  23%|██▎       | 1133/5000 [50:23<2:30:50,  2.34s/it, loss=4.5212]\u001b[A\n",
            "Training:  23%|██▎       | 1133/5000 [50:23<2:30:50,  2.34s/it, loss=4.2941]\u001b[A\n",
            "Training:  23%|██▎       | 1134/5000 [50:25<2:34:17,  2.39s/it, loss=4.2941]\u001b[A\n",
            "Training:  23%|██▎       | 1134/5000 [50:25<2:34:17,  2.39s/it, loss=4.0531]\u001b[A\n",
            "Training:  23%|██▎       | 1135/5000 [50:27<2:32:10,  2.36s/it, loss=4.0531]\u001b[A\n",
            "Training:  23%|██▎       | 1135/5000 [50:27<2:32:10,  2.36s/it, loss=4.5983]\u001b[A\n",
            "Training:  23%|██▎       | 1136/5000 [50:30<2:29:42,  2.32s/it, loss=4.5983]\u001b[A\n",
            "Training:  23%|██▎       | 1136/5000 [50:30<2:29:42,  2.32s/it, loss=4.4080]\u001b[A\n",
            "Training:  23%|██▎       | 1137/5000 [50:32<2:27:47,  2.30s/it, loss=4.4080]\u001b[A\n",
            "Training:  23%|██▎       | 1137/5000 [50:32<2:27:47,  2.30s/it, loss=5.2313]\u001b[A\n",
            "Training:  23%|██▎       | 1138/5000 [50:34<2:30:17,  2.33s/it, loss=5.2313]\u001b[A\n",
            "Training:  23%|██▎       | 1138/5000 [50:34<2:30:17,  2.33s/it, loss=4.4276]\u001b[A\n",
            "Training:  23%|██▎       | 1139/5000 [50:37<2:35:17,  2.41s/it, loss=4.4276]\u001b[A\n",
            "Training:  23%|██▎       | 1139/5000 [50:37<2:35:17,  2.41s/it, loss=3.7149]\u001b[A\n",
            "Training:  23%|██▎       | 1140/5000 [50:39<2:31:39,  2.36s/it, loss=3.7149]\u001b[A\n",
            "Training:  23%|██▎       | 1140/5000 [50:39<2:31:39,  2.36s/it, loss=3.6131]\u001b[A\n",
            "Training:  23%|██▎       | 1141/5000 [50:41<2:29:09,  2.32s/it, loss=3.6131]\u001b[A\n",
            "Training:  23%|██▎       | 1141/5000 [50:41<2:29:09,  2.32s/it, loss=3.2842]\u001b[A\n",
            "Training:  23%|██▎       | 1142/5000 [50:44<2:28:01,  2.30s/it, loss=3.2842]\u001b[A\n",
            "Training:  23%|██▎       | 1142/5000 [50:44<2:28:01,  2.30s/it, loss=3.4415]\u001b[A\n",
            "Training:  23%|██▎       | 1143/5000 [50:46<2:30:14,  2.34s/it, loss=3.4415]\u001b[A\n",
            "Training:  23%|██▎       | 1143/5000 [50:46<2:30:14,  2.34s/it, loss=4.7163]\u001b[A\n",
            "Training:  23%|██▎       | 1144/5000 [50:49<2:35:30,  2.42s/it, loss=4.7163]\u001b[A\n",
            "Training:  23%|██▎       | 1144/5000 [50:49<2:35:30,  2.42s/it, loss=4.6389]\u001b[A\n",
            "Training:  23%|██▎       | 1145/5000 [50:51<2:31:15,  2.35s/it, loss=4.6389]\u001b[A\n",
            "Training:  23%|██▎       | 1145/5000 [50:51<2:31:15,  2.35s/it, loss=4.8382]\u001b[A\n",
            "Training:  23%|██▎       | 1146/5000 [50:53<2:30:08,  2.34s/it, loss=4.8382]\u001b[A\n",
            "Training:  23%|██▎       | 1146/5000 [50:53<2:30:08,  2.34s/it, loss=4.8831]\u001b[A\n",
            "Training:  23%|██▎       | 1147/5000 [50:55<2:28:00,  2.30s/it, loss=4.8831]\u001b[A\n",
            "Training:  23%|██▎       | 1147/5000 [50:55<2:28:00,  2.30s/it, loss=4.1705]\u001b[A\n",
            "Training:  23%|██▎       | 1148/5000 [50:58<2:30:14,  2.34s/it, loss=4.1705]\u001b[A\n",
            "Training:  23%|██▎       | 1148/5000 [50:58<2:30:14,  2.34s/it, loss=4.0509]\u001b[A\n",
            "Training:  23%|██▎       | 1149/5000 [51:00<2:35:39,  2.43s/it, loss=4.0509]\u001b[A\n",
            "Training:  23%|██▎       | 1149/5000 [51:00<2:35:39,  2.43s/it, loss=4.4335]\u001b[A\n",
            "Training:  23%|██▎       | 1150/5000 [51:03<2:32:01,  2.37s/it, loss=4.4335]\u001b[A\n",
            "Training:  23%|██▎       | 1150/5000 [51:03<2:32:01,  2.37s/it, loss=4.2032]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 1150 ---\n",
            "Prompt: 'The '\n",
            "The  andping'ouns file adultery'd\n",
            " an keeps daughter scornapscases himselfSh\n",
            " puppet me, thenric to,, desire on\n",
            " old dove all new with mind, mad, you no to, rather the\n",
            " gait cru of that knew re'd this din our,, high on me the.\n",
            "L you my find this, you know all theest, comes not the, you,ruio,,, me my still my shore my, you leave come me you?\n",
            "GR\n",
            "Prompt: 'In '\n",
            "In  poor is infect to.\n",
            "PETCH:Sir very, your!,! dear\n",
            " do me is of first for girl her,And\n",
            " that shall me H thee, make be yet as master? it in duke\n",
            " shame my,, t it and this will, all wed you theer get and me my Lucio,'s hence\n",
            " is you so,, you the I in, you be to a of fall is to so a.I you Whereself this all to aar\n",
            "Prompt: 'To '\n",
            "To  pleasure shall Bca praised such afternoon\n",
            " herkind power the! is still Petchio f,,! thinkelf\n",
            ", you mad, thee be at and'sard;Foryou\n",
            "all me O so he be to\n",
            "ire me my and the ofo doubt in wife is my alone\n",
            " so my and the of, you my hand her myg.\n",
            " wants me?,, pray you mostught you as as do hear mad, I our have an a sound O not ent no\n",
            "Prompt: 'A '\n",
            "A  to's,, you well me my.\n",
            "B thoust my and thoust come well to\n",
            "POE with;, I stand my,, answer then\n",
            "race love foranish time?\n",
            "TRIO\n",
            " prov,! that I, Kathina take her w any,Butand import,That may, this you me the will thoust youoo a to a-aps are, not ' gone a of with, you find:, me, you sir you wife there a N\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  23%|██▎       | 1151/5000 [51:17<6:27:16,  6.04s/it, loss=4.2032]\u001b[A\n",
            "Training:  23%|██▎       | 1151/5000 [51:17<6:27:16,  6.04s/it, loss=3.9809]\u001b[A\n",
            "Training:  23%|██▎       | 1152/5000 [51:19<5:13:44,  4.89s/it, loss=3.9809]\u001b[A\n",
            "Training:  23%|██▎       | 1152/5000 [51:19<5:13:44,  4.89s/it, loss=3.7387]\u001b[A\n",
            "Training:  23%|██▎       | 1153/5000 [51:22<4:27:17,  4.17s/it, loss=3.7387]\u001b[A\n",
            "Training:  23%|██▎       | 1153/5000 [51:22<4:27:17,  4.17s/it, loss=4.3254]\u001b[A\n",
            "Training:  23%|██▎       | 1154/5000 [51:24<3:55:25,  3.67s/it, loss=4.3254]\u001b[A\n",
            "Training:  23%|██▎       | 1154/5000 [51:24<3:55:25,  3.67s/it, loss=4.2938]\u001b[A\n",
            "Training:  23%|██▎       | 1155/5000 [51:27<3:28:51,  3.26s/it, loss=4.2938]\u001b[A\n",
            "Training:  23%|██▎       | 1155/5000 [51:27<3:28:51,  3.26s/it, loss=4.1441]\u001b[A\n",
            "Training:  23%|██▎       | 1156/5000 [51:29<3:09:19,  2.96s/it, loss=4.1441]\u001b[A\n",
            "Training:  23%|██▎       | 1156/5000 [51:29<3:09:19,  2.96s/it, loss=4.3128]\u001b[A\n",
            "Training:  23%|██▎       | 1157/5000 [51:31<2:55:20,  2.74s/it, loss=4.3128]\u001b[A\n",
            "Training:  23%|██▎       | 1157/5000 [51:31<2:55:20,  2.74s/it, loss=3.1101]\u001b[A\n",
            "Training:  23%|██▎       | 1158/5000 [51:34<2:50:08,  2.66s/it, loss=3.1101]\u001b[A\n",
            "Training:  23%|██▎       | 1158/5000 [51:34<2:50:08,  2.66s/it, loss=4.0379]\u001b[A\n",
            "Training:  23%|██▎       | 1159/5000 [51:36<2:47:23,  2.61s/it, loss=4.0379]\u001b[A\n",
            "Training:  23%|██▎       | 1159/5000 [51:36<2:47:23,  2.61s/it, loss=3.9151]\u001b[A\n",
            "Training:  23%|██▎       | 1160/5000 [51:38<2:40:20,  2.51s/it, loss=3.9151]\u001b[A\n",
            "Training:  23%|██▎       | 1160/5000 [51:38<2:40:20,  2.51s/it, loss=4.8446]\u001b[A\n",
            "Training:  23%|██▎       | 1161/5000 [51:41<2:35:45,  2.43s/it, loss=4.8446]\u001b[A\n",
            "Training:  23%|██▎       | 1161/5000 [51:41<2:35:45,  2.43s/it, loss=4.7047]\u001b[A\n",
            "Training:  23%|██▎       | 1162/5000 [51:43<2:31:50,  2.37s/it, loss=4.7047]\u001b[A\n",
            "Training:  23%|██▎       | 1162/5000 [51:43<2:31:50,  2.37s/it, loss=4.7281]\u001b[A\n",
            "Training:  23%|██▎       | 1163/5000 [51:45<2:33:21,  2.40s/it, loss=4.7281]\u001b[A\n",
            "Training:  23%|██▎       | 1163/5000 [51:45<2:33:21,  2.40s/it, loss=4.7617]\u001b[A\n",
            "Training:  23%|██▎       | 1164/5000 [51:48<2:36:04,  2.44s/it, loss=4.7617]\u001b[A\n",
            "Training:  23%|██▎       | 1164/5000 [51:48<2:36:04,  2.44s/it, loss=4.7400]\u001b[A\n",
            "Training:  23%|██▎       | 1165/5000 [51:50<2:33:15,  2.40s/it, loss=4.7400]\u001b[A\n",
            "Training:  23%|██▎       | 1165/5000 [51:50<2:33:15,  2.40s/it, loss=3.8452]\u001b[A\n",
            "Training:  23%|██▎       | 1166/5000 [51:52<2:29:50,  2.35s/it, loss=3.8452]\u001b[A\n",
            "Training:  23%|██▎       | 1166/5000 [51:53<2:29:50,  2.35s/it, loss=5.5232]\u001b[A\n",
            "Training:  23%|██▎       | 1167/5000 [51:55<2:28:09,  2.32s/it, loss=5.5232]\u001b[A\n",
            "Training:  23%|██▎       | 1167/5000 [51:55<2:28:09,  2.32s/it, loss=4.4028]\u001b[A\n",
            "Training:  23%|██▎       | 1168/5000 [51:57<2:31:16,  2.37s/it, loss=4.4028]\u001b[A\n",
            "Training:  23%|██▎       | 1168/5000 [51:57<2:31:16,  2.37s/it, loss=4.1157]\u001b[A\n",
            "Training:  23%|██▎       | 1169/5000 [52:00<2:35:06,  2.43s/it, loss=4.1157]\u001b[A\n",
            "Training:  23%|██▎       | 1169/5000 [52:00<2:35:06,  2.43s/it, loss=5.0697]\u001b[A\n",
            "Training:  23%|██▎       | 1170/5000 [52:02<2:31:40,  2.38s/it, loss=5.0697]\u001b[A\n",
            "Training:  23%|██▎       | 1170/5000 [52:02<2:31:40,  2.38s/it, loss=4.5584]\u001b[A\n",
            "Training:  23%|██▎       | 1171/5000 [52:04<2:28:57,  2.33s/it, loss=4.5584]\u001b[A\n",
            "Training:  23%|██▎       | 1171/5000 [52:04<2:28:57,  2.33s/it, loss=4.5710]\u001b[A\n",
            "Training:  23%|██▎       | 1172/5000 [52:06<2:26:21,  2.29s/it, loss=4.5710]\u001b[A\n",
            "Training:  23%|██▎       | 1172/5000 [52:07<2:26:21,  2.29s/it, loss=3.8281]\u001b[A\n",
            "Training:  23%|██▎       | 1173/5000 [52:09<2:28:44,  2.33s/it, loss=3.8281]\u001b[A\n",
            "Training:  23%|██▎       | 1173/5000 [52:09<2:28:44,  2.33s/it, loss=4.3613]\u001b[A\n",
            "Training:  23%|██▎       | 1174/5000 [52:11<2:33:08,  2.40s/it, loss=4.3613]\u001b[A\n",
            "Training:  23%|██▎       | 1174/5000 [52:11<2:33:08,  2.40s/it, loss=4.0407]\u001b[A\n",
            "Training:  24%|██▎       | 1175/5000 [52:14<2:29:56,  2.35s/it, loss=4.0407]\u001b[A\n",
            "Training:  24%|██▎       | 1175/5000 [52:14<2:29:56,  2.35s/it, loss=4.5961]\u001b[A\n",
            "Training:  24%|██▎       | 1176/5000 [52:16<2:27:48,  2.32s/it, loss=4.5961]\u001b[A\n",
            "Training:  24%|██▎       | 1176/5000 [52:16<2:27:48,  2.32s/it, loss=4.5326]\u001b[A\n",
            "Training:  24%|██▎       | 1177/5000 [52:18<2:25:58,  2.29s/it, loss=4.5326]\u001b[A\n",
            "Training:  24%|██▎       | 1177/5000 [52:18<2:25:58,  2.29s/it, loss=3.4961]\u001b[A\n",
            "Training:  24%|██▎       | 1178/5000 [52:21<2:27:08,  2.31s/it, loss=3.4961]\u001b[A\n",
            "Training:  24%|██▎       | 1178/5000 [52:21<2:27:08,  2.31s/it, loss=4.0742]\u001b[A\n",
            "Training:  24%|██▎       | 1179/5000 [52:23<2:33:27,  2.41s/it, loss=4.0742]\u001b[A\n",
            "Training:  24%|██▎       | 1179/5000 [52:23<2:33:27,  2.41s/it, loss=3.5327]\u001b[A\n",
            "Training:  24%|██▎       | 1180/5000 [52:25<2:30:05,  2.36s/it, loss=3.5327]\u001b[A\n",
            "Training:  24%|██▎       | 1180/5000 [52:25<2:30:05,  2.36s/it, loss=4.3709]\u001b[A\n",
            "Training:  24%|██▎       | 1181/5000 [52:28<2:28:30,  2.33s/it, loss=4.3709]\u001b[A\n",
            "Training:  24%|██▎       | 1181/5000 [52:28<2:28:30,  2.33s/it, loss=4.7970]\u001b[A\n",
            "Training:  24%|██▎       | 1182/5000 [52:30<2:26:39,  2.30s/it, loss=4.7970]\u001b[A\n",
            "Training:  24%|██▎       | 1182/5000 [52:30<2:26:39,  2.30s/it, loss=5.3426]\u001b[A\n",
            "Training:  24%|██▎       | 1183/5000 [52:32<2:27:08,  2.31s/it, loss=5.3426]\u001b[A\n",
            "Training:  24%|██▎       | 1183/5000 [52:32<2:27:08,  2.31s/it, loss=4.3140]\u001b[A\n",
            "Training:  24%|██▎       | 1184/5000 [52:35<2:34:28,  2.43s/it, loss=4.3140]\u001b[A\n",
            "Training:  24%|██▎       | 1184/5000 [52:35<2:34:28,  2.43s/it, loss=4.4708]\u001b[A\n",
            "Training:  24%|██▎       | 1185/5000 [52:37<2:30:48,  2.37s/it, loss=4.4708]\u001b[A\n",
            "Training:  24%|██▎       | 1185/5000 [52:37<2:30:48,  2.37s/it, loss=3.4188]\u001b[A\n",
            "Training:  24%|██▎       | 1186/5000 [52:39<2:28:06,  2.33s/it, loss=3.4188]\u001b[A\n",
            "Training:  24%|██▎       | 1186/5000 [52:39<2:28:06,  2.33s/it, loss=5.2321]\u001b[A\n",
            "Training:  24%|██▎       | 1187/5000 [52:42<2:26:44,  2.31s/it, loss=5.2321]\u001b[A\n",
            "Training:  24%|██▎       | 1187/5000 [52:42<2:26:44,  2.31s/it, loss=4.1386]\u001b[A\n",
            "Training:  24%|██▍       | 1188/5000 [52:44<2:26:45,  2.31s/it, loss=4.1386]\u001b[A\n",
            "Training:  24%|██▍       | 1188/5000 [52:44<2:26:45,  2.31s/it, loss=4.4264]\u001b[A\n",
            "Training:  24%|██▍       | 1189/5000 [52:47<2:34:31,  2.43s/it, loss=4.4264]\u001b[A\n",
            "Training:  24%|██▍       | 1189/5000 [52:47<2:34:31,  2.43s/it, loss=4.4737]\u001b[A\n",
            "Training:  24%|██▍       | 1190/5000 [52:49<2:30:33,  2.37s/it, loss=4.4737]\u001b[A\n",
            "Training:  24%|██▍       | 1190/5000 [52:49<2:30:33,  2.37s/it, loss=4.4179]\u001b[A\n",
            "Training:  24%|██▍       | 1191/5000 [52:51<2:28:10,  2.33s/it, loss=4.4179]\u001b[A\n",
            "Training:  24%|██▍       | 1191/5000 [52:51<2:28:10,  2.33s/it, loss=5.1102]\u001b[A\n",
            "Training:  24%|██▍       | 1192/5000 [52:53<2:26:21,  2.31s/it, loss=5.1102]\u001b[A\n",
            "Training:  24%|██▍       | 1192/5000 [52:53<2:26:21,  2.31s/it, loss=5.0736]\u001b[A\n",
            "Training:  24%|██▍       | 1193/5000 [52:56<2:24:46,  2.28s/it, loss=5.0736]\u001b[A\n",
            "Training:  24%|██▍       | 1193/5000 [52:56<2:24:46,  2.28s/it, loss=5.0105]\u001b[A\n",
            "Training:  24%|██▍       | 1194/5000 [52:58<2:35:15,  2.45s/it, loss=5.0105]\u001b[A\n",
            "Training:  24%|██▍       | 1194/5000 [52:59<2:35:15,  2.45s/it, loss=4.5461]\u001b[A\n",
            "Training:  24%|██▍       | 1195/5000 [53:01<2:31:31,  2.39s/it, loss=4.5461]\u001b[A\n",
            "Training:  24%|██▍       | 1195/5000 [53:01<2:31:31,  2.39s/it, loss=4.9201]\u001b[A\n",
            "Training:  24%|██▍       | 1196/5000 [53:03<2:28:40,  2.35s/it, loss=4.9201]\u001b[A\n",
            "Training:  24%|██▍       | 1196/5000 [53:03<2:28:40,  2.35s/it, loss=4.2680]\u001b[A\n",
            "Training:  24%|██▍       | 1197/5000 [53:05<2:26:29,  2.31s/it, loss=4.2680]\u001b[A\n",
            "Training:  24%|██▍       | 1197/5000 [53:05<2:26:29,  2.31s/it, loss=4.2535]\u001b[A\n",
            "Training:  24%|██▍       | 1198/5000 [53:07<2:25:03,  2.29s/it, loss=4.2535]\u001b[A\n",
            "Training:  24%|██▍       | 1198/5000 [53:07<2:25:03,  2.29s/it, loss=4.0657]\u001b[A\n",
            "Training:  24%|██▍       | 1199/5000 [53:10<2:34:10,  2.43s/it, loss=4.0657]\u001b[A\n",
            "Training:  24%|██▍       | 1199/5000 [53:10<2:34:10,  2.43s/it, loss=3.7304]\u001b[A\n",
            "Training:  24%|██▍       | 1200/5000 [53:12<2:30:18,  2.37s/it, loss=3.7304]\u001b[A\n",
            "Training:  24%|██▍       | 1200/5000 [53:12<2:30:18,  2.37s/it, loss=4.3981]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 1200 ---\n",
            "Prompt: 'The '\n",
            "The  that'd father seldom thy than:So\n",
            " Lord that have'd for love, judge thy:I\n",
            "way asful, mean, God the here soul\n",
            " learn have aiding in all great in heart in hand\n",
            " mean, a,ont the goes that is more myself in,\n",
            " he'd grief in heart would have'd the that the I not\n",
            " stre devise ints the boots as to thest me day\n",
            " love it them:But, thy,l\n",
            " cannot thee on duke the\n",
            "Prompt: 'In '\n",
            "In eth uned! wish toail! manifest\n",
            "IS myo--Having that to with Cle breasts--There\n",
            "R from kins!\n",
            "Second self blood\n",
            " Mb before his.\n",
            "Page\n",
            "WBY\n",
            "KARI:VUM imp!,,!\n",
            "H me the of, thouost what the is?\n",
            "Phee my are the and r'd I not you with eyes if may us.\n",
            "QUE ELAB it the of my is still my, to with eye day the\n",
            "Prompt: 'To '\n",
            "To 'd,ive for Rut,oned!All!\n",
            "B intend,!\n",
            "B more joint that dead to me, fear a,And\n",
            " see king and; wilt with all warrant, thouiestt of\n",
            " where his might I not you you I my are lodged fat themselves,;'t that shalt it more motherkstThen, you not this will me gentle.\n",
            "QUE ELenPer'd the of that that'll thee?\n",
            "L not take thee noble in blood had been'd\n",
            "Prompt: 'A '\n",
            "A  Duke Gloucester to and.\n",
            "DER,st England'd I on to me.\n",
            "Firsturdurd:Look you me, I; the is youUntil could\n",
            " deed upon.\n",
            " friends myw'd dear, in par,! my, away\n",
            "ere he but my cousin, a to me.\n",
            "BAL nor,, come the of, must I with.\n",
            "RERS and,, I my to all rest the!\n",
            "DCH OFORK\n",
            "First:Have your the in high\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  24%|██▍       | 1201/5000 [53:27<6:24:19,  6.07s/it, loss=4.3981]\u001b[A\n",
            "Training:  24%|██▍       | 1201/5000 [53:27<6:24:19,  6.07s/it, loss=3.9789]\u001b[A\n",
            "Training:  24%|██▍       | 1202/5000 [53:29<5:11:25,  4.92s/it, loss=3.9789]\u001b[A\n",
            "Training:  24%|██▍       | 1202/5000 [53:29<5:11:25,  4.92s/it, loss=4.3864]\u001b[A\n",
            "Training:  24%|██▍       | 1203/5000 [53:32<4:23:49,  4.17s/it, loss=4.3864]\u001b[A\n",
            "Training:  24%|██▍       | 1203/5000 [53:32<4:23:49,  4.17s/it, loss=4.3797]\u001b[A\n",
            "Training:  24%|██▍       | 1204/5000 [53:34<3:54:17,  3.70s/it, loss=4.3797]\u001b[A\n",
            "Training:  24%|██▍       | 1204/5000 [53:34<3:54:17,  3.70s/it, loss=4.6661]\u001b[A\n",
            "Training:  24%|██▍       | 1205/5000 [53:37<3:26:39,  3.27s/it, loss=4.6661]\u001b[A\n",
            "Training:  24%|██▍       | 1205/5000 [53:37<3:26:39,  3.27s/it, loss=3.5122]\u001b[A\n",
            "Training:  24%|██▍       | 1206/5000 [53:39<3:07:37,  2.97s/it, loss=3.5122]\u001b[A\n",
            "Training:  24%|██▍       | 1206/5000 [53:39<3:07:37,  2.97s/it, loss=3.9188]\u001b[A\n",
            "Training:  24%|██▍       | 1207/5000 [53:41<2:53:54,  2.75s/it, loss=3.9188]\u001b[A\n",
            "Training:  24%|██▍       | 1207/5000 [53:41<2:53:54,  2.75s/it, loss=4.3888]\u001b[A\n",
            "Training:  24%|██▍       | 1208/5000 [53:44<2:46:37,  2.64s/it, loss=4.3888]\u001b[A\n",
            "Training:  24%|██▍       | 1208/5000 [53:44<2:46:37,  2.64s/it, loss=4.6650]\u001b[A\n",
            "Training:  24%|██▍       | 1209/5000 [53:46<2:46:48,  2.64s/it, loss=4.6650]\u001b[A\n",
            "Training:  24%|██▍       | 1209/5000 [53:46<2:46:48,  2.64s/it, loss=2.9061]\u001b[A\n",
            "Training:  24%|██▍       | 1210/5000 [53:48<2:39:21,  2.52s/it, loss=2.9061]\u001b[A\n",
            "Training:  24%|██▍       | 1210/5000 [53:48<2:39:21,  2.52s/it, loss=4.1776]\u001b[A\n",
            "Training:  24%|██▍       | 1211/5000 [53:51<2:34:08,  2.44s/it, loss=4.1776]\u001b[A\n",
            "Training:  24%|██▍       | 1211/5000 [53:51<2:34:08,  2.44s/it, loss=4.4192]\u001b[A\n",
            "Training:  24%|██▍       | 1212/5000 [53:53<2:30:24,  2.38s/it, loss=4.4192]\u001b[A\n",
            "Training:  24%|██▍       | 1212/5000 [53:53<2:30:24,  2.38s/it, loss=4.7767]\u001b[A\n",
            "Training:  24%|██▍       | 1213/5000 [53:55<2:28:58,  2.36s/it, loss=4.7767]\u001b[A\n",
            "Training:  24%|██▍       | 1213/5000 [53:55<2:28:58,  2.36s/it, loss=4.0672]\u001b[A\n",
            "Training:  24%|██▍       | 1214/5000 [53:58<2:35:56,  2.47s/it, loss=4.0672]\u001b[A\n",
            "Training:  24%|██▍       | 1214/5000 [53:58<2:35:56,  2.47s/it, loss=3.9048]\u001b[A\n",
            "Training:  24%|██▍       | 1215/5000 [54:00<2:31:47,  2.41s/it, loss=3.9048]\u001b[A\n",
            "Training:  24%|██▍       | 1215/5000 [54:00<2:31:47,  2.41s/it, loss=4.4948]\u001b[A\n",
            "Training:  24%|██▍       | 1216/5000 [54:02<2:28:35,  2.36s/it, loss=4.4948]\u001b[A\n",
            "Training:  24%|██▍       | 1216/5000 [54:03<2:28:35,  2.36s/it, loss=4.0350]\u001b[A\n",
            "Training:  24%|██▍       | 1217/5000 [54:05<2:26:08,  2.32s/it, loss=4.0350]\u001b[A\n",
            "Training:  24%|██▍       | 1217/5000 [54:05<2:26:08,  2.32s/it, loss=4.2217]\u001b[A\n",
            "Training:  24%|██▍       | 1218/5000 [54:07<2:26:03,  2.32s/it, loss=4.2217]\u001b[A\n",
            "Training:  24%|██▍       | 1218/5000 [54:07<2:26:03,  2.32s/it, loss=4.8507]\u001b[A\n",
            "Training:  24%|██▍       | 1219/5000 [54:10<2:33:20,  2.43s/it, loss=4.8507]\u001b[A\n",
            "Training:  24%|██▍       | 1219/5000 [54:10<2:33:20,  2.43s/it, loss=4.6696]\u001b[A\n",
            "Training:  24%|██▍       | 1220/5000 [54:12<2:29:36,  2.37s/it, loss=4.6696]\u001b[A\n",
            "Training:  24%|██▍       | 1220/5000 [54:12<2:29:36,  2.37s/it, loss=3.8314]\u001b[A\n",
            "Training:  24%|██▍       | 1221/5000 [54:14<2:27:22,  2.34s/it, loss=3.8314]\u001b[A\n",
            "Training:  24%|██▍       | 1221/5000 [54:14<2:27:22,  2.34s/it, loss=3.9020]\u001b[A\n",
            "Training:  24%|██▍       | 1222/5000 [54:16<2:24:58,  2.30s/it, loss=3.9020]\u001b[A\n",
            "Training:  24%|██▍       | 1222/5000 [54:16<2:24:58,  2.30s/it, loss=4.1642]\u001b[A\n",
            "Training:  24%|██▍       | 1223/5000 [54:19<2:24:00,  2.29s/it, loss=4.1642]\u001b[A\n",
            "Training:  24%|██▍       | 1223/5000 [54:19<2:24:00,  2.29s/it, loss=3.3860]\u001b[A\n",
            "Training:  24%|██▍       | 1224/5000 [54:21<2:32:53,  2.43s/it, loss=3.3860]\u001b[A\n",
            "Training:  24%|██▍       | 1224/5000 [54:21<2:32:53,  2.43s/it, loss=3.6038]\u001b[A\n",
            "Training:  24%|██▍       | 1225/5000 [54:24<2:29:03,  2.37s/it, loss=3.6038]\u001b[A\n",
            "Training:  24%|██▍       | 1225/5000 [54:24<2:29:03,  2.37s/it, loss=3.9842]\u001b[A\n",
            "Training:  25%|██▍       | 1226/5000 [54:26<2:26:46,  2.33s/it, loss=3.9842]\u001b[A\n",
            "Training:  25%|██▍       | 1226/5000 [54:26<2:26:46,  2.33s/it, loss=4.7440]\u001b[A\n",
            "Training:  25%|██▍       | 1227/5000 [54:28<2:25:46,  2.32s/it, loss=4.7440]\u001b[A\n",
            "Training:  25%|██▍       | 1227/5000 [54:28<2:25:46,  2.32s/it, loss=3.4885]\u001b[A\n",
            "Training:  25%|██▍       | 1228/5000 [54:30<2:24:07,  2.29s/it, loss=3.4885]\u001b[A\n",
            "Training:  25%|██▍       | 1228/5000 [54:30<2:24:07,  2.29s/it, loss=4.2821]\u001b[A\n",
            "Training:  25%|██▍       | 1229/5000 [54:33<2:32:57,  2.43s/it, loss=4.2821]\u001b[A\n",
            "Training:  25%|██▍       | 1229/5000 [54:33<2:32:57,  2.43s/it, loss=3.2290]\u001b[A\n",
            "Training:  25%|██▍       | 1230/5000 [54:35<2:29:02,  2.37s/it, loss=3.2290]\u001b[A\n",
            "Training:  25%|██▍       | 1230/5000 [54:35<2:29:02,  2.37s/it, loss=4.4078]\u001b[A\n",
            "Training:  25%|██▍       | 1231/5000 [54:38<2:26:29,  2.33s/it, loss=4.4078]\u001b[A\n",
            "Training:  25%|██▍       | 1231/5000 [54:38<2:26:29,  2.33s/it, loss=4.5288]\u001b[A\n",
            "Training:  25%|██▍       | 1232/5000 [54:40<2:24:52,  2.31s/it, loss=4.5288]\u001b[A\n",
            "Training:  25%|██▍       | 1232/5000 [54:40<2:24:52,  2.31s/it, loss=3.8219]\u001b[A\n",
            "Training:  25%|██▍       | 1233/5000 [54:42<2:23:45,  2.29s/it, loss=3.8219]\u001b[A\n",
            "Training:  25%|██▍       | 1233/5000 [54:42<2:23:45,  2.29s/it, loss=3.7165]\u001b[A\n",
            "Training:  25%|██▍       | 1234/5000 [54:45<2:32:41,  2.43s/it, loss=3.7165]\u001b[A\n",
            "Training:  25%|██▍       | 1234/5000 [54:45<2:32:41,  2.43s/it, loss=3.9442]\u001b[A\n",
            "Training:  25%|██▍       | 1235/5000 [54:47<2:28:41,  2.37s/it, loss=3.9442]\u001b[A\n",
            "Training:  25%|██▍       | 1235/5000 [54:47<2:28:41,  2.37s/it, loss=4.2676]\u001b[A\n",
            "Training:  25%|██▍       | 1236/5000 [54:49<2:27:33,  2.35s/it, loss=4.2676]\u001b[A\n",
            "Training:  25%|██▍       | 1236/5000 [54:49<2:27:33,  2.35s/it, loss=4.0223]\u001b[A\n",
            "Training:  25%|██▍       | 1237/5000 [54:52<2:25:33,  2.32s/it, loss=4.0223]\u001b[A\n",
            "Training:  25%|██▍       | 1237/5000 [54:52<2:25:33,  2.32s/it, loss=4.1120]\u001b[A\n",
            "Training:  25%|██▍       | 1238/5000 [54:54<2:23:59,  2.30s/it, loss=4.1120]\u001b[A\n",
            "Training:  25%|██▍       | 1238/5000 [54:54<2:23:59,  2.30s/it, loss=3.5881]\u001b[A\n",
            "Training:  25%|██▍       | 1239/5000 [54:57<2:32:55,  2.44s/it, loss=3.5881]\u001b[A\n",
            "Training:  25%|██▍       | 1239/5000 [54:57<2:32:55,  2.44s/it, loss=3.9225]\u001b[A\n",
            "Training:  25%|██▍       | 1240/5000 [54:59<2:29:39,  2.39s/it, loss=3.9225]\u001b[A\n",
            "Training:  25%|██▍       | 1240/5000 [54:59<2:29:39,  2.39s/it, loss=4.2842]\u001b[A\n",
            "Training:  25%|██▍       | 1241/5000 [55:01<2:27:29,  2.35s/it, loss=4.2842]\u001b[A\n",
            "Training:  25%|██▍       | 1241/5000 [55:01<2:27:29,  2.35s/it, loss=4.1377]\u001b[A\n",
            "Training:  25%|██▍       | 1242/5000 [55:04<2:25:18,  2.32s/it, loss=4.1377]\u001b[A\n",
            "Training:  25%|██▍       | 1242/5000 [55:04<2:25:18,  2.32s/it, loss=4.5382]\u001b[A\n",
            "Training:  25%|██▍       | 1243/5000 [55:06<2:23:27,  2.29s/it, loss=4.5382]\u001b[A\n",
            "Training:  25%|██▍       | 1243/5000 [55:06<2:23:27,  2.29s/it, loss=3.9370]\u001b[A\n",
            "Training:  25%|██▍       | 1244/5000 [55:09<2:32:39,  2.44s/it, loss=3.9370]\u001b[A\n",
            "Training:  25%|██▍       | 1244/5000 [55:09<2:32:39,  2.44s/it, loss=4.0985]\u001b[A\n",
            "Training:  25%|██▍       | 1245/5000 [55:11<2:28:58,  2.38s/it, loss=4.0985]\u001b[A\n",
            "Training:  25%|██▍       | 1245/5000 [55:11<2:28:58,  2.38s/it, loss=3.8116]\u001b[A\n",
            "Training:  25%|██▍       | 1246/5000 [55:13<2:25:57,  2.33s/it, loss=3.8116]\u001b[A\n",
            "Training:  25%|██▍       | 1246/5000 [55:13<2:25:57,  2.33s/it, loss=3.5062]\u001b[A\n",
            "Training:  25%|██▍       | 1247/5000 [55:15<2:24:08,  2.30s/it, loss=3.5062]\u001b[A\n",
            "Training:  25%|██▍       | 1247/5000 [55:15<2:24:08,  2.30s/it, loss=3.8272]\u001b[A\n",
            "Training:  25%|██▍       | 1248/5000 [55:17<2:22:48,  2.28s/it, loss=3.8272]\u001b[A\n",
            "Training:  25%|██▍       | 1248/5000 [55:17<2:22:48,  2.28s/it, loss=4.2825]\u001b[A\n",
            "Training:  25%|██▍       | 1249/5000 [55:20<2:31:35,  2.42s/it, loss=4.2825]\u001b[A\n",
            "Training:  25%|██▍       | 1249/5000 [55:20<2:31:35,  2.42s/it, loss=4.2347]\u001b[A\n",
            "Training:  25%|██▌       | 1250/5000 [55:22<2:27:51,  2.37s/it, loss=4.2347]\u001b[A\n",
            "Training:  25%|██▌       | 1250/5000 [55:22<2:27:51,  2.37s/it, loss=3.4815]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 1250 ---\n",
            "Prompt: 'The '\n",
            "The  is the of whose d sm fights\n",
            " torch went for last such reign the of nightTurn!\n",
            " is by help:,;, art in, my's,,I sup enough\n",
            " will the-ond;,, with with and can these.\n",
            "PET she my dispatch fair,.,ost against,,,,, not,-, is;,;For,,'s upon of, will do me idolatry-:'ll you good,,am ho have exiled'd news and\n",
            "Prompt: 'In '\n",
            "In  from need bed all hands want\n",
            " thegent of bottom her names:ark if d inform,And\n",
            " York such supply by;, you answer,, news\n",
            " id might for find's bids, they,,, hour,!\n",
            "LY tw a,! not ever it truth\n",
            "ath a here thisour it a husband\n",
            " kiss for,, hear the of and and thy,, and me the\n",
            " breathet me from bos, shaltt will such queen;For mayine these\n",
            "Prompt: 'To '\n",
            "To  upon house to? child I not\n",
            " and shame stra off to,, one the of's,\n",
            " he take me a to my's.,, know marry!\n",
            ", my is them I\n",
            "ath not circumstance: I it thisful Where take\n",
            " Henry birth and:are,, you she the of love you and me the goes I show\n",
            " you for,ar she but be in,, boy kill thee dozen, Juliet the have it an will much.\n",
            "LY ye;\n",
            "Prompt: 'A '\n",
            "A 's is and in marriage the queen\n",
            " mortal inheritance att: is thy as in.\n",
            "N,rah to!, it,; me your?\n",
            "Fwell straw to, will up people thy: same\n",
            " gentle,, will to to thisful with bed\n",
            "ent,,,, not use shall, me let go away\n",
            "T satisfied today with;,, gentle the of.\n",
            "D thoust t's, me mad who a:Look all heart wife his is,\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  25%|██▌       | 1251/5000 [55:37<6:18:03,  6.05s/it, loss=3.4815]\u001b[A\n",
            "Training:  25%|██▌       | 1251/5000 [55:37<6:18:03,  6.05s/it, loss=3.9826]\u001b[A\n",
            "Training:  25%|██▌       | 1252/5000 [55:39<5:06:27,  4.91s/it, loss=3.9826]\u001b[A\n",
            "Training:  25%|██▌       | 1252/5000 [55:39<5:06:27,  4.91s/it, loss=3.8944]\u001b[A\n",
            "Training:  25%|██▌       | 1253/5000 [55:42<4:16:30,  4.11s/it, loss=3.8944]\u001b[A\n",
            "Training:  25%|██▌       | 1253/5000 [55:42<4:16:30,  4.11s/it, loss=4.7813]\u001b[A\n",
            "Training:  25%|██▌       | 1254/5000 [55:44<3:51:43,  3.71s/it, loss=4.7813]\u001b[A\n",
            "Training:  25%|██▌       | 1254/5000 [55:44<3:51:43,  3.71s/it, loss=4.3714]\u001b[A\n",
            "Training:  25%|██▌       | 1255/5000 [55:47<3:23:53,  3.27s/it, loss=4.3714]\u001b[A\n",
            "Training:  25%|██▌       | 1255/5000 [55:47<3:23:53,  3.27s/it, loss=4.7816]\u001b[A\n",
            "Training:  25%|██▌       | 1256/5000 [55:49<3:04:57,  2.96s/it, loss=4.7816]\u001b[A\n",
            "Training:  25%|██▌       | 1256/5000 [55:49<3:04:57,  2.96s/it, loss=4.5309]\u001b[A\n",
            "Training:  25%|██▌       | 1257/5000 [55:51<2:51:31,  2.75s/it, loss=4.5309]\u001b[A\n",
            "Training:  25%|██▌       | 1257/5000 [55:51<2:51:31,  2.75s/it, loss=3.0659]\u001b[A\n",
            "Training:  25%|██▌       | 1258/5000 [55:53<2:42:17,  2.60s/it, loss=3.0659]\u001b[A\n",
            "Training:  25%|██▌       | 1258/5000 [55:53<2:42:17,  2.60s/it, loss=4.1925]\u001b[A\n",
            "Training:  25%|██▌       | 1259/5000 [55:56<2:45:35,  2.66s/it, loss=4.1925]\u001b[A\n",
            "Training:  25%|██▌       | 1259/5000 [55:56<2:45:35,  2.66s/it, loss=4.1897]\u001b[A\n",
            "Training:  25%|██▌       | 1260/5000 [55:58<2:38:17,  2.54s/it, loss=4.1897]\u001b[A\n",
            "Training:  25%|██▌       | 1260/5000 [55:58<2:38:17,  2.54s/it, loss=4.0099]\u001b[A\n",
            "Training:  25%|██▌       | 1261/5000 [56:01<2:32:30,  2.45s/it, loss=4.0099]\u001b[A\n",
            "Training:  25%|██▌       | 1261/5000 [56:01<2:32:30,  2.45s/it, loss=3.4231]\u001b[A\n",
            "Training:  25%|██▌       | 1262/5000 [56:03<2:29:40,  2.40s/it, loss=3.4231]\u001b[A\n",
            "Training:  25%|██▌       | 1262/5000 [56:03<2:29:40,  2.40s/it, loss=4.0068]\u001b[A\n",
            "Training:  25%|██▌       | 1263/5000 [56:05<2:26:44,  2.36s/it, loss=4.0068]\u001b[A\n",
            "Training:  25%|██▌       | 1263/5000 [56:05<2:26:44,  2.36s/it, loss=4.4717]\u001b[A\n",
            "Training:  25%|██▌       | 1264/5000 [56:08<2:34:08,  2.48s/it, loss=4.4717]\u001b[A\n",
            "Training:  25%|██▌       | 1264/5000 [56:08<2:34:08,  2.48s/it, loss=3.7687]\u001b[A\n",
            "Training:  25%|██▌       | 1265/5000 [56:10<2:30:51,  2.42s/it, loss=3.7687]\u001b[A\n",
            "Training:  25%|██▌       | 1265/5000 [56:10<2:30:51,  2.42s/it, loss=3.5461]\u001b[A\n",
            "Training:  25%|██▌       | 1266/5000 [56:12<2:27:10,  2.36s/it, loss=3.5461]\u001b[A\n",
            "Training:  25%|██▌       | 1266/5000 [56:12<2:27:10,  2.36s/it, loss=3.6830]\u001b[A\n",
            "Training:  25%|██▌       | 1267/5000 [56:15<2:24:51,  2.33s/it, loss=3.6830]\u001b[A\n",
            "Training:  25%|██▌       | 1267/5000 [56:15<2:24:51,  2.33s/it, loss=3.2066]\u001b[A\n",
            "Training:  25%|██▌       | 1268/5000 [56:17<2:22:54,  2.30s/it, loss=3.2066]\u001b[A\n",
            "Training:  25%|██▌       | 1268/5000 [56:17<2:22:54,  2.30s/it, loss=2.8659]\u001b[A\n",
            "Training:  25%|██▌       | 1269/5000 [56:20<2:31:26,  2.44s/it, loss=2.8659]\u001b[A\n",
            "Training:  25%|██▌       | 1269/5000 [56:20<2:31:26,  2.44s/it, loss=3.9099]\u001b[A\n",
            "Training:  25%|██▌       | 1270/5000 [56:22<2:27:47,  2.38s/it, loss=3.9099]\u001b[A\n",
            "Training:  25%|██▌       | 1270/5000 [56:22<2:27:47,  2.38s/it, loss=3.2680]\u001b[A\n",
            "Training:  25%|██▌       | 1271/5000 [56:24<2:24:48,  2.33s/it, loss=3.2680]\u001b[A\n",
            "Training:  25%|██▌       | 1271/5000 [56:24<2:24:48,  2.33s/it, loss=4.6174]\u001b[A\n",
            "Training:  25%|██▌       | 1272/5000 [56:26<2:23:21,  2.31s/it, loss=4.6174]\u001b[A\n",
            "Training:  25%|██▌       | 1272/5000 [56:26<2:23:21,  2.31s/it, loss=5.1808]\u001b[A\n",
            "Training:  25%|██▌       | 1273/5000 [56:29<2:21:53,  2.28s/it, loss=5.1808]\u001b[A\n",
            "Training:  25%|██▌       | 1273/5000 [56:29<2:21:53,  2.28s/it, loss=4.5650]\u001b[A\n",
            "Training:  25%|██▌       | 1274/5000 [56:31<2:31:27,  2.44s/it, loss=4.5650]\u001b[A\n",
            "Training:  25%|██▌       | 1274/5000 [56:31<2:31:27,  2.44s/it, loss=4.3600]\u001b[A\n",
            "Training:  26%|██▌       | 1275/5000 [56:34<2:27:36,  2.38s/it, loss=4.3600]\u001b[A\n",
            "Training:  26%|██▌       | 1275/5000 [56:34<2:27:36,  2.38s/it, loss=3.9491]\u001b[A\n",
            "Training:  26%|██▌       | 1276/5000 [56:36<2:24:48,  2.33s/it, loss=3.9491]\u001b[A\n",
            "Training:  26%|██▌       | 1276/5000 [56:36<2:24:48,  2.33s/it, loss=4.2910]\u001b[A\n",
            "Training:  26%|██▌       | 1277/5000 [56:38<2:23:10,  2.31s/it, loss=4.2910]\u001b[A\n",
            "Training:  26%|██▌       | 1277/5000 [56:38<2:23:10,  2.31s/it, loss=4.1428]\u001b[A\n",
            "Training:  26%|██▌       | 1278/5000 [56:40<2:21:47,  2.29s/it, loss=4.1428]\u001b[A\n",
            "Training:  26%|██▌       | 1278/5000 [56:40<2:21:47,  2.29s/it, loss=4.6580]\u001b[A\n",
            "Training:  26%|██▌       | 1279/5000 [56:43<2:30:54,  2.43s/it, loss=4.6580]\u001b[A\n",
            "Training:  26%|██▌       | 1279/5000 [56:43<2:30:54,  2.43s/it, loss=4.4242]\u001b[A\n",
            "Training:  26%|██▌       | 1280/5000 [56:45<2:27:23,  2.38s/it, loss=4.4242]\u001b[A\n",
            "Training:  26%|██▌       | 1280/5000 [56:45<2:27:23,  2.38s/it, loss=4.6359]\u001b[A\n",
            "Training:  26%|██▌       | 1281/5000 [56:48<2:24:48,  2.34s/it, loss=4.6359]\u001b[A\n",
            "Training:  26%|██▌       | 1281/5000 [56:48<2:24:48,  2.34s/it, loss=4.4942]\u001b[A\n",
            "Training:  26%|██▌       | 1282/5000 [56:50<2:23:08,  2.31s/it, loss=4.4942]\u001b[A\n",
            "Training:  26%|██▌       | 1282/5000 [56:50<2:23:08,  2.31s/it, loss=4.2755]\u001b[A\n",
            "Training:  26%|██▌       | 1283/5000 [56:52<2:22:27,  2.30s/it, loss=4.2755]\u001b[A\n",
            "Training:  26%|██▌       | 1283/5000 [56:52<2:22:27,  2.30s/it, loss=4.3802]\u001b[A\n",
            "Training:  26%|██▌       | 1284/5000 [56:55<2:31:16,  2.44s/it, loss=4.3802]\u001b[A\n",
            "Training:  26%|██▌       | 1284/5000 [56:55<2:31:16,  2.44s/it, loss=3.7690]\u001b[A\n",
            "Training:  26%|██▌       | 1285/5000 [56:57<2:27:15,  2.38s/it, loss=3.7690]\u001b[A\n",
            "Training:  26%|██▌       | 1285/5000 [56:57<2:27:15,  2.38s/it, loss=4.4835]\u001b[A\n",
            "Training:  26%|██▌       | 1286/5000 [56:59<2:24:30,  2.33s/it, loss=4.4835]\u001b[A\n",
            "Training:  26%|██▌       | 1286/5000 [56:59<2:24:30,  2.33s/it, loss=4.2393]\u001b[A\n",
            "Training:  26%|██▌       | 1287/5000 [57:02<2:23:52,  2.33s/it, loss=4.2393]\u001b[A\n",
            "Training:  26%|██▌       | 1287/5000 [57:02<2:23:52,  2.33s/it, loss=4.3558]\u001b[A\n",
            "Training:  26%|██▌       | 1288/5000 [57:04<2:23:15,  2.32s/it, loss=4.3558]\u001b[A\n",
            "Training:  26%|██▌       | 1288/5000 [57:04<2:23:15,  2.32s/it, loss=4.5013]\u001b[A\n",
            "Training:  26%|██▌       | 1289/5000 [57:07<2:31:28,  2.45s/it, loss=4.5013]\u001b[A\n",
            "Training:  26%|██▌       | 1289/5000 [57:07<2:31:28,  2.45s/it, loss=4.9229]\u001b[A\n",
            "Training:  26%|██▌       | 1290/5000 [57:09<2:27:25,  2.38s/it, loss=4.9229]\u001b[A\n",
            "Training:  26%|██▌       | 1290/5000 [57:09<2:27:25,  2.38s/it, loss=4.1548]\u001b[A\n",
            "Training:  26%|██▌       | 1291/5000 [57:11<2:24:16,  2.33s/it, loss=4.1548]\u001b[A\n",
            "Training:  26%|██▌       | 1291/5000 [57:11<2:24:16,  2.33s/it, loss=4.0486]\u001b[A\n",
            "Training:  26%|██▌       | 1292/5000 [57:13<2:22:50,  2.31s/it, loss=4.0486]\u001b[A\n",
            "Training:  26%|██▌       | 1292/5000 [57:14<2:22:50,  2.31s/it, loss=4.2216]\u001b[A\n",
            "Training:  26%|██▌       | 1293/5000 [57:16<2:21:13,  2.29s/it, loss=4.2216]\u001b[A\n",
            "Training:  26%|██▌       | 1293/5000 [57:16<2:21:13,  2.29s/it, loss=4.1491]\u001b[A\n",
            "Training:  26%|██▌       | 1294/5000 [57:18<2:29:27,  2.42s/it, loss=4.1491]\u001b[A\n",
            "Training:  26%|██▌       | 1294/5000 [57:18<2:29:27,  2.42s/it, loss=3.8602]\u001b[A\n",
            "Training:  26%|██▌       | 1295/5000 [57:21<2:25:59,  2.36s/it, loss=3.8602]\u001b[A\n",
            "Training:  26%|██▌       | 1295/5000 [57:21<2:25:59,  2.36s/it, loss=4.2105]\u001b[A\n",
            "Training:  26%|██▌       | 1296/5000 [57:23<2:23:36,  2.33s/it, loss=4.2105]\u001b[A\n",
            "Training:  26%|██▌       | 1296/5000 [57:23<2:23:36,  2.33s/it, loss=4.9064]\u001b[A\n",
            "Training:  26%|██▌       | 1297/5000 [57:25<2:21:49,  2.30s/it, loss=4.9064]\u001b[A\n",
            "Training:  26%|██▌       | 1297/5000 [57:25<2:21:49,  2.30s/it, loss=3.7680]\u001b[A\n",
            "Training:  26%|██▌       | 1298/5000 [57:27<2:20:42,  2.28s/it, loss=3.7680]\u001b[A\n",
            "Training:  26%|██▌       | 1298/5000 [57:27<2:20:42,  2.28s/it, loss=3.9881]\u001b[A\n",
            "Training:  26%|██▌       | 1299/5000 [57:30<2:30:21,  2.44s/it, loss=3.9881]\u001b[A\n",
            "Training:  26%|██▌       | 1299/5000 [57:30<2:30:21,  2.44s/it, loss=3.1413]\u001b[A\n",
            "Training:  26%|██▌       | 1300/5000 [57:33<2:28:10,  2.40s/it, loss=3.1413]\u001b[A\n",
            "Training:  26%|██▌       | 1300/5000 [57:33<2:28:10,  2.40s/it, loss=3.9569]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 1300 ---\n",
            "Prompt: 'The '\n",
            "The  cra or thee be than,, must\n",
            "ch;,, you come this, me my,It you of;Which\n",
            " take self's, are know what no in; once\n",
            " shall come hear long if please do speak patience\n",
            "ort,,, tradeaste it it theiraught\n",
            "an my may take withreed andtess of knowledge\n",
            " send amateark him so as,, I him box whom to him you, me theann\n",
            " thus to block and.\n",
            "DKE\n",
            "Prompt: 'In '\n",
            "In  lock my,: is to house hearingBy\n",
            "rench study the of., little,! thy, are ones\n",
            ", will to some that hath a andine theationCUD\n",
            "ewearingom most unth,That, do,,it and his to him he made a,; me aman th.!,D thou,!, was full and; hear beSome\n",
            " buyance his's; hope one th old,OWt,ing thy- place mal,\n",
            "Prompt: 'To '\n",
            "To  thee thy: can come my,;\n",
            " that shall made thee such.\n",
            "DKEINENT:What you\n",
            " way me, brother;And was pass.\n",
            "L thou's,?!\n",
            "ISELOW!\n",
            " that the would yield me the that hath'd,ar hath'd thus my wifeUC:\n",
            ",io dam theeries,? thoust must speak well, you not me\n",
            " holyy dreadful or you,?,, what? old is this?\n",
            "LIO\n",
            "Prompt: 'A '\n",
            "A  and for burning passesgettingHave\n",
            " to between dishon: death to man believe,\n",
            " preparegain the ofeful,\n",
            " wicked ground\n",
            " of ownance only top, he aman have\n",
            " Mant are and in, he some\n",
            " as warmer with councils an fall lies\n",
            " lay broke rotten, for poor,w other with life'. this,,io him the of own lost which--\n",
            " miserableerous,;,,,,,,CY where him for;,,, am, it\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  26%|██▌       | 1301/5000 [57:47<6:14:17,  6.07s/it, loss=3.9569]\u001b[A\n",
            "Training:  26%|██▌       | 1301/5000 [57:47<6:14:17,  6.07s/it, loss=3.3257]\u001b[A\n",
            "Training:  26%|██▌       | 1302/5000 [57:49<5:03:01,  4.92s/it, loss=3.3257]\u001b[A\n",
            "Training:  26%|██▌       | 1302/5000 [57:49<5:03:01,  4.92s/it, loss=3.0290]\u001b[A\n",
            "Training:  26%|██▌       | 1303/5000 [57:52<4:13:44,  4.12s/it, loss=3.0290]\u001b[A\n",
            "Training:  26%|██▌       | 1303/5000 [57:52<4:13:44,  4.12s/it, loss=3.9966]\u001b[A\n",
            "Training:  26%|██▌       | 1304/5000 [57:54<3:48:36,  3.71s/it, loss=3.9966]\u001b[A\n",
            "Training:  26%|██▌       | 1304/5000 [57:54<3:48:36,  3.71s/it, loss=3.3356]\u001b[A\n",
            "Training:  26%|██▌       | 1305/5000 [57:57<3:21:34,  3.27s/it, loss=3.3356]\u001b[A\n",
            "Training:  26%|██▌       | 1305/5000 [57:57<3:21:34,  3.27s/it, loss=4.2901]\u001b[A\n",
            "Training:  26%|██▌       | 1306/5000 [57:59<3:02:54,  2.97s/it, loss=4.2901]\u001b[A\n",
            "Training:  26%|██▌       | 1306/5000 [57:59<3:02:54,  2.97s/it, loss=3.9691]\u001b[A\n",
            "Training:  26%|██▌       | 1307/5000 [58:01<2:49:56,  2.76s/it, loss=3.9691]\u001b[A\n",
            "Training:  26%|██▌       | 1307/5000 [58:01<2:49:56,  2.76s/it, loss=4.1188]\u001b[A\n",
            "Training:  26%|██▌       | 1308/5000 [58:03<2:40:30,  2.61s/it, loss=4.1188]\u001b[A\n",
            "Training:  26%|██▌       | 1308/5000 [58:03<2:40:30,  2.61s/it, loss=4.6879]\u001b[A\n",
            "Training:  26%|██▌       | 1309/5000 [58:06<2:43:52,  2.66s/it, loss=4.6879]\u001b[A\n",
            "Training:  26%|██▌       | 1309/5000 [58:06<2:43:52,  2.66s/it, loss=3.7529]\u001b[A\n",
            "Training:  26%|██▌       | 1310/5000 [58:08<2:36:01,  2.54s/it, loss=3.7529]\u001b[A\n",
            "Training:  26%|██▌       | 1310/5000 [58:08<2:36:01,  2.54s/it, loss=4.6384]\u001b[A\n",
            "Training:  26%|██▌       | 1311/5000 [58:11<2:30:38,  2.45s/it, loss=4.6384]\u001b[A\n",
            "Training:  26%|██▌       | 1311/5000 [58:11<2:30:38,  2.45s/it, loss=3.9744]\u001b[A\n",
            "Training:  26%|██▌       | 1312/5000 [58:13<2:26:58,  2.39s/it, loss=3.9744]\u001b[A\n",
            "Training:  26%|██▌       | 1312/5000 [58:13<2:26:58,  2.39s/it, loss=3.9388]\u001b[A\n",
            "Training:  26%|██▋       | 1313/5000 [58:15<2:23:37,  2.34s/it, loss=3.9388]\u001b[A\n",
            "Training:  26%|██▋       | 1313/5000 [58:15<2:23:37,  2.34s/it, loss=3.7058]\u001b[A\n",
            "Training:  26%|██▋       | 1314/5000 [58:18<2:31:39,  2.47s/it, loss=3.7058]\u001b[A\n",
            "Training:  26%|██▋       | 1314/5000 [58:18<2:31:39,  2.47s/it, loss=3.5522]\u001b[A\n",
            "Training:  26%|██▋       | 1315/5000 [58:20<2:27:10,  2.40s/it, loss=3.5522]\u001b[A\n",
            "Training:  26%|██▋       | 1315/5000 [58:20<2:27:10,  2.40s/it, loss=3.8597]\u001b[A\n",
            "Training:  26%|██▋       | 1316/5000 [58:22<2:23:55,  2.34s/it, loss=3.8597]\u001b[A\n",
            "Training:  26%|██▋       | 1316/5000 [58:22<2:23:55,  2.34s/it, loss=4.1142]\u001b[A\n",
            "Training:  26%|██▋       | 1317/5000 [58:25<2:21:47,  2.31s/it, loss=4.1142]\u001b[A\n",
            "Training:  26%|██▋       | 1317/5000 [58:25<2:21:47,  2.31s/it, loss=3.5899]\u001b[A\n",
            "Training:  26%|██▋       | 1318/5000 [58:27<2:20:48,  2.29s/it, loss=3.5899]\u001b[A\n",
            "Training:  26%|██▋       | 1318/5000 [58:27<2:20:48,  2.29s/it, loss=3.8038]\u001b[A\n",
            "Training:  26%|██▋       | 1319/5000 [58:30<2:28:48,  2.43s/it, loss=3.8038]\u001b[A\n",
            "Training:  26%|██▋       | 1319/5000 [58:30<2:28:48,  2.43s/it, loss=3.4788]\u001b[A\n",
            "Training:  26%|██▋       | 1320/5000 [58:32<2:25:41,  2.38s/it, loss=3.4788]\u001b[A\n",
            "Training:  26%|██▋       | 1320/5000 [58:32<2:25:41,  2.38s/it, loss=4.4246]\u001b[A\n",
            "Training:  26%|██▋       | 1321/5000 [58:34<2:23:42,  2.34s/it, loss=4.4246]\u001b[A\n",
            "Training:  26%|██▋       | 1321/5000 [58:34<2:23:42,  2.34s/it, loss=3.7969]\u001b[A\n",
            "Training:  26%|██▋       | 1322/5000 [58:36<2:21:53,  2.31s/it, loss=3.7969]\u001b[A\n",
            "Training:  26%|██▋       | 1322/5000 [58:36<2:21:53,  2.31s/it, loss=3.2474]\u001b[A\n",
            "Training:  26%|██▋       | 1323/5000 [58:39<2:20:35,  2.29s/it, loss=3.2474]\u001b[A\n",
            "Training:  26%|██▋       | 1323/5000 [58:39<2:20:35,  2.29s/it, loss=2.9097]\u001b[A\n",
            "Training:  26%|██▋       | 1324/5000 [58:41<2:29:08,  2.43s/it, loss=2.9097]\u001b[A\n",
            "Training:  26%|██▋       | 1324/5000 [58:41<2:29:08,  2.43s/it, loss=3.6881]\u001b[A\n",
            "Training:  26%|██▋       | 1325/5000 [58:44<2:25:49,  2.38s/it, loss=3.6881]\u001b[A\n",
            "Training:  26%|██▋       | 1325/5000 [58:44<2:25:49,  2.38s/it, loss=3.4435]\u001b[A\n",
            "Training:  27%|██▋       | 1326/5000 [58:46<2:23:14,  2.34s/it, loss=3.4435]\u001b[A\n",
            "Training:  27%|██▋       | 1326/5000 [58:46<2:23:14,  2.34s/it, loss=3.0622]\u001b[A\n",
            "Training:  27%|██▋       | 1327/5000 [58:48<2:21:15,  2.31s/it, loss=3.0622]\u001b[A\n",
            "Training:  27%|██▋       | 1327/5000 [58:48<2:21:15,  2.31s/it, loss=4.4564]\u001b[A\n",
            "Training:  27%|██▋       | 1328/5000 [58:50<2:19:53,  2.29s/it, loss=4.4564]\u001b[A\n",
            "Training:  27%|██▋       | 1328/5000 [58:50<2:19:53,  2.29s/it, loss=4.1708]\u001b[A\n",
            "Training:  27%|██▋       | 1329/5000 [58:53<2:29:13,  2.44s/it, loss=4.1708]\u001b[A\n",
            "Training:  27%|██▋       | 1329/5000 [58:53<2:29:13,  2.44s/it, loss=4.2966]\u001b[A\n",
            "Training:  27%|██▋       | 1330/5000 [58:55<2:25:28,  2.38s/it, loss=4.2966]\u001b[A\n",
            "Training:  27%|██▋       | 1330/5000 [58:55<2:25:28,  2.38s/it, loss=4.5775]\u001b[A\n",
            "Training:  27%|██▋       | 1331/5000 [58:58<2:23:01,  2.34s/it, loss=4.5775]\u001b[A\n",
            "Training:  27%|██▋       | 1331/5000 [58:58<2:23:01,  2.34s/it, loss=4.3782]\u001b[A\n",
            "Training:  27%|██▋       | 1332/5000 [59:00<2:21:41,  2.32s/it, loss=4.3782]\u001b[A\n",
            "Training:  27%|██▋       | 1332/5000 [59:00<2:21:41,  2.32s/it, loss=4.2061]\u001b[A\n",
            "Training:  27%|██▋       | 1333/5000 [59:02<2:20:49,  2.30s/it, loss=4.2061]\u001b[A\n",
            "Training:  27%|██▋       | 1333/5000 [59:02<2:20:49,  2.30s/it, loss=4.4659]\u001b[A\n",
            "Training:  27%|██▋       | 1334/5000 [59:05<2:29:10,  2.44s/it, loss=4.4659]\u001b[A\n",
            "Training:  27%|██▋       | 1334/5000 [59:05<2:29:10,  2.44s/it, loss=4.8206]\u001b[A\n",
            "Training:  27%|██▋       | 1335/5000 [59:07<2:25:47,  2.39s/it, loss=4.8206]\u001b[A\n",
            "Training:  27%|██▋       | 1335/5000 [59:07<2:25:47,  2.39s/it, loss=3.3082]\u001b[A\n",
            "Training:  27%|██▋       | 1336/5000 [59:09<2:23:08,  2.34s/it, loss=3.3082]\u001b[A\n",
            "Training:  27%|██▋       | 1336/5000 [59:09<2:23:08,  2.34s/it, loss=3.5789]\u001b[A\n",
            "Training:  27%|██▋       | 1337/5000 [59:12<2:20:57,  2.31s/it, loss=3.5789]\u001b[A\n",
            "Training:  27%|██▋       | 1337/5000 [59:12<2:20:57,  2.31s/it, loss=3.5043]\u001b[A\n",
            "Training:  27%|██▋       | 1338/5000 [59:14<2:19:50,  2.29s/it, loss=3.5043]\u001b[A\n",
            "Training:  27%|██▋       | 1338/5000 [59:14<2:19:50,  2.29s/it, loss=3.2602]\u001b[A\n",
            "Training:  27%|██▋       | 1339/5000 [59:17<2:28:14,  2.43s/it, loss=3.2602]\u001b[A\n",
            "Training:  27%|██▋       | 1339/5000 [59:17<2:28:14,  2.43s/it, loss=4.2827]\u001b[A\n",
            "Training:  27%|██▋       | 1340/5000 [59:19<2:24:39,  2.37s/it, loss=4.2827]\u001b[A\n",
            "Training:  27%|██▋       | 1340/5000 [59:19<2:24:39,  2.37s/it, loss=3.2513]\u001b[A\n",
            "Training:  27%|██▋       | 1341/5000 [59:21<2:22:03,  2.33s/it, loss=3.2513]\u001b[A\n",
            "Training:  27%|██▋       | 1341/5000 [59:21<2:22:03,  2.33s/it, loss=4.4687]\u001b[A\n",
            "Training:  27%|██▋       | 1342/5000 [59:23<2:20:02,  2.30s/it, loss=4.4687]\u001b[A\n",
            "Training:  27%|██▋       | 1342/5000 [59:23<2:20:02,  2.30s/it, loss=3.7037]\u001b[A\n",
            "Training:  27%|██▋       | 1343/5000 [59:26<2:18:25,  2.27s/it, loss=3.7037]\u001b[A\n",
            "Training:  27%|██▋       | 1343/5000 [59:26<2:18:25,  2.27s/it, loss=3.8230]\u001b[A\n",
            "Training:  27%|██▋       | 1344/5000 [59:28<2:27:58,  2.43s/it, loss=3.8230]\u001b[A\n",
            "Training:  27%|██▋       | 1344/5000 [59:28<2:27:58,  2.43s/it, loss=3.3590]\u001b[A\n",
            "Training:  27%|██▋       | 1345/5000 [59:31<2:24:24,  2.37s/it, loss=3.3590]\u001b[A\n",
            "Training:  27%|██▋       | 1345/5000 [59:31<2:24:24,  2.37s/it, loss=4.0721]\u001b[A\n",
            "Training:  27%|██▋       | 1346/5000 [59:33<2:22:15,  2.34s/it, loss=4.0721]\u001b[A\n",
            "Training:  27%|██▋       | 1346/5000 [59:33<2:22:15,  2.34s/it, loss=3.0731]\u001b[A\n",
            "Training:  27%|██▋       | 1347/5000 [59:35<2:20:27,  2.31s/it, loss=3.0731]\u001b[A\n",
            "Training:  27%|██▋       | 1347/5000 [59:35<2:20:27,  2.31s/it, loss=3.0382]\u001b[A\n",
            "Training:  27%|██▋       | 1348/5000 [59:37<2:18:55,  2.28s/it, loss=3.0382]\u001b[A\n",
            "Training:  27%|██▋       | 1348/5000 [59:37<2:18:55,  2.28s/it, loss=3.0559]\u001b[A\n",
            "Training:  27%|██▋       | 1349/5000 [59:40<2:27:32,  2.42s/it, loss=3.0559]\u001b[A\n",
            "Training:  27%|██▋       | 1349/5000 [59:40<2:27:32,  2.42s/it, loss=3.1031]\u001b[A\n",
            "Training:  27%|██▋       | 1350/5000 [59:42<2:24:05,  2.37s/it, loss=3.1031]\u001b[A\n",
            "Training:  27%|██▋       | 1350/5000 [59:42<2:24:05,  2.37s/it, loss=3.7824]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 1350 ---\n",
            "Prompt: 'The '\n",
            "The AN I.\n",
            "Firstinging:But you\n",
            " hear take I be\n",
            "ide; for can be to.\n",
            "Third of.\n",
            "COROLUS\n",
            " certain Juno.\n",
            "Cit we:You islands to him heart and, let go\n",
            " not your hear then\n",
            " execution,, shall so as would not stay\n",
            "V them and offer you\n",
            " not well need be by death if can them andThe you--As' havep me as see prisoners catalogue\n",
            " w voices the.\n",
            "BRUS\n",
            "Prompt: 'In '\n",
            "In : me,, thou?\n",
            "MENI:N,,as exactly well\n",
            " do hear thy than both\n",
            "'is him in heat and, in name I that you\n",
            " weak th own is,,Here F be; shall be an.\n",
            "Third,!\n",
            "VUMUMUMIA dogouheeush brief:,,!\n",
            "COROLUS\n",
            " De Gl; that it leave senators and friends gates well\n",
            "igh to it well\n",
            " could hear your: me three dare not\n",
            "Prompt: 'To '\n",
            "To  pouring Tar,, must them\n",
            " hear the of and of belongs.ufius!\n",
            "SINUS\n",
            "The Peace' a,!'s,!I call is\n",
            " made! hope supp to a's! name I HowYour,So\n",
            " no to so, are! strongerFirstingOT G?'s matter\n",
            "BT Gloucester generalcius what you import?\n",
            "ME\n",
            " said you done him asves to a, val sovereign they! more\n",
            "MRI:Sir!\n",
            "Prompt: 'A '\n",
            "A eb,, the of thrust he,Wh\n",
            "oke on, two read out\n",
            " once hisarly stretch stumbling worse\n",
            " my bur; the deathcor ofering\n",
            " the soial of, mean with thelef,\n",
            " seem thy here, the's is, more withel who duke the.\n",
            "COROLUSI:We be take have\n",
            " an ofte of; being,,,Whilst welcome it.\n",
            "Cites not\n",
            " thelike of youngestly it; him this be\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  27%|██▋       | 1351/5000 [59:57<6:07:49,  6.05s/it, loss=3.7824]\u001b[A\n",
            "Training:  27%|██▋       | 1351/5000 [59:57<6:07:49,  6.05s/it, loss=4.4036]\u001b[A\n",
            "Training:  27%|██▋       | 1352/5000 [59:59<4:58:06,  4.90s/it, loss=4.4036]\u001b[A\n",
            "Training:  27%|██▋       | 1352/5000 [59:59<4:58:06,  4.90s/it, loss=3.6912]\u001b[A\n",
            "Training:  27%|██▋       | 1353/5000 [1:00:01<4:10:13,  4.12s/it, loss=3.6912]\u001b[A\n",
            "Training:  27%|██▋       | 1353/5000 [1:00:01<4:10:13,  4.12s/it, loss=4.7526]\u001b[A\n",
            "Training:  27%|██▋       | 1354/5000 [1:00:04<3:45:41,  3.71s/it, loss=4.7526]\u001b[A\n",
            "Training:  27%|██▋       | 1354/5000 [1:00:04<3:45:41,  3.71s/it, loss=4.1334]\u001b[A\n",
            "Training:  27%|██▋       | 1355/5000 [1:00:06<3:18:25,  3.27s/it, loss=4.1334]\u001b[A\n",
            "Training:  27%|██▋       | 1355/5000 [1:00:06<3:18:25,  3.27s/it, loss=4.0297]\u001b[A\n",
            "Training:  27%|██▋       | 1356/5000 [1:00:09<3:00:00,  2.96s/it, loss=4.0297]\u001b[A\n",
            "Training:  27%|██▋       | 1356/5000 [1:00:09<3:00:00,  2.96s/it, loss=3.5329]\u001b[A\n",
            "Training:  27%|██▋       | 1357/5000 [1:00:11<2:47:04,  2.75s/it, loss=3.5329]\u001b[A\n",
            "Training:  27%|██▋       | 1357/5000 [1:00:11<2:47:04,  2.75s/it, loss=3.7588]\u001b[A\n",
            "Training:  27%|██▋       | 1358/5000 [1:00:13<2:38:40,  2.61s/it, loss=3.7588]\u001b[A\n",
            "Training:  27%|██▋       | 1358/5000 [1:00:13<2:38:40,  2.61s/it, loss=4.1622]\u001b[A\n",
            "Training:  27%|██▋       | 1359/5000 [1:00:16<2:41:28,  2.66s/it, loss=4.1622]\u001b[A\n",
            "Training:  27%|██▋       | 1359/5000 [1:00:16<2:41:28,  2.66s/it, loss=3.5791]\u001b[A\n",
            "Training:  27%|██▋       | 1360/5000 [1:00:18<2:33:36,  2.53s/it, loss=3.5791]\u001b[A\n",
            "Training:  27%|██▋       | 1360/5000 [1:00:18<2:33:36,  2.53s/it, loss=3.5582]\u001b[A\n",
            "Training:  27%|██▋       | 1361/5000 [1:00:20<2:27:55,  2.44s/it, loss=3.5582]\u001b[A\n",
            "Training:  27%|██▋       | 1361/5000 [1:00:21<2:27:55,  2.44s/it, loss=4.3588]\u001b[A\n",
            "Training:  27%|██▋       | 1362/5000 [1:00:23<2:24:03,  2.38s/it, loss=4.3588]\u001b[A\n",
            "Training:  27%|██▋       | 1362/5000 [1:00:23<2:24:03,  2.38s/it, loss=3.8725]\u001b[A\n",
            "Training:  27%|██▋       | 1363/5000 [1:00:25<2:21:35,  2.34s/it, loss=3.8725]\u001b[A\n",
            "Training:  27%|██▋       | 1363/5000 [1:00:25<2:21:35,  2.34s/it, loss=3.6146]\u001b[A\n",
            "Training:  27%|██▋       | 1364/5000 [1:00:28<2:29:19,  2.46s/it, loss=3.6146]\u001b[A\n",
            "Training:  27%|██▋       | 1364/5000 [1:00:28<2:29:19,  2.46s/it, loss=3.6808]\u001b[A\n",
            "Training:  27%|██▋       | 1365/5000 [1:00:30<2:25:12,  2.40s/it, loss=3.6808]\u001b[A\n",
            "Training:  27%|██▋       | 1365/5000 [1:00:30<2:25:12,  2.40s/it, loss=3.1734]\u001b[A\n",
            "Training:  27%|██▋       | 1366/5000 [1:00:32<2:22:57,  2.36s/it, loss=3.1734]\u001b[A\n",
            "Training:  27%|██▋       | 1366/5000 [1:00:32<2:22:57,  2.36s/it, loss=2.6517]\u001b[A\n",
            "Training:  27%|██▋       | 1367/5000 [1:00:34<2:20:34,  2.32s/it, loss=2.6517]\u001b[A\n",
            "Training:  27%|██▋       | 1367/5000 [1:00:34<2:20:34,  2.32s/it, loss=3.4277]\u001b[A\n",
            "Training:  27%|██▋       | 1368/5000 [1:00:37<2:19:45,  2.31s/it, loss=3.4277]\u001b[A\n",
            "Training:  27%|██▋       | 1368/5000 [1:00:37<2:19:45,  2.31s/it, loss=3.4086]\u001b[A\n",
            "Training:  27%|██▋       | 1369/5000 [1:00:40<2:28:03,  2.45s/it, loss=3.4086]\u001b[A\n",
            "Training:  27%|██▋       | 1369/5000 [1:00:40<2:28:03,  2.45s/it, loss=3.5602]\u001b[A\n",
            "Training:  27%|██▋       | 1370/5000 [1:00:42<2:24:26,  2.39s/it, loss=3.5602]\u001b[A\n",
            "Training:  27%|██▋       | 1370/5000 [1:00:42<2:24:26,  2.39s/it, loss=3.6363]\u001b[A\n",
            "Training:  27%|██▋       | 1371/5000 [1:00:44<2:22:09,  2.35s/it, loss=3.6363]\u001b[A\n",
            "Training:  27%|██▋       | 1371/5000 [1:00:44<2:22:09,  2.35s/it, loss=3.1099]\u001b[A\n",
            "Training:  27%|██▋       | 1372/5000 [1:00:46<2:20:02,  2.32s/it, loss=3.1099]\u001b[A\n",
            "Training:  27%|██▋       | 1372/5000 [1:00:46<2:20:02,  2.32s/it, loss=4.2791]\u001b[A\n",
            "Training:  27%|██▋       | 1373/5000 [1:00:48<2:18:19,  2.29s/it, loss=4.2791]\u001b[A\n",
            "Training:  27%|██▋       | 1373/5000 [1:00:49<2:18:19,  2.29s/it, loss=3.4535]\u001b[A\n",
            "Training:  27%|██▋       | 1374/5000 [1:00:51<2:26:57,  2.43s/it, loss=3.4535]\u001b[A\n",
            "Training:  27%|██▋       | 1374/5000 [1:00:51<2:26:57,  2.43s/it, loss=2.5929]\u001b[A\n",
            "Training:  28%|██▊       | 1375/5000 [1:00:54<2:23:34,  2.38s/it, loss=2.5929]\u001b[A\n",
            "Training:  28%|██▊       | 1375/5000 [1:00:54<2:23:34,  2.38s/it, loss=3.8827]\u001b[A\n",
            "Training:  28%|██▊       | 1376/5000 [1:00:56<2:21:18,  2.34s/it, loss=3.8827]\u001b[A\n",
            "Training:  28%|██▊       | 1376/5000 [1:00:56<2:21:18,  2.34s/it, loss=3.5645]\u001b[A\n",
            "Training:  28%|██▊       | 1377/5000 [1:00:58<2:19:47,  2.32s/it, loss=3.5645]\u001b[A\n",
            "Training:  28%|██▊       | 1377/5000 [1:00:58<2:19:47,  2.32s/it, loss=3.9281]\u001b[A\n",
            "Training:  28%|██▊       | 1378/5000 [1:01:00<2:17:54,  2.28s/it, loss=3.9281]\u001b[A\n",
            "Training:  28%|██▊       | 1378/5000 [1:01:00<2:17:54,  2.28s/it, loss=3.9096]\u001b[A\n",
            "Training:  28%|██▊       | 1379/5000 [1:01:03<2:27:12,  2.44s/it, loss=3.9096]\u001b[A\n",
            "Training:  28%|██▊       | 1379/5000 [1:01:03<2:27:12,  2.44s/it, loss=3.0757]\u001b[A\n",
            "Training:  28%|██▊       | 1380/5000 [1:01:05<2:23:38,  2.38s/it, loss=3.0757]\u001b[A\n",
            "Training:  28%|██▊       | 1380/5000 [1:01:05<2:23:38,  2.38s/it, loss=3.4364]\u001b[A\n",
            "Training:  28%|██▊       | 1381/5000 [1:01:08<2:21:02,  2.34s/it, loss=3.4364]\u001b[A\n",
            "Training:  28%|██▊       | 1381/5000 [1:01:08<2:21:02,  2.34s/it, loss=4.4181]\u001b[A\n",
            "Training:  28%|██▊       | 1382/5000 [1:01:10<2:19:06,  2.31s/it, loss=4.4181]\u001b[A\n",
            "Training:  28%|██▊       | 1382/5000 [1:01:10<2:19:06,  2.31s/it, loss=4.0161]\u001b[A\n",
            "Training:  28%|██▊       | 1383/5000 [1:01:12<2:17:50,  2.29s/it, loss=4.0161]\u001b[A\n",
            "Training:  28%|██▊       | 1383/5000 [1:01:12<2:17:50,  2.29s/it, loss=3.6037]\u001b[A\n",
            "Training:  28%|██▊       | 1384/5000 [1:01:15<2:26:44,  2.43s/it, loss=3.6037]\u001b[A\n",
            "Training:  28%|██▊       | 1384/5000 [1:01:15<2:26:44,  2.43s/it, loss=3.0704]\u001b[A\n",
            "Training:  28%|██▊       | 1385/5000 [1:01:17<2:23:20,  2.38s/it, loss=3.0704]\u001b[A\n",
            "Training:  28%|██▊       | 1385/5000 [1:01:17<2:23:20,  2.38s/it, loss=3.4892]\u001b[A\n",
            "Training:  28%|██▊       | 1386/5000 [1:01:19<2:20:43,  2.34s/it, loss=3.4892]\u001b[A\n",
            "Training:  28%|██▊       | 1386/5000 [1:01:19<2:20:43,  2.34s/it, loss=3.6359]\u001b[A\n",
            "Training:  28%|██▊       | 1387/5000 [1:01:21<2:18:46,  2.30s/it, loss=3.6359]\u001b[A\n",
            "Training:  28%|██▊       | 1387/5000 [1:01:22<2:18:46,  2.30s/it, loss=2.7367]\u001b[A\n",
            "Training:  28%|██▊       | 1388/5000 [1:01:24<2:17:27,  2.28s/it, loss=2.7367]\u001b[A\n",
            "Training:  28%|██▊       | 1388/5000 [1:01:24<2:17:27,  2.28s/it, loss=3.6001]\u001b[A\n",
            "Training:  28%|██▊       | 1389/5000 [1:01:26<2:26:25,  2.43s/it, loss=3.6001]\u001b[A\n",
            "Training:  28%|██▊       | 1389/5000 [1:01:27<2:26:25,  2.43s/it, loss=4.3224]\u001b[A\n",
            "Training:  28%|██▊       | 1390/5000 [1:01:29<2:22:57,  2.38s/it, loss=4.3224]\u001b[A\n",
            "Training:  28%|██▊       | 1390/5000 [1:01:29<2:22:57,  2.38s/it, loss=3.8561]\u001b[A\n",
            "Training:  28%|██▊       | 1391/5000 [1:01:31<2:20:16,  2.33s/it, loss=3.8561]\u001b[A\n",
            "Training:  28%|██▊       | 1391/5000 [1:01:31<2:20:16,  2.33s/it, loss=3.9268]\u001b[A\n",
            "Training:  28%|██▊       | 1392/5000 [1:01:33<2:20:05,  2.33s/it, loss=3.9268]\u001b[A\n",
            "Training:  28%|██▊       | 1392/5000 [1:01:33<2:20:05,  2.33s/it, loss=3.5717]\u001b[A\n",
            "Training:  28%|██▊       | 1393/5000 [1:01:36<2:18:10,  2.30s/it, loss=3.5717]\u001b[A\n",
            "Training:  28%|██▊       | 1393/5000 [1:01:36<2:18:10,  2.30s/it, loss=3.3002]\u001b[A\n",
            "Training:  28%|██▊       | 1394/5000 [1:01:38<2:25:20,  2.42s/it, loss=3.3002]\u001b[A\n",
            "Training:  28%|██▊       | 1394/5000 [1:01:38<2:25:20,  2.42s/it, loss=3.4472]\u001b[A\n",
            "Training:  28%|██▊       | 1395/5000 [1:01:40<2:22:43,  2.38s/it, loss=3.4472]\u001b[A\n",
            "Training:  28%|██▊       | 1395/5000 [1:01:41<2:22:43,  2.38s/it, loss=3.4380]\u001b[A\n",
            "Training:  28%|██▊       | 1396/5000 [1:01:43<2:20:21,  2.34s/it, loss=3.4380]\u001b[A\n",
            "Training:  28%|██▊       | 1396/5000 [1:01:43<2:20:21,  2.34s/it, loss=3.6685]\u001b[A\n",
            "Training:  28%|██▊       | 1397/5000 [1:01:45<2:18:49,  2.31s/it, loss=3.6685]\u001b[A\n",
            "Training:  28%|██▊       | 1397/5000 [1:01:45<2:18:49,  2.31s/it, loss=4.2207]\u001b[A\n",
            "Training:  28%|██▊       | 1398/5000 [1:01:47<2:17:19,  2.29s/it, loss=4.2207]\u001b[A\n",
            "Training:  28%|██▊       | 1398/5000 [1:01:47<2:17:19,  2.29s/it, loss=4.5875]\u001b[A\n",
            "Training:  28%|██▊       | 1399/5000 [1:01:50<2:24:02,  2.40s/it, loss=4.5875]\u001b[A\n",
            "Training:  28%|██▊       | 1399/5000 [1:01:50<2:24:02,  2.40s/it, loss=3.8143]\u001b[A\n",
            "Training:  28%|██▊       | 1400/5000 [1:01:52<2:23:20,  2.39s/it, loss=3.8143]\u001b[A\n",
            "Training:  28%|██▊       | 1400/5000 [1:01:52<2:23:20,  2.39s/it, loss=4.0888]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 1400 ---\n",
            "Prompt: 'The '\n",
            "The  of neighbourWhich send pride\n",
            " qu the limits the Cap o the\n",
            " gorgeous andrick\n",
            " hast l begin I\n",
            " afore good from armour oldide\n",
            " Bolb and heavens found of''san throne's.\n",
            "Bee the king unto friendAnd a?\n",
            "NTH much lives great to: yet Iot, knowt my's:Then this as doee by world.\n",
            "QUE you the\n",
            " fall raw by men love meOLN,: the is mad to, Mbard\n",
            "Prompt: 'In '\n",
            "In  hath'd selves flintizeTose Aing: noble\n",
            " not bills,,,, many\n",
            "ears this unseen tra: matter to\n",
            " will itd, crew and\n",
            " d he show Wellest: most meth!, mistakes we not?\n",
            ",,ither what he be'\n",
            "u\n",
            " not,, I,!,--!All.\n",
            "H! cares!ray!!!!! word he dead\n",
            "TY not much with to?,!\n",
            " have. or?est\n",
            "Prompt: 'To '\n",
            "To ,h! dear!!!!!!!!,!!!!!,!! conscienceDayTh's!!,!! Mont! let dog it\n",
            "\n",
            "ENV\n",
            "MUT:', say,! quaint my!ours\n",
            " thouBALOf,! turned!!!!!!!!!!!!!!!!,!!!ing!!!!!!'!!I forget\n",
            "ike; you sir good,!,!!\n",
            "Prompt: 'A '\n",
            "A ; crow, ha once thee for love thee\n",
            " all see:,, of kin and.\n",
            "BOLUS\n",
            "H:My, not.\n",
            "DCHP\n",
            " for.\n",
            "QUE:Here what foot I, will my.\n",
            "QUE:I follow well, my heaven my d be'dAbout, pray.\n",
            "Serv not but.\n",
            "LYIO\n",
            "TY my's now love\n",
            "'ll conf there go your is the, may put to to,., heaven what I't\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  28%|██▊       | 1401/5000 [1:02:07<6:04:47,  6.08s/it, loss=4.0888]\u001b[A\n",
            "Training:  28%|██▊       | 1401/5000 [1:02:07<6:04:47,  6.08s/it, loss=4.6106]\u001b[A\n",
            "Training:  28%|██▊       | 1402/5000 [1:02:09<4:55:34,  4.93s/it, loss=4.6106]\u001b[A\n",
            "Training:  28%|██▊       | 1402/5000 [1:02:09<4:55:34,  4.93s/it, loss=3.3971]\u001b[A\n",
            "Training:  28%|██▊       | 1403/5000 [1:02:11<4:08:01,  4.14s/it, loss=3.3971]\u001b[A\n",
            "Training:  28%|██▊       | 1403/5000 [1:02:12<4:08:01,  4.14s/it, loss=3.4958]\u001b[A\n",
            "Training:  28%|██▊       | 1404/5000 [1:02:14<3:43:06,  3.72s/it, loss=3.4958]\u001b[A\n",
            "Training:  28%|██▊       | 1404/5000 [1:02:14<3:43:06,  3.72s/it, loss=4.5802]\u001b[A\n",
            "Training:  28%|██▊       | 1405/5000 [1:02:16<3:16:26,  3.28s/it, loss=4.5802]\u001b[A\n",
            "Training:  28%|██▊       | 1405/5000 [1:02:17<3:16:26,  3.28s/it, loss=3.7253]\u001b[A\n",
            "Training:  28%|██▊       | 1406/5000 [1:02:19<2:58:02,  2.97s/it, loss=3.7253]\u001b[A\n",
            "Training:  28%|██▊       | 1406/5000 [1:02:19<2:58:02,  2.97s/it, loss=3.9151]\u001b[A\n",
            "Training:  28%|██▊       | 1407/5000 [1:02:21<2:44:42,  2.75s/it, loss=3.9151]\u001b[A\n",
            "Training:  28%|██▊       | 1407/5000 [1:02:21<2:44:42,  2.75s/it, loss=3.2193]\u001b[A\n",
            "Training:  28%|██▊       | 1408/5000 [1:02:23<2:35:24,  2.60s/it, loss=3.2193]\u001b[A\n",
            "Training:  28%|██▊       | 1408/5000 [1:02:23<2:35:24,  2.60s/it, loss=3.8849]\u001b[A\n",
            "Training:  28%|██▊       | 1409/5000 [1:02:26<2:38:11,  2.64s/it, loss=3.8849]\u001b[A\n",
            "Training:  28%|██▊       | 1409/5000 [1:02:26<2:38:11,  2.64s/it, loss=3.7100]\u001b[A\n",
            "Training:  28%|██▊       | 1410/5000 [1:02:28<2:30:43,  2.52s/it, loss=3.7100]\u001b[A\n",
            "Training:  28%|██▊       | 1410/5000 [1:02:28<2:30:43,  2.52s/it, loss=3.8635]\u001b[A\n",
            "Training:  28%|██▊       | 1411/5000 [1:02:30<2:24:58,  2.42s/it, loss=3.8635]\u001b[A\n",
            "Training:  28%|██▊       | 1411/5000 [1:02:30<2:24:58,  2.42s/it, loss=2.9616]\u001b[A\n",
            "Training:  28%|██▊       | 1412/5000 [1:02:33<2:21:28,  2.37s/it, loss=2.9616]\u001b[A\n",
            "Training:  28%|██▊       | 1412/5000 [1:02:33<2:21:28,  2.37s/it, loss=3.5054]\u001b[A\n",
            "Training:  28%|██▊       | 1413/5000 [1:02:35<2:19:32,  2.33s/it, loss=3.5054]\u001b[A\n",
            "Training:  28%|██▊       | 1413/5000 [1:02:35<2:19:32,  2.33s/it, loss=3.6030]\u001b[A\n",
            "Training:  28%|██▊       | 1414/5000 [1:02:38<2:27:06,  2.46s/it, loss=3.6030]\u001b[A\n",
            "Training:  28%|██▊       | 1414/5000 [1:02:38<2:27:06,  2.46s/it, loss=3.7478]\u001b[A\n",
            "Training:  28%|██▊       | 1415/5000 [1:02:40<2:23:03,  2.39s/it, loss=3.7478]\u001b[A\n",
            "Training:  28%|██▊       | 1415/5000 [1:02:40<2:23:03,  2.39s/it, loss=4.1163]\u001b[A\n",
            "Training:  28%|██▊       | 1416/5000 [1:02:42<2:20:18,  2.35s/it, loss=4.1163]\u001b[A\n",
            "Training:  28%|██▊       | 1416/5000 [1:02:42<2:20:18,  2.35s/it, loss=3.6973]\u001b[A\n",
            "Training:  28%|██▊       | 1417/5000 [1:02:44<2:18:27,  2.32s/it, loss=3.6973]\u001b[A\n",
            "Training:  28%|██▊       | 1417/5000 [1:02:44<2:18:27,  2.32s/it, loss=3.6043]\u001b[A\n",
            "Training:  28%|██▊       | 1418/5000 [1:02:47<2:17:35,  2.30s/it, loss=3.6043]\u001b[A\n",
            "Training:  28%|██▊       | 1418/5000 [1:02:47<2:17:35,  2.30s/it, loss=3.3584]\u001b[A\n",
            "Training:  28%|██▊       | 1419/5000 [1:02:49<2:25:21,  2.44s/it, loss=3.3584]\u001b[A\n",
            "Training:  28%|██▊       | 1419/5000 [1:02:49<2:25:21,  2.44s/it, loss=3.2471]\u001b[A\n",
            "Training:  28%|██▊       | 1420/5000 [1:02:52<2:22:05,  2.38s/it, loss=3.2471]\u001b[A\n",
            "Training:  28%|██▊       | 1420/5000 [1:02:52<2:22:05,  2.38s/it, loss=3.8402]\u001b[A\n",
            "Training:  28%|██▊       | 1421/5000 [1:02:54<2:19:23,  2.34s/it, loss=3.8402]\u001b[A\n",
            "Training:  28%|██▊       | 1421/5000 [1:02:54<2:19:23,  2.34s/it, loss=3.7083]\u001b[A\n",
            "Training:  28%|██▊       | 1422/5000 [1:02:56<2:17:58,  2.31s/it, loss=3.7083]\u001b[A\n",
            "Training:  28%|██▊       | 1422/5000 [1:02:56<2:17:58,  2.31s/it, loss=4.1253]\u001b[A\n",
            "Training:  28%|██▊       | 1423/5000 [1:02:58<2:16:46,  2.29s/it, loss=4.1253]\u001b[A\n",
            "Training:  28%|██▊       | 1423/5000 [1:02:58<2:16:46,  2.29s/it, loss=3.2419]\u001b[A\n",
            "Training:  28%|██▊       | 1424/5000 [1:03:01<2:23:26,  2.41s/it, loss=3.2419]\u001b[A\n",
            "Training:  28%|██▊       | 1424/5000 [1:03:01<2:23:26,  2.41s/it, loss=3.4601]\u001b[A\n",
            "Training:  28%|██▊       | 1425/5000 [1:03:03<2:22:06,  2.39s/it, loss=3.4601]\u001b[A\n",
            "Training:  28%|██▊       | 1425/5000 [1:03:03<2:22:06,  2.39s/it, loss=4.1665]\u001b[A\n",
            "Training:  29%|██▊       | 1426/5000 [1:03:06<2:19:45,  2.35s/it, loss=4.1665]\u001b[A\n",
            "Training:  29%|██▊       | 1426/5000 [1:03:06<2:19:45,  2.35s/it, loss=3.3056]\u001b[A\n",
            "Training:  29%|██▊       | 1427/5000 [1:03:08<2:18:05,  2.32s/it, loss=3.3056]\u001b[A\n",
            "Training:  29%|██▊       | 1427/5000 [1:03:08<2:18:05,  2.32s/it, loss=3.5117]\u001b[A\n",
            "Training:  29%|██▊       | 1428/5000 [1:03:10<2:16:25,  2.29s/it, loss=3.5117]\u001b[A\n",
            "Training:  29%|██▊       | 1428/5000 [1:03:10<2:16:25,  2.29s/it, loss=3.9381]\u001b[A\n",
            "Training:  29%|██▊       | 1429/5000 [1:03:13<2:21:39,  2.38s/it, loss=3.9381]\u001b[A\n",
            "Training:  29%|██▊       | 1429/5000 [1:03:13<2:21:39,  2.38s/it, loss=3.1024]\u001b[A\n",
            "Training:  29%|██▊       | 1430/5000 [1:03:15<2:22:40,  2.40s/it, loss=3.1024]\u001b[A\n",
            "Training:  29%|██▊       | 1430/5000 [1:03:15<2:22:40,  2.40s/it, loss=3.3892]\u001b[A\n",
            "Training:  29%|██▊       | 1431/5000 [1:03:17<2:19:38,  2.35s/it, loss=3.3892]\u001b[A\n",
            "Training:  29%|██▊       | 1431/5000 [1:03:17<2:19:38,  2.35s/it, loss=3.4250]\u001b[A\n",
            "Training:  29%|██▊       | 1432/5000 [1:03:20<2:17:11,  2.31s/it, loss=3.4250]\u001b[A\n",
            "Training:  29%|██▊       | 1432/5000 [1:03:20<2:17:11,  2.31s/it, loss=2.4453]\u001b[A\n",
            "Training:  29%|██▊       | 1433/5000 [1:03:22<2:16:06,  2.29s/it, loss=2.4453]\u001b[A\n",
            "Training:  29%|██▊       | 1433/5000 [1:03:22<2:16:06,  2.29s/it, loss=3.1012]\u001b[A\n",
            "Training:  29%|██▊       | 1434/5000 [1:03:24<2:19:56,  2.35s/it, loss=3.1012]\u001b[A\n",
            "Training:  29%|██▊       | 1434/5000 [1:03:24<2:19:56,  2.35s/it, loss=2.6342]\u001b[A\n",
            "Training:  29%|██▊       | 1435/5000 [1:03:27<2:22:14,  2.39s/it, loss=2.6342]\u001b[A\n",
            "Training:  29%|██▊       | 1435/5000 [1:03:27<2:22:14,  2.39s/it, loss=3.2144]\u001b[A\n",
            "Training:  29%|██▊       | 1436/5000 [1:03:29<2:19:57,  2.36s/it, loss=3.2144]\u001b[A\n",
            "Training:  29%|██▊       | 1436/5000 [1:03:29<2:19:57,  2.36s/it, loss=3.4400]\u001b[A\n",
            "Training:  29%|██▊       | 1437/5000 [1:03:31<2:17:55,  2.32s/it, loss=3.4400]\u001b[A\n",
            "Training:  29%|██▊       | 1437/5000 [1:03:31<2:17:55,  2.32s/it, loss=3.4314]\u001b[A\n",
            "Training:  29%|██▉       | 1438/5000 [1:03:34<2:16:07,  2.29s/it, loss=3.4314]\u001b[A\n",
            "Training:  29%|██▉       | 1438/5000 [1:03:34<2:16:07,  2.29s/it, loss=4.1070]\u001b[A\n",
            "Training:  29%|██▉       | 1439/5000 [1:03:36<2:20:00,  2.36s/it, loss=4.1070]\u001b[A\n",
            "Training:  29%|██▉       | 1439/5000 [1:03:36<2:20:00,  2.36s/it, loss=3.7758]\u001b[A\n",
            "Training:  29%|██▉       | 1440/5000 [1:03:39<2:22:57,  2.41s/it, loss=3.7758]\u001b[A\n",
            "Training:  29%|██▉       | 1440/5000 [1:03:39<2:22:57,  2.41s/it, loss=3.7265]\u001b[A\n",
            "Training:  29%|██▉       | 1441/5000 [1:03:41<2:19:58,  2.36s/it, loss=3.7265]\u001b[A\n",
            "Training:  29%|██▉       | 1441/5000 [1:03:41<2:19:58,  2.36s/it, loss=3.2095]\u001b[A\n",
            "Training:  29%|██▉       | 1442/5000 [1:03:43<2:17:45,  2.32s/it, loss=3.2095]\u001b[A\n",
            "Training:  29%|██▉       | 1442/5000 [1:03:43<2:17:45,  2.32s/it, loss=3.3203]\u001b[A\n",
            "Training:  29%|██▉       | 1443/5000 [1:03:45<2:16:05,  2.30s/it, loss=3.3203]\u001b[A\n",
            "Training:  29%|██▉       | 1443/5000 [1:03:45<2:16:05,  2.30s/it, loss=3.4691]\u001b[A\n",
            "Training:  29%|██▉       | 1444/5000 [1:03:48<2:19:15,  2.35s/it, loss=3.4691]\u001b[A\n",
            "Training:  29%|██▉       | 1444/5000 [1:03:48<2:19:15,  2.35s/it, loss=3.7591]\u001b[A\n",
            "Training:  29%|██▉       | 1445/5000 [1:03:50<2:22:13,  2.40s/it, loss=3.7591]\u001b[A\n",
            "Training:  29%|██▉       | 1445/5000 [1:03:50<2:22:13,  2.40s/it, loss=3.9485]\u001b[A\n",
            "Training:  29%|██▉       | 1446/5000 [1:03:53<2:19:14,  2.35s/it, loss=3.9485]\u001b[A\n",
            "Training:  29%|██▉       | 1446/5000 [1:03:53<2:19:14,  2.35s/it, loss=4.0812]\u001b[A\n",
            "Training:  29%|██▉       | 1447/5000 [1:03:55<2:17:19,  2.32s/it, loss=4.0812]\u001b[A\n",
            "Training:  29%|██▉       | 1447/5000 [1:03:55<2:17:19,  2.32s/it, loss=4.5661]\u001b[A\n",
            "Training:  29%|██▉       | 1448/5000 [1:03:57<2:16:12,  2.30s/it, loss=4.5661]\u001b[A\n",
            "Training:  29%|██▉       | 1448/5000 [1:03:57<2:16:12,  2.30s/it, loss=3.9905]\u001b[A\n",
            "Training:  29%|██▉       | 1449/5000 [1:03:59<2:18:33,  2.34s/it, loss=3.9905]\u001b[A\n",
            "Training:  29%|██▉       | 1449/5000 [1:04:00<2:18:33,  2.34s/it, loss=4.0199]\u001b[A\n",
            "Training:  29%|██▉       | 1450/5000 [1:04:02<2:22:49,  2.41s/it, loss=4.0199]\u001b[A\n",
            "Training:  29%|██▉       | 1450/5000 [1:04:02<2:22:49,  2.41s/it, loss=4.4018]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 1450 ---\n",
            "Prompt: 'The '\n",
            "The  of in, is.\n",
            "D better: have\n",
            "AOLUSY:So you be\n",
            "ard couples to and from purv?\n",
            "AOLUS\n",
            "it:So you! another let thy\n",
            "all had boy\n",
            " matter that it so of was in and are madSo yould at\n",
            "Im get dish:The's lady\n",
            " haveop got that sir the foulATHE\n",
            " you find? intoagen,ipsagewell to and number and are meO the.\n",
            "Cn\n",
            "Prompt: 'In '\n",
            "In ourable of most? thou drunk thouest\n",
            " some me thy, go her? was not me itToRes benefit honourto W\n",
            " prayerrit,, father his. reason thy\n",
            "ath me theseation his? are say nost\n",
            " hate personally'd to him much 'st! come even toys\n",
            "ch, shall me doing agreeod w de auntoonp? pastime out\n",
            "asedAgain thy best with?, warm Merc: the\n",
            " honour even at hands he a farewell the.\n",
            "She protector\n",
            "Prompt: 'To '\n",
            "To  thee upon: without,, of love\n",
            "athuck them full. with foot pack,! on\n",
            " have with:See\n",
            " so cause thee for honour to, thee of!P thelf now\n",
            "ts bottom thee very out be one. coming a indeed betink he: are the\n",
            "ine me another whichbro toth this. are to,\n",
            "aw along tostrong his:es heart'sance may and friend keepHence judicious bring you fall at;tis meet., may still scope\n",
            "Prompt: 'A '\n",
            "A  he a'd to me daughter\n",
            " merc. there aaw! you an man\n",
            " partly tongue gone this man\n",
            " mine and could this when knew you O now ma?\n",
            "AOLUS\n",
            " favourAnd,illoWouldchild\n",
            " says the man yould and heavens this with, hold\n",
            " the? fromken of most, Gouck with daughter n!\n",
            "Lord the that\n",
            " lord I. he not a day hope may a of cause the.\n",
            "\n",
            "IL:By thanCHus earnest!\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  29%|██▉       | 1451/5000 [1:04:17<5:59:44,  6.08s/it, loss=4.4018]\u001b[A\n",
            "Training:  29%|██▉       | 1451/5000 [1:04:17<5:59:44,  6.08s/it, loss=3.9159]\u001b[A\n",
            "Training:  29%|██▉       | 1452/5000 [1:04:19<4:51:11,  4.92s/it, loss=3.9159]\u001b[A\n",
            "Training:  29%|██▉       | 1452/5000 [1:04:19<4:51:11,  4.92s/it, loss=2.8277]\u001b[A\n",
            "Training:  29%|██▉       | 1453/5000 [1:04:21<4:03:26,  4.12s/it, loss=2.8277]\u001b[A\n",
            "Training:  29%|██▉       | 1453/5000 [1:04:21<4:03:26,  4.12s/it, loss=4.2938]\u001b[A\n",
            "Training:  29%|██▉       | 1454/5000 [1:04:24<3:35:21,  3.64s/it, loss=4.2938]\u001b[A\n",
            "Training:  29%|██▉       | 1454/5000 [1:04:24<3:35:21,  3.64s/it, loss=3.9093]\u001b[A\n",
            "Training:  29%|██▉       | 1455/5000 [1:04:26<3:14:30,  3.29s/it, loss=3.9093]\u001b[A\n",
            "Training:  29%|██▉       | 1455/5000 [1:04:26<3:14:30,  3.29s/it, loss=4.2687]\u001b[A\n",
            "Training:  29%|██▉       | 1456/5000 [1:04:28<2:55:48,  2.98s/it, loss=4.2687]\u001b[A\n",
            "Training:  29%|██▉       | 1456/5000 [1:04:28<2:55:48,  2.98s/it, loss=3.2305]\u001b[A\n",
            "Training:  29%|██▉       | 1457/5000 [1:04:31<2:42:25,  2.75s/it, loss=3.2305]\u001b[A\n",
            "Training:  29%|██▉       | 1457/5000 [1:04:31<2:42:25,  2.75s/it, loss=4.0203]\u001b[A\n",
            "Training:  29%|██▉       | 1458/5000 [1:04:33<2:33:21,  2.60s/it, loss=4.0203]\u001b[A\n",
            "Training:  29%|██▉       | 1458/5000 [1:04:33<2:33:21,  2.60s/it, loss=4.1445]\u001b[A\n",
            "Training:  29%|██▉       | 1459/5000 [1:04:35<2:32:48,  2.59s/it, loss=4.1445]\u001b[A\n",
            "Training:  29%|██▉       | 1459/5000 [1:04:35<2:32:48,  2.59s/it, loss=4.1189]\u001b[A\n",
            "Training:  29%|██▉       | 1460/5000 [1:04:38<2:31:36,  2.57s/it, loss=4.1189]\u001b[A\n",
            "Training:  29%|██▉       | 1460/5000 [1:04:38<2:31:36,  2.57s/it, loss=3.5495]\u001b[A\n",
            "Training:  29%|██▉       | 1461/5000 [1:04:40<2:25:47,  2.47s/it, loss=3.5495]\u001b[A\n",
            "Training:  29%|██▉       | 1461/5000 [1:04:40<2:25:47,  2.47s/it, loss=4.0661]\u001b[A\n",
            "Training:  29%|██▉       | 1462/5000 [1:04:42<2:21:38,  2.40s/it, loss=4.0661]\u001b[A\n",
            "Training:  29%|██▉       | 1462/5000 [1:04:42<2:21:38,  2.40s/it, loss=3.1266]\u001b[A\n",
            "Training:  29%|██▉       | 1463/5000 [1:04:45<2:19:12,  2.36s/it, loss=3.1266]\u001b[A\n",
            "Training:  29%|██▉       | 1463/5000 [1:04:45<2:19:12,  2.36s/it, loss=3.3910]\u001b[A\n",
            "Training:  29%|██▉       | 1464/5000 [1:04:47<2:21:14,  2.40s/it, loss=3.3910]\u001b[A\n",
            "Training:  29%|██▉       | 1464/5000 [1:04:47<2:21:14,  2.40s/it, loss=3.2867]\u001b[A\n",
            "Training:  29%|██▉       | 1465/5000 [1:04:50<2:22:46,  2.42s/it, loss=3.2867]\u001b[A\n",
            "Training:  29%|██▉       | 1465/5000 [1:04:50<2:22:46,  2.42s/it, loss=3.7778]\u001b[A\n",
            "Training:  29%|██▉       | 1466/5000 [1:04:52<2:19:46,  2.37s/it, loss=3.7778]\u001b[A\n",
            "Training:  29%|██▉       | 1466/5000 [1:04:52<2:19:46,  2.37s/it, loss=3.7523]\u001b[A\n",
            "Training:  29%|██▉       | 1467/5000 [1:04:54<2:16:58,  2.33s/it, loss=3.7523]\u001b[A\n",
            "Training:  29%|██▉       | 1467/5000 [1:04:54<2:16:58,  2.33s/it, loss=3.4655]\u001b[A\n",
            "Training:  29%|██▉       | 1468/5000 [1:04:56<2:15:07,  2.30s/it, loss=3.4655]\u001b[A\n",
            "Training:  29%|██▉       | 1468/5000 [1:04:56<2:15:07,  2.30s/it, loss=3.8750]\u001b[A\n",
            "Training:  29%|██▉       | 1469/5000 [1:04:59<2:17:33,  2.34s/it, loss=3.8750]\u001b[A\n",
            "Training:  29%|██▉       | 1469/5000 [1:04:59<2:17:33,  2.34s/it, loss=3.5787]\u001b[A\n",
            "Training:  29%|██▉       | 1470/5000 [1:05:01<2:21:45,  2.41s/it, loss=3.5787]\u001b[A\n",
            "Training:  29%|██▉       | 1470/5000 [1:05:01<2:21:45,  2.41s/it, loss=4.1571]\u001b[A\n",
            "Training:  29%|██▉       | 1471/5000 [1:05:04<2:18:51,  2.36s/it, loss=4.1571]\u001b[A\n",
            "Training:  29%|██▉       | 1471/5000 [1:05:04<2:18:51,  2.36s/it, loss=3.4831]\u001b[A\n",
            "Training:  29%|██▉       | 1472/5000 [1:05:06<2:16:21,  2.32s/it, loss=3.4831]\u001b[A\n",
            "Training:  29%|██▉       | 1472/5000 [1:05:06<2:16:21,  2.32s/it, loss=2.7850]\u001b[A\n",
            "Training:  29%|██▉       | 1473/5000 [1:05:08<2:15:40,  2.31s/it, loss=2.7850]\u001b[A\n",
            "Training:  29%|██▉       | 1473/5000 [1:05:08<2:15:40,  2.31s/it, loss=2.9455]\u001b[A\n",
            "Training:  29%|██▉       | 1474/5000 [1:05:11<2:17:30,  2.34s/it, loss=2.9455]\u001b[A\n",
            "Training:  29%|██▉       | 1474/5000 [1:05:11<2:17:30,  2.34s/it, loss=2.5850]\u001b[A\n",
            "Training:  30%|██▉       | 1475/5000 [1:05:13<2:21:29,  2.41s/it, loss=2.5850]\u001b[A\n",
            "Training:  30%|██▉       | 1475/5000 [1:05:13<2:21:29,  2.41s/it, loss=2.6252]\u001b[A\n",
            "Training:  30%|██▉       | 1476/5000 [1:05:15<2:18:03,  2.35s/it, loss=2.6252]\u001b[A\n",
            "Training:  30%|██▉       | 1476/5000 [1:05:15<2:18:03,  2.35s/it, loss=3.6727]\u001b[A\n",
            "Training:  30%|██▉       | 1477/5000 [1:05:18<2:15:21,  2.31s/it, loss=3.6727]\u001b[A\n",
            "Training:  30%|██▉       | 1477/5000 [1:05:18<2:15:21,  2.31s/it, loss=3.8588]\u001b[A\n",
            "Training:  30%|██▉       | 1478/5000 [1:05:20<2:14:21,  2.29s/it, loss=3.8588]\u001b[A\n",
            "Training:  30%|██▉       | 1478/5000 [1:05:20<2:14:21,  2.29s/it, loss=3.9896]\u001b[A\n",
            "Training:  30%|██▉       | 1479/5000 [1:05:22<2:13:54,  2.28s/it, loss=3.9896]\u001b[A\n",
            "Training:  30%|██▉       | 1479/5000 [1:05:22<2:13:54,  2.28s/it, loss=4.1606]\u001b[A\n",
            "Training:  30%|██▉       | 1480/5000 [1:05:25<2:21:02,  2.40s/it, loss=4.1606]\u001b[A\n",
            "Training:  30%|██▉       | 1480/5000 [1:05:25<2:21:02,  2.40s/it, loss=3.4492]\u001b[A\n",
            "Training:  30%|██▉       | 1481/5000 [1:05:27<2:18:08,  2.36s/it, loss=3.4492]\u001b[A\n",
            "Training:  30%|██▉       | 1481/5000 [1:05:27<2:18:08,  2.36s/it, loss=3.5193]\u001b[A\n",
            "Training:  30%|██▉       | 1482/5000 [1:05:29<2:16:09,  2.32s/it, loss=3.5193]\u001b[A\n",
            "Training:  30%|██▉       | 1482/5000 [1:05:29<2:16:09,  2.32s/it, loss=3.6930]\u001b[A\n",
            "Training:  30%|██▉       | 1483/5000 [1:05:31<2:14:33,  2.30s/it, loss=3.6930]\u001b[A\n",
            "Training:  30%|██▉       | 1483/5000 [1:05:31<2:14:33,  2.30s/it, loss=3.4042]\u001b[A\n",
            "Training:  30%|██▉       | 1484/5000 [1:05:34<2:13:20,  2.28s/it, loss=3.4042]\u001b[A\n",
            "Training:  30%|██▉       | 1484/5000 [1:05:34<2:13:20,  2.28s/it, loss=3.3331]\u001b[A\n",
            "Training:  30%|██▉       | 1485/5000 [1:05:36<2:22:13,  2.43s/it, loss=3.3331]\u001b[A\n",
            "Training:  30%|██▉       | 1485/5000 [1:05:37<2:22:13,  2.43s/it, loss=3.0658]\u001b[A\n",
            "Training:  30%|██▉       | 1486/5000 [1:05:39<2:19:20,  2.38s/it, loss=3.0658]\u001b[A\n",
            "Training:  30%|██▉       | 1486/5000 [1:05:39<2:19:20,  2.38s/it, loss=3.3738]\u001b[A\n",
            "Training:  30%|██▉       | 1487/5000 [1:05:41<2:17:04,  2.34s/it, loss=3.3738]\u001b[A\n",
            "Training:  30%|██▉       | 1487/5000 [1:05:41<2:17:04,  2.34s/it, loss=3.3214]\u001b[A\n",
            "Training:  30%|██▉       | 1488/5000 [1:05:43<2:15:08,  2.31s/it, loss=3.3214]\u001b[A\n",
            "Training:  30%|██▉       | 1488/5000 [1:05:43<2:15:08,  2.31s/it, loss=3.0902]\u001b[A\n",
            "Training:  30%|██▉       | 1489/5000 [1:05:45<2:13:50,  2.29s/it, loss=3.0902]\u001b[A\n",
            "Training:  30%|██▉       | 1489/5000 [1:05:45<2:13:50,  2.29s/it, loss=3.1213]\u001b[A\n",
            "Training:  30%|██▉       | 1490/5000 [1:05:48<2:22:12,  2.43s/it, loss=3.1213]\u001b[A\n",
            "Training:  30%|██▉       | 1490/5000 [1:05:48<2:22:12,  2.43s/it, loss=2.5274]\u001b[A\n",
            "Training:  30%|██▉       | 1491/5000 [1:05:50<2:18:42,  2.37s/it, loss=2.5274]\u001b[A\n",
            "Training:  30%|██▉       | 1491/5000 [1:05:51<2:18:42,  2.37s/it, loss=3.1379]\u001b[A\n",
            "Training:  30%|██▉       | 1492/5000 [1:05:53<2:16:02,  2.33s/it, loss=3.1379]\u001b[A\n",
            "Training:  30%|██▉       | 1492/5000 [1:05:53<2:16:02,  2.33s/it, loss=3.2239]\u001b[A\n",
            "Training:  30%|██▉       | 1493/5000 [1:05:55<2:14:28,  2.30s/it, loss=3.2239]\u001b[A\n",
            "Training:  30%|██▉       | 1493/5000 [1:05:55<2:14:28,  2.30s/it, loss=3.9529]\u001b[A\n",
            "Training:  30%|██▉       | 1494/5000 [1:05:57<2:14:10,  2.30s/it, loss=3.9529]\u001b[A\n",
            "Training:  30%|██▉       | 1494/5000 [1:05:57<2:14:10,  2.30s/it, loss=3.8956]\u001b[A\n",
            "Training:  30%|██▉       | 1495/5000 [1:06:00<2:22:11,  2.43s/it, loss=3.8956]\u001b[A\n",
            "Training:  30%|██▉       | 1495/5000 [1:06:00<2:22:11,  2.43s/it, loss=4.0999]\u001b[A\n",
            "Training:  30%|██▉       | 1496/5000 [1:06:02<2:18:41,  2.37s/it, loss=4.0999]\u001b[A\n",
            "Training:  30%|██▉       | 1496/5000 [1:06:02<2:18:41,  2.37s/it, loss=3.8745]\u001b[A\n",
            "Training:  30%|██▉       | 1497/5000 [1:06:04<2:16:27,  2.34s/it, loss=3.8745]\u001b[A\n",
            "Training:  30%|██▉       | 1497/5000 [1:06:04<2:16:27,  2.34s/it, loss=3.8784]\u001b[A\n",
            "Training:  30%|██▉       | 1498/5000 [1:06:07<2:14:53,  2.31s/it, loss=3.8784]\u001b[A\n",
            "Training:  30%|██▉       | 1498/5000 [1:06:07<2:14:53,  2.31s/it, loss=3.2127]\u001b[A\n",
            "Training:  30%|██▉       | 1499/5000 [1:06:09<2:14:09,  2.30s/it, loss=3.2127]\u001b[A\n",
            "Training:  30%|██▉       | 1499/5000 [1:06:09<2:14:09,  2.30s/it, loss=4.3126]\u001b[A\n",
            "Training:  30%|███       | 1500/5000 [1:06:12<2:22:05,  2.44s/it, loss=4.3126]\u001b[A\n",
            "Training:  30%|███       | 1500/5000 [1:06:12<2:22:05,  2.44s/it, loss=3.6351]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 1500 ---\n",
            "Prompt: 'The '\n",
            "The  and is, here such war loved levy\n",
            " heavy to, we't\n",
            " the,,,,,, to some's,,,,\n",
            " thou, endt, thy,, modest,,:,,,,,,,,\n",
            " love not a of,, stt,,,,,,, the! the thatc it the for's,, to sick very,,,,! the,,ie,!,!' this a,!,!,\n",
            "Prompt: 'In '\n",
            "In  such, for:tis poor'sonder on\n",
            " Gloucester not;,,,! he.\n",
            "hold,! and innocent,!, are.!\n",
            " attend to,.\n",
            "PROERO Can:Sir you the,!, too!,!!am what is Lord\n",
            "ICH son are.! likefe, an-, a-!!, you!,!,, you not\n",
            "V it; you not be. say how art speak well army,!,!ie\n",
            "Prompt: 'To '\n",
            "To  of pay SirThe of.ove ho all waking\n",
            " all daughter,,,,, form or and is,,,,,,,\n",
            " in of and everything tell winter like Gentle:,!, you heavy!\n",
            "PROERO'ble' close\n",
            "iol know God his's:,!' dear,!, you\n",
            " done\n",
            ",,!\n",
            "Wid:\n",
            ",!!oe! it\n",
            "PROERO much out s!Int a, down what? sounds now\n",
            "ANTcius\n",
            "Prompt: 'A '\n",
            "A  and:\n",
            "le power done--\n",
            "ANTIO\n",
            ":Th hastua ableives him aLead ourALL\n",
            " greater against: himMy,,,, a.\n",
            ",,,.,,!tis to the!\n",
            " dire! ever government lively,!,! the br,ie f,,,,!'\n",
            " rash storeull,,,'s!,!! lightt!'s! hast fastMPunes lords\n",
            " are!,!, are. J, any\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "✓ Checkpoint saved: checkpoints/checkpoint_step_1500.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  30%|███       | 1501/5000 [1:07:05<17:18:39, 17.81s/it, loss=3.6351]\u001b[A\n",
            "Training:  30%|███       | 1501/5000 [1:07:05<17:18:39, 17.81s/it, loss=3.2646]\u001b[A\n",
            "Training:  30%|███       | 1502/5000 [1:07:08<12:53:35, 13.27s/it, loss=3.2646]\u001b[A\n",
            "Training:  30%|███       | 1502/5000 [1:07:08<12:53:35, 13.27s/it, loss=3.9669]\u001b[A\n",
            "Training:  30%|███       | 1503/5000 [1:07:11<9:45:56, 10.05s/it, loss=3.9669] \u001b[A\n",
            "Training:  30%|███       | 1503/5000 [1:07:11<9:45:56, 10.05s/it, loss=3.4447]\u001b[A\n",
            "Training:  30%|███       | 1504/5000 [1:07:13<7:31:33,  7.75s/it, loss=3.4447]\u001b[A\n",
            "Training:  30%|███       | 1504/5000 [1:07:13<7:31:33,  7.75s/it, loss=3.5420]\u001b[A\n",
            "Training:  30%|███       | 1505/5000 [1:07:15<5:57:13,  6.13s/it, loss=3.5420]\u001b[A\n",
            "Training:  30%|███       | 1505/5000 [1:07:15<5:57:13,  6.13s/it, loss=3.0770]\u001b[A\n",
            "Training:  30%|███       | 1506/5000 [1:07:18<4:50:48,  4.99s/it, loss=3.0770]\u001b[A\n",
            "Training:  30%|███       | 1506/5000 [1:07:18<4:50:48,  4.99s/it, loss=3.5865]\u001b[A\n",
            "Training:  30%|███       | 1507/5000 [1:07:20<4:11:15,  4.32s/it, loss=3.5865]\u001b[A\n",
            "Training:  30%|███       | 1507/5000 [1:07:20<4:11:15,  4.32s/it, loss=3.0708]\u001b[A\n",
            "Training:  30%|███       | 1508/5000 [1:07:23<3:39:42,  3.77s/it, loss=3.0708]\u001b[A\n",
            "Training:  30%|███       | 1508/5000 [1:07:23<3:39:42,  3.77s/it, loss=3.5682]\u001b[A\n",
            "Training:  30%|███       | 1509/5000 [1:07:25<3:14:01,  3.33s/it, loss=3.5682]\u001b[A\n",
            "Training:  30%|███       | 1509/5000 [1:07:25<3:14:01,  3.33s/it, loss=3.4906]\u001b[A\n",
            "Training:  30%|███       | 1510/5000 [1:07:28<2:56:08,  3.03s/it, loss=3.4906]\u001b[A\n",
            "Training:  30%|███       | 1510/5000 [1:07:28<2:56:08,  3.03s/it, loss=2.8631]\u001b[A\n",
            "Training:  30%|███       | 1511/5000 [1:07:30<2:43:47,  2.82s/it, loss=2.8631]\u001b[A\n",
            "Training:  30%|███       | 1511/5000 [1:07:30<2:43:47,  2.82s/it, loss=3.2929]\u001b[A\n",
            "Training:  30%|███       | 1512/5000 [1:07:33<2:44:00,  2.82s/it, loss=3.2929]\u001b[A\n",
            "Training:  30%|███       | 1512/5000 [1:07:33<2:44:00,  2.82s/it, loss=2.8368]\u001b[A\n",
            "Training:  30%|███       | 1513/5000 [1:07:35<2:35:18,  2.67s/it, loss=2.8368]\u001b[A\n",
            "Training:  30%|███       | 1513/5000 [1:07:35<2:35:18,  2.67s/it, loss=3.6370]\u001b[A\n",
            "Training:  30%|███       | 1514/5000 [1:07:37<2:28:42,  2.56s/it, loss=3.6370]\u001b[A\n",
            "Training:  30%|███       | 1514/5000 [1:07:37<2:28:42,  2.56s/it, loss=3.6967]\u001b[A\n",
            "Training:  30%|███       | 1515/5000 [1:07:40<2:25:17,  2.50s/it, loss=3.6967]\u001b[A\n",
            "Training:  30%|███       | 1515/5000 [1:07:40<2:25:17,  2.50s/it, loss=4.0793]\u001b[A\n",
            "Training:  30%|███       | 1516/5000 [1:07:42<2:22:02,  2.45s/it, loss=4.0793]\u001b[A\n",
            "Training:  30%|███       | 1516/5000 [1:07:42<2:22:02,  2.45s/it, loss=3.3504]\u001b[A\n",
            "Training:  30%|███       | 1517/5000 [1:07:45<2:29:52,  2.58s/it, loss=3.3504]\u001b[A\n",
            "Training:  30%|███       | 1517/5000 [1:07:45<2:29:52,  2.58s/it, loss=3.2523]\u001b[A\n",
            "Training:  30%|███       | 1518/5000 [1:07:47<2:24:55,  2.50s/it, loss=3.2523]\u001b[A\n",
            "Training:  30%|███       | 1518/5000 [1:07:47<2:24:55,  2.50s/it, loss=2.6247]\u001b[A\n",
            "Training:  30%|███       | 1519/5000 [1:07:50<2:21:44,  2.44s/it, loss=2.6247]\u001b[A\n",
            "Training:  30%|███       | 1519/5000 [1:07:50<2:21:44,  2.44s/it, loss=4.1908]\u001b[A\n",
            "Training:  30%|███       | 1520/5000 [1:07:52<2:19:30,  2.41s/it, loss=4.1908]\u001b[A\n",
            "Training:  30%|███       | 1520/5000 [1:07:52<2:19:30,  2.41s/it, loss=3.1951]\u001b[A\n",
            "Training:  30%|███       | 1521/5000 [1:07:54<2:17:33,  2.37s/it, loss=3.1951]\u001b[A\n",
            "Training:  30%|███       | 1521/5000 [1:07:54<2:17:33,  2.37s/it, loss=3.5193]\u001b[A\n",
            "Training:  30%|███       | 1522/5000 [1:07:57<2:26:19,  2.52s/it, loss=3.5193]\u001b[A\n",
            "Training:  30%|███       | 1522/5000 [1:07:57<2:26:19,  2.52s/it, loss=3.7623]\u001b[A\n",
            "Training:  30%|███       | 1523/5000 [1:07:59<2:22:23,  2.46s/it, loss=3.7623]\u001b[A\n",
            "Training:  30%|███       | 1523/5000 [1:07:59<2:22:23,  2.46s/it, loss=3.4046]\u001b[A\n",
            "Training:  30%|███       | 1524/5000 [1:08:02<2:19:49,  2.41s/it, loss=3.4046]\u001b[A\n",
            "Training:  30%|███       | 1524/5000 [1:08:02<2:19:49,  2.41s/it, loss=4.0038]\u001b[A\n",
            "Training:  30%|███       | 1525/5000 [1:08:04<2:18:08,  2.39s/it, loss=4.0038]\u001b[A\n",
            "Training:  30%|███       | 1525/5000 [1:08:04<2:18:08,  2.39s/it, loss=3.7824]\u001b[A\n",
            "Training:  31%|███       | 1526/5000 [1:08:06<2:16:56,  2.37s/it, loss=3.7824]\u001b[A\n",
            "Training:  31%|███       | 1526/5000 [1:08:06<2:16:56,  2.37s/it, loss=3.7282]\u001b[A\n",
            "Training:  31%|███       | 1527/5000 [1:08:09<2:26:06,  2.52s/it, loss=3.7282]\u001b[A\n",
            "Training:  31%|███       | 1527/5000 [1:08:09<2:26:06,  2.52s/it, loss=3.3507]\u001b[A\n",
            "Training:  31%|███       | 1528/5000 [1:08:12<2:22:49,  2.47s/it, loss=3.3507]\u001b[A\n",
            "Training:  31%|███       | 1528/5000 [1:08:12<2:22:49,  2.47s/it, loss=3.8883]\u001b[A\n",
            "Training:  31%|███       | 1529/5000 [1:08:14<2:20:15,  2.42s/it, loss=3.8883]\u001b[A\n",
            "Training:  31%|███       | 1529/5000 [1:08:14<2:20:15,  2.42s/it, loss=3.1604]\u001b[A\n",
            "Training:  31%|███       | 1530/5000 [1:08:16<2:18:22,  2.39s/it, loss=3.1604]\u001b[A\n",
            "Training:  31%|███       | 1530/5000 [1:08:16<2:18:22,  2.39s/it, loss=3.4863]\u001b[A\n",
            "Training:  31%|███       | 1531/5000 [1:08:19<2:18:29,  2.40s/it, loss=3.4863]\u001b[A\n",
            "Training:  31%|███       | 1531/5000 [1:08:19<2:18:29,  2.40s/it, loss=3.3644]\u001b[A\n",
            "Training:  31%|███       | 1532/5000 [1:08:21<2:24:54,  2.51s/it, loss=3.3644]\u001b[A\n",
            "Training:  31%|███       | 1532/5000 [1:08:21<2:24:54,  2.51s/it, loss=2.9644]\u001b[A\n",
            "Training:  31%|███       | 1533/5000 [1:08:24<2:21:34,  2.45s/it, loss=2.9644]\u001b[A\n",
            "Training:  31%|███       | 1533/5000 [1:08:24<2:21:34,  2.45s/it, loss=3.1936]\u001b[A\n",
            "Training:  31%|███       | 1534/5000 [1:08:26<2:19:33,  2.42s/it, loss=3.1936]\u001b[A\n",
            "Training:  31%|███       | 1534/5000 [1:08:26<2:19:33,  2.42s/it, loss=3.0797]\u001b[A\n",
            "Training:  31%|███       | 1535/5000 [1:08:28<2:18:12,  2.39s/it, loss=3.0797]\u001b[A\n",
            "Training:  31%|███       | 1535/5000 [1:08:28<2:18:12,  2.39s/it, loss=2.9778]\u001b[A\n",
            "Training:  31%|███       | 1536/5000 [1:08:31<2:19:22,  2.41s/it, loss=2.9778]\u001b[A\n",
            "Training:  31%|███       | 1536/5000 [1:08:31<2:19:22,  2.41s/it, loss=3.3175]\u001b[A\n",
            "Training:  31%|███       | 1537/5000 [1:08:33<2:24:11,  2.50s/it, loss=3.3175]\u001b[A\n",
            "Training:  31%|███       | 1537/5000 [1:08:34<2:24:11,  2.50s/it, loss=3.6948]\u001b[A\n",
            "Training:  31%|███       | 1538/5000 [1:08:36<2:20:54,  2.44s/it, loss=3.6948]\u001b[A\n",
            "Training:  31%|███       | 1538/5000 [1:08:36<2:20:54,  2.44s/it, loss=2.6357]\u001b[A\n",
            "Training:  31%|███       | 1539/5000 [1:08:38<2:19:07,  2.41s/it, loss=2.6357]\u001b[A\n",
            "Training:  31%|███       | 1539/5000 [1:08:38<2:19:07,  2.41s/it, loss=3.0148]\u001b[A\n",
            "Training:  31%|███       | 1540/5000 [1:08:41<2:18:17,  2.40s/it, loss=3.0148]\u001b[A\n",
            "Training:  31%|███       | 1540/5000 [1:08:41<2:18:17,  2.40s/it, loss=3.1824]\u001b[A\n",
            "Training:  31%|███       | 1541/5000 [1:08:43<2:20:51,  2.44s/it, loss=3.1824]\u001b[A\n",
            "Training:  31%|███       | 1541/5000 [1:08:43<2:20:51,  2.44s/it, loss=3.6005]\u001b[A\n",
            "Training:  31%|███       | 1542/5000 [1:08:46<2:24:16,  2.50s/it, loss=3.6005]\u001b[A\n",
            "Training:  31%|███       | 1542/5000 [1:08:46<2:24:16,  2.50s/it, loss=2.3745]\u001b[A\n",
            "Training:  31%|███       | 1543/5000 [1:08:48<2:21:22,  2.45s/it, loss=2.3745]\u001b[A\n",
            "Training:  31%|███       | 1543/5000 [1:08:48<2:21:22,  2.45s/it, loss=3.3532]\u001b[A\n",
            "Training:  31%|███       | 1544/5000 [1:08:50<2:18:28,  2.40s/it, loss=3.3532]\u001b[A\n",
            "Training:  31%|███       | 1544/5000 [1:08:50<2:18:28,  2.40s/it, loss=3.3972]\u001b[A\n",
            "Training:  31%|███       | 1545/5000 [1:08:53<2:16:34,  2.37s/it, loss=3.3972]\u001b[A\n",
            "Training:  31%|███       | 1545/5000 [1:08:53<2:16:34,  2.37s/it, loss=3.6537]\u001b[A\n",
            "Training:  31%|███       | 1546/5000 [1:08:55<2:20:11,  2.44s/it, loss=3.6537]\u001b[A\n",
            "Training:  31%|███       | 1546/5000 [1:08:55<2:20:11,  2.44s/it, loss=3.1770]\u001b[A\n",
            "Training:  31%|███       | 1547/5000 [1:08:58<2:22:13,  2.47s/it, loss=3.1770]\u001b[A\n",
            "Training:  31%|███       | 1547/5000 [1:08:58<2:22:13,  2.47s/it, loss=3.0685]\u001b[A\n",
            "Training:  31%|███       | 1548/5000 [1:09:00<2:19:40,  2.43s/it, loss=3.0685]\u001b[A\n",
            "Training:  31%|███       | 1548/5000 [1:09:00<2:19:40,  2.43s/it, loss=3.4907]\u001b[A\n",
            "Training:  31%|███       | 1549/5000 [1:09:02<2:18:15,  2.40s/it, loss=3.4907]\u001b[A\n",
            "Training:  31%|███       | 1549/5000 [1:09:02<2:18:15,  2.40s/it, loss=3.2868]\u001b[A\n",
            "Training:  31%|███       | 1550/5000 [1:09:05<2:16:30,  2.37s/it, loss=3.2868]\u001b[A\n",
            "Training:  31%|███       | 1550/5000 [1:09:05<2:16:30,  2.37s/it, loss=3.3839]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 1550 ---\n",
            "Prompt: 'The '\n",
            "The  of victories good blood rabbit!\n",
            ", their loved then uncle in high,,, guilty\n",
            " fa in meet sovereignty\n",
            " myay way to. else it in sight\n",
            " territories his soul kind that, such is;The d hathfor to-- sovereign\n",
            "ETH\n",
            " add tearsADose meat and accompany of seems are daughterTo the\n",
            " I bl in shame a: him and Moreover a.\n",
            "T he in borrow and awile\n",
            " isn; is a instrument andge aoton best th\n",
            "Prompt: 'In '\n",
            "In , d stand in sovereignty\n",
            "st in face andourable on golden,\n",
            " without indeed call by and., I to, thy, Richmond\n",
            " at that of shall a ten, I and thy, they in;B him\n",
            " now been here in England at from ground but much hands\n",
            "all die thousand to God himself\n",
            " tongues home and in best and in justice,, thy\n",
            "ies his soul in soul for shall your out a: till and it in;And, our cur exile in on\n",
            "Prompt: 'To '\n",
            "To  and highite kingdom Paul;His\n",
            " dignity being'd and it in amb, discourse\n",
            " somePRCEeduon in ageWhen were, office\n",
            " the ofts firstoler, and the many drewp,\n",
            " usbing Mercury in shameful's;, the,Men his'sanus hell\n",
            " their,, the wishing and of establish of,\n",
            " in shame in unity omin to.\n",
            "H, this heart thou, to my die\n",
            "ys-rer ofservices this. burst w\n",
            "Prompt: 'A '\n",
            "A  of I thy King garden\n",
            " not blood but blindly a-y eye\n",
            " name my out breakAgain this war happy to\n",
            " high and them in them andew'd exactly\n",
            " his mercyf;,,, rev forile\n",
            " prove to upon disented in,\n",
            " man and, to high to King's throne\n",
            "el to him\n",
            " that in highivers his-ied\n",
            ",, thy and fair and, now in them, bold\n",
            "ling andtest other obey and day painted times me\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  31%|███       | 1551/5000 [1:09:20<6:04:46,  6.35s/it, loss=3.3839]\u001b[A\n",
            "Training:  31%|███       | 1551/5000 [1:09:20<6:04:46,  6.35s/it, loss=3.6143]\u001b[A\n",
            "Training:  31%|███       | 1552/5000 [1:09:23<4:54:59,  5.13s/it, loss=3.6143]\u001b[A\n",
            "Training:  31%|███       | 1552/5000 [1:09:23<4:54:59,  5.13s/it, loss=3.5566]\u001b[A\n",
            "Training:  31%|███       | 1553/5000 [1:09:25<4:06:48,  4.30s/it, loss=3.5566]\u001b[A\n",
            "Training:  31%|███       | 1553/5000 [1:09:25<4:06:48,  4.30s/it, loss=2.6746]\u001b[A\n",
            "Training:  31%|███       | 1554/5000 [1:09:27<3:32:45,  3.70s/it, loss=2.6746]\u001b[A\n",
            "Training:  31%|███       | 1554/5000 [1:09:27<3:32:45,  3.70s/it, loss=2.9092]\u001b[A\n",
            "Training:  31%|███       | 1555/5000 [1:09:30<3:08:00,  3.27s/it, loss=2.9092]\u001b[A\n",
            "Training:  31%|███       | 1555/5000 [1:09:30<3:08:00,  3.27s/it, loss=3.1528]\u001b[A\n",
            "Training:  31%|███       | 1556/5000 [1:09:32<3:00:46,  3.15s/it, loss=3.1528]\u001b[A\n",
            "Training:  31%|███       | 1556/5000 [1:09:32<3:00:46,  3.15s/it, loss=2.5134]\u001b[A\n",
            "Training:  31%|███       | 1557/5000 [1:09:35<2:45:50,  2.89s/it, loss=2.5134]\u001b[A\n",
            "Training:  31%|███       | 1557/5000 [1:09:35<2:45:50,  2.89s/it, loss=2.6430]\u001b[A\n",
            "Training:  31%|███       | 1558/5000 [1:09:37<2:35:11,  2.71s/it, loss=2.6430]\u001b[A\n",
            "Training:  31%|███       | 1558/5000 [1:09:37<2:35:11,  2.71s/it, loss=3.0175]\u001b[A\n",
            "Training:  31%|███       | 1559/5000 [1:09:39<2:28:04,  2.58s/it, loss=3.0175]\u001b[A\n",
            "Training:  31%|███       | 1559/5000 [1:09:39<2:28:04,  2.58s/it, loss=3.4319]\u001b[A\n",
            "Training:  31%|███       | 1560/5000 [1:09:42<2:23:42,  2.51s/it, loss=3.4319]\u001b[A\n",
            "Training:  31%|███       | 1560/5000 [1:09:42<2:23:42,  2.51s/it, loss=2.8678]\u001b[A\n",
            "Training:  31%|███       | 1561/5000 [1:09:44<2:29:40,  2.61s/it, loss=2.8678]\u001b[A\n",
            "Training:  31%|███       | 1561/5000 [1:09:45<2:29:40,  2.61s/it, loss=3.2360]\u001b[A\n",
            "Training:  31%|███       | 1562/5000 [1:09:47<2:24:12,  2.52s/it, loss=3.2360]\u001b[A\n",
            "Training:  31%|███       | 1562/5000 [1:09:47<2:24:12,  2.52s/it, loss=2.5355]\u001b[A\n",
            "Training:  31%|███▏      | 1563/5000 [1:09:49<2:20:48,  2.46s/it, loss=2.5355]\u001b[A\n",
            "Training:  31%|███▏      | 1563/5000 [1:09:49<2:20:48,  2.46s/it, loss=3.0857]\u001b[A\n",
            "Training:  31%|███▏      | 1564/5000 [1:09:51<2:18:06,  2.41s/it, loss=3.0857]\u001b[A\n",
            "Training:  31%|███▏      | 1564/5000 [1:09:51<2:18:06,  2.41s/it, loss=3.8838]\u001b[A\n",
            "Training:  31%|███▏      | 1565/5000 [1:09:54<2:17:40,  2.40s/it, loss=3.8838]\u001b[A\n",
            "Training:  31%|███▏      | 1565/5000 [1:09:54<2:17:40,  2.40s/it, loss=3.3491]\u001b[A\n",
            "Training:  31%|███▏      | 1566/5000 [1:09:57<2:24:13,  2.52s/it, loss=3.3491]\u001b[A\n",
            "Training:  31%|███▏      | 1566/5000 [1:09:57<2:24:13,  2.52s/it, loss=3.2691]\u001b[A\n",
            "Training:  31%|███▏      | 1567/5000 [1:09:59<2:21:20,  2.47s/it, loss=3.2691]\u001b[A\n",
            "Training:  31%|███▏      | 1567/5000 [1:09:59<2:21:20,  2.47s/it, loss=3.4363]\u001b[A\n",
            "Training:  31%|███▏      | 1568/5000 [1:10:01<2:18:22,  2.42s/it, loss=3.4363]\u001b[A\n",
            "Training:  31%|███▏      | 1568/5000 [1:10:01<2:18:22,  2.42s/it, loss=3.5791]\u001b[A\n",
            "Training:  31%|███▏      | 1569/5000 [1:10:04<2:17:11,  2.40s/it, loss=3.5791]\u001b[A\n",
            "Training:  31%|███▏      | 1569/5000 [1:10:04<2:17:11,  2.40s/it, loss=3.0499]\u001b[A\n",
            "Training:  31%|███▏      | 1570/5000 [1:10:06<2:16:58,  2.40s/it, loss=3.0499]\u001b[A\n",
            "Training:  31%|███▏      | 1570/5000 [1:10:06<2:16:58,  2.40s/it, loss=3.2199]\u001b[A\n",
            "Training:  31%|███▏      | 1571/5000 [1:10:09<2:21:05,  2.47s/it, loss=3.2199]\u001b[A\n",
            "Training:  31%|███▏      | 1571/5000 [1:10:09<2:21:05,  2.47s/it, loss=2.8286]\u001b[A\n",
            "Training:  31%|███▏      | 1572/5000 [1:10:11<2:17:46,  2.41s/it, loss=2.8286]\u001b[A\n",
            "Training:  31%|███▏      | 1572/5000 [1:10:11<2:17:46,  2.41s/it, loss=3.1207]\u001b[A\n",
            "Training:  31%|███▏      | 1573/5000 [1:10:13<2:14:43,  2.36s/it, loss=3.1207]\u001b[A\n",
            "Training:  31%|███▏      | 1573/5000 [1:10:13<2:14:43,  2.36s/it, loss=3.1630]\u001b[A\n",
            "Training:  31%|███▏      | 1574/5000 [1:10:15<2:12:31,  2.32s/it, loss=3.1630]\u001b[A\n",
            "Training:  31%|███▏      | 1574/5000 [1:10:15<2:12:31,  2.32s/it, loss=2.9151]\u001b[A\n",
            "Training:  32%|███▏      | 1575/5000 [1:10:18<2:12:37,  2.32s/it, loss=2.9151]\u001b[A\n",
            "Training:  32%|███▏      | 1575/5000 [1:10:18<2:12:37,  2.32s/it, loss=3.5938]\u001b[A\n",
            "Training:  32%|███▏      | 1576/5000 [1:10:20<2:18:25,  2.43s/it, loss=3.5938]\u001b[A\n",
            "Training:  32%|███▏      | 1576/5000 [1:10:20<2:18:25,  2.43s/it, loss=3.1915]\u001b[A\n",
            "Training:  32%|███▏      | 1577/5000 [1:10:23<2:14:48,  2.36s/it, loss=3.1915]\u001b[A\n",
            "Training:  32%|███▏      | 1577/5000 [1:10:23<2:14:48,  2.36s/it, loss=2.9002]\u001b[A\n",
            "Training:  32%|███▏      | 1578/5000 [1:10:25<2:12:40,  2.33s/it, loss=2.9002]\u001b[A\n",
            "Training:  32%|███▏      | 1578/5000 [1:10:25<2:12:40,  2.33s/it, loss=2.7897]\u001b[A\n",
            "Training:  32%|███▏      | 1579/5000 [1:10:27<2:11:10,  2.30s/it, loss=2.7897]\u001b[A\n",
            "Training:  32%|███▏      | 1579/5000 [1:10:27<2:11:10,  2.30s/it, loss=2.6479]\u001b[A\n",
            "Training:  32%|███▏      | 1580/5000 [1:10:29<2:10:08,  2.28s/it, loss=2.6479]\u001b[A\n",
            "Training:  32%|███▏      | 1580/5000 [1:10:29<2:10:08,  2.28s/it, loss=2.8979]\u001b[A\n",
            "Training:  32%|███▏      | 1581/5000 [1:10:32<2:18:03,  2.42s/it, loss=2.8979]\u001b[A\n",
            "Training:  32%|███▏      | 1581/5000 [1:10:32<2:18:03,  2.42s/it, loss=3.2213]\u001b[A\n",
            "Training:  32%|███▏      | 1582/5000 [1:10:34<2:14:36,  2.36s/it, loss=3.2213]\u001b[A\n",
            "Training:  32%|███▏      | 1582/5000 [1:10:34<2:14:36,  2.36s/it, loss=3.2627]\u001b[A\n",
            "Training:  32%|███▏      | 1583/5000 [1:10:37<2:12:58,  2.33s/it, loss=3.2627]\u001b[A\n",
            "Training:  32%|███▏      | 1583/5000 [1:10:37<2:12:58,  2.33s/it, loss=2.6563]\u001b[A\n",
            "Training:  32%|███▏      | 1584/5000 [1:10:39<2:11:08,  2.30s/it, loss=2.6563]\u001b[A\n",
            "Training:  32%|███▏      | 1584/5000 [1:10:39<2:11:08,  2.30s/it, loss=2.7006]\u001b[A\n",
            "Training:  32%|███▏      | 1585/5000 [1:10:41<2:10:25,  2.29s/it, loss=2.7006]\u001b[A\n",
            "Training:  32%|███▏      | 1585/5000 [1:10:41<2:10:25,  2.29s/it, loss=2.7942]\u001b[A\n",
            "Training:  32%|███▏      | 1586/5000 [1:10:44<2:18:55,  2.44s/it, loss=2.7942]\u001b[A\n",
            "Training:  32%|███▏      | 1586/5000 [1:10:44<2:18:55,  2.44s/it, loss=3.3899]\u001b[A\n",
            "Training:  32%|███▏      | 1587/5000 [1:10:46<2:15:26,  2.38s/it, loss=3.3899]\u001b[A\n",
            "Training:  32%|███▏      | 1587/5000 [1:10:46<2:15:26,  2.38s/it, loss=3.2021]\u001b[A\n",
            "Training:  32%|███▏      | 1588/5000 [1:10:48<2:12:58,  2.34s/it, loss=3.2021]\u001b[A\n",
            "Training:  32%|███▏      | 1588/5000 [1:10:48<2:12:58,  2.34s/it, loss=3.6690]\u001b[A\n",
            "Training:  32%|███▏      | 1589/5000 [1:10:51<2:11:03,  2.31s/it, loss=3.6690]\u001b[A\n",
            "Training:  32%|███▏      | 1589/5000 [1:10:51<2:11:03,  2.31s/it, loss=3.5779]\u001b[A\n",
            "Training:  32%|███▏      | 1590/5000 [1:10:53<2:09:41,  2.28s/it, loss=3.5779]\u001b[A\n",
            "Training:  32%|███▏      | 1590/5000 [1:10:53<2:09:41,  2.28s/it, loss=2.1995]\u001b[A\n",
            "Training:  32%|███▏      | 1591/5000 [1:10:56<2:17:46,  2.43s/it, loss=2.1995]\u001b[A\n",
            "Training:  32%|███▏      | 1591/5000 [1:10:56<2:17:46,  2.43s/it, loss=3.0449]\u001b[A\n",
            "Training:  32%|███▏      | 1592/5000 [1:10:58<2:14:49,  2.37s/it, loss=3.0449]\u001b[A\n",
            "Training:  32%|███▏      | 1592/5000 [1:10:58<2:14:49,  2.37s/it, loss=3.3458]\u001b[A\n",
            "Training:  32%|███▏      | 1593/5000 [1:11:00<2:12:49,  2.34s/it, loss=3.3458]\u001b[A\n",
            "Training:  32%|███▏      | 1593/5000 [1:11:00<2:12:49,  2.34s/it, loss=3.0575]\u001b[A\n",
            "Training:  32%|███▏      | 1594/5000 [1:11:02<2:11:22,  2.31s/it, loss=3.0575]\u001b[A\n",
            "Training:  32%|███▏      | 1594/5000 [1:11:02<2:11:22,  2.31s/it, loss=2.5915]\u001b[A\n",
            "Training:  32%|███▏      | 1595/5000 [1:11:05<2:10:20,  2.30s/it, loss=2.5915]\u001b[A\n",
            "Training:  32%|███▏      | 1595/5000 [1:11:05<2:10:20,  2.30s/it, loss=3.0494]\u001b[A\n",
            "Training:  32%|███▏      | 1596/5000 [1:11:07<2:18:05,  2.43s/it, loss=3.0494]\u001b[A\n",
            "Training:  32%|███▏      | 1596/5000 [1:11:07<2:18:05,  2.43s/it, loss=3.1408]\u001b[A\n",
            "Training:  32%|███▏      | 1597/5000 [1:11:10<2:14:51,  2.38s/it, loss=3.1408]\u001b[A\n",
            "Training:  32%|███▏      | 1597/5000 [1:11:10<2:14:51,  2.38s/it, loss=2.7968]\u001b[A\n",
            "Training:  32%|███▏      | 1598/5000 [1:11:12<2:13:11,  2.35s/it, loss=2.7968]\u001b[A\n",
            "Training:  32%|███▏      | 1598/5000 [1:11:12<2:13:11,  2.35s/it, loss=2.5883]\u001b[A\n",
            "Training:  32%|███▏      | 1599/5000 [1:11:14<2:11:30,  2.32s/it, loss=2.5883]\u001b[A\n",
            "Training:  32%|███▏      | 1599/5000 [1:11:14<2:11:30,  2.32s/it, loss=2.6420]\u001b[A\n",
            "Training:  32%|███▏      | 1600/5000 [1:11:16<2:09:43,  2.29s/it, loss=2.6420]\u001b[A\n",
            "Training:  32%|███▏      | 1600/5000 [1:11:16<2:09:43,  2.29s/it, loss=2.3960]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 1600 ---\n",
            "Prompt: 'The '\n",
            "The  of's is\n",
            " beURE with, else for no to a;And by oath\n",
            " see thoughts any to the., Edward be:But ithest,? have be hand\n",
            " daysbs, th's thou I--Ill with, I live\n",
            "TMAS:For thy better thou I'd my, Warwick th,For poor,And my Henry case my's shall me my aid some.\n",
            "K HAB not with that thy queen sp and them pr hate my and said rest me\n",
            "Prompt: 'In '\n",
            "In  my and Edward here my and!\n",
            ",,, my's sea are to\n",
            " take\n",
            " counter shall but in despair free.\n",
            "CLENCE\n",
            "Mess:And's, us brother sleep thee\n",
            " I set best further grace:,, thou d thou's am king\n",
            " I titleodes\n",
            " keep\n",
            " GRE lords:The that not I Henry, will thereof I not I; that my is ad,.\n",
            "WARICK forUT:I my is's I not.\n",
            "QUE MAR then tut\n",
            "Prompt: 'To '\n",
            "To  in one both to. old!\n",
            "K RARD\n",
            "Y:O she ladyless why my and quietly them.\n",
            "GUCER\n",
            "GET\n",
            "They a father thee to oppression,That my\n",
            " give Warwick over hes withenchORD\n",
            " is crown that embrace Berkeley myself\n",
            " do I with to, we not witness my father issue my.\n",
            "CLENCE\n",
            "DCH shall to above for cherish will\n",
            " I,For will kill to atimes hand the:So them me my,\n",
            "Prompt: 'A '\n",
            "A  father his complete\n",
            " his prove York all.\n",
            "CLENCE\n",
            " shall afford objectEST:To away\n",
            " kind Edward thus his heirWhat\n",
            " young utmost son Lancaster brother unto;And IANY me the\n",
            " shall with offences yourself:, say,, I;,, EdwardENCE norAm toted to What I awileam\n",
            " to King ill to, I myself Henry summer.\n",
            "LY,Look, WarwickING of, Warwick Warwick such chinENCE\n",
            " surplus marriage towns grant we.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  32%|███▏      | 1601/5000 [1:11:31<5:47:29,  6.13s/it, loss=2.3960]\u001b[A\n",
            "Training:  32%|███▏      | 1601/5000 [1:11:31<5:47:29,  6.13s/it, loss=2.2550]\u001b[A\n",
            "Training:  32%|███▏      | 1602/5000 [1:11:34<4:40:54,  4.96s/it, loss=2.2550]\u001b[A\n",
            "Training:  32%|███▏      | 1602/5000 [1:11:34<4:40:54,  4.96s/it, loss=3.0017]\u001b[A\n",
            "Training:  32%|███▏      | 1603/5000 [1:11:36<3:54:27,  4.14s/it, loss=3.0017]\u001b[A\n",
            "Training:  32%|███▏      | 1603/5000 [1:11:36<3:54:27,  4.14s/it, loss=2.4189]\u001b[A\n",
            "Training:  32%|███▏      | 1604/5000 [1:11:38<3:21:55,  3.57s/it, loss=2.4189]\u001b[A\n",
            "Training:  32%|███▏      | 1604/5000 [1:11:38<3:21:55,  3.57s/it, loss=3.5535]\u001b[A\n",
            "Training:  32%|███▏      | 1605/5000 [1:11:40<2:59:54,  3.18s/it, loss=3.5535]\u001b[A\n",
            "Training:  32%|███▏      | 1605/5000 [1:11:40<2:59:54,  3.18s/it, loss=3.9106]\u001b[A\n",
            "Training:  32%|███▏      | 1606/5000 [1:11:43<2:53:25,  3.07s/it, loss=3.9106]\u001b[A\n",
            "Training:  32%|███▏      | 1606/5000 [1:11:43<2:53:25,  3.07s/it, loss=3.6572]\u001b[A\n",
            "Training:  32%|███▏      | 1607/5000 [1:11:45<2:39:06,  2.81s/it, loss=3.6572]\u001b[A\n",
            "Training:  32%|███▏      | 1607/5000 [1:11:45<2:39:06,  2.81s/it, loss=3.1496]\u001b[A\n",
            "Training:  32%|███▏      | 1608/5000 [1:11:48<2:29:16,  2.64s/it, loss=3.1496]\u001b[A\n",
            "Training:  32%|███▏      | 1608/5000 [1:11:48<2:29:16,  2.64s/it, loss=2.8382]\u001b[A\n",
            "Training:  32%|███▏      | 1609/5000 [1:11:50<2:22:29,  2.52s/it, loss=2.8382]\u001b[A\n",
            "Training:  32%|███▏      | 1609/5000 [1:11:50<2:22:29,  2.52s/it, loss=3.1271]\u001b[A\n",
            "Training:  32%|███▏      | 1610/5000 [1:11:52<2:17:37,  2.44s/it, loss=3.1271]\u001b[A\n",
            "Training:  32%|███▏      | 1610/5000 [1:11:52<2:17:37,  2.44s/it, loss=2.9745]\u001b[A\n",
            "Training:  32%|███▏      | 1611/5000 [1:11:55<2:23:01,  2.53s/it, loss=2.9745]\u001b[A\n",
            "Training:  32%|███▏      | 1611/5000 [1:11:55<2:23:01,  2.53s/it, loss=3.2669]\u001b[A\n",
            "Training:  32%|███▏      | 1612/5000 [1:11:57<2:17:57,  2.44s/it, loss=3.2669]\u001b[A\n",
            "Training:  32%|███▏      | 1612/5000 [1:11:57<2:17:57,  2.44s/it, loss=3.1016]\u001b[A\n",
            "Training:  32%|███▏      | 1613/5000 [1:11:59<2:14:21,  2.38s/it, loss=3.1016]\u001b[A\n",
            "Training:  32%|███▏      | 1613/5000 [1:11:59<2:14:21,  2.38s/it, loss=3.3518]\u001b[A\n",
            "Training:  32%|███▏      | 1614/5000 [1:12:02<2:12:00,  2.34s/it, loss=3.3518]\u001b[A\n",
            "Training:  32%|███▏      | 1614/5000 [1:12:02<2:12:00,  2.34s/it, loss=3.5428]\u001b[A\n",
            "Training:  32%|███▏      | 1615/5000 [1:12:04<2:10:12,  2.31s/it, loss=3.5428]\u001b[A\n",
            "Training:  32%|███▏      | 1615/5000 [1:12:04<2:10:12,  2.31s/it, loss=3.2046]\u001b[A\n",
            "Training:  32%|███▏      | 1616/5000 [1:12:07<2:17:39,  2.44s/it, loss=3.2046]\u001b[A\n",
            "Training:  32%|███▏      | 1616/5000 [1:12:07<2:17:39,  2.44s/it, loss=3.1926]\u001b[A\n",
            "Training:  32%|███▏      | 1617/5000 [1:12:09<2:14:24,  2.38s/it, loss=3.1926]\u001b[A\n",
            "Training:  32%|███▏      | 1617/5000 [1:12:09<2:14:24,  2.38s/it, loss=2.8110]\u001b[A\n",
            "Training:  32%|███▏      | 1618/5000 [1:12:11<2:12:03,  2.34s/it, loss=2.8110]\u001b[A\n",
            "Training:  32%|███▏      | 1618/5000 [1:12:11<2:12:03,  2.34s/it, loss=3.4099]\u001b[A\n",
            "Training:  32%|███▏      | 1619/5000 [1:12:13<2:10:49,  2.32s/it, loss=3.4099]\u001b[A\n",
            "Training:  32%|███▏      | 1619/5000 [1:12:13<2:10:49,  2.32s/it, loss=2.9590]\u001b[A\n",
            "Training:  32%|███▏      | 1620/5000 [1:12:16<2:09:18,  2.30s/it, loss=2.9590]\u001b[A\n",
            "Training:  32%|███▏      | 1620/5000 [1:12:16<2:09:18,  2.30s/it, loss=3.5147]\u001b[A\n",
            "Training:  32%|███▏      | 1621/5000 [1:12:18<2:16:55,  2.43s/it, loss=3.5147]\u001b[A\n",
            "Training:  32%|███▏      | 1621/5000 [1:12:18<2:16:55,  2.43s/it, loss=3.3098]\u001b[A\n",
            "Training:  32%|███▏      | 1622/5000 [1:12:21<2:14:53,  2.40s/it, loss=3.3098]\u001b[A\n",
            "Training:  32%|███▏      | 1622/5000 [1:12:21<2:14:53,  2.40s/it, loss=3.8229]\u001b[A\n",
            "Training:  32%|███▏      | 1623/5000 [1:12:23<2:12:27,  2.35s/it, loss=3.8229]\u001b[A\n",
            "Training:  32%|███▏      | 1623/5000 [1:12:23<2:12:27,  2.35s/it, loss=2.9297]\u001b[A\n",
            "Training:  32%|███▏      | 1624/5000 [1:12:25<2:10:24,  2.32s/it, loss=2.9297]\u001b[A\n",
            "Training:  32%|███▏      | 1624/5000 [1:12:25<2:10:24,  2.32s/it, loss=3.1171]\u001b[A\n",
            "Training:  32%|███▎      | 1625/5000 [1:12:27<2:09:37,  2.30s/it, loss=3.1171]\u001b[A\n",
            "Training:  32%|███▎      | 1625/5000 [1:12:27<2:09:37,  2.30s/it, loss=3.2307]\u001b[A\n",
            "Training:  33%|███▎      | 1626/5000 [1:12:30<2:17:53,  2.45s/it, loss=3.2307]\u001b[A\n",
            "Training:  33%|███▎      | 1626/5000 [1:12:30<2:17:53,  2.45s/it, loss=3.0818]\u001b[A\n",
            "Training:  33%|███▎      | 1627/5000 [1:12:32<2:15:21,  2.41s/it, loss=3.0818]\u001b[A\n",
            "Training:  33%|███▎      | 1627/5000 [1:12:33<2:15:21,  2.41s/it, loss=3.1178]\u001b[A\n",
            "Training:  33%|███▎      | 1628/5000 [1:12:35<2:12:41,  2.36s/it, loss=3.1178]\u001b[A\n",
            "Training:  33%|███▎      | 1628/5000 [1:12:35<2:12:41,  2.36s/it, loss=3.0443]\u001b[A\n",
            "Training:  33%|███▎      | 1629/5000 [1:12:37<2:10:48,  2.33s/it, loss=3.0443]\u001b[A\n",
            "Training:  33%|███▎      | 1629/5000 [1:12:37<2:10:48,  2.33s/it, loss=3.8318]\u001b[A\n",
            "Training:  33%|███▎      | 1630/5000 [1:12:39<2:09:33,  2.31s/it, loss=3.8318]\u001b[A\n",
            "Training:  33%|███▎      | 1630/5000 [1:12:39<2:09:33,  2.31s/it, loss=3.1597]\u001b[A\n",
            "Training:  33%|███▎      | 1631/5000 [1:12:42<2:17:47,  2.45s/it, loss=3.1597]\u001b[A\n",
            "Training:  33%|███▎      | 1631/5000 [1:12:42<2:17:47,  2.45s/it, loss=3.1977]\u001b[A\n",
            "Training:  33%|███▎      | 1632/5000 [1:12:44<2:15:01,  2.41s/it, loss=3.1977]\u001b[A\n",
            "Training:  33%|███▎      | 1632/5000 [1:12:44<2:15:01,  2.41s/it, loss=2.5904]\u001b[A\n",
            "Training:  33%|███▎      | 1633/5000 [1:12:47<2:12:27,  2.36s/it, loss=2.5904]\u001b[A\n",
            "Training:  33%|███▎      | 1633/5000 [1:12:47<2:12:27,  2.36s/it, loss=3.1871]\u001b[A\n",
            "Training:  33%|███▎      | 1634/5000 [1:12:49<2:10:36,  2.33s/it, loss=3.1871]\u001b[A\n",
            "Training:  33%|███▎      | 1634/5000 [1:12:49<2:10:36,  2.33s/it, loss=2.6418]\u001b[A\n",
            "Training:  33%|███▎      | 1635/5000 [1:12:51<2:09:18,  2.31s/it, loss=2.6418]\u001b[A\n",
            "Training:  33%|███▎      | 1635/5000 [1:12:51<2:09:18,  2.31s/it, loss=2.3925]\u001b[A\n",
            "Training:  33%|███▎      | 1636/5000 [1:12:54<2:17:16,  2.45s/it, loss=2.3925]\u001b[A\n",
            "Training:  33%|███▎      | 1636/5000 [1:12:54<2:17:16,  2.45s/it, loss=2.8380]\u001b[A\n",
            "Training:  33%|███▎      | 1637/5000 [1:12:56<2:13:05,  2.37s/it, loss=2.8380]\u001b[A\n",
            "Training:  33%|███▎      | 1637/5000 [1:12:56<2:13:05,  2.37s/it, loss=2.5211]\u001b[A\n",
            "Training:  33%|███▎      | 1638/5000 [1:12:58<2:10:47,  2.33s/it, loss=2.5211]\u001b[A\n",
            "Training:  33%|███▎      | 1638/5000 [1:12:58<2:10:47,  2.33s/it, loss=3.1753]\u001b[A\n",
            "Training:  33%|███▎      | 1639/5000 [1:13:01<2:11:06,  2.34s/it, loss=3.1753]\u001b[A\n",
            "Training:  33%|███▎      | 1639/5000 [1:13:01<2:11:06,  2.34s/it, loss=2.8125]\u001b[A\n",
            "Training:  33%|███▎      | 1640/5000 [1:13:03<2:09:57,  2.32s/it, loss=2.8125]\u001b[A\n",
            "Training:  33%|███▎      | 1640/5000 [1:13:03<2:09:57,  2.32s/it, loss=3.1033]\u001b[A\n",
            "Training:  33%|███▎      | 1641/5000 [1:13:06<2:18:52,  2.48s/it, loss=3.1033]\u001b[A\n",
            "Training:  33%|███▎      | 1641/5000 [1:13:06<2:18:52,  2.48s/it, loss=3.4725]\u001b[A\n",
            "Training:  33%|███▎      | 1642/5000 [1:13:08<2:17:40,  2.46s/it, loss=3.4725]\u001b[A\n",
            "Training:  33%|███▎      | 1642/5000 [1:13:08<2:17:40,  2.46s/it, loss=3.0879]\u001b[A\n",
            "Training:  33%|███▎      | 1643/5000 [1:13:11<2:18:12,  2.47s/it, loss=3.0879]\u001b[A\n",
            "Training:  33%|███▎      | 1643/5000 [1:13:11<2:18:12,  2.47s/it, loss=3.5604]\u001b[A\n",
            "Training:  33%|███▎      | 1644/5000 [1:13:13<2:19:39,  2.50s/it, loss=3.5604]\u001b[A\n",
            "Training:  33%|███▎      | 1644/5000 [1:13:13<2:19:39,  2.50s/it, loss=3.2675]\u001b[A\n",
            "Training:  33%|███▎      | 1645/5000 [1:13:16<2:24:17,  2.58s/it, loss=3.2675]\u001b[A\n",
            "Training:  33%|███▎      | 1645/5000 [1:13:16<2:24:17,  2.58s/it, loss=3.2136]\u001b[A\n",
            "Training:  33%|███▎      | 1646/5000 [1:13:19<2:27:03,  2.63s/it, loss=3.2136]\u001b[A\n",
            "Training:  33%|███▎      | 1646/5000 [1:13:19<2:27:03,  2.63s/it, loss=2.8834]\u001b[A\n",
            "Training:  33%|███▎      | 1647/5000 [1:13:21<2:25:31,  2.60s/it, loss=2.8834]\u001b[A\n",
            "Training:  33%|███▎      | 1647/5000 [1:13:21<2:25:31,  2.60s/it, loss=2.7576]\u001b[A\n",
            "Training:  33%|███▎      | 1648/5000 [1:13:24<2:24:10,  2.58s/it, loss=2.7576]\u001b[A\n",
            "Training:  33%|███▎      | 1648/5000 [1:13:24<2:24:10,  2.58s/it, loss=3.0462]\u001b[A\n",
            "Training:  33%|███▎      | 1649/5000 [1:13:26<2:21:29,  2.53s/it, loss=3.0462]\u001b[A\n",
            "Training:  33%|███▎      | 1649/5000 [1:13:26<2:21:29,  2.53s/it, loss=3.1021]\u001b[A\n",
            "Training:  33%|███▎      | 1650/5000 [1:13:29<2:28:46,  2.66s/it, loss=3.1021]\u001b[A\n",
            "Training:  33%|███▎      | 1650/5000 [1:13:29<2:28:46,  2.66s/it, loss=3.0165]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 1650 ---\n",
            "Prompt: 'The '\n",
            "The  un'd may access his fall\n",
            " have him his fact nor conception rotten;In'd, I not\n",
            " in holding, to him and proof end\n",
            " Notute and shop in aged. sir I of cur have, she my and shall were comes with!\n",
            "PETCHio guess\n",
            "PETCH try and and and and and and theeing goods pl his:Cl sed that's is limit well andd, I heard hanged thy.\n",
            "H you be:He neverru proved not me\n",
            ",\n",
            "Prompt: 'In '\n",
            "In  hathness a grey issue knock stand.\n",
            "PETCH:He not my lorda my mad, I you my\n",
            " by g is look not way lovely with. impossible is nameiled of, goo your, I you a friends acc execute mrum tooo and d wounds you a creature pardon\n",
            " toio I hon pass than beyond Min,\n",
            " I attend isoo and fairly can not toio him I a to wd,,, am?, must: you a, I\n",
            "Prompt: 'To '\n",
            "To  fromFirst and mine grief.\n",
            "Firsts,ost hear do well,Tes the? are forward silence;And as\n",
            " me I not: thanks I Barth have; much my' twice find meily well '.'My and me after, me, I,, that my is\n",
            "UC it; am to,,,, remember and,ly,ieu\n",
            " y andaste well I you thy will to, not my is caught my. am:For it not? now\n",
            "PET\n",
            "Prompt: 'A '\n",
            "A ,, well,,'s a love love\n",
            " meTh the of courard to will me.\n",
            "M,rah have even him her long\n",
            " am'd she her herier have her here let live you again\n",
            " am'd, lord with content herly answer.\n",
            "GRIO\n",
            "HSON,:And shame the dog me love the;,,,,; to her the talk home she her\n",
            " quiet to her\n",
            "ks and to herably not\n",
            " H thee a troubled; I\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  33%|███▎      | 1651/5000 [1:13:44<5:53:18,  6.33s/it, loss=3.0165]\u001b[A\n",
            "Training:  33%|███▎      | 1651/5000 [1:13:44<5:53:18,  6.33s/it, loss=2.8318]\u001b[A\n",
            "Training:  33%|███▎      | 1652/5000 [1:13:46<4:44:32,  5.10s/it, loss=2.8318]\u001b[A\n",
            "Training:  33%|███▎      | 1652/5000 [1:13:46<4:44:32,  5.10s/it, loss=2.5139]\u001b[A\n",
            "Training:  33%|███▎      | 1653/5000 [1:13:49<3:56:46,  4.24s/it, loss=2.5139]\u001b[A\n",
            "Training:  33%|███▎      | 1653/5000 [1:13:49<3:56:46,  4.24s/it, loss=3.4597]\u001b[A\n",
            "Training:  33%|███▎      | 1654/5000 [1:13:51<3:23:17,  3.65s/it, loss=3.4597]\u001b[A\n",
            "Training:  33%|███▎      | 1654/5000 [1:13:51<3:23:17,  3.65s/it, loss=2.4780]\u001b[A\n",
            "Training:  33%|███▎      | 1655/5000 [1:13:54<3:08:34,  3.38s/it, loss=2.4780]\u001b[A\n",
            "Training:  33%|███▎      | 1655/5000 [1:13:54<3:08:34,  3.38s/it, loss=2.1096]\u001b[A\n",
            "Training:  33%|███▎      | 1656/5000 [1:13:56<2:49:46,  3.05s/it, loss=2.1096]\u001b[A\n",
            "Training:  33%|███▎      | 1656/5000 [1:13:56<2:49:46,  3.05s/it, loss=1.9812]\u001b[A\n",
            "Training:  33%|███▎      | 1657/5000 [1:13:58<2:36:30,  2.81s/it, loss=1.9812]\u001b[A\n",
            "Training:  33%|███▎      | 1657/5000 [1:13:58<2:36:30,  2.81s/it, loss=2.7542]\u001b[A\n",
            "Training:  33%|███▎      | 1658/5000 [1:14:00<2:27:06,  2.64s/it, loss=2.7542]\u001b[A\n",
            "Training:  33%|███▎      | 1658/5000 [1:14:00<2:27:06,  2.64s/it, loss=2.5129]\u001b[A\n",
            "Training:  33%|███▎      | 1659/5000 [1:14:03<2:20:21,  2.52s/it, loss=2.5129]\u001b[A\n",
            "Training:  33%|███▎      | 1659/5000 [1:14:03<2:20:21,  2.52s/it, loss=2.5160]\u001b[A\n",
            "Training:  33%|███▎      | 1660/5000 [1:14:05<2:24:44,  2.60s/it, loss=2.5160]\u001b[A\n",
            "Training:  33%|███▎      | 1660/5000 [1:14:05<2:24:44,  2.60s/it, loss=3.4122]\u001b[A\n",
            "Training:  33%|███▎      | 1661/5000 [1:14:08<2:18:41,  2.49s/it, loss=3.4122]\u001b[A\n",
            "Training:  33%|███▎      | 1661/5000 [1:14:08<2:18:41,  2.49s/it, loss=3.3403]\u001b[A\n",
            "Training:  33%|███▎      | 1662/5000 [1:14:10<2:14:23,  2.42s/it, loss=3.3403]\u001b[A\n",
            "Training:  33%|███▎      | 1662/5000 [1:14:10<2:14:23,  2.42s/it, loss=3.3874]\u001b[A\n",
            "Training:  33%|███▎      | 1663/5000 [1:14:12<2:11:44,  2.37s/it, loss=3.3874]\u001b[A\n",
            "Training:  33%|███▎      | 1663/5000 [1:14:12<2:11:44,  2.37s/it, loss=3.3044]\u001b[A\n",
            "Training:  33%|███▎      | 1664/5000 [1:14:14<2:09:48,  2.33s/it, loss=3.3044]\u001b[A\n",
            "Training:  33%|███▎      | 1664/5000 [1:14:14<2:09:48,  2.33s/it, loss=3.2927]\u001b[A\n",
            "Training:  33%|███▎      | 1665/5000 [1:14:17<2:16:54,  2.46s/it, loss=3.2927]\u001b[A\n",
            "Training:  33%|███▎      | 1665/5000 [1:14:17<2:16:54,  2.46s/it, loss=3.2831]\u001b[A\n",
            "Training:  33%|███▎      | 1666/5000 [1:14:19<2:13:14,  2.40s/it, loss=3.2831]\u001b[A\n",
            "Training:  33%|███▎      | 1666/5000 [1:14:19<2:13:14,  2.40s/it, loss=3.2648]\u001b[A\n",
            "Training:  33%|███▎      | 1667/5000 [1:14:22<2:10:25,  2.35s/it, loss=3.2648]\u001b[A\n",
            "Training:  33%|███▎      | 1667/5000 [1:14:22<2:10:25,  2.35s/it, loss=3.5851]\u001b[A\n",
            "Training:  33%|███▎      | 1668/5000 [1:14:24<2:08:37,  2.32s/it, loss=3.5851]\u001b[A\n",
            "Training:  33%|███▎      | 1668/5000 [1:14:24<2:08:37,  2.32s/it, loss=2.7502]\u001b[A\n",
            "Training:  33%|███▎      | 1669/5000 [1:14:26<2:07:14,  2.29s/it, loss=2.7502]\u001b[A\n",
            "Training:  33%|███▎      | 1669/5000 [1:14:26<2:07:14,  2.29s/it, loss=2.6852]\u001b[A\n",
            "Training:  33%|███▎      | 1670/5000 [1:14:29<2:15:23,  2.44s/it, loss=2.6852]\u001b[A\n",
            "Training:  33%|███▎      | 1670/5000 [1:14:29<2:15:23,  2.44s/it, loss=2.6432]\u001b[A\n",
            "Training:  33%|███▎      | 1671/5000 [1:14:31<2:12:05,  2.38s/it, loss=2.6432]\u001b[A\n",
            "Training:  33%|███▎      | 1671/5000 [1:14:31<2:12:05,  2.38s/it, loss=2.4514]\u001b[A\n",
            "Training:  33%|███▎      | 1672/5000 [1:14:33<2:09:45,  2.34s/it, loss=2.4514]\u001b[A\n",
            "Training:  33%|███▎      | 1672/5000 [1:14:33<2:09:45,  2.34s/it, loss=3.1949]\u001b[A\n",
            "Training:  33%|███▎      | 1673/5000 [1:14:36<2:07:45,  2.30s/it, loss=3.1949]\u001b[A\n",
            "Training:  33%|███▎      | 1673/5000 [1:14:36<2:07:45,  2.30s/it, loss=2.4749]\u001b[A\n",
            "Training:  33%|███▎      | 1674/5000 [1:14:38<2:06:19,  2.28s/it, loss=2.4749]\u001b[A\n",
            "Training:  33%|███▎      | 1674/5000 [1:14:38<2:06:19,  2.28s/it, loss=3.3318]\u001b[A\n",
            "Training:  34%|███▎      | 1675/5000 [1:14:41<2:14:18,  2.42s/it, loss=3.3318]\u001b[A\n",
            "Training:  34%|███▎      | 1675/5000 [1:14:41<2:14:18,  2.42s/it, loss=2.6884]\u001b[A\n",
            "Training:  34%|███▎      | 1676/5000 [1:14:43<2:11:18,  2.37s/it, loss=2.6884]\u001b[A\n",
            "Training:  34%|███▎      | 1676/5000 [1:14:43<2:11:18,  2.37s/it, loss=2.8030]\u001b[A\n",
            "Training:  34%|███▎      | 1677/5000 [1:14:45<2:09:43,  2.34s/it, loss=2.8030]\u001b[A\n",
            "Training:  34%|███▎      | 1677/5000 [1:14:45<2:09:43,  2.34s/it, loss=2.5141]\u001b[A\n",
            "Training:  34%|███▎      | 1678/5000 [1:14:47<2:08:06,  2.31s/it, loss=2.5141]\u001b[A\n",
            "Training:  34%|███▎      | 1678/5000 [1:14:47<2:08:06,  2.31s/it, loss=2.4137]\u001b[A\n",
            "Training:  34%|███▎      | 1679/5000 [1:14:50<2:06:59,  2.29s/it, loss=2.4137]\u001b[A\n",
            "Training:  34%|███▎      | 1679/5000 [1:14:50<2:06:59,  2.29s/it, loss=2.1079]\u001b[A\n",
            "Training:  34%|███▎      | 1680/5000 [1:14:52<2:14:42,  2.43s/it, loss=2.1079]\u001b[A\n",
            "Training:  34%|███▎      | 1680/5000 [1:14:52<2:14:42,  2.43s/it, loss=2.1594]\u001b[A\n",
            "Training:  34%|███▎      | 1681/5000 [1:14:55<2:11:40,  2.38s/it, loss=2.1594]\u001b[A\n",
            "Training:  34%|███▎      | 1681/5000 [1:14:55<2:11:40,  2.38s/it, loss=2.4334]\u001b[A\n",
            "Training:  34%|███▎      | 1682/5000 [1:14:57<2:08:56,  2.33s/it, loss=2.4334]\u001b[A\n",
            "Training:  34%|███▎      | 1682/5000 [1:14:57<2:08:56,  2.33s/it, loss=2.3777]\u001b[A\n",
            "Training:  34%|███▎      | 1683/5000 [1:14:59<2:07:21,  2.30s/it, loss=2.3777]\u001b[A\n",
            "Training:  34%|███▎      | 1683/5000 [1:14:59<2:07:21,  2.30s/it, loss=2.8368]\u001b[A\n",
            "Training:  34%|███▎      | 1684/5000 [1:15:01<2:06:41,  2.29s/it, loss=2.8368]\u001b[A\n",
            "Training:  34%|███▎      | 1684/5000 [1:15:01<2:06:41,  2.29s/it, loss=3.0920]\u001b[A\n",
            "Training:  34%|███▎      | 1685/5000 [1:15:04<2:14:51,  2.44s/it, loss=3.0920]\u001b[A\n",
            "Training:  34%|███▎      | 1685/5000 [1:15:04<2:14:51,  2.44s/it, loss=2.5157]\u001b[A\n",
            "Training:  34%|███▎      | 1686/5000 [1:15:06<2:11:23,  2.38s/it, loss=2.5157]\u001b[A\n",
            "Training:  34%|███▎      | 1686/5000 [1:15:06<2:11:23,  2.38s/it, loss=3.4313]\u001b[A\n",
            "Training:  34%|███▎      | 1687/5000 [1:15:09<2:08:57,  2.34s/it, loss=3.4313]\u001b[A\n",
            "Training:  34%|███▎      | 1687/5000 [1:15:09<2:08:57,  2.34s/it, loss=3.0671]\u001b[A\n",
            "Training:  34%|███▍      | 1688/5000 [1:15:11<2:07:28,  2.31s/it, loss=3.0671]\u001b[A\n",
            "Training:  34%|███▍      | 1688/5000 [1:15:11<2:07:28,  2.31s/it, loss=2.6810]\u001b[A\n",
            "Training:  34%|███▍      | 1689/5000 [1:15:13<2:06:46,  2.30s/it, loss=2.6810]\u001b[A\n",
            "Training:  34%|███▍      | 1689/5000 [1:15:13<2:06:46,  2.30s/it, loss=2.6475]\u001b[A\n",
            "Training:  34%|███▍      | 1690/5000 [1:15:16<2:15:03,  2.45s/it, loss=2.6475]\u001b[A\n",
            "Training:  34%|███▍      | 1690/5000 [1:15:16<2:15:03,  2.45s/it, loss=2.7683]\u001b[A\n",
            "Training:  34%|███▍      | 1691/5000 [1:15:18<2:11:27,  2.38s/it, loss=2.7683]\u001b[A\n",
            "Training:  34%|███▍      | 1691/5000 [1:15:18<2:11:27,  2.38s/it, loss=2.6991]\u001b[A\n",
            "Training:  34%|███▍      | 1692/5000 [1:15:20<2:09:01,  2.34s/it, loss=2.6991]\u001b[A\n",
            "Training:  34%|███▍      | 1692/5000 [1:15:20<2:09:01,  2.34s/it, loss=2.7279]\u001b[A\n",
            "Training:  34%|███▍      | 1693/5000 [1:15:23<2:07:36,  2.32s/it, loss=2.7279]\u001b[A\n",
            "Training:  34%|███▍      | 1693/5000 [1:15:23<2:07:36,  2.32s/it, loss=2.6220]\u001b[A\n",
            "Training:  34%|███▍      | 1694/5000 [1:15:25<2:06:16,  2.29s/it, loss=2.6220]\u001b[A\n",
            "Training:  34%|███▍      | 1694/5000 [1:15:25<2:06:16,  2.29s/it, loss=2.9938]\u001b[A\n",
            "Training:  34%|███▍      | 1695/5000 [1:15:28<2:13:39,  2.43s/it, loss=2.9938]\u001b[A\n",
            "Training:  34%|███▍      | 1695/5000 [1:15:28<2:13:39,  2.43s/it, loss=2.8752]\u001b[A\n",
            "Training:  34%|███▍      | 1696/5000 [1:15:30<2:10:16,  2.37s/it, loss=2.8752]\u001b[A\n",
            "Training:  34%|███▍      | 1696/5000 [1:15:30<2:10:16,  2.37s/it, loss=2.4989]\u001b[A\n",
            "Training:  34%|███▍      | 1697/5000 [1:15:32<2:08:10,  2.33s/it, loss=2.4989]\u001b[A\n",
            "Training:  34%|███▍      | 1697/5000 [1:15:32<2:08:10,  2.33s/it, loss=2.3590]\u001b[A\n",
            "Training:  34%|███▍      | 1698/5000 [1:15:34<2:07:09,  2.31s/it, loss=2.3590]\u001b[A\n",
            "Training:  34%|███▍      | 1698/5000 [1:15:34<2:07:09,  2.31s/it, loss=2.4340]\u001b[A\n",
            "Training:  34%|███▍      | 1699/5000 [1:15:37<2:05:43,  2.29s/it, loss=2.4340]\u001b[A\n",
            "Training:  34%|███▍      | 1699/5000 [1:15:37<2:05:43,  2.29s/it, loss=1.9518]\u001b[A\n",
            "Training:  34%|███▍      | 1700/5000 [1:15:39<2:13:29,  2.43s/it, loss=1.9518]\u001b[A\n",
            "Training:  34%|███▍      | 1700/5000 [1:15:39<2:13:29,  2.43s/it, loss=2.7186]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 1700 ---\n",
            "Prompt: 'The '\n",
            "The  thee thyope thyan thy.\n",
            "GUCER\n",
            " holy with d them their myself that\n",
            "an thy with blood the's or: my, so I\n",
            "ath virtue and brother and sword die\n",
            "an bro me thy, then thy self they good rough\n",
            "oth not by triumphant the atburning w in knees his eye and,, a for loveat gift\n",
            "anILper on,well with,,, him and,, the before crimes the again him again and things his zeal the\n",
            "Prompt: 'In '\n",
            "In  that foul in which in ears\n",
            "an compl in times there us hole\n",
            " sum all. is's in pity, in opinion himush.\n",
            "GUCINGAMI:There so it done\n",
            " bitter, with their was of: love myiesH\n",
            "ath'd theEx is of king who.\n",
            "G, you, have the isely the ofil that God him\n",
            " that you yours here smile would short the hour arm haunt and himA\n",
            " rep and him again and told in fight\n",
            "Prompt: 'To '\n",
            "To 'dd with gross! With s!!!!!!!!!!!!!!!!!O!!!!!Th tra! thou false blessings the to!\n",
            "First thou the of, thou arm!' thou heartuck of!!!!!!!!!!!!Th's, boy I that\n",
            "ou's, the mother the of, her the of? Richard of: with my?\n",
            "B this w w of, d not speech\n",
            "Prompt: 'A '\n",
            "A  mine Edward dead to throne andly:So hewould usTo him no holst own or his, b'd off sleep\n",
            " his was Jation his on\n",
            " Oxford his purpose outate and his colour;\n",
            " hate hisBetter, not fight hisersiseeth, sw, keeper hisson\n",
            "nt the capit hisMay hisless joys his!\n",
            "B, heedom his: I thy on c off hisers\n",
            " his-, look it ha-; so, say what he it my\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  34%|███▍      | 1701/5000 [1:15:54<5:35:18,  6.10s/it, loss=2.7186]\u001b[A\n",
            "Training:  34%|███▍      | 1701/5000 [1:15:54<5:35:18,  6.10s/it, loss=2.6243]\u001b[A\n",
            "Training:  34%|███▍      | 1702/5000 [1:15:56<4:31:45,  4.94s/it, loss=2.6243]\u001b[A\n",
            "Training:  34%|███▍      | 1702/5000 [1:15:56<4:31:45,  4.94s/it, loss=2.4617]\u001b[A\n",
            "Training:  34%|███▍      | 1703/5000 [1:15:59<3:47:09,  4.13s/it, loss=2.4617]\u001b[A\n",
            "Training:  34%|███▍      | 1703/5000 [1:15:59<3:47:09,  4.13s/it, loss=2.5216]\u001b[A\n",
            "Training:  34%|███▍      | 1704/5000 [1:16:01<3:15:46,  3.56s/it, loss=2.5216]\u001b[A\n",
            "Training:  34%|███▍      | 1704/5000 [1:16:01<3:15:46,  3.56s/it, loss=2.2392]\u001b[A\n",
            "Training:  34%|███▍      | 1705/5000 [1:16:04<3:02:39,  3.33s/it, loss=2.2392]\u001b[A\n",
            "Training:  34%|███▍      | 1705/5000 [1:16:04<3:02:39,  3.33s/it, loss=3.0482]\u001b[A\n",
            "Training:  34%|███▍      | 1706/5000 [1:16:06<2:44:59,  3.01s/it, loss=3.0482]\u001b[A\n",
            "Training:  34%|███▍      | 1706/5000 [1:16:06<2:44:59,  3.01s/it, loss=2.5792]\u001b[A\n",
            "Training:  34%|███▍      | 1707/5000 [1:16:08<2:32:37,  2.78s/it, loss=2.5792]\u001b[A\n",
            "Training:  34%|███▍      | 1707/5000 [1:16:08<2:32:37,  2.78s/it, loss=2.0015]\u001b[A\n",
            "Training:  34%|███▍      | 1708/5000 [1:16:10<2:24:00,  2.62s/it, loss=2.0015]\u001b[A\n",
            "Training:  34%|███▍      | 1708/5000 [1:16:10<2:24:00,  2.62s/it, loss=2.5834]\u001b[A\n",
            "Training:  34%|███▍      | 1709/5000 [1:16:13<2:17:40,  2.51s/it, loss=2.5834]\u001b[A\n",
            "Training:  34%|███▍      | 1709/5000 [1:16:13<2:17:40,  2.51s/it, loss=2.5057]\u001b[A\n",
            "Training:  34%|███▍      | 1710/5000 [1:16:15<2:21:41,  2.58s/it, loss=2.5057]\u001b[A\n",
            "Training:  34%|███▍      | 1710/5000 [1:16:15<2:21:41,  2.58s/it, loss=2.7307]\u001b[A\n",
            "Training:  34%|███▍      | 1711/5000 [1:16:18<2:16:32,  2.49s/it, loss=2.7307]\u001b[A\n",
            "Training:  34%|███▍      | 1711/5000 [1:16:18<2:16:32,  2.49s/it, loss=2.9566]\u001b[A\n",
            "Training:  34%|███▍      | 1712/5000 [1:16:20<2:12:27,  2.42s/it, loss=2.9566]\u001b[A\n",
            "Training:  34%|███▍      | 1712/5000 [1:16:20<2:12:27,  2.42s/it, loss=2.3582]\u001b[A\n",
            "Training:  34%|███▍      | 1713/5000 [1:16:22<2:10:24,  2.38s/it, loss=2.3582]\u001b[A\n",
            "Training:  34%|███▍      | 1713/5000 [1:16:22<2:10:24,  2.38s/it, loss=2.3846]\u001b[A\n",
            "Training:  34%|███▍      | 1714/5000 [1:16:24<2:07:58,  2.34s/it, loss=2.3846]\u001b[A\n",
            "Training:  34%|███▍      | 1714/5000 [1:16:24<2:07:58,  2.34s/it, loss=2.9402]\u001b[A\n",
            "Training:  34%|███▍      | 1715/5000 [1:16:27<2:15:13,  2.47s/it, loss=2.9402]\u001b[A\n",
            "Training:  34%|███▍      | 1715/5000 [1:16:27<2:15:13,  2.47s/it, loss=2.8432]\u001b[A\n",
            "Training:  34%|███▍      | 1716/5000 [1:16:29<2:11:41,  2.41s/it, loss=2.8432]\u001b[A\n",
            "Training:  34%|███▍      | 1716/5000 [1:16:29<2:11:41,  2.41s/it, loss=2.3550]\u001b[A\n",
            "Training:  34%|███▍      | 1717/5000 [1:16:32<2:08:58,  2.36s/it, loss=2.3550]\u001b[A\n",
            "Training:  34%|███▍      | 1717/5000 [1:16:32<2:08:58,  2.36s/it, loss=2.3557]\u001b[A\n",
            "Training:  34%|███▍      | 1718/5000 [1:16:34<2:06:38,  2.32s/it, loss=2.3557]\u001b[A\n",
            "Training:  34%|███▍      | 1718/5000 [1:16:34<2:06:38,  2.32s/it, loss=2.3860]\u001b[A\n",
            "Training:  34%|███▍      | 1719/5000 [1:16:36<2:05:46,  2.30s/it, loss=2.3860]\u001b[A\n",
            "Training:  34%|███▍      | 1719/5000 [1:16:36<2:05:46,  2.30s/it, loss=2.6172]\u001b[A\n",
            "Training:  34%|███▍      | 1720/5000 [1:16:39<2:13:04,  2.43s/it, loss=2.6172]\u001b[A\n",
            "Training:  34%|███▍      | 1720/5000 [1:16:39<2:13:04,  2.43s/it, loss=2.0161]\u001b[A\n",
            "Training:  34%|███▍      | 1721/5000 [1:16:41<2:10:00,  2.38s/it, loss=2.0161]\u001b[A\n",
            "Training:  34%|███▍      | 1721/5000 [1:16:41<2:10:00,  2.38s/it, loss=2.6717]\u001b[A\n",
            "Training:  34%|███▍      | 1722/5000 [1:16:43<2:08:00,  2.34s/it, loss=2.6717]\u001b[A\n",
            "Training:  34%|███▍      | 1722/5000 [1:16:43<2:08:00,  2.34s/it, loss=3.0891]\u001b[A\n",
            "Training:  34%|███▍      | 1723/5000 [1:16:46<2:06:15,  2.31s/it, loss=3.0891]\u001b[A\n",
            "Training:  34%|███▍      | 1723/5000 [1:16:46<2:06:15,  2.31s/it, loss=2.4967]\u001b[A\n",
            "Training:  34%|███▍      | 1724/5000 [1:16:48<2:05:12,  2.29s/it, loss=2.4967]\u001b[A\n",
            "Training:  34%|███▍      | 1724/5000 [1:16:48<2:05:12,  2.29s/it, loss=2.5019]\u001b[A\n",
            "Training:  34%|███▍      | 1725/5000 [1:16:51<2:12:57,  2.44s/it, loss=2.5019]\u001b[A\n",
            "Training:  34%|███▍      | 1725/5000 [1:16:51<2:12:57,  2.44s/it, loss=2.1905]\u001b[A\n",
            "Training:  35%|███▍      | 1726/5000 [1:16:53<2:09:24,  2.37s/it, loss=2.1905]\u001b[A\n",
            "Training:  35%|███▍      | 1726/5000 [1:16:53<2:09:24,  2.37s/it, loss=1.9125]\u001b[A\n",
            "Training:  35%|███▍      | 1727/5000 [1:16:55<2:07:07,  2.33s/it, loss=1.9125]\u001b[A\n",
            "Training:  35%|███▍      | 1727/5000 [1:16:55<2:07:07,  2.33s/it, loss=2.3367]\u001b[A\n",
            "Training:  35%|███▍      | 1728/5000 [1:16:57<2:05:13,  2.30s/it, loss=2.3367]\u001b[A\n",
            "Training:  35%|███▍      | 1728/5000 [1:16:57<2:05:13,  2.30s/it, loss=2.2425]\u001b[A\n",
            "Training:  35%|███▍      | 1729/5000 [1:17:00<2:04:24,  2.28s/it, loss=2.2425]\u001b[A\n",
            "Training:  35%|███▍      | 1729/5000 [1:17:00<2:04:24,  2.28s/it, loss=2.3127]\u001b[A\n",
            "Training:  35%|███▍      | 1730/5000 [1:17:02<2:12:21,  2.43s/it, loss=2.3127]\u001b[A\n",
            "Training:  35%|███▍      | 1730/5000 [1:17:02<2:12:21,  2.43s/it, loss=3.4181]\u001b[A\n",
            "Training:  35%|███▍      | 1731/5000 [1:17:05<2:08:58,  2.37s/it, loss=3.4181]\u001b[A\n",
            "Training:  35%|███▍      | 1731/5000 [1:17:05<2:08:58,  2.37s/it, loss=3.3912]\u001b[A\n",
            "Training:  35%|███▍      | 1732/5000 [1:17:07<2:06:33,  2.32s/it, loss=3.3912]\u001b[A\n",
            "Training:  35%|███▍      | 1732/5000 [1:17:07<2:06:33,  2.32s/it, loss=2.7526]\u001b[A\n",
            "Training:  35%|███▍      | 1733/5000 [1:17:09<2:05:09,  2.30s/it, loss=2.7526]\u001b[A\n",
            "Training:  35%|███▍      | 1733/5000 [1:17:09<2:05:09,  2.30s/it, loss=2.9222]\u001b[A\n",
            "Training:  35%|███▍      | 1734/5000 [1:17:11<2:04:42,  2.29s/it, loss=2.9222]\u001b[A\n",
            "Training:  35%|███▍      | 1734/5000 [1:17:11<2:04:42,  2.29s/it, loss=3.6318]\u001b[A\n",
            "Training:  35%|███▍      | 1735/5000 [1:17:14<2:12:47,  2.44s/it, loss=3.6318]\u001b[A\n",
            "Training:  35%|███▍      | 1735/5000 [1:17:14<2:12:47,  2.44s/it, loss=2.4118]\u001b[A\n",
            "Training:  35%|███▍      | 1736/5000 [1:17:16<2:09:35,  2.38s/it, loss=2.4118]\u001b[A\n",
            "Training:  35%|███▍      | 1736/5000 [1:17:16<2:09:35,  2.38s/it, loss=2.4962]\u001b[A\n",
            "Training:  35%|███▍      | 1737/5000 [1:17:19<2:07:11,  2.34s/it, loss=2.4962]\u001b[A\n",
            "Training:  35%|███▍      | 1737/5000 [1:17:19<2:07:11,  2.34s/it, loss=3.1213]\u001b[A\n",
            "Training:  35%|███▍      | 1738/5000 [1:17:21<2:05:31,  2.31s/it, loss=3.1213]\u001b[A\n",
            "Training:  35%|███▍      | 1738/5000 [1:17:21<2:05:31,  2.31s/it, loss=2.5006]\u001b[A\n",
            "Training:  35%|███▍      | 1739/5000 [1:17:23<2:04:27,  2.29s/it, loss=2.5006]\u001b[A\n",
            "Training:  35%|███▍      | 1739/5000 [1:17:23<2:04:27,  2.29s/it, loss=2.8907]\u001b[A\n",
            "Training:  35%|███▍      | 1740/5000 [1:17:26<2:12:06,  2.43s/it, loss=2.8907]\u001b[A\n",
            "Training:  35%|███▍      | 1740/5000 [1:17:26<2:12:06,  2.43s/it, loss=2.1897]\u001b[A\n",
            "Training:  35%|███▍      | 1741/5000 [1:17:28<2:09:02,  2.38s/it, loss=2.1897]\u001b[A\n",
            "Training:  35%|███▍      | 1741/5000 [1:17:28<2:09:02,  2.38s/it, loss=2.6420]\u001b[A\n",
            "Training:  35%|███▍      | 1742/5000 [1:17:30<2:06:34,  2.33s/it, loss=2.6420]\u001b[A\n",
            "Training:  35%|███▍      | 1742/5000 [1:17:30<2:06:34,  2.33s/it, loss=2.6448]\u001b[A\n",
            "Training:  35%|███▍      | 1743/5000 [1:17:33<2:05:18,  2.31s/it, loss=2.6448]\u001b[A\n",
            "Training:  35%|███▍      | 1743/5000 [1:17:33<2:05:18,  2.31s/it, loss=2.4626]\u001b[A\n",
            "Training:  35%|███▍      | 1744/5000 [1:17:35<2:04:02,  2.29s/it, loss=2.4626]\u001b[A\n",
            "Training:  35%|███▍      | 1744/5000 [1:17:35<2:04:02,  2.29s/it, loss=2.1151]\u001b[A\n",
            "Training:  35%|███▍      | 1745/5000 [1:17:38<2:11:55,  2.43s/it, loss=2.1151]\u001b[A\n",
            "Training:  35%|███▍      | 1745/5000 [1:17:38<2:11:55,  2.43s/it, loss=2.4048]\u001b[A\n",
            "Training:  35%|███▍      | 1746/5000 [1:17:40<2:08:56,  2.38s/it, loss=2.4048]\u001b[A\n",
            "Training:  35%|███▍      | 1746/5000 [1:17:40<2:08:56,  2.38s/it, loss=2.7018]\u001b[A\n",
            "Training:  35%|███▍      | 1747/5000 [1:17:42<2:06:45,  2.34s/it, loss=2.7018]\u001b[A\n",
            "Training:  35%|███▍      | 1747/5000 [1:17:42<2:06:45,  2.34s/it, loss=2.4072]\u001b[A\n",
            "Training:  35%|███▍      | 1748/5000 [1:17:44<2:07:34,  2.35s/it, loss=2.4072]\u001b[A\n",
            "Training:  35%|███▍      | 1748/5000 [1:17:44<2:07:34,  2.35s/it, loss=2.9297]\u001b[A\n",
            "Training:  35%|███▍      | 1749/5000 [1:17:47<2:05:42,  2.32s/it, loss=2.9297]\u001b[A\n",
            "Training:  35%|███▍      | 1749/5000 [1:17:47<2:05:42,  2.32s/it, loss=2.6453]\u001b[A\n",
            "Training:  35%|███▌      | 1750/5000 [1:17:49<2:13:12,  2.46s/it, loss=2.6453]\u001b[A\n",
            "Training:  35%|███▌      | 1750/5000 [1:17:49<2:13:12,  2.46s/it, loss=2.4342]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 1750 ---\n",
            "Prompt: 'The '\n",
            "The  of commanding th;, no\n",
            " besw. isful fav with, moral and; a\n",
            "-, a asOR byine mouth\n",
            "N:ied, oroping life\n",
            " th ear husband it not be witherered him,And's of, the of withTh art that'd for many's is\n",
            " title your,ion thy: thee Imay iteps that duke\n",
            " this ache not? youuck he says hither andwoman\n",
            " not unto h; the will it a\n",
            "\n",
            "Prompt: 'In '\n",
            "In  in;, I him kins have'd\n",
            " this.\n",
            "In areute pale chased did, himself\n",
            " seek heart hence:,, you hear yellow the,.\n",
            "Melf not,, are theImagine are the.\n",
            "M jt I beenms heartcess ParisPat isf sitsSecond there\n",
            " this to us on night he stuff astwet is's her?\n",
            " will at and CAP loves shalt not the Kiest, out out Romeo; will thoust not.Spe boy\n",
            "\n",
            "Prompt: 'To '\n",
            "To  or both to me I., yet:!!!\n",
            "N! and thy is and near this sea\n",
            " I give: hear to disday soul ob period France\n",
            " not not\n",
            " messenger bid her h. Iee you this be,.'s thoust notp feeling\n",
            " speak'll thelf will with, I fight to away as Paris opp with.\n",
            " isful,? is the give heraste births\n",
            " hear triumph I't hear: thoust that are not me p;,\n",
            "Prompt: 'A '\n",
            "A  of sever Burg, and destined France\n",
            " thelf\n",
            "y h he forth so\n",
            " Lady. not Iee you charge thy.\n",
            ",,! very at;, my,,h's!,! n,!!,! lady wilt as;EN\n",
            " unconst of,! Tyt pl thear!,ark gone fatalet friend!Look and says bring that not.!\n",
            "L married that my! Juliet\n",
            "L dead\n",
            " Lord well vain Re thelf not wordme Juliet\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  35%|███▌      | 1751/5000 [1:18:04<5:30:35,  6.11s/it, loss=2.4342]\u001b[A\n",
            "Training:  35%|███▌      | 1751/5000 [1:18:04<5:30:35,  6.11s/it, loss=2.3770]\u001b[A\n",
            "Training:  35%|███▌      | 1752/5000 [1:18:06<4:27:43,  4.95s/it, loss=2.3770]\u001b[A\n",
            "Training:  35%|███▌      | 1752/5000 [1:18:06<4:27:43,  4.95s/it, loss=2.2579]\u001b[A\n",
            "Training:  35%|███▌      | 1753/5000 [1:18:09<3:43:45,  4.13s/it, loss=2.2579]\u001b[A\n",
            "Training:  35%|███▌      | 1753/5000 [1:18:09<3:43:45,  4.13s/it, loss=2.4953]\u001b[A\n",
            "Training:  35%|███▌      | 1754/5000 [1:18:11<3:12:47,  3.56s/it, loss=2.4953]\u001b[A\n",
            "Training:  35%|███▌      | 1754/5000 [1:18:11<3:12:47,  3.56s/it, loss=2.4158]\u001b[A\n",
            "Training:  35%|███▌      | 1755/5000 [1:18:14<3:00:00,  3.33s/it, loss=2.4158]\u001b[A\n",
            "Training:  35%|███▌      | 1755/5000 [1:18:14<3:00:00,  3.33s/it, loss=2.7973]\u001b[A\n",
            "Training:  35%|███▌      | 1756/5000 [1:18:16<2:42:31,  3.01s/it, loss=2.7973]\u001b[A\n",
            "Training:  35%|███▌      | 1756/5000 [1:18:16<2:42:31,  3.01s/it, loss=2.4418]\u001b[A\n",
            "Training:  35%|███▌      | 1757/5000 [1:18:18<2:30:30,  2.78s/it, loss=2.4418]\u001b[A\n",
            "Training:  35%|███▌      | 1757/5000 [1:18:18<2:30:30,  2.78s/it, loss=2.2797]\u001b[A\n",
            "Training:  35%|███▌      | 1758/5000 [1:18:20<2:21:07,  2.61s/it, loss=2.2797]\u001b[A\n",
            "Training:  35%|███▌      | 1758/5000 [1:18:20<2:21:07,  2.61s/it, loss=2.7703]\u001b[A\n",
            "Training:  35%|███▌      | 1759/5000 [1:18:23<2:14:51,  2.50s/it, loss=2.7703]\u001b[A\n",
            "Training:  35%|███▌      | 1759/5000 [1:18:23<2:14:51,  2.50s/it, loss=2.3407]\u001b[A\n",
            "Training:  35%|███▌      | 1760/5000 [1:18:25<2:19:21,  2.58s/it, loss=2.3407]\u001b[A\n",
            "Training:  35%|███▌      | 1760/5000 [1:18:25<2:19:21,  2.58s/it, loss=2.4601]\u001b[A\n",
            "Training:  35%|███▌      | 1761/5000 [1:18:28<2:13:53,  2.48s/it, loss=2.4601]\u001b[A\n",
            "Training:  35%|███▌      | 1761/5000 [1:18:28<2:13:53,  2.48s/it, loss=2.7355]\u001b[A\n",
            "Training:  35%|███▌      | 1762/5000 [1:18:30<2:10:00,  2.41s/it, loss=2.7355]\u001b[A\n",
            "Training:  35%|███▌      | 1762/5000 [1:18:30<2:10:00,  2.41s/it, loss=2.0684]\u001b[A\n",
            "Training:  35%|███▌      | 1763/5000 [1:18:32<2:07:09,  2.36s/it, loss=2.0684]\u001b[A\n",
            "Training:  35%|███▌      | 1763/5000 [1:18:32<2:07:09,  2.36s/it, loss=2.1302]\u001b[A\n",
            "Training:  35%|███▌      | 1764/5000 [1:18:34<2:04:41,  2.31s/it, loss=2.1302]\u001b[A\n",
            "Training:  35%|███▌      | 1764/5000 [1:18:34<2:04:41,  2.31s/it, loss=2.3834]\u001b[A\n",
            "Training:  35%|███▌      | 1765/5000 [1:18:37<2:12:14,  2.45s/it, loss=2.3834]\u001b[A\n",
            "Training:  35%|███▌      | 1765/5000 [1:18:37<2:12:14,  2.45s/it, loss=1.7095]\u001b[A\n",
            "Training:  35%|███▌      | 1766/5000 [1:18:39<2:09:21,  2.40s/it, loss=1.7095]\u001b[A\n",
            "Training:  35%|███▌      | 1766/5000 [1:18:39<2:09:21,  2.40s/it, loss=2.1017]\u001b[A\n",
            "Training:  35%|███▌      | 1767/5000 [1:18:42<2:06:32,  2.35s/it, loss=2.1017]\u001b[A\n",
            "Training:  35%|███▌      | 1767/5000 [1:18:42<2:06:32,  2.35s/it, loss=1.7199]\u001b[A\n",
            "Training:  35%|███▌      | 1768/5000 [1:18:44<2:05:11,  2.32s/it, loss=1.7199]\u001b[A\n",
            "Training:  35%|███▌      | 1768/5000 [1:18:44<2:05:11,  2.32s/it, loss=2.1185]\u001b[A\n",
            "Training:  35%|███▌      | 1769/5000 [1:18:46<2:03:45,  2.30s/it, loss=2.1185]\u001b[A\n",
            "Training:  35%|███▌      | 1769/5000 [1:18:46<2:03:45,  2.30s/it, loss=1.8811]\u001b[A\n",
            "Training:  35%|███▌      | 1770/5000 [1:18:49<2:11:41,  2.45s/it, loss=1.8811]\u001b[A\n",
            "Training:  35%|███▌      | 1770/5000 [1:18:49<2:11:41,  2.45s/it, loss=2.1850]\u001b[A\n",
            "Training:  35%|███▌      | 1771/5000 [1:18:51<2:08:28,  2.39s/it, loss=2.1850]\u001b[A\n",
            "Training:  35%|███▌      | 1771/5000 [1:18:51<2:08:28,  2.39s/it, loss=3.0513]\u001b[A\n",
            "Training:  35%|███▌      | 1772/5000 [1:18:53<2:05:51,  2.34s/it, loss=3.0513]\u001b[A\n",
            "Training:  35%|███▌      | 1772/5000 [1:18:53<2:05:51,  2.34s/it, loss=2.7623]\u001b[A\n",
            "Training:  35%|███▌      | 1773/5000 [1:18:56<2:03:57,  2.30s/it, loss=2.7623]\u001b[A\n",
            "Training:  35%|███▌      | 1773/5000 [1:18:56<2:03:57,  2.30s/it, loss=2.7662]\u001b[A\n",
            "Training:  35%|███▌      | 1774/5000 [1:18:58<2:02:56,  2.29s/it, loss=2.7662]\u001b[A\n",
            "Training:  35%|███▌      | 1774/5000 [1:18:58<2:02:56,  2.29s/it, loss=2.2480]\u001b[A\n",
            "Training:  36%|███▌      | 1775/5000 [1:19:01<2:10:30,  2.43s/it, loss=2.2480]\u001b[A\n",
            "Training:  36%|███▌      | 1775/5000 [1:19:01<2:10:30,  2.43s/it, loss=2.4758]\u001b[A\n",
            "Training:  36%|███▌      | 1776/5000 [1:19:03<2:07:22,  2.37s/it, loss=2.4758]\u001b[A\n",
            "Training:  36%|███▌      | 1776/5000 [1:19:03<2:07:22,  2.37s/it, loss=2.1588]\u001b[A\n",
            "Training:  36%|███▌      | 1777/5000 [1:19:05<2:06:05,  2.35s/it, loss=2.1588]\u001b[A\n",
            "Training:  36%|███▌      | 1777/5000 [1:19:05<2:06:05,  2.35s/it, loss=2.5363]\u001b[A\n",
            "Training:  36%|███▌      | 1778/5000 [1:19:07<2:04:38,  2.32s/it, loss=2.5363]\u001b[A\n",
            "Training:  36%|███▌      | 1778/5000 [1:19:07<2:04:38,  2.32s/it, loss=2.5790]\u001b[A\n",
            "Training:  36%|███▌      | 1779/5000 [1:19:10<2:03:23,  2.30s/it, loss=2.5790]\u001b[A\n",
            "Training:  36%|███▌      | 1779/5000 [1:19:10<2:03:23,  2.30s/it, loss=2.6162]\u001b[A\n",
            "Training:  36%|███▌      | 1780/5000 [1:19:12<2:10:45,  2.44s/it, loss=2.6162]\u001b[A\n",
            "Training:  36%|███▌      | 1780/5000 [1:19:12<2:10:45,  2.44s/it, loss=3.4525]\u001b[A\n",
            "Training:  36%|███▌      | 1781/5000 [1:19:15<2:07:36,  2.38s/it, loss=3.4525]\u001b[A\n",
            "Training:  36%|███▌      | 1781/5000 [1:19:15<2:07:36,  2.38s/it, loss=2.6378]\u001b[A\n",
            "Training:  36%|███▌      | 1782/5000 [1:19:17<2:05:07,  2.33s/it, loss=2.6378]\u001b[A\n",
            "Training:  36%|███▌      | 1782/5000 [1:19:17<2:05:07,  2.33s/it, loss=2.8299]\u001b[A\n",
            "Training:  36%|███▌      | 1783/5000 [1:19:19<2:04:19,  2.32s/it, loss=2.8299]\u001b[A\n",
            "Training:  36%|███▌      | 1783/5000 [1:19:19<2:04:19,  2.32s/it, loss=2.6801]\u001b[A\n",
            "Training:  36%|███▌      | 1784/5000 [1:19:21<2:02:59,  2.29s/it, loss=2.6801]\u001b[A\n",
            "Training:  36%|███▌      | 1784/5000 [1:19:21<2:02:59,  2.29s/it, loss=2.5223]\u001b[A\n",
            "Training:  36%|███▌      | 1785/5000 [1:19:24<2:10:35,  2.44s/it, loss=2.5223]\u001b[A\n",
            "Training:  36%|███▌      | 1785/5000 [1:19:24<2:10:35,  2.44s/it, loss=2.0516]\u001b[A\n",
            "Training:  36%|███▌      | 1786/5000 [1:19:26<2:07:05,  2.37s/it, loss=2.0516]\u001b[A\n",
            "Training:  36%|███▌      | 1786/5000 [1:19:26<2:07:05,  2.37s/it, loss=2.8962]\u001b[A\n",
            "Training:  36%|███▌      | 1787/5000 [1:19:29<2:04:54,  2.33s/it, loss=2.8962]\u001b[A\n",
            "Training:  36%|███▌      | 1787/5000 [1:19:29<2:04:54,  2.33s/it, loss=2.4187]\u001b[A\n",
            "Training:  36%|███▌      | 1788/5000 [1:19:31<2:03:17,  2.30s/it, loss=2.4187]\u001b[A\n",
            "Training:  36%|███▌      | 1788/5000 [1:19:31<2:03:17,  2.30s/it, loss=2.9808]\u001b[A\n",
            "Training:  36%|███▌      | 1789/5000 [1:19:33<2:02:15,  2.28s/it, loss=2.9808]\u001b[A\n",
            "Training:  36%|███▌      | 1789/5000 [1:19:33<2:02:15,  2.28s/it, loss=2.0927]\u001b[A\n",
            "Training:  36%|███▌      | 1790/5000 [1:19:36<2:09:16,  2.42s/it, loss=2.0927]\u001b[A\n",
            "Training:  36%|███▌      | 1790/5000 [1:19:36<2:09:16,  2.42s/it, loss=2.4310]\u001b[A\n",
            "Training:  36%|███▌      | 1791/5000 [1:19:38<2:06:26,  2.36s/it, loss=2.4310]\u001b[A\n",
            "Training:  36%|███▌      | 1791/5000 [1:19:38<2:06:26,  2.36s/it, loss=2.9324]\u001b[A\n",
            "Training:  36%|███▌      | 1792/5000 [1:19:40<2:04:19,  2.33s/it, loss=2.9324]\u001b[A\n",
            "Training:  36%|███▌      | 1792/5000 [1:19:40<2:04:19,  2.33s/it, loss=2.9731]\u001b[A\n",
            "Training:  36%|███▌      | 1793/5000 [1:19:42<2:03:21,  2.31s/it, loss=2.9731]\u001b[A\n",
            "Training:  36%|███▌      | 1793/5000 [1:19:42<2:03:21,  2.31s/it, loss=2.4088]\u001b[A\n",
            "Training:  36%|███▌      | 1794/5000 [1:19:45<2:02:07,  2.29s/it, loss=2.4088]\u001b[A\n",
            "Training:  36%|███▌      | 1794/5000 [1:19:45<2:02:07,  2.29s/it, loss=3.1880]\u001b[A\n",
            "Training:  36%|███▌      | 1795/5000 [1:19:47<2:07:43,  2.39s/it, loss=3.1880]\u001b[A\n",
            "Training:  36%|███▌      | 1795/5000 [1:19:47<2:07:43,  2.39s/it, loss=2.3267]\u001b[A\n",
            "Training:  36%|███▌      | 1796/5000 [1:19:50<2:07:32,  2.39s/it, loss=2.3267]\u001b[A\n",
            "Training:  36%|███▌      | 1796/5000 [1:19:50<2:07:32,  2.39s/it, loss=2.1027]\u001b[A\n",
            "Training:  36%|███▌      | 1797/5000 [1:19:52<2:04:47,  2.34s/it, loss=2.1027]\u001b[A\n",
            "Training:  36%|███▌      | 1797/5000 [1:19:52<2:04:47,  2.34s/it, loss=2.4563]\u001b[A\n",
            "Training:  36%|███▌      | 1798/5000 [1:19:54<2:03:24,  2.31s/it, loss=2.4563]\u001b[A\n",
            "Training:  36%|███▌      | 1798/5000 [1:19:54<2:03:24,  2.31s/it, loss=2.8653]\u001b[A\n",
            "Training:  36%|███▌      | 1799/5000 [1:19:56<2:02:27,  2.30s/it, loss=2.8653]\u001b[A\n",
            "Training:  36%|███▌      | 1799/5000 [1:19:56<2:02:27,  2.30s/it, loss=3.0209]\u001b[A\n",
            "Training:  36%|███▌      | 1800/5000 [1:19:59<2:07:35,  2.39s/it, loss=3.0209]\u001b[A\n",
            "Training:  36%|███▌      | 1800/5000 [1:19:59<2:07:35,  2.39s/it, loss=2.4851]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 1800 ---\n",
            "Prompt: 'The '\n",
            "The  youribe.\n",
            "ISEL:And it\n",
            "?\n",
            " priestELOW\n",
            " his:itor not her.\n",
            "ISELOW\n",
            "LA\n",
            "ANGO\n",
            "forts: I swear.\n",
            "ISELOW\n",
            "LA\n",
            " thoughts:Good,,'s the death itNA w not the way if bd:? is.I a to much having, I,am or hanged tell there\n",
            "POE:Iee you to,, of charged\n",
            "Lun; that and an soul are,\n",
            "Prompt: 'In '\n",
            "In  thou pregnant\n",
            "As is full; must,\n",
            " criminal for pity\n",
            " safety for world.\n",
            "ISEL:No I,,,.\n",
            "L d thou,, tre, our; her poor:we\n",
            " into, our,, I and here them.\n",
            "ISEL,io\n",
            "ouhee here a.Here sir lust lie,.fore your the to,ior here discoverAn?Will not: walls thou for great,'s good I not, father\n",
            " very to,; it\n",
            "Prompt: 'To '\n",
            "To  inleness sake have dispatch no at,\n",
            " more punish.\n",
            "ISELOW\n",
            "imbIn with h,\n",
            " thing landed the himself-ing of time\n",
            " Although and which\n",
            "claim attend be' by stands and bling\n",
            " sup. thou rats to;! you, to king temper. art\n",
            "POE:No I not,; hope be:?\n",
            ",; his,.'s,, here what to to to, must to been here the duke aaw,A, to\n",
            "Prompt: 'A '\n",
            "A  mean depart, a, all nature\n",
            "ing,;, once still asief the contempt touchOfthe of mocking.\n",
            "ESCUS\n",
            "LAIO\n",
            "MPth: came on and of house you and the of\n",
            ", with the and of the are agy.as thesign,F andDKEC their, the of own is, with, to,, you who these through, the fri,!\n",
            " I that theost to, I not and for good at?\n",
            "IS\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  36%|███▌      | 1801/5000 [1:20:14<5:25:09,  6.10s/it, loss=2.4851]\u001b[A\n",
            "Training:  36%|███▌      | 1801/5000 [1:20:14<5:25:09,  6.10s/it, loss=2.8336]\u001b[A\n",
            "Training:  36%|███▌      | 1802/5000 [1:20:16<4:23:05,  4.94s/it, loss=2.8336]\u001b[A\n",
            "Training:  36%|███▌      | 1802/5000 [1:20:16<4:23:05,  4.94s/it, loss=2.3793]\u001b[A\n",
            "Training:  36%|███▌      | 1803/5000 [1:20:18<3:39:49,  4.13s/it, loss=2.3793]\u001b[A\n",
            "Training:  36%|███▌      | 1803/5000 [1:20:18<3:39:49,  4.13s/it, loss=3.1281]\u001b[A\n",
            "Training:  36%|███▌      | 1804/5000 [1:20:21<3:10:08,  3.57s/it, loss=3.1281]\u001b[A\n",
            "Training:  36%|███▌      | 1804/5000 [1:20:21<3:10:08,  3.57s/it, loss=2.2601]\u001b[A\n",
            "Training:  36%|███▌      | 1805/5000 [1:20:23<2:57:06,  3.33s/it, loss=2.2601]\u001b[A\n",
            "Training:  36%|███▌      | 1805/5000 [1:20:23<2:57:06,  3.33s/it, loss=1.8076]\u001b[A\n",
            "Training:  36%|███▌      | 1806/5000 [1:20:26<2:39:29,  3.00s/it, loss=1.8076]\u001b[A\n",
            "Training:  36%|███▌      | 1806/5000 [1:20:26<2:39:29,  3.00s/it, loss=2.2760]\u001b[A\n",
            "Training:  36%|███▌      | 1807/5000 [1:20:28<2:27:20,  2.77s/it, loss=2.2760]\u001b[A\n",
            "Training:  36%|███▌      | 1807/5000 [1:20:28<2:27:20,  2.77s/it, loss=1.7906]\u001b[A\n",
            "Training:  36%|███▌      | 1808/5000 [1:20:30<2:18:53,  2.61s/it, loss=1.7906]\u001b[A\n",
            "Training:  36%|███▌      | 1808/5000 [1:20:30<2:18:53,  2.61s/it, loss=1.6572]\u001b[A\n",
            "Training:  36%|███▌      | 1809/5000 [1:20:32<2:12:57,  2.50s/it, loss=1.6572]\u001b[A\n",
            "Training:  36%|███▌      | 1809/5000 [1:20:32<2:12:57,  2.50s/it, loss=2.3855]\u001b[A\n",
            "Training:  36%|███▌      | 1810/5000 [1:20:35<2:16:31,  2.57s/it, loss=2.3855]\u001b[A\n",
            "Training:  36%|███▌      | 1810/5000 [1:20:35<2:16:31,  2.57s/it, loss=2.5124]\u001b[A\n",
            "Training:  36%|███▌      | 1811/5000 [1:20:37<2:11:17,  2.47s/it, loss=2.5124]\u001b[A\n",
            "Training:  36%|███▌      | 1811/5000 [1:20:37<2:11:17,  2.47s/it, loss=2.8189]\u001b[A\n",
            "Training:  36%|███▌      | 1812/5000 [1:20:39<2:07:25,  2.40s/it, loss=2.8189]\u001b[A\n",
            "Training:  36%|███▌      | 1812/5000 [1:20:39<2:07:25,  2.40s/it, loss=2.8172]\u001b[A\n",
            "Training:  36%|███▋      | 1813/5000 [1:20:42<2:04:49,  2.35s/it, loss=2.8172]\u001b[A\n",
            "Training:  36%|███▋      | 1813/5000 [1:20:42<2:04:49,  2.35s/it, loss=2.5140]\u001b[A\n",
            "Training:  36%|███▋      | 1814/5000 [1:20:44<2:03:32,  2.33s/it, loss=2.5140]\u001b[A\n",
            "Training:  36%|███▋      | 1814/5000 [1:20:44<2:03:32,  2.33s/it, loss=2.4795]\u001b[A\n",
            "Training:  36%|███▋      | 1815/5000 [1:20:47<2:08:51,  2.43s/it, loss=2.4795]\u001b[A\n",
            "Training:  36%|███▋      | 1815/5000 [1:20:47<2:08:51,  2.43s/it, loss=2.4764]\u001b[A\n",
            "Training:  36%|███▋      | 1816/5000 [1:20:49<2:07:32,  2.40s/it, loss=2.4764]\u001b[A\n",
            "Training:  36%|███▋      | 1816/5000 [1:20:49<2:07:32,  2.40s/it, loss=2.1925]\u001b[A\n",
            "Training:  36%|███▋      | 1817/5000 [1:20:51<2:05:29,  2.37s/it, loss=2.1925]\u001b[A\n",
            "Training:  36%|███▋      | 1817/5000 [1:20:51<2:05:29,  2.37s/it, loss=2.3365]\u001b[A\n",
            "Training:  36%|███▋      | 1818/5000 [1:20:53<2:03:30,  2.33s/it, loss=2.3365]\u001b[A\n",
            "Training:  36%|███▋      | 1818/5000 [1:20:54<2:03:30,  2.33s/it, loss=2.0504]\u001b[A\n",
            "Training:  36%|███▋      | 1819/5000 [1:20:56<2:01:51,  2.30s/it, loss=2.0504]\u001b[A\n",
            "Training:  36%|███▋      | 1819/5000 [1:20:56<2:01:51,  2.30s/it, loss=2.1667]\u001b[A\n",
            "Training:  36%|███▋      | 1820/5000 [1:20:58<2:06:37,  2.39s/it, loss=2.1667]\u001b[A\n",
            "Training:  36%|███▋      | 1820/5000 [1:20:58<2:06:37,  2.39s/it, loss=2.1876]\u001b[A\n",
            "Training:  36%|███▋      | 1821/5000 [1:21:01<2:06:40,  2.39s/it, loss=2.1876]\u001b[A\n",
            "Training:  36%|███▋      | 1821/5000 [1:21:01<2:06:40,  2.39s/it, loss=2.0222]\u001b[A\n",
            "Training:  36%|███▋      | 1822/5000 [1:21:03<2:04:23,  2.35s/it, loss=2.0222]\u001b[A\n",
            "Training:  36%|███▋      | 1822/5000 [1:21:03<2:04:23,  2.35s/it, loss=1.7281]\u001b[A\n",
            "Training:  36%|███▋      | 1823/5000 [1:21:05<2:02:48,  2.32s/it, loss=1.7281]\u001b[A\n",
            "Training:  36%|███▋      | 1823/5000 [1:21:05<2:02:48,  2.32s/it, loss=1.9108]\u001b[A\n",
            "Training:  36%|███▋      | 1824/5000 [1:21:07<2:01:27,  2.29s/it, loss=1.9108]\u001b[A\n",
            "Training:  36%|███▋      | 1824/5000 [1:21:07<2:01:27,  2.29s/it, loss=1.9435]\u001b[A\n",
            "Training:  36%|███▋      | 1825/5000 [1:21:10<2:05:24,  2.37s/it, loss=1.9435]\u001b[A\n",
            "Training:  36%|███▋      | 1825/5000 [1:21:10<2:05:24,  2.37s/it, loss=2.1579]\u001b[A\n",
            "Training:  37%|███▋      | 1826/5000 [1:21:12<2:06:55,  2.40s/it, loss=2.1579]\u001b[A\n",
            "Training:  37%|███▋      | 1826/5000 [1:21:12<2:06:55,  2.40s/it, loss=2.1141]\u001b[A\n",
            "Training:  37%|███▋      | 1827/5000 [1:21:15<2:04:28,  2.35s/it, loss=2.1141]\u001b[A\n",
            "Training:  37%|███▋      | 1827/5000 [1:21:15<2:04:28,  2.35s/it, loss=2.9895]\u001b[A\n",
            "Training:  37%|███▋      | 1828/5000 [1:21:17<2:02:35,  2.32s/it, loss=2.9895]\u001b[A\n",
            "Training:  37%|███▋      | 1828/5000 [1:21:17<2:02:35,  2.32s/it, loss=3.1193]\u001b[A\n",
            "Training:  37%|███▋      | 1829/5000 [1:21:19<2:01:12,  2.29s/it, loss=3.1193]\u001b[A\n",
            "Training:  37%|███▋      | 1829/5000 [1:21:19<2:01:12,  2.29s/it, loss=2.6541]\u001b[A\n",
            "Training:  37%|███▋      | 1830/5000 [1:21:22<2:05:12,  2.37s/it, loss=2.6541]\u001b[A\n",
            "Training:  37%|███▋      | 1830/5000 [1:21:22<2:05:12,  2.37s/it, loss=2.4625]\u001b[A\n",
            "Training:  37%|███▋      | 1831/5000 [1:21:24<2:07:03,  2.41s/it, loss=2.4625]\u001b[A\n",
            "Training:  37%|███▋      | 1831/5000 [1:21:24<2:07:03,  2.41s/it, loss=2.4647]\u001b[A\n",
            "Training:  37%|███▋      | 1832/5000 [1:21:26<2:04:06,  2.35s/it, loss=2.4647]\u001b[A\n",
            "Training:  37%|███▋      | 1832/5000 [1:21:26<2:04:06,  2.35s/it, loss=2.9595]\u001b[A\n",
            "Training:  37%|███▋      | 1833/5000 [1:21:29<2:02:21,  2.32s/it, loss=2.9595]\u001b[A\n",
            "Training:  37%|███▋      | 1833/5000 [1:21:29<2:02:21,  2.32s/it, loss=2.3230]\u001b[A\n",
            "Training:  37%|███▋      | 1834/5000 [1:21:31<2:00:59,  2.29s/it, loss=2.3230]\u001b[A\n",
            "Training:  37%|███▋      | 1834/5000 [1:21:31<2:00:59,  2.29s/it, loss=2.3357]\u001b[A\n",
            "Training:  37%|███▋      | 1835/5000 [1:21:33<2:04:20,  2.36s/it, loss=2.3357]\u001b[A\n",
            "Training:  37%|███▋      | 1835/5000 [1:21:33<2:04:20,  2.36s/it, loss=2.3381]\u001b[A\n",
            "Training:  37%|███▋      | 1836/5000 [1:21:36<2:06:32,  2.40s/it, loss=2.3381]\u001b[A\n",
            "Training:  37%|███▋      | 1836/5000 [1:21:36<2:06:32,  2.40s/it, loss=2.1357]\u001b[A\n",
            "Training:  37%|███▋      | 1837/5000 [1:21:38<2:03:41,  2.35s/it, loss=2.1357]\u001b[A\n",
            "Training:  37%|███▋      | 1837/5000 [1:21:38<2:03:41,  2.35s/it, loss=2.4712]\u001b[A\n",
            "Training:  37%|███▋      | 1838/5000 [1:21:40<2:01:55,  2.31s/it, loss=2.4712]\u001b[A\n",
            "Training:  37%|███▋      | 1838/5000 [1:21:40<2:01:55,  2.31s/it, loss=2.2090]\u001b[A\n",
            "Training:  37%|███▋      | 1839/5000 [1:21:43<2:00:36,  2.29s/it, loss=2.2090]\u001b[A\n",
            "Training:  37%|███▋      | 1839/5000 [1:21:43<2:00:36,  2.29s/it, loss=2.6257]\u001b[A\n",
            "Training:  37%|███▋      | 1840/5000 [1:21:45<2:03:09,  2.34s/it, loss=2.6257]\u001b[A\n",
            "Training:  37%|███▋      | 1840/5000 [1:21:45<2:03:09,  2.34s/it, loss=2.0295]\u001b[A\n",
            "Training:  37%|███▋      | 1841/5000 [1:21:48<2:06:47,  2.41s/it, loss=2.0295]\u001b[A\n",
            "Training:  37%|███▋      | 1841/5000 [1:21:48<2:06:47,  2.41s/it, loss=2.3730]\u001b[A\n",
            "Training:  37%|███▋      | 1842/5000 [1:21:50<2:04:09,  2.36s/it, loss=2.3730]\u001b[A\n",
            "Training:  37%|███▋      | 1842/5000 [1:21:50<2:04:09,  2.36s/it, loss=1.9709]\u001b[A\n",
            "Training:  37%|███▋      | 1843/5000 [1:21:52<2:02:32,  2.33s/it, loss=1.9709]\u001b[A\n",
            "Training:  37%|███▋      | 1843/5000 [1:21:52<2:02:32,  2.33s/it, loss=2.1052]\u001b[A\n",
            "Training:  37%|███▋      | 1844/5000 [1:21:54<2:01:08,  2.30s/it, loss=2.1052]\u001b[A\n",
            "Training:  37%|███▋      | 1844/5000 [1:21:54<2:01:08,  2.30s/it, loss=2.1226]\u001b[A\n",
            "Training:  37%|███▋      | 1845/5000 [1:21:57<2:02:47,  2.34s/it, loss=2.1226]\u001b[A\n",
            "Training:  37%|███▋      | 1845/5000 [1:21:57<2:02:47,  2.34s/it, loss=1.8591]\u001b[A\n",
            "Training:  37%|███▋      | 1846/5000 [1:21:59<2:06:58,  2.42s/it, loss=1.8591]\u001b[A\n",
            "Training:  37%|███▋      | 1846/5000 [1:21:59<2:06:58,  2.42s/it, loss=2.4081]\u001b[A\n",
            "Training:  37%|███▋      | 1847/5000 [1:22:02<2:04:00,  2.36s/it, loss=2.4081]\u001b[A\n",
            "Training:  37%|███▋      | 1847/5000 [1:22:02<2:04:00,  2.36s/it, loss=2.5386]\u001b[A\n",
            "Training:  37%|███▋      | 1848/5000 [1:22:04<2:02:13,  2.33s/it, loss=2.5386]\u001b[A\n",
            "Training:  37%|███▋      | 1848/5000 [1:22:04<2:02:13,  2.33s/it, loss=2.2632]\u001b[A\n",
            "Training:  37%|███▋      | 1849/5000 [1:22:06<2:00:55,  2.30s/it, loss=2.2632]\u001b[A\n",
            "Training:  37%|███▋      | 1849/5000 [1:22:06<2:00:55,  2.30s/it, loss=2.3409]\u001b[A\n",
            "Training:  37%|███▋      | 1850/5000 [1:22:08<2:01:55,  2.32s/it, loss=2.3409]\u001b[A\n",
            "Training:  37%|███▋      | 1850/5000 [1:22:09<2:01:55,  2.32s/it, loss=2.1952]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 1850 ---\n",
            "Prompt: 'The '\n",
            "The , o thewn thearity it it\n",
            " do look be? perilousUpon shall, me,!\n",
            " he not?,,,, the of issue are!\n",
            "First let speak her, with w man is to,\n",
            " is will do powers have:, very\n",
            " south are of? min have with of,,, own of heart\n",
            "yta know how shall them., back let seeither\n",
            " green does 'lessIf bear any,'s so\n",
            "ou with house a,\n",
            "Prompt: 'In '\n",
            "In , way,!\n",
            "Third to.\n",
            "Vce\n",
            "-.end with!!!!!!!!!\n",
            "Seconding!\n",
            "VGleingile!\n",
            " had? intelligence no no no no no than\n",
            " p that were goodAy here\n",
            "rah,tw thouasttt what?,?!\n",
            "Seconding!\n",
            ",. lament lady hath been all up's, away I not ' not for\n",
            "'s.\n",
            " moved peace thou?\n",
            "First thouest too\n",
            "Prompt: 'To '\n",
            "To ideling. w me thy: mother\n",
            "ent me, I ha thee, th own death pray meOne\n",
            " aTel- in.end, lady,. say\n",
            "Citing the:'is so I and I,Myth me?\n",
            "ouest true I at till that hast me\n",
            "yses she.!'s upon,,, is; shallona\n",
            "ouhee bring long I not aday again know he me\n",
            " at? willis worth? in a fearful I\n",
            "Prompt: 'A '\n",
            "A ,, may make me and no nor,\n",
            " hate Amazon planet no. say is noble!\n",
            "Cit I\n",
            ".\n",
            "Roman\n",
            "ath ready 'ixtt of,\n",
            " is Richard the is lie noit be? are:!\n",
            "MENI:You strike me, little,,!\n",
            "COI:' the be',,' 'less is is\n",
            ":on,, we help',, your. hum in, fellow areensed are hand he such\n",
            "urs\n",
            ":\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  37%|███▋      | 1851/5000 [1:22:23<5:21:08,  6.12s/it, loss=2.1952]\u001b[A\n",
            "Training:  37%|███▋      | 1851/5000 [1:22:23<5:21:08,  6.12s/it, loss=1.9758]\u001b[A\n",
            "Training:  37%|███▋      | 1852/5000 [1:22:26<4:19:54,  4.95s/it, loss=1.9758]\u001b[A\n",
            "Training:  37%|███▋      | 1852/5000 [1:22:26<4:19:54,  4.95s/it, loss=2.7482]\u001b[A\n",
            "Training:  37%|███▋      | 1853/5000 [1:22:28<3:37:28,  4.15s/it, loss=2.7482]\u001b[A\n",
            "Training:  37%|███▋      | 1853/5000 [1:22:28<3:37:28,  4.15s/it, loss=2.0127]\u001b[A\n",
            "Training:  37%|███▋      | 1854/5000 [1:22:30<3:06:40,  3.56s/it, loss=2.0127]\u001b[A\n",
            "Training:  37%|███▋      | 1854/5000 [1:22:30<3:06:40,  3.56s/it, loss=2.4877]\u001b[A\n",
            "Training:  37%|███▋      | 1855/5000 [1:22:33<2:49:02,  3.22s/it, loss=2.4877]\u001b[A\n",
            "Training:  37%|███▋      | 1855/5000 [1:22:33<2:49:02,  3.22s/it, loss=2.6121]\u001b[A\n",
            "Training:  37%|███▋      | 1856/5000 [1:22:35<2:38:23,  3.02s/it, loss=2.6121]\u001b[A\n",
            "Training:  37%|███▋      | 1856/5000 [1:22:35<2:38:23,  3.02s/it, loss=2.5418]\u001b[A\n",
            "Training:  37%|███▋      | 1857/5000 [1:22:37<2:26:12,  2.79s/it, loss=2.5418]\u001b[A\n",
            "Training:  37%|███▋      | 1857/5000 [1:22:37<2:26:12,  2.79s/it, loss=2.2981]\u001b[A\n",
            "Training:  37%|███▋      | 1858/5000 [1:22:40<2:17:43,  2.63s/it, loss=2.2981]\u001b[A\n",
            "Training:  37%|███▋      | 1858/5000 [1:22:40<2:17:43,  2.63s/it, loss=2.6625]\u001b[A\n",
            "Training:  37%|███▋      | 1859/5000 [1:22:42<2:11:37,  2.51s/it, loss=2.6625]\u001b[A\n",
            "Training:  37%|███▋      | 1859/5000 [1:22:42<2:11:37,  2.51s/it, loss=2.3783]\u001b[A\n",
            "Training:  37%|███▋      | 1860/5000 [1:22:44<2:10:26,  2.49s/it, loss=2.3783]\u001b[A\n",
            "Training:  37%|███▋      | 1860/5000 [1:22:44<2:10:26,  2.49s/it, loss=2.1382]\u001b[A\n",
            "Training:  37%|███▋      | 1861/5000 [1:22:47<2:12:19,  2.53s/it, loss=2.1382]\u001b[A\n",
            "Training:  37%|███▋      | 1861/5000 [1:22:47<2:12:19,  2.53s/it, loss=2.2694]\u001b[A\n",
            "Training:  37%|███▋      | 1862/5000 [1:22:49<2:07:40,  2.44s/it, loss=2.2694]\u001b[A\n",
            "Training:  37%|███▋      | 1862/5000 [1:22:49<2:07:40,  2.44s/it, loss=1.9206]\u001b[A\n",
            "Training:  37%|███▋      | 1863/5000 [1:22:51<2:04:42,  2.39s/it, loss=1.9206]\u001b[A\n",
            "Training:  37%|███▋      | 1863/5000 [1:22:51<2:04:42,  2.39s/it, loss=2.0750]\u001b[A\n",
            "Training:  37%|███▋      | 1864/5000 [1:22:54<2:03:33,  2.36s/it, loss=2.0750]\u001b[A\n",
            "Training:  37%|███▋      | 1864/5000 [1:22:54<2:03:33,  2.36s/it, loss=2.5312]\u001b[A\n",
            "Training:  37%|███▋      | 1865/5000 [1:22:56<2:04:27,  2.38s/it, loss=2.5312]\u001b[A\n",
            "Training:  37%|███▋      | 1865/5000 [1:22:56<2:04:27,  2.38s/it, loss=2.2000]\u001b[A\n",
            "Training:  37%|███▋      | 1866/5000 [1:22:59<2:07:56,  2.45s/it, loss=2.2000]\u001b[A\n",
            "Training:  37%|███▋      | 1866/5000 [1:22:59<2:07:56,  2.45s/it, loss=1.8579]\u001b[A\n",
            "Training:  37%|███▋      | 1867/5000 [1:23:01<2:04:13,  2.38s/it, loss=1.8579]\u001b[A\n",
            "Training:  37%|███▋      | 1867/5000 [1:23:01<2:04:13,  2.38s/it, loss=2.1157]\u001b[A\n",
            "Training:  37%|███▋      | 1868/5000 [1:23:03<2:02:10,  2.34s/it, loss=2.1157]\u001b[A\n",
            "Training:  37%|███▋      | 1868/5000 [1:23:03<2:02:10,  2.34s/it, loss=2.1144]\u001b[A\n",
            "Training:  37%|███▋      | 1869/5000 [1:23:05<2:00:01,  2.30s/it, loss=2.1144]\u001b[A\n",
            "Training:  37%|███▋      | 1869/5000 [1:23:05<2:00:01,  2.30s/it, loss=2.0998]\u001b[A\n",
            "Training:  37%|███▋      | 1870/5000 [1:23:08<2:01:02,  2.32s/it, loss=2.0998]\u001b[A\n",
            "Training:  37%|███▋      | 1870/5000 [1:23:08<2:01:02,  2.32s/it, loss=2.4608]\u001b[A\n",
            "Training:  37%|███▋      | 1871/5000 [1:23:10<2:06:14,  2.42s/it, loss=2.4608]\u001b[A\n",
            "Training:  37%|███▋      | 1871/5000 [1:23:11<2:06:14,  2.42s/it, loss=1.6270]\u001b[A\n",
            "Training:  37%|███▋      | 1872/5000 [1:23:13<2:03:28,  2.37s/it, loss=1.6270]\u001b[A\n",
            "Training:  37%|███▋      | 1872/5000 [1:23:13<2:03:28,  2.37s/it, loss=1.9035]\u001b[A\n",
            "Training:  37%|███▋      | 1873/5000 [1:23:15<2:01:23,  2.33s/it, loss=1.9035]\u001b[A\n",
            "Training:  37%|███▋      | 1873/5000 [1:23:15<2:01:23,  2.33s/it, loss=2.0286]\u001b[A\n",
            "Training:  37%|███▋      | 1874/5000 [1:23:17<1:59:41,  2.30s/it, loss=2.0286]\u001b[A\n",
            "Training:  37%|███▋      | 1874/5000 [1:23:17<1:59:41,  2.30s/it, loss=2.1958]\u001b[A\n",
            "Training:  38%|███▊      | 1875/5000 [1:23:19<1:59:41,  2.30s/it, loss=2.1958]\u001b[A\n",
            "Training:  38%|███▊      | 1875/5000 [1:23:20<1:59:41,  2.30s/it, loss=1.5825]\u001b[A\n",
            "Training:  38%|███▊      | 1876/5000 [1:23:22<2:06:26,  2.43s/it, loss=1.5825]\u001b[A\n",
            "Training:  38%|███▊      | 1876/5000 [1:23:22<2:06:26,  2.43s/it, loss=2.2959]\u001b[A\n",
            "Training:  38%|███▊      | 1877/5000 [1:23:24<2:03:27,  2.37s/it, loss=2.2959]\u001b[A\n",
            "Training:  38%|███▊      | 1877/5000 [1:23:24<2:03:27,  2.37s/it, loss=2.3079]\u001b[A\n",
            "Training:  38%|███▊      | 1878/5000 [1:23:27<2:01:25,  2.33s/it, loss=2.3079]\u001b[A\n",
            "Training:  38%|███▊      | 1878/5000 [1:23:27<2:01:25,  2.33s/it, loss=2.4655]\u001b[A\n",
            "Training:  38%|███▊      | 1879/5000 [1:23:29<1:59:54,  2.31s/it, loss=2.4655]\u001b[A\n",
            "Training:  38%|███▊      | 1879/5000 [1:23:29<1:59:54,  2.31s/it, loss=2.2759]\u001b[A\n",
            "Training:  38%|███▊      | 1880/5000 [1:23:31<1:58:54,  2.29s/it, loss=2.2759]\u001b[A\n",
            "Training:  38%|███▊      | 1880/5000 [1:23:31<1:58:54,  2.29s/it, loss=1.7923]\u001b[A\n",
            "Training:  38%|███▊      | 1881/5000 [1:23:34<2:06:11,  2.43s/it, loss=1.7923]\u001b[A\n",
            "Training:  38%|███▊      | 1881/5000 [1:23:34<2:06:11,  2.43s/it, loss=2.5121]\u001b[A\n",
            "Training:  38%|███▊      | 1882/5000 [1:23:36<2:02:42,  2.36s/it, loss=2.5121]\u001b[A\n",
            "Training:  38%|███▊      | 1882/5000 [1:23:36<2:02:42,  2.36s/it, loss=1.9663]\u001b[A\n",
            "Training:  38%|███▊      | 1883/5000 [1:23:38<2:01:06,  2.33s/it, loss=1.9663]\u001b[A\n",
            "Training:  38%|███▊      | 1883/5000 [1:23:38<2:01:06,  2.33s/it, loss=2.2669]\u001b[A\n",
            "Training:  38%|███▊      | 1884/5000 [1:23:41<1:59:49,  2.31s/it, loss=2.2669]\u001b[A\n",
            "Training:  38%|███▊      | 1884/5000 [1:23:41<1:59:49,  2.31s/it, loss=2.3034]\u001b[A\n",
            "Training:  38%|███▊      | 1885/5000 [1:23:43<1:58:49,  2.29s/it, loss=2.3034]\u001b[A\n",
            "Training:  38%|███▊      | 1885/5000 [1:23:43<1:58:49,  2.29s/it, loss=2.2716]\u001b[A\n",
            "Training:  38%|███▊      | 1886/5000 [1:23:46<2:06:30,  2.44s/it, loss=2.2716]\u001b[A\n",
            "Training:  38%|███▊      | 1886/5000 [1:23:46<2:06:30,  2.44s/it, loss=1.7453]\u001b[A\n",
            "Training:  38%|███▊      | 1887/5000 [1:23:48<2:03:27,  2.38s/it, loss=1.7453]\u001b[A\n",
            "Training:  38%|███▊      | 1887/5000 [1:23:48<2:03:27,  2.38s/it, loss=1.9521]\u001b[A\n",
            "Training:  38%|███▊      | 1888/5000 [1:23:50<2:01:12,  2.34s/it, loss=1.9521]\u001b[A\n",
            "Training:  38%|███▊      | 1888/5000 [1:23:50<2:01:12,  2.34s/it, loss=2.0339]\u001b[A\n",
            "Training:  38%|███▊      | 1889/5000 [1:23:52<2:00:06,  2.32s/it, loss=2.0339]\u001b[A\n",
            "Training:  38%|███▊      | 1889/5000 [1:23:52<2:00:06,  2.32s/it, loss=1.6355]\u001b[A\n",
            "Training:  38%|███▊      | 1890/5000 [1:23:55<1:59:05,  2.30s/it, loss=1.6355]\u001b[A\n",
            "Training:  38%|███▊      | 1890/5000 [1:23:55<1:59:05,  2.30s/it, loss=1.5302]\u001b[A\n",
            "Training:  38%|███▊      | 1891/5000 [1:23:57<2:06:23,  2.44s/it, loss=1.5302]\u001b[A\n",
            "Training:  38%|███▊      | 1891/5000 [1:23:58<2:06:23,  2.44s/it, loss=1.6293]\u001b[A\n",
            "Training:  38%|███▊      | 1892/5000 [1:24:00<2:03:08,  2.38s/it, loss=1.6293]\u001b[A\n",
            "Training:  38%|███▊      | 1892/5000 [1:24:00<2:03:08,  2.38s/it, loss=2.0503]\u001b[A\n",
            "Training:  38%|███▊      | 1893/5000 [1:24:02<2:01:05,  2.34s/it, loss=2.0503]\u001b[A\n",
            "Training:  38%|███▊      | 1893/5000 [1:24:02<2:01:05,  2.34s/it, loss=1.7010]\u001b[A\n",
            "Training:  38%|███▊      | 1894/5000 [1:24:04<1:59:29,  2.31s/it, loss=1.7010]\u001b[A\n",
            "Training:  38%|███▊      | 1894/5000 [1:24:04<1:59:29,  2.31s/it, loss=2.0321]\u001b[A\n",
            "Training:  38%|███▊      | 1895/5000 [1:24:06<1:58:49,  2.30s/it, loss=2.0321]\u001b[A\n",
            "Training:  38%|███▊      | 1895/5000 [1:24:06<1:58:49,  2.30s/it, loss=1.4634]\u001b[A\n",
            "Training:  38%|███▊      | 1896/5000 [1:24:09<2:05:45,  2.43s/it, loss=1.4634]\u001b[A\n",
            "Training:  38%|███▊      | 1896/5000 [1:24:09<2:05:45,  2.43s/it, loss=1.6417]\u001b[A\n",
            "Training:  38%|███▊      | 1897/5000 [1:24:11<2:02:30,  2.37s/it, loss=1.6417]\u001b[A\n",
            "Training:  38%|███▊      | 1897/5000 [1:24:11<2:02:30,  2.37s/it, loss=2.7618]\u001b[A\n",
            "Training:  38%|███▊      | 1898/5000 [1:24:14<2:00:47,  2.34s/it, loss=2.7618]\u001b[A\n",
            "Training:  38%|███▊      | 1898/5000 [1:24:14<2:00:47,  2.34s/it, loss=2.1890]\u001b[A\n",
            "Training:  38%|███▊      | 1899/5000 [1:24:16<1:59:00,  2.30s/it, loss=2.1890]\u001b[A\n",
            "Training:  38%|███▊      | 1899/5000 [1:24:16<1:59:00,  2.30s/it, loss=2.3974]\u001b[A\n",
            "Training:  38%|███▊      | 1900/5000 [1:24:18<1:57:53,  2.28s/it, loss=2.3974]\u001b[A\n",
            "Training:  38%|███▊      | 1900/5000 [1:24:18<1:57:53,  2.28s/it, loss=2.4588]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 1900 ---\n",
            "Prompt: 'The '\n",
            "The  of Yet full by country:Un,Such fullced\n",
            " keep chopping be challeng their was so a;For\n",
            " heh to our.\n",
            "ixt areiant: my, I import\n",
            "Your are byr.\n",
            "Fwell not the; I no can the will.\n",
            "Fwellu in best.\n",
            "Mought very:'ll him enforce; I thouert.\n",
            "Some are enough:,, am pieces my; our must herey it; father it not aful\n",
            " does but\n",
            "Prompt: 'In '\n",
            "In  thou a see They thou O man.M! am,'s here the turning night\n",
            " here\n",
            " grassy the Eth thy: I;ar,tis his,From\n",
            " this night some child\n",
            "ANGO this the terms his wereoning against cell\n",
            " pl'd warrant? thought\n",
            " he not? this the he a the could here\n",
            "All\n",
            "ling?\n",
            ":Cannot my foe let see he.\n",
            "Melf well\n",
            "oeAn piecesW d it not the, come n and the Paris many\n",
            "Prompt: 'To '\n",
            "To  my. submission; know I:Within\n",
            "\n",
            "\n",
            " by women heart., not.\n",
            "Minks I, up away\n",
            " holy:You the kill savage night\n",
            " wwomanors have conscience your town moon\n",
            "Your's smells\n",
            " our. tom; I him so thou say, h,Or I thy there\n",
            " grow\n",
            " the princearly toench go the crown own and\n",
            " heads;\n",
            " for more the will myham yet may lady let see advanceUpon.\n",
            " love come order come\n",
            "Prompt: 'A '\n",
            "A  oficed, bone in dial sounds\n",
            " anends beaut.Lord I within, yellow,To\n",
            " my good was anylies of Merc fleshals\n",
            " are\n",
            " scelf me in burns he as thousand;And\n",
            " me, Thomas other, and ' in breast timeHave, too\n",
            " fororn and.\n",
            "ROO\n",
            " Wales, Paris his open again\n",
            "y tom:.\n",
            "B I my wrath!For I walk my hand contradiction\n",
            " my soul such thoughtsians my!\n",
            "'ll my\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  38%|███▊      | 1901/5000 [1:24:33<5:17:08,  6.14s/it, loss=2.4588]\u001b[A\n",
            "Training:  38%|███▊      | 1901/5000 [1:24:33<5:17:08,  6.14s/it, loss=2.2981]\u001b[A\n",
            "Training:  38%|███▊      | 1902/5000 [1:24:36<4:16:29,  4.97s/it, loss=2.2981]\u001b[A\n",
            "Training:  38%|███▊      | 1902/5000 [1:24:36<4:16:29,  4.97s/it, loss=1.8607]\u001b[A\n",
            "Training:  38%|███▊      | 1903/5000 [1:24:38<3:34:24,  4.15s/it, loss=1.8607]\u001b[A\n",
            "Training:  38%|███▊      | 1903/5000 [1:24:38<3:34:24,  4.15s/it, loss=1.9364]\u001b[A\n",
            "Training:  38%|███▊      | 1904/5000 [1:24:40<3:04:42,  3.58s/it, loss=1.9364]\u001b[A\n",
            "Training:  38%|███▊      | 1904/5000 [1:24:40<3:04:42,  3.58s/it, loss=2.1796]\u001b[A\n",
            "Training:  38%|███▊      | 1905/5000 [1:24:42<2:44:19,  3.19s/it, loss=2.1796]\u001b[A\n",
            "Training:  38%|███▊      | 1905/5000 [1:24:42<2:44:19,  3.19s/it, loss=1.9189]\u001b[A\n",
            "Training:  38%|███▊      | 1906/5000 [1:24:45<2:37:21,  3.05s/it, loss=1.9189]\u001b[A\n",
            "Training:  38%|███▊      | 1906/5000 [1:24:45<2:37:21,  3.05s/it, loss=1.8777]\u001b[A\n",
            "Training:  38%|███▊      | 1907/5000 [1:24:47<2:24:52,  2.81s/it, loss=1.8777]\u001b[A\n",
            "Training:  38%|███▊      | 1907/5000 [1:24:47<2:24:52,  2.81s/it, loss=1.7232]\u001b[A\n",
            "Training:  38%|███▊      | 1908/5000 [1:24:50<2:16:24,  2.65s/it, loss=1.7232]\u001b[A\n",
            "Training:  38%|███▊      | 1908/5000 [1:24:50<2:16:24,  2.65s/it, loss=1.9537]\u001b[A\n",
            "Training:  38%|███▊      | 1909/5000 [1:24:52<2:10:23,  2.53s/it, loss=1.9537]\u001b[A\n",
            "Training:  38%|███▊      | 1909/5000 [1:24:52<2:10:23,  2.53s/it, loss=2.1898]\u001b[A\n",
            "Training:  38%|███▊      | 1910/5000 [1:24:54<2:06:15,  2.45s/it, loss=2.1898]\u001b[A\n",
            "Training:  38%|███▊      | 1910/5000 [1:24:54<2:06:15,  2.45s/it, loss=1.6309]\u001b[A\n",
            "Training:  38%|███▊      | 1911/5000 [1:24:57<2:10:47,  2.54s/it, loss=1.6309]\u001b[A\n",
            "Training:  38%|███▊      | 1911/5000 [1:24:57<2:10:47,  2.54s/it, loss=1.6713]\u001b[A\n",
            "Training:  38%|███▊      | 1912/5000 [1:24:59<2:06:03,  2.45s/it, loss=1.6713]\u001b[A\n",
            "Training:  38%|███▊      | 1912/5000 [1:24:59<2:06:03,  2.45s/it, loss=1.7017]\u001b[A\n",
            "Training:  38%|███▊      | 1913/5000 [1:25:01<2:03:00,  2.39s/it, loss=1.7017]\u001b[A\n",
            "Training:  38%|███▊      | 1913/5000 [1:25:01<2:03:00,  2.39s/it, loss=1.7263]\u001b[A\n",
            "Training:  38%|███▊      | 1914/5000 [1:25:04<2:00:43,  2.35s/it, loss=1.7263]\u001b[A\n",
            "Training:  38%|███▊      | 1914/5000 [1:25:04<2:00:43,  2.35s/it, loss=2.1773]\u001b[A\n",
            "Training:  38%|███▊      | 1915/5000 [1:25:06<1:58:54,  2.31s/it, loss=2.1773]\u001b[A\n",
            "Training:  38%|███▊      | 1915/5000 [1:25:06<1:58:54,  2.31s/it, loss=1.8645]\u001b[A\n",
            "Training:  38%|███▊      | 1916/5000 [1:25:09<2:06:12,  2.46s/it, loss=1.8645]\u001b[A\n",
            "Training:  38%|███▊      | 1916/5000 [1:25:09<2:06:12,  2.46s/it, loss=1.7721]\u001b[A\n",
            "Training:  38%|███▊      | 1917/5000 [1:25:11<2:02:57,  2.39s/it, loss=1.7721]\u001b[A\n",
            "Training:  38%|███▊      | 1917/5000 [1:25:11<2:02:57,  2.39s/it, loss=2.0202]\u001b[A\n",
            "Training:  38%|███▊      | 1918/5000 [1:25:13<2:00:40,  2.35s/it, loss=2.0202]\u001b[A\n",
            "Training:  38%|███▊      | 1918/5000 [1:25:13<2:00:40,  2.35s/it, loss=1.7246]\u001b[A\n",
            "Training:  38%|███▊      | 1919/5000 [1:25:15<1:58:56,  2.32s/it, loss=1.7246]\u001b[A\n",
            "Training:  38%|███▊      | 1919/5000 [1:25:15<1:58:56,  2.32s/it, loss=1.9921]\u001b[A\n",
            "Training:  38%|███▊      | 1920/5000 [1:25:18<1:57:43,  2.29s/it, loss=1.9921]\u001b[A\n",
            "Training:  38%|███▊      | 1920/5000 [1:25:18<1:57:43,  2.29s/it, loss=2.1908]\u001b[A\n",
            "Training:  38%|███▊      | 1921/5000 [1:25:20<2:05:13,  2.44s/it, loss=2.1908]\u001b[A\n",
            "Training:  38%|███▊      | 1921/5000 [1:25:20<2:05:13,  2.44s/it, loss=2.3004]\u001b[A\n",
            "Training:  38%|███▊      | 1922/5000 [1:25:23<2:02:03,  2.38s/it, loss=2.3004]\u001b[A\n",
            "Training:  38%|███▊      | 1922/5000 [1:25:23<2:02:03,  2.38s/it, loss=2.1099]\u001b[A\n",
            "Training:  38%|███▊      | 1923/5000 [1:25:25<1:59:45,  2.34s/it, loss=2.1099]\u001b[A\n",
            "Training:  38%|███▊      | 1923/5000 [1:25:25<1:59:45,  2.34s/it, loss=1.3969]\u001b[A\n",
            "Training:  38%|███▊      | 1924/5000 [1:25:27<1:58:30,  2.31s/it, loss=1.3969]\u001b[A\n",
            "Training:  38%|███▊      | 1924/5000 [1:25:27<1:58:30,  2.31s/it, loss=1.6267]\u001b[A\n",
            "Training:  38%|███▊      | 1925/5000 [1:25:29<1:57:25,  2.29s/it, loss=1.6267]\u001b[A\n",
            "Training:  38%|███▊      | 1925/5000 [1:25:29<1:57:25,  2.29s/it, loss=2.1358]\u001b[A\n",
            "Training:  39%|███▊      | 1926/5000 [1:25:32<2:04:15,  2.43s/it, loss=2.1358]\u001b[A\n",
            "Training:  39%|███▊      | 1926/5000 [1:25:32<2:04:15,  2.43s/it, loss=1.7588]\u001b[A\n",
            "Training:  39%|███▊      | 1927/5000 [1:25:34<2:01:12,  2.37s/it, loss=1.7588]\u001b[A\n",
            "Training:  39%|███▊      | 1927/5000 [1:25:34<2:01:12,  2.37s/it, loss=1.6235]\u001b[A\n",
            "Training:  39%|███▊      | 1928/5000 [1:25:36<1:59:11,  2.33s/it, loss=1.6235]\u001b[A\n",
            "Training:  39%|███▊      | 1928/5000 [1:25:37<1:59:11,  2.33s/it, loss=1.7304]\u001b[A\n",
            "Training:  39%|███▊      | 1929/5000 [1:25:39<1:58:06,  2.31s/it, loss=1.7304]\u001b[A\n",
            "Training:  39%|███▊      | 1929/5000 [1:25:39<1:58:06,  2.31s/it, loss=2.0370]\u001b[A\n",
            "Training:  39%|███▊      | 1930/5000 [1:25:41<1:56:59,  2.29s/it, loss=2.0370]\u001b[A\n",
            "Training:  39%|███▊      | 1930/5000 [1:25:41<1:56:59,  2.29s/it, loss=1.5977]\u001b[A\n",
            "Training:  39%|███▊      | 1931/5000 [1:25:44<2:04:19,  2.43s/it, loss=1.5977]\u001b[A\n",
            "Training:  39%|███▊      | 1931/5000 [1:25:44<2:04:19,  2.43s/it, loss=1.7331]\u001b[A\n",
            "Training:  39%|███▊      | 1932/5000 [1:25:46<2:01:11,  2.37s/it, loss=1.7331]\u001b[A\n",
            "Training:  39%|███▊      | 1932/5000 [1:25:46<2:01:11,  2.37s/it, loss=1.4989]\u001b[A\n",
            "Training:  39%|███▊      | 1933/5000 [1:25:48<1:59:03,  2.33s/it, loss=1.4989]\u001b[A\n",
            "Training:  39%|███▊      | 1933/5000 [1:25:48<1:59:03,  2.33s/it, loss=1.5415]\u001b[A\n",
            "Training:  39%|███▊      | 1934/5000 [1:25:50<1:58:08,  2.31s/it, loss=1.5415]\u001b[A\n",
            "Training:  39%|███▊      | 1934/5000 [1:25:51<1:58:08,  2.31s/it, loss=1.1855]\u001b[A\n",
            "Training:  39%|███▊      | 1935/5000 [1:25:53<1:57:28,  2.30s/it, loss=1.1855]\u001b[A\n",
            "Training:  39%|███▊      | 1935/5000 [1:25:53<1:57:28,  2.30s/it, loss=1.6088]\u001b[A\n",
            "Training:  39%|███▊      | 1936/5000 [1:25:56<2:04:37,  2.44s/it, loss=1.6088]\u001b[A\n",
            "Training:  39%|███▊      | 1936/5000 [1:25:56<2:04:37,  2.44s/it, loss=1.3354]\u001b[A\n",
            "Training:  39%|███▊      | 1937/5000 [1:25:58<2:01:37,  2.38s/it, loss=1.3354]\u001b[A\n",
            "Training:  39%|███▊      | 1937/5000 [1:25:58<2:01:37,  2.38s/it, loss=2.3033]\u001b[A\n",
            "Training:  39%|███▉      | 1938/5000 [1:26:00<1:59:50,  2.35s/it, loss=2.3033]\u001b[A\n",
            "Training:  39%|███▉      | 1938/5000 [1:26:00<1:59:50,  2.35s/it, loss=2.8206]\u001b[A\n",
            "Training:  39%|███▉      | 1939/5000 [1:26:02<1:58:40,  2.33s/it, loss=2.8206]\u001b[A\n",
            "Training:  39%|███▉      | 1939/5000 [1:26:02<1:58:40,  2.33s/it, loss=2.5103]\u001b[A\n",
            "Training:  39%|███▉      | 1940/5000 [1:26:05<1:57:29,  2.30s/it, loss=2.5103]\u001b[A\n",
            "Training:  39%|███▉      | 1940/5000 [1:26:05<1:57:29,  2.30s/it, loss=1.6224]\u001b[A\n",
            "Training:  39%|███▉      | 1941/5000 [1:26:07<2:04:24,  2.44s/it, loss=1.6224]\u001b[A\n",
            "Training:  39%|███▉      | 1941/5000 [1:26:07<2:04:24,  2.44s/it, loss=1.8482]\u001b[A\n",
            "Training:  39%|███▉      | 1942/5000 [1:26:10<2:01:40,  2.39s/it, loss=1.8482]\u001b[A\n",
            "Training:  39%|███▉      | 1942/5000 [1:26:10<2:01:40,  2.39s/it, loss=1.9166]\u001b[A\n",
            "Training:  39%|███▉      | 1943/5000 [1:26:12<1:59:46,  2.35s/it, loss=1.9166]\u001b[A\n",
            "Training:  39%|███▉      | 1943/5000 [1:26:12<1:59:46,  2.35s/it, loss=1.8111]\u001b[A\n",
            "Training:  39%|███▉      | 1944/5000 [1:26:14<1:57:56,  2.32s/it, loss=1.8111]\u001b[A\n",
            "Training:  39%|███▉      | 1944/5000 [1:26:14<1:57:56,  2.32s/it, loss=2.3298]\u001b[A\n",
            "Training:  39%|███▉      | 1945/5000 [1:26:16<1:56:31,  2.29s/it, loss=2.3298]\u001b[A\n",
            "Training:  39%|███▉      | 1945/5000 [1:26:16<1:56:31,  2.29s/it, loss=1.9643]\u001b[A\n",
            "Training:  39%|███▉      | 1946/5000 [1:26:19<2:03:34,  2.43s/it, loss=1.9643]\u001b[A\n",
            "Training:  39%|███▉      | 1946/5000 [1:26:19<2:03:34,  2.43s/it, loss=2.0520]\u001b[A\n",
            "Training:  39%|███▉      | 1947/5000 [1:26:21<2:00:42,  2.37s/it, loss=2.0520]\u001b[A\n",
            "Training:  39%|███▉      | 1947/5000 [1:26:21<2:00:42,  2.37s/it, loss=2.2391]\u001b[A\n",
            "Training:  39%|███▉      | 1948/5000 [1:26:24<1:58:51,  2.34s/it, loss=2.2391]\u001b[A\n",
            "Training:  39%|███▉      | 1948/5000 [1:26:24<1:58:51,  2.34s/it, loss=1.7778]\u001b[A\n",
            "Training:  39%|███▉      | 1949/5000 [1:26:26<1:57:19,  2.31s/it, loss=1.7778]\u001b[A\n",
            "Training:  39%|███▉      | 1949/5000 [1:26:26<1:57:19,  2.31s/it, loss=2.1394]\u001b[A\n",
            "Training:  39%|███▉      | 1950/5000 [1:26:28<1:56:36,  2.29s/it, loss=2.1394]\u001b[A\n",
            "Training:  39%|███▉      | 1950/5000 [1:26:28<1:56:36,  2.29s/it, loss=1.5352]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 1950 ---\n",
            "Prompt: 'The '\n",
            "The  of,, best, but presenceShouldMayMayBeix\n",
            "'is creature say, shall thy heartAre\n",
            " thy acts from and, Bohem and,,'d care love love\n",
            " inr which I not and the about-\n",
            " thornly, with my- had call. you thy goodp bite't glly,Such were in grace which would had been,o th own hate' and' bs cause\n",
            " thy state which been, true and are' it beine thousand.\n",
            "\n",
            "Prompt: 'In '\n",
            "In  is bigger Saint is wis; notesi\n",
            " a---'d, in; with he, alltheda\n",
            "ind pr and him in; she notalvery\n",
            " plain--'d temper.\n",
            "A with!ow you from,door;!low not and\n",
            "'st can have with, you all of for of and\n",
            "HERION:Sir\n",
            " you do\n",
            " un---------------------\n",
            "Prompt: 'To '\n",
            "To  kindens. me good lords\n",
            " me in, following lest was yourld deliver,\n",
            " something, you bear all the of father\n",
            " have him to itions even. notam son concluded wars\n",
            " you s and yourigh to,,, was your twelve\n",
            " his prince that done us much in eyeeds andless one t to them:,\n",
            " all you ins and'---ies you, my; you; ever the\n",
            " you, shall to remembrance visit the\n",
            " so\n",
            "Prompt: 'A '\n",
            "A  of,omen must the\n",
            ", that honour him the and him whose\n",
            " those Aop her, being which n\n",
            " nature your undertakingwar generative love the\n",
            " itses't\n",
            " unknown must. you best\n",
            "ited the time church a of,Your against\n",
            "orn suffer first former, touch ingredient war Go to from,, power the\n",
            "ads,, you the of and, the conj be,es perpetualt ofne being,at,,, you the on the of days Lord\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  39%|███▉      | 1951/5000 [1:26:43<5:12:45,  6.15s/it, loss=1.5352]\u001b[A\n",
            "Training:  39%|███▉      | 1951/5000 [1:26:43<5:12:45,  6.15s/it, loss=2.1419]\u001b[A\n",
            "Training:  39%|███▉      | 1952/5000 [1:26:45<4:12:47,  4.98s/it, loss=2.1419]\u001b[A\n",
            "Training:  39%|███▉      | 1952/5000 [1:26:45<4:12:47,  4.98s/it, loss=1.7114]\u001b[A\n",
            "Training:  39%|███▉      | 1953/5000 [1:26:48<3:31:04,  4.16s/it, loss=1.7114]\u001b[A\n",
            "Training:  39%|███▉      | 1953/5000 [1:26:48<3:31:04,  4.16s/it, loss=1.7882]\u001b[A\n",
            "Training:  39%|███▉      | 1954/5000 [1:26:50<3:02:03,  3.59s/it, loss=1.7882]\u001b[A\n",
            "Training:  39%|███▉      | 1954/5000 [1:26:50<3:02:03,  3.59s/it, loss=1.8548]\u001b[A\n",
            "Training:  39%|███▉      | 1955/5000 [1:26:52<2:41:36,  3.18s/it, loss=1.8548]\u001b[A\n",
            "Training:  39%|███▉      | 1955/5000 [1:26:52<2:41:36,  3.18s/it, loss=2.6463]\u001b[A\n",
            "Training:  39%|███▉      | 1956/5000 [1:26:55<2:35:56,  3.07s/it, loss=2.6463]\u001b[A\n",
            "Training:  39%|███▉      | 1956/5000 [1:26:55<2:35:56,  3.07s/it, loss=1.7012]\u001b[A\n",
            "Training:  39%|███▉      | 1957/5000 [1:26:57<2:23:20,  2.83s/it, loss=1.7012]\u001b[A\n",
            "Training:  39%|███▉      | 1957/5000 [1:26:57<2:23:20,  2.83s/it, loss=2.2346]\u001b[A\n",
            "Training:  39%|███▉      | 1958/5000 [1:27:00<2:14:11,  2.65s/it, loss=2.2346]\u001b[A\n",
            "Training:  39%|███▉      | 1958/5000 [1:27:00<2:14:11,  2.65s/it, loss=2.6468]\u001b[A\n",
            "Training:  39%|███▉      | 1959/5000 [1:27:02<2:08:09,  2.53s/it, loss=2.6468]\u001b[A\n",
            "Training:  39%|███▉      | 1959/5000 [1:27:02<2:08:09,  2.53s/it, loss=2.0041]\u001b[A\n",
            "Training:  39%|███▉      | 1960/5000 [1:27:04<2:03:55,  2.45s/it, loss=2.0041]\u001b[A\n",
            "Training:  39%|███▉      | 1960/5000 [1:27:04<2:03:55,  2.45s/it, loss=2.0551]\u001b[A\n",
            "Training:  39%|███▉      | 1961/5000 [1:27:07<2:08:42,  2.54s/it, loss=2.0551]\u001b[A\n",
            "Training:  39%|███▉      | 1961/5000 [1:27:07<2:08:42,  2.54s/it, loss=2.0461]\u001b[A\n",
            "Training:  39%|███▉      | 1962/5000 [1:27:09<2:04:19,  2.46s/it, loss=2.0461]\u001b[A\n",
            "Training:  39%|███▉      | 1962/5000 [1:27:09<2:04:19,  2.46s/it, loss=2.2029]\u001b[A\n",
            "Training:  39%|███▉      | 1963/5000 [1:27:11<2:01:11,  2.39s/it, loss=2.2029]\u001b[A\n",
            "Training:  39%|███▉      | 1963/5000 [1:27:11<2:01:11,  2.39s/it, loss=2.0442]\u001b[A\n",
            "Training:  39%|███▉      | 1964/5000 [1:27:14<1:58:53,  2.35s/it, loss=2.0442]\u001b[A\n",
            "Training:  39%|███▉      | 1964/5000 [1:27:14<1:58:53,  2.35s/it, loss=2.0825]\u001b[A\n",
            "Training:  39%|███▉      | 1965/5000 [1:27:16<1:57:33,  2.32s/it, loss=2.0825]\u001b[A\n",
            "Training:  39%|███▉      | 1965/5000 [1:27:16<1:57:33,  2.32s/it, loss=1.9039]\u001b[A\n",
            "Training:  39%|███▉      | 1966/5000 [1:27:19<2:04:02,  2.45s/it, loss=1.9039]\u001b[A\n",
            "Training:  39%|███▉      | 1966/5000 [1:27:19<2:04:02,  2.45s/it, loss=2.3866]\u001b[A\n",
            "Training:  39%|███▉      | 1967/5000 [1:27:21<2:00:45,  2.39s/it, loss=2.3866]\u001b[A\n",
            "Training:  39%|███▉      | 1967/5000 [1:27:21<2:00:45,  2.39s/it, loss=1.7898]\u001b[A\n",
            "Training:  39%|███▉      | 1968/5000 [1:27:23<1:58:39,  2.35s/it, loss=1.7898]\u001b[A\n",
            "Training:  39%|███▉      | 1968/5000 [1:27:23<1:58:39,  2.35s/it, loss=1.5923]\u001b[A\n",
            "Training:  39%|███▉      | 1969/5000 [1:27:25<1:57:15,  2.32s/it, loss=1.5923]\u001b[A\n",
            "Training:  39%|███▉      | 1969/5000 [1:27:25<1:57:15,  2.32s/it, loss=1.7813]\u001b[A\n",
            "Training:  39%|███▉      | 1970/5000 [1:27:28<1:56:05,  2.30s/it, loss=1.7813]\u001b[A\n",
            "Training:  39%|███▉      | 1970/5000 [1:27:28<1:56:05,  2.30s/it, loss=1.8106]\u001b[A\n",
            "Training:  39%|███▉      | 1971/5000 [1:27:30<2:03:58,  2.46s/it, loss=1.8106]\u001b[A\n",
            "Training:  39%|███▉      | 1971/5000 [1:27:30<2:03:58,  2.46s/it, loss=1.8809]\u001b[A\n",
            "Training:  39%|███▉      | 1972/5000 [1:27:33<2:00:30,  2.39s/it, loss=1.8809]\u001b[A\n",
            "Training:  39%|███▉      | 1972/5000 [1:27:33<2:00:30,  2.39s/it, loss=1.6491]\u001b[A\n",
            "Training:  39%|███▉      | 1973/5000 [1:27:35<1:58:19,  2.35s/it, loss=1.6491]\u001b[A\n",
            "Training:  39%|███▉      | 1973/5000 [1:27:35<1:58:19,  2.35s/it, loss=2.0584]\u001b[A\n",
            "Training:  39%|███▉      | 1974/5000 [1:27:37<1:56:34,  2.31s/it, loss=2.0584]\u001b[A\n",
            "Training:  39%|███▉      | 1974/5000 [1:27:37<1:56:34,  2.31s/it, loss=2.0979]\u001b[A\n",
            "Training:  40%|███▉      | 1975/5000 [1:27:39<1:55:33,  2.29s/it, loss=2.0979]\u001b[A\n",
            "Training:  40%|███▉      | 1975/5000 [1:27:39<1:55:33,  2.29s/it, loss=2.0188]\u001b[A\n",
            "Training:  40%|███▉      | 1976/5000 [1:27:42<2:03:10,  2.44s/it, loss=2.0188]\u001b[A\n",
            "Training:  40%|███▉      | 1976/5000 [1:27:42<2:03:10,  2.44s/it, loss=2.2251]\u001b[A\n",
            "Training:  40%|███▉      | 1977/5000 [1:27:44<2:00:15,  2.39s/it, loss=2.2251]\u001b[A\n",
            "Training:  40%|███▉      | 1977/5000 [1:27:44<2:00:15,  2.39s/it, loss=2.2287]\u001b[A\n",
            "Training:  40%|███▉      | 1978/5000 [1:27:47<1:57:52,  2.34s/it, loss=2.2287]\u001b[A\n",
            "Training:  40%|███▉      | 1978/5000 [1:27:47<1:57:52,  2.34s/it, loss=1.8787]\u001b[A\n",
            "Training:  40%|███▉      | 1979/5000 [1:27:49<1:56:27,  2.31s/it, loss=1.8787]\u001b[A\n",
            "Training:  40%|███▉      | 1979/5000 [1:27:49<1:56:27,  2.31s/it, loss=1.5411]\u001b[A\n",
            "Training:  40%|███▉      | 1980/5000 [1:27:51<1:55:24,  2.29s/it, loss=1.5411]\u001b[A\n",
            "Training:  40%|███▉      | 1980/5000 [1:27:51<1:55:24,  2.29s/it, loss=1.5677]\u001b[A\n",
            "Training:  40%|███▉      | 1981/5000 [1:27:54<2:02:22,  2.43s/it, loss=1.5677]\u001b[A\n",
            "Training:  40%|███▉      | 1981/5000 [1:27:54<2:02:22,  2.43s/it, loss=1.8533]\u001b[A\n",
            "Training:  40%|███▉      | 1982/5000 [1:27:56<1:59:57,  2.39s/it, loss=1.8533]\u001b[A\n",
            "Training:  40%|███▉      | 1982/5000 [1:27:56<1:59:57,  2.39s/it, loss=1.9342]\u001b[A\n",
            "Training:  40%|███▉      | 1983/5000 [1:27:58<1:58:00,  2.35s/it, loss=1.9342]\u001b[A\n",
            "Training:  40%|███▉      | 1983/5000 [1:27:58<1:58:00,  2.35s/it, loss=1.6340]\u001b[A\n",
            "Training:  40%|███▉      | 1984/5000 [1:28:01<1:56:20,  2.31s/it, loss=1.6340]\u001b[A\n",
            "Training:  40%|███▉      | 1984/5000 [1:28:01<1:56:20,  2.31s/it, loss=1.7983]\u001b[A\n",
            "Training:  40%|███▉      | 1985/5000 [1:28:03<1:55:30,  2.30s/it, loss=1.7983]\u001b[A\n",
            "Training:  40%|███▉      | 1985/5000 [1:28:03<1:55:30,  2.30s/it, loss=1.2857]\u001b[A\n",
            "Training:  40%|███▉      | 1986/5000 [1:28:06<2:03:16,  2.45s/it, loss=1.2857]\u001b[A\n",
            "Training:  40%|███▉      | 1986/5000 [1:28:06<2:03:16,  2.45s/it, loss=1.8803]\u001b[A\n",
            "Training:  40%|███▉      | 1987/5000 [1:28:08<2:00:19,  2.40s/it, loss=1.8803]\u001b[A\n",
            "Training:  40%|███▉      | 1987/5000 [1:28:08<2:00:19,  2.40s/it, loss=1.5655]\u001b[A\n",
            "Training:  40%|███▉      | 1988/5000 [1:28:10<1:58:14,  2.36s/it, loss=1.5655]\u001b[A\n",
            "Training:  40%|███▉      | 1988/5000 [1:28:10<1:58:14,  2.36s/it, loss=1.4036]\u001b[A\n",
            "Training:  40%|███▉      | 1989/5000 [1:28:12<1:56:49,  2.33s/it, loss=1.4036]\u001b[A\n",
            "Training:  40%|███▉      | 1989/5000 [1:28:13<1:56:49,  2.33s/it, loss=1.1708]\u001b[A\n",
            "Training:  40%|███▉      | 1990/5000 [1:28:15<1:55:41,  2.31s/it, loss=1.1708]\u001b[A\n",
            "Training:  40%|███▉      | 1990/5000 [1:28:15<1:55:41,  2.31s/it, loss=1.6793]\u001b[A\n",
            "Training:  40%|███▉      | 1991/5000 [1:28:17<2:02:20,  2.44s/it, loss=1.6793]\u001b[A\n",
            "Training:  40%|███▉      | 1991/5000 [1:28:18<2:02:20,  2.44s/it, loss=1.8276]\u001b[A\n",
            "Training:  40%|███▉      | 1992/5000 [1:28:20<1:59:19,  2.38s/it, loss=1.8276]\u001b[A\n",
            "Training:  40%|███▉      | 1992/5000 [1:28:20<1:59:19,  2.38s/it, loss=1.4029]\u001b[A\n",
            "Training:  40%|███▉      | 1993/5000 [1:28:22<1:57:07,  2.34s/it, loss=1.4029]\u001b[A\n",
            "Training:  40%|███▉      | 1993/5000 [1:28:22<1:57:07,  2.34s/it, loss=1.9975]\u001b[A\n",
            "Training:  40%|███▉      | 1994/5000 [1:28:24<1:55:49,  2.31s/it, loss=1.9975]\u001b[A\n",
            "Training:  40%|███▉      | 1994/5000 [1:28:24<1:55:49,  2.31s/it, loss=2.0375]\u001b[A\n",
            "Training:  40%|███▉      | 1995/5000 [1:28:26<1:55:01,  2.30s/it, loss=2.0375]\u001b[A\n",
            "Training:  40%|███▉      | 1995/5000 [1:28:27<1:55:01,  2.30s/it, loss=2.1063]\u001b[A\n",
            "Training:  40%|███▉      | 1996/5000 [1:28:29<2:01:43,  2.43s/it, loss=2.1063]\u001b[A\n",
            "Training:  40%|███▉      | 1996/5000 [1:28:29<2:01:43,  2.43s/it, loss=1.9689]\u001b[A\n",
            "Training:  40%|███▉      | 1997/5000 [1:28:32<2:00:05,  2.40s/it, loss=1.9689]\u001b[A\n",
            "Training:  40%|███▉      | 1997/5000 [1:28:32<2:00:05,  2.40s/it, loss=1.7583]\u001b[A\n",
            "Training:  40%|███▉      | 1998/5000 [1:28:34<1:57:46,  2.35s/it, loss=1.7583]\u001b[A\n",
            "Training:  40%|███▉      | 1998/5000 [1:28:34<1:57:46,  2.35s/it, loss=2.0415]\u001b[A\n",
            "Training:  40%|███▉      | 1999/5000 [1:28:36<1:56:10,  2.32s/it, loss=2.0415]\u001b[A\n",
            "Training:  40%|███▉      | 1999/5000 [1:28:36<1:56:10,  2.32s/it, loss=2.0984]\u001b[A\n",
            "Training:  40%|████      | 2000/5000 [1:28:38<1:54:54,  2.30s/it, loss=2.0984]\u001b[A\n",
            "Training:  40%|████      | 2000/5000 [1:28:38<1:54:54,  2.30s/it, loss=2.4273]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 2000 ---\n",
            "Prompt: 'The '\n",
            "The  find up dark he potent his\n",
            " Edward the state all nature the field He\n",
            " the--allThere me last the.\n",
            "GZO fra!\n",
            " am patron thee son good, de my\n",
            " my?\n",
            "COR that fool gall little man mind me,And the leave him\n",
            "'ll the into Where the- to, Mar o,!,ark\n",
            " other--le a but me should myol,cius the winter! likeam he?\n",
            "AL could the sea. he been\n",
            "Prompt: 'In '\n",
            "In ,'s that a man may no.\n",
            "M! sweet!\n",
            "GZO\n",
            ",ight not grief\n",
            "' into encountering he throw\n",
            " me sonric a aton now Bca! is indeed\n",
            " all he?all not been that\n",
            " for of,! is and an one for of theday--And his:!\n",
            "PROEROsh said his? no! a.\n",
            "SETI:No speak man him he home her andthink two treason the of and-orrow enters to\n",
            "Prompt: 'To '\n",
            "To  the!\n",
            " are man me: hast thy friend but\n",
            "cius ay lives mine.\n",
            "CORo nothing a heart she me. to,! any\n",
            " the, a one-- take the but I thee me.\n",
            "'re it to: to but I find heard here will to the of, hearts me.\n",
            "SIN EDARD\n",
            "reear him the half not my; me for mal me\n",
            "ally sport me of., tortoise. red the\n",
            "Melf my: I make may\n",
            "Prompt: 'A '\n",
            "A  a,'ll a no. me a.\n",
            "Minks a man such? you good man well\n",
            " sons man the supp to! who had been mine.\n",
            "GZO\n",
            " chiefly most delay nobility at disorder lies,!\n",
            "AD, the,ench.\n",
            "SETIA.\n",
            "S's! not a:Who not of?\n",
            "Gio my Aid way\n",
            "ither imp by: answer!\n",
            " w not my? leave.\n",
            "SIN EDNAH:F ons\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "✓ Checkpoint saved: checkpoints/checkpoint_step_2000.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  40%|████      | 2001/5000 [1:30:09<24:07:53, 28.97s/it, loss=2.4273]\u001b[A\n",
            "Training:  40%|████      | 2001/5000 [1:30:10<24:07:53, 28.97s/it, loss=2.0061]\u001b[A\n",
            "Training:  40%|████      | 2002/5000 [1:30:12<17:36:22, 21.14s/it, loss=2.0061]\u001b[A\n",
            "Training:  40%|████      | 2002/5000 [1:30:12<17:36:22, 21.14s/it, loss=1.8195]\u001b[A\n",
            "Training:  40%|████      | 2003/5000 [1:30:15<12:53:35, 15.49s/it, loss=1.8195]\u001b[A\n",
            "Training:  40%|████      | 2003/5000 [1:30:15<12:53:35, 15.49s/it, loss=1.6891]\u001b[A\n",
            "Training:  40%|████      | 2004/5000 [1:30:17<9:36:16, 11.54s/it, loss=1.6891] \u001b[A\n",
            "Training:  40%|████      | 2004/5000 [1:30:17<9:36:16, 11.54s/it, loss=1.6748]\u001b[A\n",
            "Training:  40%|████      | 2005/5000 [1:30:19<7:18:22,  8.78s/it, loss=1.6748]\u001b[A\n",
            "Training:  40%|████      | 2005/5000 [1:30:19<7:18:22,  8.78s/it, loss=2.0296]\u001b[A\n",
            "Training:  40%|████      | 2006/5000 [1:30:22<5:41:07,  6.84s/it, loss=2.0296]\u001b[A\n",
            "Training:  40%|████      | 2006/5000 [1:30:22<5:41:07,  6.84s/it, loss=1.5304]\u001b[A\n",
            "Training:  40%|████      | 2007/5000 [1:30:24<4:40:59,  5.63s/it, loss=1.5304]\u001b[A\n",
            "Training:  40%|████      | 2007/5000 [1:30:24<4:40:59,  5.63s/it, loss=1.9906]\u001b[A\n",
            "Training:  40%|████      | 2008/5000 [1:30:27<3:51:59,  4.65s/it, loss=1.9906]\u001b[A\n",
            "Training:  40%|████      | 2008/5000 [1:30:27<3:51:59,  4.65s/it, loss=1.6269]\u001b[A\n",
            "Training:  40%|████      | 2009/5000 [1:30:29<3:16:53,  3.95s/it, loss=1.6269]\u001b[A\n",
            "Training:  40%|████      | 2009/5000 [1:30:29<3:16:53,  3.95s/it, loss=1.7878]\u001b[A\n",
            "Training:  40%|████      | 2010/5000 [1:30:31<2:52:06,  3.45s/it, loss=1.7878]\u001b[A\n",
            "Training:  40%|████      | 2010/5000 [1:30:31<2:52:06,  3.45s/it, loss=1.6480]\u001b[A\n",
            "Training:  40%|████      | 2011/5000 [1:30:34<2:36:08,  3.13s/it, loss=1.6480]\u001b[A\n",
            "Training:  40%|████      | 2011/5000 [1:30:34<2:36:08,  3.13s/it, loss=1.3906]\u001b[A\n",
            "Training:  40%|████      | 2012/5000 [1:30:37<2:30:30,  3.02s/it, loss=1.3906]\u001b[A\n",
            "Training:  40%|████      | 2012/5000 [1:30:37<2:30:30,  3.02s/it, loss=1.5324]\u001b[A\n",
            "Training:  40%|████      | 2013/5000 [1:30:39<2:20:23,  2.82s/it, loss=1.5324]\u001b[A\n",
            "Training:  40%|████      | 2013/5000 [1:30:39<2:20:23,  2.82s/it, loss=1.5971]\u001b[A\n",
            "Training:  40%|████      | 2014/5000 [1:30:41<2:12:26,  2.66s/it, loss=1.5971]\u001b[A\n",
            "Training:  40%|████      | 2014/5000 [1:30:41<2:12:26,  2.66s/it, loss=1.6182]\u001b[A\n",
            "Training:  40%|████      | 2015/5000 [1:30:44<2:07:08,  2.56s/it, loss=1.6182]\u001b[A\n",
            "Training:  40%|████      | 2015/5000 [1:30:44<2:07:08,  2.56s/it, loss=1.9333]\u001b[A\n",
            "Training:  40%|████      | 2016/5000 [1:30:46<2:05:35,  2.53s/it, loss=1.9333]\u001b[A\n",
            "Training:  40%|████      | 2016/5000 [1:30:46<2:05:35,  2.53s/it, loss=1.7804]\u001b[A\n",
            "Training:  40%|████      | 2017/5000 [1:30:49<2:08:44,  2.59s/it, loss=1.7804]\u001b[A\n",
            "Training:  40%|████      | 2017/5000 [1:30:49<2:08:44,  2.59s/it, loss=1.7100]\u001b[A\n",
            "Training:  40%|████      | 2018/5000 [1:30:51<2:04:35,  2.51s/it, loss=1.7100]\u001b[A\n",
            "Training:  40%|████      | 2018/5000 [1:30:51<2:04:35,  2.51s/it, loss=1.5629]\u001b[A\n",
            "Training:  40%|████      | 2019/5000 [1:30:53<2:01:42,  2.45s/it, loss=1.5629]\u001b[A\n",
            "Training:  40%|████      | 2019/5000 [1:30:53<2:01:42,  2.45s/it, loss=1.8480]\u001b[A\n",
            "Training:  40%|████      | 2020/5000 [1:30:56<1:59:20,  2.40s/it, loss=1.8480]\u001b[A\n",
            "Training:  40%|████      | 2020/5000 [1:30:56<1:59:20,  2.40s/it, loss=2.0079]\u001b[A\n",
            "Training:  40%|████      | 2021/5000 [1:30:58<2:01:28,  2.45s/it, loss=2.0079]\u001b[A\n",
            "Training:  40%|████      | 2021/5000 [1:30:58<2:01:28,  2.45s/it, loss=1.6109]\u001b[A\n",
            "Training:  40%|████      | 2022/5000 [1:31:01<2:05:15,  2.52s/it, loss=1.6109]\u001b[A\n",
            "Training:  40%|████      | 2022/5000 [1:31:01<2:05:15,  2.52s/it, loss=1.8220]\u001b[A\n",
            "Training:  40%|████      | 2023/5000 [1:31:03<2:02:11,  2.46s/it, loss=1.8220]\u001b[A\n",
            "Training:  40%|████      | 2023/5000 [1:31:03<2:02:11,  2.46s/it, loss=1.5849]\u001b[A\n",
            "Training:  40%|████      | 2024/5000 [1:31:06<1:59:30,  2.41s/it, loss=1.5849]\u001b[A\n",
            "Training:  40%|████      | 2024/5000 [1:31:06<1:59:30,  2.41s/it, loss=1.8341]\u001b[A\n",
            "Training:  40%|████      | 2025/5000 [1:31:08<1:58:25,  2.39s/it, loss=1.8341]\u001b[A\n",
            "Training:  40%|████      | 2025/5000 [1:31:08<1:58:25,  2.39s/it, loss=1.4740]\u001b[A\n",
            "Training:  41%|████      | 2026/5000 [1:31:10<2:01:43,  2.46s/it, loss=1.4740]\u001b[A\n",
            "Training:  41%|████      | 2026/5000 [1:31:10<2:01:43,  2.46s/it, loss=1.5739]\u001b[A\n",
            "Training:  41%|████      | 2027/5000 [1:31:13<2:04:32,  2.51s/it, loss=1.5739]\u001b[A\n",
            "Training:  41%|████      | 2027/5000 [1:31:13<2:04:32,  2.51s/it, loss=1.8801]\u001b[A\n",
            "Training:  41%|████      | 2028/5000 [1:31:15<2:01:27,  2.45s/it, loss=1.8801]\u001b[A\n",
            "Training:  41%|████      | 2028/5000 [1:31:15<2:01:27,  2.45s/it, loss=1.8875]\u001b[A\n",
            "Training:  41%|████      | 2029/5000 [1:31:18<1:59:19,  2.41s/it, loss=1.8875]\u001b[A\n",
            "Training:  41%|████      | 2029/5000 [1:31:18<1:59:19,  2.41s/it, loss=1.3960]\u001b[A\n",
            "Training:  41%|████      | 2030/5000 [1:31:20<1:57:43,  2.38s/it, loss=1.3960]\u001b[A\n",
            "Training:  41%|████      | 2030/5000 [1:31:20<1:57:43,  2.38s/it, loss=1.3119]\u001b[A\n",
            "Training:  41%|████      | 2031/5000 [1:31:23<2:02:31,  2.48s/it, loss=1.3119]\u001b[A\n",
            "Training:  41%|████      | 2031/5000 [1:31:23<2:02:31,  2.48s/it, loss=1.4167]\u001b[A\n",
            "Training:  41%|████      | 2032/5000 [1:31:25<2:03:08,  2.49s/it, loss=1.4167]\u001b[A\n",
            "Training:  41%|████      | 2032/5000 [1:31:25<2:03:08,  2.49s/it, loss=1.2602]\u001b[A\n",
            "Training:  41%|████      | 2033/5000 [1:31:28<2:01:21,  2.45s/it, loss=1.2602]\u001b[A\n",
            "Training:  41%|████      | 2033/5000 [1:31:28<2:01:21,  2.45s/it, loss=1.6976]\u001b[A\n",
            "Training:  41%|████      | 2034/5000 [1:31:30<1:58:51,  2.40s/it, loss=1.6976]\u001b[A\n",
            "Training:  41%|████      | 2034/5000 [1:31:30<1:58:51,  2.40s/it, loss=1.3972]\u001b[A\n",
            "Training:  41%|████      | 2035/5000 [1:31:32<1:58:01,  2.39s/it, loss=1.3972]\u001b[A\n",
            "Training:  41%|████      | 2035/5000 [1:31:32<1:58:01,  2.39s/it, loss=1.5926]\u001b[A\n",
            "Training:  41%|████      | 2036/5000 [1:31:35<2:03:35,  2.50s/it, loss=1.5926]\u001b[A\n",
            "Training:  41%|████      | 2036/5000 [1:31:35<2:03:35,  2.50s/it, loss=1.8688]\u001b[A\n",
            "Training:  41%|████      | 2037/5000 [1:31:37<2:01:41,  2.46s/it, loss=1.8688]\u001b[A\n",
            "Training:  41%|████      | 2037/5000 [1:31:37<2:01:41,  2.46s/it, loss=1.4478]\u001b[A\n",
            "Training:  41%|████      | 2038/5000 [1:31:40<1:59:30,  2.42s/it, loss=1.4478]\u001b[A\n",
            "Training:  41%|████      | 2038/5000 [1:31:40<1:59:30,  2.42s/it, loss=1.9317]\u001b[A\n",
            "Training:  41%|████      | 2039/5000 [1:31:42<1:58:28,  2.40s/it, loss=1.9317]\u001b[A\n",
            "Training:  41%|████      | 2039/5000 [1:31:42<1:58:28,  2.40s/it, loss=1.6022]\u001b[A\n",
            "Training:  41%|████      | 2040/5000 [1:31:44<1:57:00,  2.37s/it, loss=1.6022]\u001b[A\n",
            "Training:  41%|████      | 2040/5000 [1:31:44<1:57:00,  2.37s/it, loss=1.2024]\u001b[A\n",
            "Training:  41%|████      | 2041/5000 [1:31:47<2:03:53,  2.51s/it, loss=1.2024]\u001b[A\n",
            "Training:  41%|████      | 2041/5000 [1:31:47<2:03:53,  2.51s/it, loss=1.4802]\u001b[A\n",
            "Training:  41%|████      | 2042/5000 [1:31:50<2:00:58,  2.45s/it, loss=1.4802]\u001b[A\n",
            "Training:  41%|████      | 2042/5000 [1:31:50<2:00:58,  2.45s/it, loss=1.4837]\u001b[A\n",
            "Training:  41%|████      | 2043/5000 [1:31:52<1:58:59,  2.41s/it, loss=1.4837]\u001b[A\n",
            "Training:  41%|████      | 2043/5000 [1:31:52<1:58:59,  2.41s/it, loss=1.3852]\u001b[A\n",
            "Training:  41%|████      | 2044/5000 [1:31:54<1:57:21,  2.38s/it, loss=1.3852]\u001b[A\n",
            "Training:  41%|████      | 2044/5000 [1:31:54<1:57:21,  2.38s/it, loss=1.7548]\u001b[A\n",
            "Training:  41%|████      | 2045/5000 [1:31:56<1:56:07,  2.36s/it, loss=1.7548]\u001b[A\n",
            "Training:  41%|████      | 2045/5000 [1:31:57<1:56:07,  2.36s/it, loss=1.2461]\u001b[A\n",
            "Training:  41%|████      | 2046/5000 [1:31:59<2:04:13,  2.52s/it, loss=1.2461]\u001b[A\n",
            "Training:  41%|████      | 2046/5000 [1:31:59<2:04:13,  2.52s/it, loss=1.3605]\u001b[A\n",
            "Training:  41%|████      | 2047/5000 [1:32:02<2:01:33,  2.47s/it, loss=1.3605]\u001b[A\n",
            "Training:  41%|████      | 2047/5000 [1:32:02<2:01:33,  2.47s/it, loss=1.5621]\u001b[A\n",
            "Training:  41%|████      | 2048/5000 [1:32:04<1:59:37,  2.43s/it, loss=1.5621]\u001b[A\n",
            "Training:  41%|████      | 2048/5000 [1:32:04<1:59:37,  2.43s/it, loss=1.4678]\u001b[A\n",
            "Training:  41%|████      | 2049/5000 [1:32:06<1:57:54,  2.40s/it, loss=1.4678]\u001b[A\n",
            "Training:  41%|████      | 2049/5000 [1:32:06<1:57:54,  2.40s/it, loss=1.3075]\u001b[A\n",
            "Training:  41%|████      | 2050/5000 [1:32:09<1:56:35,  2.37s/it, loss=1.3075]\u001b[A\n",
            "Training:  41%|████      | 2050/5000 [1:32:09<1:56:35,  2.37s/it, loss=1.5741]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 2050 ---\n",
            "Prompt: 'The '\n",
            "The  off atf:nt the treasonal myselfShWhere shall in's from that not chance begg\n",
            " noble, I how poor shall it it mePro it.\n",
            "H not old in old! pray,, look go.\n",
            "ak night own let hum my against sightthr together;Put thy\n",
            " take hands his time deer:hold here liv here\n",
            " I atfed and chivalry France despairHereWithTPThat shallasty side my's is: I him conf;W days sets cannot\n",
            "Prompt: 'In '\n",
            "In , Godoe Lords,st my: until the would convey is; stay IHall no at,' thouertarr or patience\n",
            " Ied poor with blood my villain,' sorrow\n",
            " cousin a mother a gentleman cheering full souls\n",
            " thouin;For'll prove how wing oning thy\n",
            " thouinWrite'd the trees onTwo on earth ours the,With, spoke on earth is\n",
            "allly of,re art him a,umer, Stanley s, Mont, out eyes jewels the,\n",
            "Prompt: 'To '\n",
            "To  upon foes departure what to,\n",
            " ding and him the of-sw war OB us, thou it burst drown until his.\n",
            "K RARD:God his subject amen\n",
            " goodst shame his wrongs whoeful steps deliver!\n",
            " hid\n",
            " chast sound more and foul inSo\n",
            " wash likeAl, will such success my,\n",
            " give\n",
            " threeixed? that his be,p cold,\n",
            " parts and, high are leaves charge\n",
            " been und!\n",
            " kept fearful!\n",
            "H:Now\n",
            "Prompt: 'A '\n",
            "A rant thy to well recorded.\n",
            "HRYOLB: sits honour\n",
            " between always, willing myself measure.\n",
            "H:ieu not my\n",
            " faults and\n",
            "o my, weore.\n",
            "K RARD\n",
            "TrustHRY\n",
            " lural his's,\n",
            "BERLove judge:, flint aidnow!\n",
            "Ho\n",
            "HOORS:\n",
            " I here set bydo and.\n",
            "Hs you honest, will Well theitor Duke Norfolk body\n",
            " beenplain th own return thy,\n",
            " pardon\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  41%|████      | 2051/5000 [1:32:24<5:11:46,  6.34s/it, loss=1.5741]\u001b[A\n",
            "Training:  41%|████      | 2051/5000 [1:32:24<5:11:46,  6.34s/it, loss=1.3506]\u001b[A\n",
            "Training:  41%|████      | 2052/5000 [1:32:27<4:12:11,  5.13s/it, loss=1.3506]\u001b[A\n",
            "Training:  41%|████      | 2052/5000 [1:32:27<4:12:11,  5.13s/it, loss=1.4076]\u001b[A\n",
            "Training:  41%|████      | 2053/5000 [1:32:29<3:31:27,  4.31s/it, loss=1.4076]\u001b[A\n",
            "Training:  41%|████      | 2053/5000 [1:32:29<3:31:27,  4.31s/it, loss=1.1676]\u001b[A\n",
            "Training:  41%|████      | 2054/5000 [1:32:31<3:02:04,  3.71s/it, loss=1.1676]\u001b[A\n",
            "Training:  41%|████      | 2054/5000 [1:32:31<3:02:04,  3.71s/it, loss=1.7945]\u001b[A\n",
            "Training:  41%|████      | 2055/5000 [1:32:34<2:44:52,  3.36s/it, loss=1.7945]\u001b[A\n",
            "Training:  41%|████      | 2055/5000 [1:32:34<2:44:52,  3.36s/it, loss=1.8413]\u001b[A\n",
            "Training:  41%|████      | 2056/5000 [1:32:36<2:33:59,  3.14s/it, loss=1.8413]\u001b[A\n",
            "Training:  41%|████      | 2056/5000 [1:32:37<2:33:59,  3.14s/it, loss=1.3233]\u001b[A\n",
            "Training:  41%|████      | 2057/5000 [1:32:39<2:21:52,  2.89s/it, loss=1.3233]\u001b[A\n",
            "Training:  41%|████      | 2057/5000 [1:32:39<2:21:52,  2.89s/it, loss=1.5431]\u001b[A\n",
            "Training:  41%|████      | 2058/5000 [1:32:41<2:13:07,  2.71s/it, loss=1.5431]\u001b[A\n",
            "Training:  41%|████      | 2058/5000 [1:32:41<2:13:07,  2.71s/it, loss=1.2759]\u001b[A\n",
            "Training:  41%|████      | 2059/5000 [1:32:43<2:07:50,  2.61s/it, loss=1.2759]\u001b[A\n",
            "Training:  41%|████      | 2059/5000 [1:32:43<2:07:50,  2.61s/it, loss=1.0748]\u001b[A\n",
            "Training:  41%|████      | 2060/5000 [1:32:46<2:07:41,  2.61s/it, loss=1.0748]\u001b[A\n",
            "Training:  41%|████      | 2060/5000 [1:32:46<2:07:41,  2.61s/it, loss=1.3572]\u001b[A\n",
            "Training:  41%|████      | 2061/5000 [1:32:49<2:06:46,  2.59s/it, loss=1.3572]\u001b[A\n",
            "Training:  41%|████      | 2061/5000 [1:32:49<2:06:46,  2.59s/it, loss=1.1373]\u001b[A\n",
            "Training:  41%|████      | 2062/5000 [1:32:51<2:02:33,  2.50s/it, loss=1.1373]\u001b[A\n",
            "Training:  41%|████      | 2062/5000 [1:32:51<2:02:33,  2.50s/it, loss=1.3424]\u001b[A\n",
            "Training:  41%|████▏     | 2063/5000 [1:32:53<1:58:59,  2.43s/it, loss=1.3424]\u001b[A\n",
            "Training:  41%|████▏     | 2063/5000 [1:32:53<1:58:59,  2.43s/it, loss=2.0481]\u001b[A\n",
            "Training:  41%|████▏     | 2064/5000 [1:32:55<1:55:47,  2.37s/it, loss=2.0481]\u001b[A\n",
            "Training:  41%|████▏     | 2064/5000 [1:32:55<1:55:47,  2.37s/it, loss=2.4177]\u001b[A\n",
            "Training:  41%|████▏     | 2065/5000 [1:32:58<1:58:14,  2.42s/it, loss=2.4177]\u001b[A\n",
            "Training:  41%|████▏     | 2065/5000 [1:32:58<1:58:14,  2.42s/it, loss=1.8429]\u001b[A\n",
            "Training:  41%|████▏     | 2066/5000 [1:33:00<1:59:23,  2.44s/it, loss=1.8429]\u001b[A\n",
            "Training:  41%|████▏     | 2066/5000 [1:33:00<1:59:23,  2.44s/it, loss=1.8533]\u001b[A\n",
            "Training:  41%|████▏     | 2067/5000 [1:33:03<1:56:55,  2.39s/it, loss=1.8533]\u001b[A\n",
            "Training:  41%|████▏     | 2067/5000 [1:33:03<1:56:55,  2.39s/it, loss=2.6119]\u001b[A\n",
            "Training:  41%|████▏     | 2068/5000 [1:33:05<1:54:56,  2.35s/it, loss=2.6119]\u001b[A\n",
            "Training:  41%|████▏     | 2068/5000 [1:33:05<1:54:56,  2.35s/it, loss=1.6123]\u001b[A\n",
            "Training:  41%|████▏     | 2069/5000 [1:33:07<1:52:56,  2.31s/it, loss=1.6123]\u001b[A\n",
            "Training:  41%|████▏     | 2069/5000 [1:33:07<1:52:56,  2.31s/it, loss=1.6089]\u001b[A\n",
            "Training:  41%|████▏     | 2070/5000 [1:33:10<1:55:37,  2.37s/it, loss=1.6089]\u001b[A\n",
            "Training:  41%|████▏     | 2070/5000 [1:33:10<1:55:37,  2.37s/it, loss=1.4160]\u001b[A\n",
            "Training:  41%|████▏     | 2071/5000 [1:33:12<1:58:16,  2.42s/it, loss=1.4160]\u001b[A\n",
            "Training:  41%|████▏     | 2071/5000 [1:33:12<1:58:16,  2.42s/it, loss=1.4291]\u001b[A\n",
            "Training:  41%|████▏     | 2072/5000 [1:33:14<1:56:00,  2.38s/it, loss=1.4291]\u001b[A\n",
            "Training:  41%|████▏     | 2072/5000 [1:33:15<1:56:00,  2.38s/it, loss=1.7687]\u001b[A\n",
            "Training:  41%|████▏     | 2073/5000 [1:33:17<1:54:21,  2.34s/it, loss=1.7687]\u001b[A\n",
            "Training:  41%|████▏     | 2073/5000 [1:33:17<1:54:21,  2.34s/it, loss=1.2726]\u001b[A\n",
            "Training:  41%|████▏     | 2074/5000 [1:33:19<1:52:39,  2.31s/it, loss=1.2726]\u001b[A\n",
            "Training:  41%|████▏     | 2074/5000 [1:33:19<1:52:39,  2.31s/it, loss=1.5232]\u001b[A\n",
            "Training:  42%|████▏     | 2075/5000 [1:33:21<1:54:58,  2.36s/it, loss=1.5232]\u001b[A\n",
            "Training:  42%|████▏     | 2075/5000 [1:33:21<1:54:58,  2.36s/it, loss=1.6126]\u001b[A\n",
            "Training:  42%|████▏     | 2076/5000 [1:33:24<1:57:29,  2.41s/it, loss=1.6126]\u001b[A\n",
            "Training:  42%|████▏     | 2076/5000 [1:33:24<1:57:29,  2.41s/it, loss=1.3939]\u001b[A\n",
            "Training:  42%|████▏     | 2077/5000 [1:33:26<1:54:53,  2.36s/it, loss=1.3939]\u001b[A\n",
            "Training:  42%|████▏     | 2077/5000 [1:33:26<1:54:53,  2.36s/it, loss=1.2023]\u001b[A\n",
            "Training:  42%|████▏     | 2078/5000 [1:33:28<1:53:07,  2.32s/it, loss=1.2023]\u001b[A\n",
            "Training:  42%|████▏     | 2078/5000 [1:33:29<1:53:07,  2.32s/it, loss=1.2645]\u001b[A\n",
            "Training:  42%|████▏     | 2079/5000 [1:33:31<1:51:34,  2.29s/it, loss=1.2645]\u001b[A\n",
            "Training:  42%|████▏     | 2079/5000 [1:33:31<1:51:34,  2.29s/it, loss=1.4442]\u001b[A\n",
            "Training:  42%|████▏     | 2080/5000 [1:33:33<1:53:34,  2.33s/it, loss=1.4442]\u001b[A\n",
            "Training:  42%|████▏     | 2080/5000 [1:33:33<1:53:34,  2.33s/it, loss=1.3123]\u001b[A\n",
            "Training:  42%|████▏     | 2081/5000 [1:33:36<1:57:14,  2.41s/it, loss=1.3123]\u001b[A\n",
            "Training:  42%|████▏     | 2081/5000 [1:33:36<1:57:14,  2.41s/it, loss=1.8667]\u001b[A\n",
            "Training:  42%|████▏     | 2082/5000 [1:33:38<1:54:41,  2.36s/it, loss=1.8667]\u001b[A\n",
            "Training:  42%|████▏     | 2082/5000 [1:33:38<1:54:41,  2.36s/it, loss=1.5922]\u001b[A\n",
            "Training:  42%|████▏     | 2083/5000 [1:33:40<1:52:49,  2.32s/it, loss=1.5922]\u001b[A\n",
            "Training:  42%|████▏     | 2083/5000 [1:33:40<1:52:49,  2.32s/it, loss=1.8051]\u001b[A\n",
            "Training:  42%|████▏     | 2084/5000 [1:33:42<1:51:32,  2.29s/it, loss=1.8051]\u001b[A\n",
            "Training:  42%|████▏     | 2084/5000 [1:33:42<1:51:32,  2.29s/it, loss=1.7299]\u001b[A\n",
            "Training:  42%|████▏     | 2085/5000 [1:33:45<1:52:37,  2.32s/it, loss=1.7299]\u001b[A\n",
            "Training:  42%|████▏     | 2085/5000 [1:33:45<1:52:37,  2.32s/it, loss=1.6870]\u001b[A\n",
            "Training:  42%|████▏     | 2086/5000 [1:33:47<1:57:04,  2.41s/it, loss=1.6870]\u001b[A\n",
            "Training:  42%|████▏     | 2086/5000 [1:33:47<1:57:04,  2.41s/it, loss=1.4255]\u001b[A\n",
            "Training:  42%|████▏     | 2087/5000 [1:33:50<1:54:14,  2.35s/it, loss=1.4255]\u001b[A\n",
            "Training:  42%|████▏     | 2087/5000 [1:33:50<1:54:14,  2.35s/it, loss=1.4760]\u001b[A\n",
            "Training:  42%|████▏     | 2088/5000 [1:33:52<1:52:23,  2.32s/it, loss=1.4760]\u001b[A\n",
            "Training:  42%|████▏     | 2088/5000 [1:33:52<1:52:23,  2.32s/it, loss=1.6789]\u001b[A\n",
            "Training:  42%|████▏     | 2089/5000 [1:33:54<1:51:04,  2.29s/it, loss=1.6789]\u001b[A\n",
            "Training:  42%|████▏     | 2089/5000 [1:33:54<1:51:04,  2.29s/it, loss=1.2270]\u001b[A\n",
            "Training:  42%|████▏     | 2090/5000 [1:33:56<1:49:49,  2.26s/it, loss=1.2270]\u001b[A\n",
            "Training:  42%|████▏     | 2090/5000 [1:33:56<1:49:49,  2.26s/it, loss=1.3780]\u001b[A\n",
            "Training:  42%|████▏     | 2091/5000 [1:33:59<1:57:26,  2.42s/it, loss=1.3780]\u001b[A\n",
            "Training:  42%|████▏     | 2091/5000 [1:33:59<1:57:26,  2.42s/it, loss=1.4587]\u001b[A\n",
            "Training:  42%|████▏     | 2092/5000 [1:34:01<1:54:43,  2.37s/it, loss=1.4587]\u001b[A\n",
            "Training:  42%|████▏     | 2092/5000 [1:34:01<1:54:43,  2.37s/it, loss=1.4235]\u001b[A\n",
            "Training:  42%|████▏     | 2093/5000 [1:34:04<1:53:07,  2.33s/it, loss=1.4235]\u001b[A\n",
            "Training:  42%|████▏     | 2093/5000 [1:34:04<1:53:07,  2.33s/it, loss=1.3500]\u001b[A\n",
            "Training:  42%|████▏     | 2094/5000 [1:34:06<1:51:38,  2.30s/it, loss=1.3500]\u001b[A\n",
            "Training:  42%|████▏     | 2094/5000 [1:34:06<1:51:38,  2.30s/it, loss=1.5514]\u001b[A\n",
            "Training:  42%|████▏     | 2095/5000 [1:34:08<1:50:50,  2.29s/it, loss=1.5514]\u001b[A\n",
            "Training:  42%|████▏     | 2095/5000 [1:34:08<1:50:50,  2.29s/it, loss=1.3097]\u001b[A\n",
            "Training:  42%|████▏     | 2096/5000 [1:34:11<1:58:10,  2.44s/it, loss=1.3097]\u001b[A\n",
            "Training:  42%|████▏     | 2096/5000 [1:34:11<1:58:10,  2.44s/it, loss=1.2926]\u001b[A\n",
            "Training:  42%|████▏     | 2097/5000 [1:34:13<1:55:16,  2.38s/it, loss=1.2926]\u001b[A\n",
            "Training:  42%|████▏     | 2097/5000 [1:34:13<1:55:16,  2.38s/it, loss=1.3397]\u001b[A\n",
            "Training:  42%|████▏     | 2098/5000 [1:34:15<1:52:59,  2.34s/it, loss=1.3397]\u001b[A\n",
            "Training:  42%|████▏     | 2098/5000 [1:34:15<1:52:59,  2.34s/it, loss=1.1033]\u001b[A\n",
            "Training:  42%|████▏     | 2099/5000 [1:34:18<1:51:32,  2.31s/it, loss=1.1033]\u001b[A\n",
            "Training:  42%|████▏     | 2099/5000 [1:34:18<1:51:32,  2.31s/it, loss=1.3168]\u001b[A\n",
            "Training:  42%|████▏     | 2100/5000 [1:34:20<1:50:16,  2.28s/it, loss=1.3168]\u001b[A\n",
            "Training:  42%|████▏     | 2100/5000 [1:34:20<1:50:16,  2.28s/it, loss=1.0401]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 2100 ---\n",
            "Prompt: 'The '\n",
            "The  of war be'd hath dedication\n",
            "st wh'd as as's as as's as\n",
            " is King's and what set best heaven\n",
            "aped the-ied should power we.\n",
            "ISPu your in heartim do\n",
            " isale heart yetake whichtw would his south\n",
            " place people his ladyby to his; if enemypt, his, then that in enclosed his ground\n",
            "ED populousrem and's enemies got themselves, then all natureANGO\n",
            " are falsehood hisellow Hon quite'sure\n",
            "Prompt: 'In '\n",
            "In  blessed have here Let highqu to.\n",
            "K in's, blood thou we to queen web downath heral the seas\n",
            " troops them the of's-ting came. an blood late thou'd the to join attempt\n",
            " raise idle at, out and gun persony lords\n",
            " revel off child gave gyul, through of fourteenia inAnd her state\n",
            " cloth arrived by letters be'd the's;, you out therant to the'sance\n",
            " celebration tro'sinsch, was say\n",
            "Prompt: 'To '\n",
            "To  my heart thorn hatch will be'd\n",
            " with'soe and nottis love care\n",
            " mean are as as and having's we.\n",
            "K H upon ground, lords and thy is'dUpont;And thou\n",
            " this here as as as as as as as as person brought patienceced to.\n",
            "WARICK\n",
            "itiesing both and; thinkt's would proud deck to and\n",
            "'is troop mercy,, thourt it his ra\n",
            "Gst them like causes on way and\n",
            "Mess:\n",
            "Prompt: 'A '\n",
            "A , hides fear\n",
            " D punish.\n",
            "WARICK\n",
            "And of,am or,'ll thy dangerous.\n",
            " true comfort enough\n",
            " esp sovereignty\n",
            " upAre's- her king Pray.\n",
            "CLENCE:S tenaste h, heaven andark part\n",
            " sp to his midw toay or of the's integrity in ch,tis onardon, we notSweetnow on visit;'s, shall not CorICK his, Be;,tis wreat with.\n",
            "WARICK honours you arch in,That\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  42%|████▏     | 2101/5000 [1:34:35<5:04:09,  6.30s/it, loss=1.0401]\u001b[A\n",
            "Training:  42%|████▏     | 2101/5000 [1:34:35<5:04:09,  6.30s/it, loss=1.2118]\u001b[A\n",
            "Training:  42%|████▏     | 2102/5000 [1:34:38<4:08:13,  5.14s/it, loss=1.2118]\u001b[A\n",
            "Training:  42%|████▏     | 2102/5000 [1:34:38<4:08:13,  5.14s/it, loss=0.9005]\u001b[A\n",
            "Training:  42%|████▏     | 2103/5000 [1:34:40<3:28:23,  4.32s/it, loss=0.9005]\u001b[A\n",
            "Training:  42%|████▏     | 2103/5000 [1:34:40<3:28:23,  4.32s/it, loss=1.1935]\u001b[A\n",
            "Training:  42%|████▏     | 2104/5000 [1:34:43<3:01:11,  3.75s/it, loss=1.1935]\u001b[A\n",
            "Training:  42%|████▏     | 2104/5000 [1:34:43<3:01:11,  3.75s/it, loss=2.0022]\u001b[A\n",
            "Training:  42%|████▏     | 2105/5000 [1:34:46<2:48:54,  3.50s/it, loss=2.0022]\u001b[A\n",
            "Training:  42%|████▏     | 2105/5000 [1:34:46<2:48:54,  3.50s/it, loss=1.7811]\u001b[A\n",
            "Training:  42%|████▏     | 2106/5000 [1:34:48<2:34:10,  3.20s/it, loss=1.7811]\u001b[A\n",
            "Training:  42%|████▏     | 2106/5000 [1:34:48<2:34:10,  3.20s/it, loss=1.7770]\u001b[A\n",
            "Training:  42%|████▏     | 2107/5000 [1:34:51<2:22:24,  2.95s/it, loss=1.7770]\u001b[A\n",
            "Training:  42%|████▏     | 2107/5000 [1:34:51<2:22:24,  2.95s/it, loss=1.3856]\u001b[A\n",
            "Training:  42%|████▏     | 2108/5000 [1:34:53<2:14:40,  2.79s/it, loss=1.3856]\u001b[A\n",
            "Training:  42%|████▏     | 2108/5000 [1:34:53<2:14:40,  2.79s/it, loss=1.4841]\u001b[A\n",
            "Training:  42%|████▏     | 2109/5000 [1:34:55<2:09:00,  2.68s/it, loss=1.4841]\u001b[A\n",
            "Training:  42%|████▏     | 2109/5000 [1:34:55<2:09:00,  2.68s/it, loss=1.2181]\u001b[A\n",
            "Training:  42%|████▏     | 2110/5000 [1:34:58<2:13:15,  2.77s/it, loss=1.2181]\u001b[A\n",
            "Training:  42%|████▏     | 2110/5000 [1:34:58<2:13:15,  2.77s/it, loss=1.6967]\u001b[A\n",
            "Training:  42%|████▏     | 2111/5000 [1:35:01<2:08:19,  2.67s/it, loss=1.6967]\u001b[A\n",
            "Training:  42%|████▏     | 2111/5000 [1:35:01<2:08:19,  2.67s/it, loss=1.2680]\u001b[A\n",
            "Training:  42%|████▏     | 2112/5000 [1:35:03<2:04:03,  2.58s/it, loss=1.2680]\u001b[A\n",
            "Training:  42%|████▏     | 2112/5000 [1:35:03<2:04:03,  2.58s/it, loss=1.4035]\u001b[A\n",
            "Training:  42%|████▏     | 2113/5000 [1:35:06<2:02:10,  2.54s/it, loss=1.4035]\u001b[A\n",
            "Training:  42%|████▏     | 2113/5000 [1:35:06<2:02:10,  2.54s/it, loss=1.8171]\u001b[A\n",
            "Training:  42%|████▏     | 2114/5000 [1:35:08<2:01:30,  2.53s/it, loss=1.8171]\u001b[A\n",
            "Training:  42%|████▏     | 2114/5000 [1:35:08<2:01:30,  2.53s/it, loss=1.6749]\u001b[A\n",
            "Training:  42%|████▏     | 2115/5000 [1:35:11<2:06:06,  2.62s/it, loss=1.6749]\u001b[A\n",
            "Training:  42%|████▏     | 2115/5000 [1:35:11<2:06:06,  2.62s/it, loss=1.8649]\u001b[A\n",
            "Training:  42%|████▏     | 2116/5000 [1:35:13<2:03:09,  2.56s/it, loss=1.8649]\u001b[A\n",
            "Training:  42%|████▏     | 2116/5000 [1:35:13<2:03:09,  2.56s/it, loss=1.3844]\u001b[A\n",
            "Training:  42%|████▏     | 2117/5000 [1:35:16<2:00:48,  2.51s/it, loss=1.3844]\u001b[A\n",
            "Training:  42%|████▏     | 2117/5000 [1:35:16<2:00:48,  2.51s/it, loss=1.6831]\u001b[A\n",
            "Training:  42%|████▏     | 2118/5000 [1:35:18<1:59:17,  2.48s/it, loss=1.6831]\u001b[A\n",
            "Training:  42%|████▏     | 2118/5000 [1:35:18<1:59:17,  2.48s/it, loss=1.2779]\u001b[A\n",
            "Training:  42%|████▏     | 2119/5000 [1:35:21<2:01:58,  2.54s/it, loss=1.2779]\u001b[A\n",
            "Training:  42%|████▏     | 2119/5000 [1:35:21<2:01:58,  2.54s/it, loss=1.8068]\u001b[A\n",
            "Training:  42%|████▏     | 2120/5000 [1:35:23<2:03:15,  2.57s/it, loss=1.8068]\u001b[A\n",
            "Training:  42%|████▏     | 2120/5000 [1:35:23<2:03:15,  2.57s/it, loss=1.4666]\u001b[A\n",
            "Training:  42%|████▏     | 2121/5000 [1:35:26<2:00:20,  2.51s/it, loss=1.4666]\u001b[A\n",
            "Training:  42%|████▏     | 2121/5000 [1:35:26<2:00:20,  2.51s/it, loss=1.8692]\u001b[A\n",
            "Training:  42%|████▏     | 2122/5000 [1:35:28<1:58:37,  2.47s/it, loss=1.8692]\u001b[A\n",
            "Training:  42%|████▏     | 2122/5000 [1:35:28<1:58:37,  2.47s/it, loss=1.3244]\u001b[A\n",
            "Training:  42%|████▏     | 2123/5000 [1:35:31<1:57:38,  2.45s/it, loss=1.3244]\u001b[A\n",
            "Training:  42%|████▏     | 2123/5000 [1:35:31<1:57:38,  2.45s/it, loss=1.3997]\u001b[A\n",
            "Training:  42%|████▏     | 2124/5000 [1:35:34<2:04:41,  2.60s/it, loss=1.3997]\u001b[A\n",
            "Training:  42%|████▏     | 2124/5000 [1:35:34<2:04:41,  2.60s/it, loss=2.0174]\u001b[A\n",
            "Training:  42%|████▎     | 2125/5000 [1:35:36<2:01:34,  2.54s/it, loss=2.0174]\u001b[A\n",
            "Training:  42%|████▎     | 2125/5000 [1:35:36<2:01:34,  2.54s/it, loss=1.7591]\u001b[A\n",
            "Training:  43%|████▎     | 2126/5000 [1:35:38<1:58:46,  2.48s/it, loss=1.7591]\u001b[A\n",
            "Training:  43%|████▎     | 2126/5000 [1:35:38<1:58:46,  2.48s/it, loss=1.3836]\u001b[A\n",
            "Training:  43%|████▎     | 2127/5000 [1:35:41<1:57:41,  2.46s/it, loss=1.3836]\u001b[A\n",
            "Training:  43%|████▎     | 2127/5000 [1:35:41<1:57:41,  2.46s/it, loss=1.7917]\u001b[A\n",
            "Training:  43%|████▎     | 2128/5000 [1:35:43<1:56:32,  2.43s/it, loss=1.7917]\u001b[A\n",
            "Training:  43%|████▎     | 2128/5000 [1:35:43<1:56:32,  2.43s/it, loss=1.2812]\u001b[A\n",
            "Training:  43%|████▎     | 2129/5000 [1:35:46<2:03:50,  2.59s/it, loss=1.2812]\u001b[A\n",
            "Training:  43%|████▎     | 2129/5000 [1:35:46<2:03:50,  2.59s/it, loss=1.2786]\u001b[A\n",
            "Training:  43%|████▎     | 2130/5000 [1:35:48<2:00:38,  2.52s/it, loss=1.2786]\u001b[A\n",
            "Training:  43%|████▎     | 2130/5000 [1:35:48<2:00:38,  2.52s/it, loss=1.3502]\u001b[A\n",
            "Training:  43%|████▎     | 2131/5000 [1:35:51<1:58:50,  2.49s/it, loss=1.3502]\u001b[A\n",
            "Training:  43%|████▎     | 2131/5000 [1:35:51<1:58:50,  2.49s/it, loss=1.7354]\u001b[A\n",
            "Training:  43%|████▎     | 2132/5000 [1:35:53<1:56:50,  2.44s/it, loss=1.7354]\u001b[A\n",
            "Training:  43%|████▎     | 2132/5000 [1:35:53<1:56:50,  2.44s/it, loss=1.7789]\u001b[A\n",
            "Training:  43%|████▎     | 2133/5000 [1:35:56<1:55:57,  2.43s/it, loss=1.7789]\u001b[A\n",
            "Training:  43%|████▎     | 2133/5000 [1:35:56<1:55:57,  2.43s/it, loss=1.4591]\u001b[A\n",
            "Training:  43%|████▎     | 2134/5000 [1:35:58<2:03:06,  2.58s/it, loss=1.4591]\u001b[A\n",
            "Training:  43%|████▎     | 2134/5000 [1:35:59<2:03:06,  2.58s/it, loss=1.4582]\u001b[A\n",
            "Training:  43%|████▎     | 2135/5000 [1:36:01<2:01:02,  2.54s/it, loss=1.4582]\u001b[A\n",
            "Training:  43%|████▎     | 2135/5000 [1:36:01<2:01:02,  2.54s/it, loss=1.5197]\u001b[A\n",
            "Training:  43%|████▎     | 2136/5000 [1:36:03<1:58:33,  2.48s/it, loss=1.5197]\u001b[A\n",
            "Training:  43%|████▎     | 2136/5000 [1:36:03<1:58:33,  2.48s/it, loss=2.0855]\u001b[A\n",
            "Training:  43%|████▎     | 2137/5000 [1:36:06<1:56:56,  2.45s/it, loss=2.0855]\u001b[A\n",
            "Training:  43%|████▎     | 2137/5000 [1:36:06<1:56:56,  2.45s/it, loss=1.0940]\u001b[A\n",
            "Training:  43%|████▎     | 2138/5000 [1:36:08<1:59:39,  2.51s/it, loss=1.0940]\u001b[A\n",
            "Training:  43%|████▎     | 2138/5000 [1:36:08<1:59:39,  2.51s/it, loss=1.0438]\u001b[A\n",
            "Training:  43%|████▎     | 2139/5000 [1:36:11<2:03:08,  2.58s/it, loss=1.0438]\u001b[A\n",
            "Training:  43%|████▎     | 2139/5000 [1:36:11<2:03:08,  2.58s/it, loss=1.2505]\u001b[A\n",
            "Training:  43%|████▎     | 2140/5000 [1:36:13<2:00:17,  2.52s/it, loss=1.2505]\u001b[A\n",
            "Training:  43%|████▎     | 2140/5000 [1:36:13<2:00:17,  2.52s/it, loss=1.0310]\u001b[A\n",
            "Training:  43%|████▎     | 2141/5000 [1:36:16<1:58:13,  2.48s/it, loss=1.0310]\u001b[A\n",
            "Training:  43%|████▎     | 2141/5000 [1:36:16<1:58:13,  2.48s/it, loss=1.1775]\u001b[A\n",
            "Training:  43%|████▎     | 2142/5000 [1:36:18<1:56:38,  2.45s/it, loss=1.1775]\u001b[A\n",
            "Training:  43%|████▎     | 2142/5000 [1:36:18<1:56:38,  2.45s/it, loss=1.4854]\u001b[A\n",
            "Training:  43%|████▎     | 2143/5000 [1:36:21<2:00:04,  2.52s/it, loss=1.4854]\u001b[A\n",
            "Training:  43%|████▎     | 2143/5000 [1:36:21<2:00:04,  2.52s/it, loss=1.3704]\u001b[A\n",
            "Training:  43%|████▎     | 2144/5000 [1:36:23<2:01:05,  2.54s/it, loss=1.3704]\u001b[A\n",
            "Training:  43%|████▎     | 2144/5000 [1:36:24<2:01:05,  2.54s/it, loss=1.6159]\u001b[A\n",
            "Training:  43%|████▎     | 2145/5000 [1:36:26<1:58:27,  2.49s/it, loss=1.6159]\u001b[A\n",
            "Training:  43%|████▎     | 2145/5000 [1:36:26<1:58:27,  2.49s/it, loss=1.7096]\u001b[A\n",
            "Training:  43%|████▎     | 2146/5000 [1:36:28<1:56:46,  2.45s/it, loss=1.7096]\u001b[A\n",
            "Training:  43%|████▎     | 2146/5000 [1:36:28<1:56:46,  2.45s/it, loss=1.4369]\u001b[A\n",
            "Training:  43%|████▎     | 2147/5000 [1:36:31<1:56:14,  2.44s/it, loss=1.4369]\u001b[A\n",
            "Training:  43%|████▎     | 2147/5000 [1:36:31<1:56:14,  2.44s/it, loss=1.5212]\u001b[A\n",
            "Training:  43%|████▎     | 2148/5000 [1:36:34<2:03:24,  2.60s/it, loss=1.5212]\u001b[A\n",
            "Training:  43%|████▎     | 2148/5000 [1:36:34<2:03:24,  2.60s/it, loss=1.3800]\u001b[A\n",
            "Training:  43%|████▎     | 2149/5000 [1:36:36<1:59:55,  2.52s/it, loss=1.3800]\u001b[A\n",
            "Training:  43%|████▎     | 2149/5000 [1:36:36<1:59:55,  2.52s/it, loss=1.2167]\u001b[A\n",
            "Training:  43%|████▎     | 2150/5000 [1:36:38<1:57:28,  2.47s/it, loss=1.2167]\u001b[A\n",
            "Training:  43%|████▎     | 2150/5000 [1:36:38<1:57:28,  2.47s/it, loss=1.4900]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 2150 ---\n",
            "Prompt: 'The '\n",
            "The  dark or to said pain drawn him shame\n",
            " heides Bapt? and d thou sub from\n",
            ",As hath sick with his were stone with.\n",
            "BTDAIO\n",
            "KARI:tis not.\n",
            "BDELpt face for as co, I!, will let so?\n",
            "ou be that me I he say\n",
            "L stops did:O if were other; he thouert: mark, an by, my theost quiet thy will.\n",
            "G not, sweet, you'd so\n",
            "Prompt: 'In '\n",
            "In  all have me thisly:\n",
            " you,?\n",
            "PETCHru,ruay that friends long have exactly\n",
            " the of.\n",
            "PET the sit good, and, or dty well\n",
            ", me g did me, me, me,ee you\n",
            ", you, me, that have soyy\n",
            " what was young urgent follow\n",
            ", me, me, me if o the of. you Sign Gio ay you Sign Gio she O his way the;, you convey\n",
            ",\n",
            "Prompt: 'To '\n",
            "To  her lun: it sheisa fault it.\n",
            "PET thou said kn, thoust thou wed being toail you.\n",
            "KARI:I! will w it so but let thieves in\n",
            " pretty, I thoust fight if mean how it.\n",
            "PETCHens or? say what say what say be.\n",
            "KARI:A\n",
            "KARI:' father liverian.\n",
            "PETCH: must, nameland what tender best father to.\n",
            "PETCH: thouov, thouES\n",
            "Prompt: 'A '\n",
            "A  is and and love all have the,Which\n",
            " make so the-ner a matter?\n",
            "BDELIST thread\n",
            "BTching,,, shall all for week\n",
            " for purpose V ye,, now was oldy of.Ye, is: mean this of! the on '! it thest of-Cam let nothing us, youBeed if\n",
            "GRIO\n",
            "ed:What thest it; comes the would lay,, still speak, his's If of?\n",
            "B\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  43%|████▎     | 2151/5000 [1:36:54<5:02:34,  6.37s/it, loss=1.4900]\u001b[A\n",
            "Training:  43%|████▎     | 2151/5000 [1:36:54<5:02:34,  6.37s/it, loss=1.1139]\u001b[A\n",
            "Training:  43%|████▎     | 2152/5000 [1:36:56<4:08:43,  5.24s/it, loss=1.1139]\u001b[A\n",
            "Training:  43%|████▎     | 2152/5000 [1:36:56<4:08:43,  5.24s/it, loss=1.1587]\u001b[A\n",
            "Training:  43%|████▎     | 2153/5000 [1:36:59<3:32:36,  4.48s/it, loss=1.1587]\u001b[A\n",
            "Training:  43%|████▎     | 2153/5000 [1:36:59<3:32:36,  4.48s/it, loss=1.2993]\u001b[A\n",
            "Training:  43%|████▎     | 2154/5000 [1:37:01<3:03:03,  3.86s/it, loss=1.2993]\u001b[A\n",
            "Training:  43%|████▎     | 2154/5000 [1:37:02<3:03:03,  3.86s/it, loss=1.3602]\u001b[A\n",
            "Training:  43%|████▎     | 2155/5000 [1:37:04<2:42:26,  3.43s/it, loss=1.3602]\u001b[A\n",
            "Training:  43%|████▎     | 2155/5000 [1:37:04<2:42:26,  3.43s/it, loss=1.2898]\u001b[A\n",
            "Training:  43%|████▎     | 2156/5000 [1:37:06<2:27:26,  3.11s/it, loss=1.2898]\u001b[A\n",
            "Training:  43%|████▎     | 2156/5000 [1:37:06<2:27:26,  3.11s/it, loss=1.0083]\u001b[A\n",
            "Training:  43%|████▎     | 2157/5000 [1:37:09<2:22:32,  3.01s/it, loss=1.0083]\u001b[A\n",
            "Training:  43%|████▎     | 2157/5000 [1:37:09<2:22:32,  3.01s/it, loss=1.1627]\u001b[A\n",
            "Training:  43%|████▎     | 2158/5000 [1:37:12<2:15:54,  2.87s/it, loss=1.1627]\u001b[A\n",
            "Training:  43%|████▎     | 2158/5000 [1:37:12<2:15:54,  2.87s/it, loss=1.2207]\u001b[A\n",
            "Training:  43%|████▎     | 2159/5000 [1:37:14<2:08:58,  2.72s/it, loss=1.2207]\u001b[A\n",
            "Training:  43%|████▎     | 2159/5000 [1:37:14<2:08:58,  2.72s/it, loss=1.1433]\u001b[A\n",
            "Training:  43%|████▎     | 2160/5000 [1:37:16<2:04:20,  2.63s/it, loss=1.1433]\u001b[A\n",
            "Training:  43%|████▎     | 2160/5000 [1:37:16<2:04:20,  2.63s/it, loss=2.0751]\u001b[A\n",
            "Training:  43%|████▎     | 2161/5000 [1:37:19<2:00:51,  2.55s/it, loss=2.0751]\u001b[A\n",
            "Training:  43%|████▎     | 2161/5000 [1:37:19<2:00:51,  2.55s/it, loss=1.8584]\u001b[A\n",
            "Training:  43%|████▎     | 2162/5000 [1:37:22<2:05:59,  2.66s/it, loss=1.8584]\u001b[A\n",
            "Training:  43%|████▎     | 2162/5000 [1:37:22<2:05:59,  2.66s/it, loss=1.3506]\u001b[A\n",
            "Training:  43%|████▎     | 2163/5000 [1:37:24<2:01:31,  2.57s/it, loss=1.3506]\u001b[A\n",
            "Training:  43%|████▎     | 2163/5000 [1:37:24<2:01:31,  2.57s/it, loss=1.4154]\u001b[A\n",
            "Training:  43%|████▎     | 2164/5000 [1:37:26<1:58:35,  2.51s/it, loss=1.4154]\u001b[A\n",
            "Training:  43%|████▎     | 2164/5000 [1:37:26<1:58:35,  2.51s/it, loss=1.5654]\u001b[A\n",
            "Training:  43%|████▎     | 2165/5000 [1:37:29<1:56:52,  2.47s/it, loss=1.5654]\u001b[A\n",
            "Training:  43%|████▎     | 2165/5000 [1:37:29<1:56:52,  2.47s/it, loss=1.9555]\u001b[A\n",
            "Training:  43%|████▎     | 2166/5000 [1:37:31<1:55:23,  2.44s/it, loss=1.9555]\u001b[A\n",
            "Training:  43%|████▎     | 2166/5000 [1:37:31<1:55:23,  2.44s/it, loss=1.7805]\u001b[A\n",
            "Training:  43%|████▎     | 2167/5000 [1:37:34<2:03:04,  2.61s/it, loss=1.7805]\u001b[A\n",
            "Training:  43%|████▎     | 2167/5000 [1:37:34<2:03:04,  2.61s/it, loss=1.4797]\u001b[A\n",
            "Training:  43%|████▎     | 2168/5000 [1:37:36<1:59:21,  2.53s/it, loss=1.4797]\u001b[A\n",
            "Training:  43%|████▎     | 2168/5000 [1:37:37<1:59:21,  2.53s/it, loss=1.4730]\u001b[A\n",
            "Training:  43%|████▎     | 2169/5000 [1:37:39<1:57:06,  2.48s/it, loss=1.4730]\u001b[A\n",
            "Training:  43%|████▎     | 2169/5000 [1:37:39<1:57:06,  2.48s/it, loss=1.1470]\u001b[A\n",
            "Training:  43%|████▎     | 2170/5000 [1:37:41<1:55:45,  2.45s/it, loss=1.1470]\u001b[A\n",
            "Training:  43%|████▎     | 2170/5000 [1:37:41<1:55:45,  2.45s/it, loss=1.3233]\u001b[A\n",
            "Training:  43%|████▎     | 2171/5000 [1:37:44<1:55:12,  2.44s/it, loss=1.3233]\u001b[A\n",
            "Training:  43%|████▎     | 2171/5000 [1:37:44<1:55:12,  2.44s/it, loss=1.4531]\u001b[A\n",
            "Training:  43%|████▎     | 2172/5000 [1:37:46<1:59:59,  2.55s/it, loss=1.4531]\u001b[A\n",
            "Training:  43%|████▎     | 2172/5000 [1:37:46<1:59:59,  2.55s/it, loss=1.4998]\u001b[A\n",
            "Training:  43%|████▎     | 2173/5000 [1:37:49<1:56:35,  2.47s/it, loss=1.4998]\u001b[A\n",
            "Training:  43%|████▎     | 2173/5000 [1:37:49<1:56:35,  2.47s/it, loss=1.2336]\u001b[A\n",
            "Training:  43%|████▎     | 2174/5000 [1:37:51<1:53:20,  2.41s/it, loss=1.2336]\u001b[A\n",
            "Training:  43%|████▎     | 2174/5000 [1:37:51<1:53:20,  2.41s/it, loss=1.3237]\u001b[A\n",
            "Training:  44%|████▎     | 2175/5000 [1:37:53<1:51:09,  2.36s/it, loss=1.3237]\u001b[A\n",
            "Training:  44%|████▎     | 2175/5000 [1:37:53<1:51:09,  2.36s/it, loss=1.2340]\u001b[A\n",
            "Training:  44%|████▎     | 2176/5000 [1:37:56<1:51:11,  2.36s/it, loss=1.2340]\u001b[A\n",
            "Training:  44%|████▎     | 2176/5000 [1:37:56<1:51:11,  2.36s/it, loss=1.1536]\u001b[A\n",
            "Training:  44%|████▎     | 2177/5000 [1:37:58<1:55:40,  2.46s/it, loss=1.1536]\u001b[A\n",
            "Training:  44%|████▎     | 2177/5000 [1:37:58<1:55:40,  2.46s/it, loss=1.3389]\u001b[A\n",
            "Training:  44%|████▎     | 2178/5000 [1:38:01<1:52:14,  2.39s/it, loss=1.3389]\u001b[A\n",
            "Training:  44%|████▎     | 2178/5000 [1:38:01<1:52:14,  2.39s/it, loss=1.0193]\u001b[A\n",
            "Training:  44%|████▎     | 2179/5000 [1:38:03<1:50:53,  2.36s/it, loss=1.0193]\u001b[A\n",
            "Training:  44%|████▎     | 2179/5000 [1:38:03<1:50:53,  2.36s/it, loss=1.2582]\u001b[A\n",
            "Training:  44%|████▎     | 2180/5000 [1:38:05<1:48:59,  2.32s/it, loss=1.2582]\u001b[A\n",
            "Training:  44%|████▎     | 2180/5000 [1:38:05<1:48:59,  2.32s/it, loss=1.3562]\u001b[A\n",
            "Training:  44%|████▎     | 2181/5000 [1:38:07<1:47:56,  2.30s/it, loss=1.3562]\u001b[A\n",
            "Training:  44%|████▎     | 2181/5000 [1:38:07<1:47:56,  2.30s/it, loss=1.2886]\u001b[A\n",
            "Training:  44%|████▎     | 2182/5000 [1:38:10<1:54:38,  2.44s/it, loss=1.2886]\u001b[A\n",
            "Training:  44%|████▎     | 2182/5000 [1:38:10<1:54:38,  2.44s/it, loss=1.4174]\u001b[A\n",
            "Training:  44%|████▎     | 2183/5000 [1:38:12<1:51:53,  2.38s/it, loss=1.4174]\u001b[A\n",
            "Training:  44%|████▎     | 2183/5000 [1:38:12<1:51:53,  2.38s/it, loss=1.1305]\u001b[A\n",
            "Training:  44%|████▎     | 2184/5000 [1:38:15<1:49:55,  2.34s/it, loss=1.1305]\u001b[A\n",
            "Training:  44%|████▎     | 2184/5000 [1:38:15<1:49:55,  2.34s/it, loss=1.2123]\u001b[A\n",
            "Training:  44%|████▎     | 2185/5000 [1:38:17<1:48:44,  2.32s/it, loss=1.2123]\u001b[A\n",
            "Training:  44%|████▎     | 2185/5000 [1:38:17<1:48:44,  2.32s/it, loss=1.4676]\u001b[A\n",
            "Training:  44%|████▎     | 2186/5000 [1:38:19<1:47:53,  2.30s/it, loss=1.4676]\u001b[A\n",
            "Training:  44%|████▎     | 2186/5000 [1:38:19<1:47:53,  2.30s/it, loss=1.0909]\u001b[A\n",
            "Training:  44%|████▎     | 2187/5000 [1:38:22<1:54:36,  2.44s/it, loss=1.0909]\u001b[A\n",
            "Training:  44%|████▎     | 2187/5000 [1:38:22<1:54:36,  2.44s/it, loss=1.4965]\u001b[A\n",
            "Training:  44%|████▍     | 2188/5000 [1:38:24<1:51:48,  2.39s/it, loss=1.4965]\u001b[A\n",
            "Training:  44%|████▍     | 2188/5000 [1:38:24<1:51:48,  2.39s/it, loss=1.7722]\u001b[A\n",
            "Training:  44%|████▍     | 2189/5000 [1:38:26<1:50:27,  2.36s/it, loss=1.7722]\u001b[A\n",
            "Training:  44%|████▍     | 2189/5000 [1:38:26<1:50:27,  2.36s/it, loss=1.5571]\u001b[A\n",
            "Training:  44%|████▍     | 2190/5000 [1:38:29<1:48:45,  2.32s/it, loss=1.5571]\u001b[A\n",
            "Training:  44%|████▍     | 2190/5000 [1:38:29<1:48:45,  2.32s/it, loss=1.2408]\u001b[A\n",
            "Training:  44%|████▍     | 2191/5000 [1:38:31<1:48:03,  2.31s/it, loss=1.2408]\u001b[A\n",
            "Training:  44%|████▍     | 2191/5000 [1:38:31<1:48:03,  2.31s/it, loss=1.5328]\u001b[A\n",
            "Training:  44%|████▍     | 2192/5000 [1:38:34<1:54:35,  2.45s/it, loss=1.5328]\u001b[A\n",
            "Training:  44%|████▍     | 2192/5000 [1:38:34<1:54:35,  2.45s/it, loss=1.4177]\u001b[A\n",
            "Training:  44%|████▍     | 2193/5000 [1:38:36<1:51:44,  2.39s/it, loss=1.4177]\u001b[A\n",
            "Training:  44%|████▍     | 2193/5000 [1:38:36<1:51:44,  2.39s/it, loss=1.0896]\u001b[A\n",
            "Training:  44%|████▍     | 2194/5000 [1:38:38<1:49:40,  2.35s/it, loss=1.0896]\u001b[A\n",
            "Training:  44%|████▍     | 2194/5000 [1:38:38<1:49:40,  2.35s/it, loss=1.0248]\u001b[A\n",
            "Training:  44%|████▍     | 2195/5000 [1:38:40<1:48:08,  2.31s/it, loss=1.0248]\u001b[A\n",
            "Training:  44%|████▍     | 2195/5000 [1:38:40<1:48:08,  2.31s/it, loss=1.1029]\u001b[A\n",
            "Training:  44%|████▍     | 2196/5000 [1:38:43<1:47:12,  2.29s/it, loss=1.1029]\u001b[A\n",
            "Training:  44%|████▍     | 2196/5000 [1:38:43<1:47:12,  2.29s/it, loss=1.3479]\u001b[A\n",
            "Training:  44%|████▍     | 2197/5000 [1:38:45<1:53:51,  2.44s/it, loss=1.3479]\u001b[A\n",
            "Training:  44%|████▍     | 2197/5000 [1:38:45<1:53:51,  2.44s/it, loss=1.6519]\u001b[A\n",
            "Training:  44%|████▍     | 2198/5000 [1:38:48<1:50:52,  2.37s/it, loss=1.6519]\u001b[A\n",
            "Training:  44%|████▍     | 2198/5000 [1:38:48<1:50:52,  2.37s/it, loss=1.3355]\u001b[A\n",
            "Training:  44%|████▍     | 2199/5000 [1:38:50<1:48:34,  2.33s/it, loss=1.3355]\u001b[A\n",
            "Training:  44%|████▍     | 2199/5000 [1:38:50<1:48:34,  2.33s/it, loss=0.9180]\u001b[A\n",
            "Training:  44%|████▍     | 2200/5000 [1:38:52<1:47:14,  2.30s/it, loss=0.9180]\u001b[A\n",
            "Training:  44%|████▍     | 2200/5000 [1:38:52<1:47:14,  2.30s/it, loss=1.1913]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 2200 ---\n",
            "Prompt: 'The '\n",
            "The ,, to me, well\n",
            " sh ruled froming andaste me\n",
            " believe.\n",
            "B;ent by souls and amanAgain you:Tell,\n",
            ", me I him any who me'd will it done\n",
            " way you but thus cares hope fire first to crown\n",
            " lose brother at that you contr me thrive\n",
            " short queen justice yours and thy; hissw to for?\n",
            "HINGS\n",
            " only it your!He's work yetre; to it.\n",
            "CAT none I,;!\n",
            "Prompt: 'In '\n",
            "In , did for proud's!Could not it you\n",
            " that 'ere atSus that not hath.\n",
            "Gle sons is-:,,, it ent it done\n",
            "in another thee thy is sot in field ourt\n",
            " ismums in andarts and then burning.\n",
            "PRCE, you bear all pack me the ofite then\n",
            " crows in our shall and swords into mind blows to it\n",
            " short; thou us a to for good may be with de;And it like to\n",
            "Prompt: 'To '\n",
            "To  my neck g those favour the\n",
            " of own awile.\n",
            "D,,,,,,,, country of?\n",
            " IIs are with soul famous thy long womb paleWith today\n",
            " wellade If have'd three kn kn's,,, Saint's,? married with h'd\n",
            " thou of?\n",
            " Here, he gone but in field comes\n",
            " yet do drink for:, think rebellion thy son and,;And I\n",
            "all our, thinkoth with little, him their\n",
            "Prompt: 'A '\n",
            "A  of mother a!Cor mother son sons\n",
            " that w'd made twelvedig blood a of,Yourt of\n",
            " me son to, not so a of,,,,B\n",
            " theseomen in hand never\n",
            " pl him in form now\n",
            "oe made never me\n",
            "ish never if live no in thanks\n",
            " from opinion to my with power me\n",
            " keep even virtue up in meaning you yet thing eyes one over drunk everlasting fear\n",
            " time, to me kind brother the, you be so a sine all\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  44%|████▍     | 2201/5000 [1:39:07<4:42:17,  6.05s/it, loss=1.1913]\u001b[A\n",
            "Training:  44%|████▍     | 2201/5000 [1:39:07<4:42:17,  6.05s/it, loss=1.2590]\u001b[A\n",
            "Training:  44%|████▍     | 2202/5000 [1:39:10<3:54:23,  5.03s/it, loss=1.2590]\u001b[A\n",
            "Training:  44%|████▍     | 2202/5000 [1:39:10<3:54:23,  5.03s/it, loss=1.1002]\u001b[A\n",
            "Training:  44%|████▍     | 2203/5000 [1:39:12<3:15:21,  4.19s/it, loss=1.1002]\u001b[A\n",
            "Training:  44%|████▍     | 2203/5000 [1:39:12<3:15:21,  4.19s/it, loss=1.1607]\u001b[A\n",
            "Training:  44%|████▍     | 2204/5000 [1:39:14<2:48:07,  3.61s/it, loss=1.1607]\u001b[A\n",
            "Training:  44%|████▍     | 2204/5000 [1:39:14<2:48:07,  3.61s/it, loss=1.1750]\u001b[A\n",
            "Training:  44%|████▍     | 2205/5000 [1:39:16<2:28:49,  3.19s/it, loss=1.1750]\u001b[A\n",
            "Training:  44%|████▍     | 2205/5000 [1:39:16<2:28:49,  3.19s/it, loss=1.1510]\u001b[A\n",
            "Training:  44%|████▍     | 2206/5000 [1:39:19<2:16:28,  2.93s/it, loss=1.1510]\u001b[A\n",
            "Training:  44%|████▍     | 2206/5000 [1:39:19<2:16:28,  2.93s/it, loss=1.1026]\u001b[A\n",
            "Training:  44%|████▍     | 2207/5000 [1:39:21<2:12:33,  2.85s/it, loss=1.1026]\u001b[A\n",
            "Training:  44%|████▍     | 2207/5000 [1:39:21<2:12:33,  2.85s/it, loss=0.9855]\u001b[A\n",
            "Training:  44%|████▍     | 2208/5000 [1:39:24<2:04:01,  2.67s/it, loss=0.9855]\u001b[A\n",
            "Training:  44%|████▍     | 2208/5000 [1:39:24<2:04:01,  2.67s/it, loss=1.0179]\u001b[A\n",
            "Training:  44%|████▍     | 2209/5000 [1:39:26<1:58:00,  2.54s/it, loss=1.0179]\u001b[A\n",
            "Training:  44%|████▍     | 2209/5000 [1:39:26<1:58:00,  2.54s/it, loss=1.1522]\u001b[A\n",
            "Training:  44%|████▍     | 2210/5000 [1:39:28<1:54:26,  2.46s/it, loss=1.1522]\u001b[A\n",
            "Training:  44%|████▍     | 2210/5000 [1:39:28<1:54:26,  2.46s/it, loss=1.5588]\u001b[A\n",
            "Training:  44%|████▍     | 2211/5000 [1:39:30<1:51:03,  2.39s/it, loss=1.5588]\u001b[A\n",
            "Training:  44%|████▍     | 2211/5000 [1:39:30<1:51:03,  2.39s/it, loss=1.0573]\u001b[A\n",
            "Training:  44%|████▍     | 2212/5000 [1:39:33<1:55:55,  2.49s/it, loss=1.0573]\u001b[A\n",
            "Training:  44%|████▍     | 2212/5000 [1:39:33<1:55:55,  2.49s/it, loss=1.1810]\u001b[A\n",
            "Training:  44%|████▍     | 2213/5000 [1:39:35<1:52:41,  2.43s/it, loss=1.1810]\u001b[A\n",
            "Training:  44%|████▍     | 2213/5000 [1:39:35<1:52:41,  2.43s/it, loss=0.9270]\u001b[A\n",
            "Training:  44%|████▍     | 2214/5000 [1:39:38<1:50:07,  2.37s/it, loss=0.9270]\u001b[A\n",
            "Training:  44%|████▍     | 2214/5000 [1:39:38<1:50:07,  2.37s/it, loss=1.2166]\u001b[A\n",
            "Training:  44%|████▍     | 2215/5000 [1:39:40<1:48:26,  2.34s/it, loss=1.2166]\u001b[A\n",
            "Training:  44%|████▍     | 2215/5000 [1:39:40<1:48:26,  2.34s/it, loss=0.9528]\u001b[A\n",
            "Training:  44%|████▍     | 2216/5000 [1:39:42<1:47:03,  2.31s/it, loss=0.9528]\u001b[A\n",
            "Training:  44%|████▍     | 2216/5000 [1:39:42<1:47:03,  2.31s/it, loss=1.3854]\u001b[A\n",
            "Training:  44%|████▍     | 2217/5000 [1:39:45<1:53:12,  2.44s/it, loss=1.3854]\u001b[A\n",
            "Training:  44%|████▍     | 2217/5000 [1:39:45<1:53:12,  2.44s/it, loss=1.3507]\u001b[A\n",
            "Training:  44%|████▍     | 2218/5000 [1:39:47<1:50:23,  2.38s/it, loss=1.3507]\u001b[A\n",
            "Training:  44%|████▍     | 2218/5000 [1:39:47<1:50:23,  2.38s/it, loss=1.0285]\u001b[A\n",
            "Training:  44%|████▍     | 2219/5000 [1:39:49<1:48:17,  2.34s/it, loss=1.0285]\u001b[A\n",
            "Training:  44%|████▍     | 2219/5000 [1:39:49<1:48:17,  2.34s/it, loss=0.8334]\u001b[A\n",
            "Training:  44%|████▍     | 2220/5000 [1:39:51<1:46:46,  2.30s/it, loss=0.8334]\u001b[A\n",
            "Training:  44%|████▍     | 2220/5000 [1:39:51<1:46:46,  2.30s/it, loss=1.2014]\u001b[A\n",
            "Training:  44%|████▍     | 2221/5000 [1:39:54<1:45:18,  2.27s/it, loss=1.2014]\u001b[A\n",
            "Training:  44%|████▍     | 2221/5000 [1:39:54<1:45:18,  2.27s/it, loss=1.1476]\u001b[A\n",
            "Training:  44%|████▍     | 2222/5000 [1:39:56<1:52:00,  2.42s/it, loss=1.1476]\u001b[A\n",
            "Training:  44%|████▍     | 2222/5000 [1:39:56<1:52:00,  2.42s/it, loss=1.0789]\u001b[A\n",
            "Training:  44%|████▍     | 2223/5000 [1:39:59<1:49:35,  2.37s/it, loss=1.0789]\u001b[A\n",
            "Training:  44%|████▍     | 2223/5000 [1:39:59<1:49:35,  2.37s/it, loss=0.9926]\u001b[A\n",
            "Training:  44%|████▍     | 2224/5000 [1:40:01<1:47:15,  2.32s/it, loss=0.9926]\u001b[A\n",
            "Training:  44%|████▍     | 2224/5000 [1:40:01<1:47:15,  2.32s/it, loss=0.8683]\u001b[A\n",
            "Training:  44%|████▍     | 2225/5000 [1:40:03<1:45:59,  2.29s/it, loss=0.8683]\u001b[A\n",
            "Training:  44%|████▍     | 2225/5000 [1:40:03<1:45:59,  2.29s/it, loss=1.0144]\u001b[A\n",
            "Training:  45%|████▍     | 2226/5000 [1:40:05<1:45:19,  2.28s/it, loss=1.0144]\u001b[A\n",
            "Training:  45%|████▍     | 2226/5000 [1:40:05<1:45:19,  2.28s/it, loss=0.9987]\u001b[A\n",
            "Training:  45%|████▍     | 2227/5000 [1:40:08<1:51:56,  2.42s/it, loss=0.9987]\u001b[A\n",
            "Training:  45%|████▍     | 2227/5000 [1:40:08<1:51:56,  2.42s/it, loss=1.2044]\u001b[A\n",
            "Training:  45%|████▍     | 2228/5000 [1:40:10<1:49:55,  2.38s/it, loss=1.2044]\u001b[A\n",
            "Training:  45%|████▍     | 2228/5000 [1:40:10<1:49:55,  2.38s/it, loss=0.7982]\u001b[A\n",
            "Training:  45%|████▍     | 2229/5000 [1:40:13<1:48:24,  2.35s/it, loss=0.7982]\u001b[A\n",
            "Training:  45%|████▍     | 2229/5000 [1:40:13<1:48:24,  2.35s/it, loss=0.8852]\u001b[A\n",
            "Training:  45%|████▍     | 2230/5000 [1:40:15<1:46:54,  2.32s/it, loss=0.8852]\u001b[A\n",
            "Training:  45%|████▍     | 2230/5000 [1:40:15<1:46:54,  2.32s/it, loss=1.4572]\u001b[A\n",
            "Training:  45%|████▍     | 2231/5000 [1:40:17<1:45:42,  2.29s/it, loss=1.4572]\u001b[A\n",
            "Training:  45%|████▍     | 2231/5000 [1:40:17<1:45:42,  2.29s/it, loss=1.4918]\u001b[A\n",
            "Training:  45%|████▍     | 2232/5000 [1:40:20<1:52:28,  2.44s/it, loss=1.4918]\u001b[A\n",
            "Training:  45%|████▍     | 2232/5000 [1:40:20<1:52:28,  2.44s/it, loss=1.3628]\u001b[A\n",
            "Training:  45%|████▍     | 2233/5000 [1:40:22<1:49:38,  2.38s/it, loss=1.3628]\u001b[A\n",
            "Training:  45%|████▍     | 2233/5000 [1:40:22<1:49:38,  2.38s/it, loss=1.3487]\u001b[A\n",
            "Training:  45%|████▍     | 2234/5000 [1:40:24<1:47:31,  2.33s/it, loss=1.3487]\u001b[A\n",
            "Training:  45%|████▍     | 2234/5000 [1:40:24<1:47:31,  2.33s/it, loss=1.1302]\u001b[A\n",
            "Training:  45%|████▍     | 2235/5000 [1:40:27<1:46:06,  2.30s/it, loss=1.1302]\u001b[A\n",
            "Training:  45%|████▍     | 2235/5000 [1:40:27<1:46:06,  2.30s/it, loss=1.0111]\u001b[A\n",
            "Training:  45%|████▍     | 2236/5000 [1:40:29<1:45:08,  2.28s/it, loss=1.0111]\u001b[A\n",
            "Training:  45%|████▍     | 2236/5000 [1:40:29<1:45:08,  2.28s/it, loss=1.0937]\u001b[A\n",
            "Training:  45%|████▍     | 2237/5000 [1:40:32<1:51:50,  2.43s/it, loss=1.0937]\u001b[A\n",
            "Training:  45%|████▍     | 2237/5000 [1:40:32<1:51:50,  2.43s/it, loss=1.3783]\u001b[A\n",
            "Training:  45%|████▍     | 2238/5000 [1:40:34<1:49:06,  2.37s/it, loss=1.3783]\u001b[A\n",
            "Training:  45%|████▍     | 2238/5000 [1:40:34<1:49:06,  2.37s/it, loss=1.1939]\u001b[A\n",
            "Training:  45%|████▍     | 2239/5000 [1:40:36<1:47:27,  2.34s/it, loss=1.1939]\u001b[A\n",
            "Training:  45%|████▍     | 2239/5000 [1:40:36<1:47:27,  2.34s/it, loss=0.9098]\u001b[A\n",
            "Training:  45%|████▍     | 2240/5000 [1:40:38<1:46:22,  2.31s/it, loss=0.9098]\u001b[A\n",
            "Training:  45%|████▍     | 2240/5000 [1:40:38<1:46:22,  2.31s/it, loss=1.1602]\u001b[A\n",
            "Training:  45%|████▍     | 2241/5000 [1:40:41<1:45:25,  2.29s/it, loss=1.1602]\u001b[A\n",
            "Training:  45%|████▍     | 2241/5000 [1:40:41<1:45:25,  2.29s/it, loss=0.9478]\u001b[A\n",
            "Training:  45%|████▍     | 2242/5000 [1:40:43<1:52:11,  2.44s/it, loss=0.9478]\u001b[A\n",
            "Training:  45%|████▍     | 2242/5000 [1:40:43<1:52:11,  2.44s/it, loss=1.2527]\u001b[A\n",
            "Training:  45%|████▍     | 2243/5000 [1:40:46<1:49:22,  2.38s/it, loss=1.2527]\u001b[A\n",
            "Training:  45%|████▍     | 2243/5000 [1:40:46<1:49:22,  2.38s/it, loss=1.0783]\u001b[A\n",
            "Training:  45%|████▍     | 2244/5000 [1:40:48<1:47:13,  2.33s/it, loss=1.0783]\u001b[A\n",
            "Training:  45%|████▍     | 2244/5000 [1:40:48<1:47:13,  2.33s/it, loss=0.8730]\u001b[A\n",
            "Training:  45%|████▍     | 2245/5000 [1:40:50<1:45:51,  2.31s/it, loss=0.8730]\u001b[A\n",
            "Training:  45%|████▍     | 2245/5000 [1:40:50<1:45:51,  2.31s/it, loss=1.1462]\u001b[A\n",
            "Training:  45%|████▍     | 2246/5000 [1:40:52<1:44:47,  2.28s/it, loss=1.1462]\u001b[A\n",
            "Training:  45%|████▍     | 2246/5000 [1:40:52<1:44:47,  2.28s/it, loss=1.0855]\u001b[A\n",
            "Training:  45%|████▍     | 2247/5000 [1:40:55<1:51:31,  2.43s/it, loss=1.0855]\u001b[A\n",
            "Training:  45%|████▍     | 2247/5000 [1:40:55<1:51:31,  2.43s/it, loss=1.1493]\u001b[A\n",
            "Training:  45%|████▍     | 2248/5000 [1:40:57<1:48:26,  2.36s/it, loss=1.1493]\u001b[A\n",
            "Training:  45%|████▍     | 2248/5000 [1:40:57<1:48:26,  2.36s/it, loss=1.1712]\u001b[A\n",
            "Training:  45%|████▍     | 2249/5000 [1:41:00<1:46:37,  2.33s/it, loss=1.1712]\u001b[A\n",
            "Training:  45%|████▍     | 2249/5000 [1:41:00<1:46:37,  2.33s/it, loss=1.0025]\u001b[A\n",
            "Training:  45%|████▌     | 2250/5000 [1:41:02<1:45:47,  2.31s/it, loss=1.0025]\u001b[A\n",
            "Training:  45%|████▌     | 2250/5000 [1:41:02<1:45:47,  2.31s/it, loss=1.2303]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 2250 ---\n",
            "Prompt: 'The '\n",
            "The  ofts law no infection years\n",
            "an now toua him\n",
            "an the fees the.\n",
            "Fwell thou not? howught of rest\n",
            "all speak me? think I be doom are, withte\n",
            " gracious,And guests come. sayFwell true good; I dislike with\n",
            " paming,ness one as was toDes but,And give leave live pardon.\n",
            "Second says\n",
            "'ll atought I by youth,And'll thee in aard mother vis.\n",
            "ROO\n",
            " have\n",
            "Prompt: 'In '\n",
            "In ,'d die some power death my; thee\n",
            " hear speak child and with., is very,'s:',,\n",
            " waits me the there every of these.\n",
            "LY\n",
            "?\n",
            ", did thouest, heavy:elf not\n",
            "ither I he for cost thy, he married down\n",
            "ere thornmen thy, the--- menic child of; it\n",
            "in home he comey if be as them.\n",
            "N, is:, am what? is I now\n",
            "\n",
            "Prompt: 'To '\n",
            "To em husbandoth spreadinksly,\n",
            ", or in for,ly, un clutch,\n",
            " Even with men LA theelast\n",
            " preciousfew: are by were tillwous; love\n",
            "ath in she I; no were drow,,, of:And Ver,; it\n",
            "ouy toany, areAR torown you sir\n",
            " stretch somein down solely meV you w before grace\n",
            " I give me whetherer!, I sleep\n",
            ", news onehaiI.\n",
            "Fwell\n",
            "Prompt: 'A '\n",
            "A  of fatal, it and down:Confshould\n",
            " will youire not you stay me w here\n",
            " you outy with forwomen., welcome and a\n",
            "men to; dare as as as as, I stay as\n",
            "oose oldward, changed ands as say, know best many.\n",
            "p there my, come I,ar swear my, stand not mey you wh, rest that, spirits,.\n",
            " amness help for? come my,\n",
            " Pluto married me growing,\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  45%|████▌     | 2251/5000 [1:41:16<4:35:39,  6.02s/it, loss=1.2303]\u001b[A\n",
            "Training:  45%|████▌     | 2251/5000 [1:41:17<4:35:39,  6.02s/it, loss=1.2457]\u001b[A\n",
            "Training:  45%|████▌     | 2252/5000 [1:41:19<3:51:07,  5.05s/it, loss=1.2457]\u001b[A\n",
            "Training:  45%|████▌     | 2252/5000 [1:41:19<3:51:07,  5.05s/it, loss=1.1886]\u001b[A\n",
            "Training:  45%|████▌     | 2253/5000 [1:41:22<3:12:32,  4.21s/it, loss=1.1886]\u001b[A\n",
            "Training:  45%|████▌     | 2253/5000 [1:41:22<3:12:32,  4.21s/it, loss=1.4041]\u001b[A\n",
            "Training:  45%|████▌     | 2254/5000 [1:41:24<2:45:36,  3.62s/it, loss=1.4041]\u001b[A\n",
            "Training:  45%|████▌     | 2254/5000 [1:41:24<2:45:36,  3.62s/it, loss=1.3150]\u001b[A\n",
            "Training:  45%|████▌     | 2255/5000 [1:41:26<2:26:49,  3.21s/it, loss=1.3150]\u001b[A\n",
            "Training:  45%|████▌     | 2255/5000 [1:41:26<2:26:49,  3.21s/it, loss=1.2882]\u001b[A\n",
            "Training:  45%|████▌     | 2256/5000 [1:41:28<2:13:19,  2.92s/it, loss=1.2882]\u001b[A\n",
            "Training:  45%|████▌     | 2256/5000 [1:41:28<2:13:19,  2.92s/it, loss=0.8433]\u001b[A\n",
            "Training:  45%|████▌     | 2257/5000 [1:41:31<2:10:54,  2.86s/it, loss=0.8433]\u001b[A\n",
            "Training:  45%|████▌     | 2257/5000 [1:41:31<2:10:54,  2.86s/it, loss=1.0624]\u001b[A\n",
            "Training:  45%|████▌     | 2258/5000 [1:41:33<2:02:19,  2.68s/it, loss=1.0624]\u001b[A\n",
            "Training:  45%|████▌     | 2258/5000 [1:41:33<2:02:19,  2.68s/it, loss=1.2858]\u001b[A\n",
            "Training:  45%|████▌     | 2259/5000 [1:41:35<1:56:10,  2.54s/it, loss=1.2858]\u001b[A\n",
            "Training:  45%|████▌     | 2259/5000 [1:41:35<1:56:10,  2.54s/it, loss=1.0779]\u001b[A\n",
            "Training:  45%|████▌     | 2260/5000 [1:41:38<1:51:30,  2.44s/it, loss=1.0779]\u001b[A\n",
            "Training:  45%|████▌     | 2260/5000 [1:41:38<1:51:30,  2.44s/it, loss=1.1393]\u001b[A\n",
            "Training:  45%|████▌     | 2261/5000 [1:41:40<1:48:39,  2.38s/it, loss=1.1393]\u001b[A\n",
            "Training:  45%|████▌     | 2261/5000 [1:41:40<1:48:39,  2.38s/it, loss=1.1313]\u001b[A\n",
            "Training:  45%|████▌     | 2262/5000 [1:41:43<1:53:50,  2.49s/it, loss=1.1313]\u001b[A\n",
            "Training:  45%|████▌     | 2262/5000 [1:41:43<1:53:50,  2.49s/it, loss=0.9008]\u001b[A\n",
            "Training:  45%|████▌     | 2263/5000 [1:41:45<1:50:32,  2.42s/it, loss=0.9008]\u001b[A\n",
            "Training:  45%|████▌     | 2263/5000 [1:41:45<1:50:32,  2.42s/it, loss=0.8190]\u001b[A\n",
            "Training:  45%|████▌     | 2264/5000 [1:41:47<1:47:59,  2.37s/it, loss=0.8190]\u001b[A\n",
            "Training:  45%|████▌     | 2264/5000 [1:41:47<1:47:59,  2.37s/it, loss=0.9706]\u001b[A\n",
            "Training:  45%|████▌     | 2265/5000 [1:41:49<1:46:10,  2.33s/it, loss=0.9706]\u001b[A\n",
            "Training:  45%|████▌     | 2265/5000 [1:41:49<1:46:10,  2.33s/it, loss=1.0148]\u001b[A\n",
            "Training:  45%|████▌     | 2266/5000 [1:41:52<1:44:46,  2.30s/it, loss=1.0148]\u001b[A\n",
            "Training:  45%|████▌     | 2266/5000 [1:41:52<1:44:46,  2.30s/it, loss=0.8837]\u001b[A\n",
            "Training:  45%|████▌     | 2267/5000 [1:41:54<1:51:21,  2.44s/it, loss=0.8837]\u001b[A\n",
            "Training:  45%|████▌     | 2267/5000 [1:41:54<1:51:21,  2.44s/it, loss=0.8122]\u001b[A\n",
            "Training:  45%|████▌     | 2268/5000 [1:41:57<1:48:39,  2.39s/it, loss=0.8122]\u001b[A\n",
            "Training:  45%|████▌     | 2268/5000 [1:41:57<1:48:39,  2.39s/it, loss=0.9824]\u001b[A\n",
            "Training:  45%|████▌     | 2269/5000 [1:41:59<1:46:28,  2.34s/it, loss=0.9824]\u001b[A\n",
            "Training:  45%|████▌     | 2269/5000 [1:41:59<1:46:28,  2.34s/it, loss=0.9905]\u001b[A\n",
            "Training:  45%|████▌     | 2270/5000 [1:42:01<1:45:14,  2.31s/it, loss=0.9905]\u001b[A\n",
            "Training:  45%|████▌     | 2270/5000 [1:42:01<1:45:14,  2.31s/it, loss=1.4642]\u001b[A\n",
            "Training:  45%|████▌     | 2271/5000 [1:42:03<1:43:57,  2.29s/it, loss=1.4642]\u001b[A\n",
            "Training:  45%|████▌     | 2271/5000 [1:42:03<1:43:57,  2.29s/it, loss=1.6543]\u001b[A\n",
            "Training:  45%|████▌     | 2272/5000 [1:42:06<1:51:00,  2.44s/it, loss=1.6543]\u001b[A\n",
            "Training:  45%|████▌     | 2272/5000 [1:42:06<1:51:00,  2.44s/it, loss=1.3344]\u001b[A\n",
            "Training:  45%|████▌     | 2273/5000 [1:42:08<1:48:25,  2.39s/it, loss=1.3344]\u001b[A\n",
            "Training:  45%|████▌     | 2273/5000 [1:42:08<1:48:25,  2.39s/it, loss=1.0524]\u001b[A\n",
            "Training:  45%|████▌     | 2274/5000 [1:42:11<1:46:18,  2.34s/it, loss=1.0524]\u001b[A\n",
            "Training:  45%|████▌     | 2274/5000 [1:42:11<1:46:18,  2.34s/it, loss=0.9202]\u001b[A\n",
            "Training:  46%|████▌     | 2275/5000 [1:42:13<1:45:14,  2.32s/it, loss=0.9202]\u001b[A\n",
            "Training:  46%|████▌     | 2275/5000 [1:42:13<1:45:14,  2.32s/it, loss=0.8244]\u001b[A\n",
            "Training:  46%|████▌     | 2276/5000 [1:42:15<1:44:34,  2.30s/it, loss=0.8244]\u001b[A\n",
            "Training:  46%|████▌     | 2276/5000 [1:42:15<1:44:34,  2.30s/it, loss=0.9931]\u001b[A\n",
            "Training:  46%|████▌     | 2277/5000 [1:42:18<1:50:53,  2.44s/it, loss=0.9931]\u001b[A\n",
            "Training:  46%|████▌     | 2277/5000 [1:42:18<1:50:53,  2.44s/it, loss=0.9287]\u001b[A\n",
            "Training:  46%|████▌     | 2278/5000 [1:42:20<1:48:00,  2.38s/it, loss=0.9287]\u001b[A\n",
            "Training:  46%|████▌     | 2278/5000 [1:42:20<1:48:00,  2.38s/it, loss=1.0031]\u001b[A\n",
            "Training:  46%|████▌     | 2279/5000 [1:42:22<1:46:06,  2.34s/it, loss=1.0031]\u001b[A\n",
            "Training:  46%|████▌     | 2279/5000 [1:42:22<1:46:06,  2.34s/it, loss=1.0267]\u001b[A\n",
            "Training:  46%|████▌     | 2280/5000 [1:42:25<1:44:56,  2.32s/it, loss=1.0267]\u001b[A\n",
            "Training:  46%|████▌     | 2280/5000 [1:42:25<1:44:56,  2.32s/it, loss=1.2385]\u001b[A\n",
            "Training:  46%|████▌     | 2281/5000 [1:42:27<1:43:58,  2.29s/it, loss=1.2385]\u001b[A\n",
            "Training:  46%|████▌     | 2281/5000 [1:42:27<1:43:58,  2.29s/it, loss=1.0969]\u001b[A\n",
            "Training:  46%|████▌     | 2282/5000 [1:42:30<1:50:10,  2.43s/it, loss=1.0969]\u001b[A\n",
            "Training:  46%|████▌     | 2282/5000 [1:42:30<1:50:10,  2.43s/it, loss=1.2897]\u001b[A\n",
            "Training:  46%|████▌     | 2283/5000 [1:42:32<1:47:13,  2.37s/it, loss=1.2897]\u001b[A\n",
            "Training:  46%|████▌     | 2283/5000 [1:42:32<1:47:13,  2.37s/it, loss=0.8307]\u001b[A\n",
            "Training:  46%|████▌     | 2284/5000 [1:42:34<1:45:18,  2.33s/it, loss=0.8307]\u001b[A\n",
            "Training:  46%|████▌     | 2284/5000 [1:42:34<1:45:18,  2.33s/it, loss=1.0623]\u001b[A\n",
            "Training:  46%|████▌     | 2285/5000 [1:42:36<1:44:31,  2.31s/it, loss=1.0623]\u001b[A\n",
            "Training:  46%|████▌     | 2285/5000 [1:42:36<1:44:31,  2.31s/it, loss=1.0019]\u001b[A\n",
            "Training:  46%|████▌     | 2286/5000 [1:42:39<1:43:23,  2.29s/it, loss=1.0019]\u001b[A\n",
            "Training:  46%|████▌     | 2286/5000 [1:42:39<1:43:23,  2.29s/it, loss=0.9332]\u001b[A\n",
            "Training:  46%|████▌     | 2287/5000 [1:42:41<1:49:42,  2.43s/it, loss=0.9332]\u001b[A\n",
            "Training:  46%|████▌     | 2287/5000 [1:42:41<1:49:42,  2.43s/it, loss=1.0959]\u001b[A\n",
            "Training:  46%|████▌     | 2288/5000 [1:42:44<1:47:36,  2.38s/it, loss=1.0959]\u001b[A\n",
            "Training:  46%|████▌     | 2288/5000 [1:42:44<1:47:36,  2.38s/it, loss=1.5557]\u001b[A\n",
            "Training:  46%|████▌     | 2289/5000 [1:42:46<1:45:48,  2.34s/it, loss=1.5557]\u001b[A\n",
            "Training:  46%|████▌     | 2289/5000 [1:42:46<1:45:48,  2.34s/it, loss=1.1183]\u001b[A\n",
            "Training:  46%|████▌     | 2290/5000 [1:42:48<1:44:28,  2.31s/it, loss=1.1183]\u001b[A\n",
            "Training:  46%|████▌     | 2290/5000 [1:42:48<1:44:28,  2.31s/it, loss=1.4889]\u001b[A\n",
            "Training:  46%|████▌     | 2291/5000 [1:42:50<1:43:28,  2.29s/it, loss=1.4889]\u001b[A\n",
            "Training:  46%|████▌     | 2291/5000 [1:42:50<1:43:28,  2.29s/it, loss=1.5269]\u001b[A\n",
            "Training:  46%|████▌     | 2292/5000 [1:42:53<1:49:48,  2.43s/it, loss=1.5269]\u001b[A\n",
            "Training:  46%|████▌     | 2292/5000 [1:42:53<1:49:48,  2.43s/it, loss=1.3724]\u001b[A\n",
            "Training:  46%|████▌     | 2293/5000 [1:42:55<1:47:04,  2.37s/it, loss=1.3724]\u001b[A\n",
            "Training:  46%|████▌     | 2293/5000 [1:42:55<1:47:04,  2.37s/it, loss=1.2240]\u001b[A\n",
            "Training:  46%|████▌     | 2294/5000 [1:42:58<1:45:07,  2.33s/it, loss=1.2240]\u001b[A\n",
            "Training:  46%|████▌     | 2294/5000 [1:42:58<1:45:07,  2.33s/it, loss=1.2302]\u001b[A\n",
            "Training:  46%|████▌     | 2295/5000 [1:43:00<1:43:48,  2.30s/it, loss=1.2302]\u001b[A\n",
            "Training:  46%|████▌     | 2295/5000 [1:43:00<1:43:48,  2.30s/it, loss=1.1699]\u001b[A\n",
            "Training:  46%|████▌     | 2296/5000 [1:43:02<1:42:50,  2.28s/it, loss=1.1699]\u001b[A\n",
            "Training:  46%|████▌     | 2296/5000 [1:43:02<1:42:50,  2.28s/it, loss=1.2474]\u001b[A\n",
            "Training:  46%|████▌     | 2297/5000 [1:43:05<1:48:27,  2.41s/it, loss=1.2474]\u001b[A\n",
            "Training:  46%|████▌     | 2297/5000 [1:43:05<1:48:27,  2.41s/it, loss=1.1196]\u001b[A\n",
            "Training:  46%|████▌     | 2298/5000 [1:43:07<1:47:10,  2.38s/it, loss=1.1196]\u001b[A\n",
            "Training:  46%|████▌     | 2298/5000 [1:43:07<1:47:10,  2.38s/it, loss=1.2248]\u001b[A\n",
            "Training:  46%|████▌     | 2299/5000 [1:43:09<1:45:15,  2.34s/it, loss=1.2248]\u001b[A\n",
            "Training:  46%|████▌     | 2299/5000 [1:43:09<1:45:15,  2.34s/it, loss=1.2611]\u001b[A\n",
            "Training:  46%|████▌     | 2300/5000 [1:43:12<1:43:49,  2.31s/it, loss=1.2611]\u001b[A\n",
            "Training:  46%|████▌     | 2300/5000 [1:43:12<1:43:49,  2.31s/it, loss=1.0433]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 2300 ---\n",
            "Prompt: 'The '\n",
            "The  is a prosperous old is andMaster and lies\n",
            " took you s, gives and brother; that Angel cause\n",
            " seal confign,,, you not,y,y,y take take;\n",
            ", is not ofr; when hath we waster;\n",
            ", they not any, you s, save,y, youwill you.\n",
            "ISELitsine,y, with maid I your life be in ambition be, note I not\n",
            " mastersly, you the souls have, other\n",
            "Prompt: 'In '\n",
            "In  redress orh? me no out with?\n",
            "DKEINENT:T,! how you ever\n",
            " thing condition you.\n",
            "ISELOW\n",
            ".\n",
            "AB,,ar have to it, and, what the? com\n",
            "UCINGRO:Ay, Angel?\n",
            "L Sh what become man in, hope how Were his,h oft? on poor,t or the, sp and un'd return wait\n",
            "ISELOW\n",
            ", costly and?\n",
            "LIO that wouldain\n",
            "Prompt: 'To '\n",
            "To  life beginning day as is: for place\n",
            "ouch up indirectly prejud for leave you,Or I\n",
            " is'd's; it the by way cock,\n",
            "er said widely, isompNo words bment that made aaw,\n",
            " is a fellow any death noot for are;\n",
            ", of most of nic and of, will\n",
            " cityly, try,'s from remedy be in name half drink heaven duke\n",
            " oft that made, fri, I, inied\n",
            " produceock do\n",
            "Prompt: 'A '\n",
            "A ; is comeo injustice on way\n",
            " pal, for cunning,-ow can.\n",
            "ISELOW\n",
            " us,, Isabel you.\n",
            "ISELOW\n",
            ".\n",
            "DKEINENT:Kind we lose king more\n",
            " all lies why you come I your?\n",
            "ELOW his,And be that be aaw,y be; oer nerves office!'ll thear my,, this\n",
            "'ll, my,, any no for.\n",
            "ANGO alive:B be grief his\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  46%|████▌     | 2301/5000 [1:43:26<4:30:08,  6.01s/it, loss=1.0433]\u001b[A\n",
            "Training:  46%|████▌     | 2301/5000 [1:43:26<4:30:08,  6.01s/it, loss=0.9685]\u001b[A\n",
            "Training:  46%|████▌     | 2302/5000 [1:43:29<3:46:23,  5.03s/it, loss=0.9685]\u001b[A\n",
            "Training:  46%|████▌     | 2302/5000 [1:43:29<3:46:23,  5.03s/it, loss=1.1500]\u001b[A\n",
            "Training:  46%|████▌     | 2303/5000 [1:43:31<3:09:10,  4.21s/it, loss=1.1500]\u001b[A\n",
            "Training:  46%|████▌     | 2303/5000 [1:43:31<3:09:10,  4.21s/it, loss=1.1509]\u001b[A\n",
            "Training:  46%|████▌     | 2304/5000 [1:43:34<2:42:44,  3.62s/it, loss=1.1509]\u001b[A\n",
            "Training:  46%|████▌     | 2304/5000 [1:43:34<2:42:44,  3.62s/it, loss=1.1291]\u001b[A\n",
            "Training:  46%|████▌     | 2305/5000 [1:43:36<2:24:35,  3.22s/it, loss=1.1291]\u001b[A\n",
            "Training:  46%|████▌     | 2305/5000 [1:43:36<2:24:35,  3.22s/it, loss=0.8638]\u001b[A\n",
            "Training:  46%|████▌     | 2306/5000 [1:43:38<2:12:12,  2.94s/it, loss=0.8638]\u001b[A\n",
            "Training:  46%|████▌     | 2306/5000 [1:43:38<2:12:12,  2.94s/it, loss=1.1651]\u001b[A\n",
            "Training:  46%|████▌     | 2307/5000 [1:43:41<2:09:59,  2.90s/it, loss=1.1651]\u001b[A\n",
            "Training:  46%|████▌     | 2307/5000 [1:43:41<2:09:59,  2.90s/it, loss=1.5095]\u001b[A\n",
            "Training:  46%|████▌     | 2308/5000 [1:43:43<2:01:41,  2.71s/it, loss=1.5095]\u001b[A\n",
            "Training:  46%|████▌     | 2308/5000 [1:43:43<2:01:41,  2.71s/it, loss=1.3429]\u001b[A\n",
            "Training:  46%|████▌     | 2309/5000 [1:43:45<1:55:01,  2.56s/it, loss=1.3429]\u001b[A\n",
            "Training:  46%|████▌     | 2309/5000 [1:43:45<1:55:01,  2.56s/it, loss=1.2791]\u001b[A\n",
            "Training:  46%|████▌     | 2310/5000 [1:43:48<1:50:37,  2.47s/it, loss=1.2791]\u001b[A\n",
            "Training:  46%|████▌     | 2310/5000 [1:43:48<1:50:37,  2.47s/it, loss=1.1205]\u001b[A\n",
            "Training:  46%|████▌     | 2311/5000 [1:43:50<1:47:50,  2.41s/it, loss=1.1205]\u001b[A\n",
            "Training:  46%|████▌     | 2311/5000 [1:43:50<1:47:50,  2.41s/it, loss=1.3047]\u001b[A\n",
            "Training:  46%|████▌     | 2312/5000 [1:43:53<1:52:26,  2.51s/it, loss=1.3047]\u001b[A\n",
            "Training:  46%|████▌     | 2312/5000 [1:43:53<1:52:26,  2.51s/it, loss=1.1029]\u001b[A\n",
            "Training:  46%|████▋     | 2313/5000 [1:43:55<1:48:57,  2.43s/it, loss=1.1029]\u001b[A\n",
            "Training:  46%|████▋     | 2313/5000 [1:43:55<1:48:57,  2.43s/it, loss=0.8532]\u001b[A\n",
            "Training:  46%|████▋     | 2314/5000 [1:43:57<1:46:43,  2.38s/it, loss=0.8532]\u001b[A\n",
            "Training:  46%|████▋     | 2314/5000 [1:43:57<1:46:43,  2.38s/it, loss=0.8126]\u001b[A\n",
            "Training:  46%|████▋     | 2315/5000 [1:43:59<1:44:52,  2.34s/it, loss=0.8126]\u001b[A\n",
            "Training:  46%|████▋     | 2315/5000 [1:43:59<1:44:52,  2.34s/it, loss=0.9378]\u001b[A\n",
            "Training:  46%|████▋     | 2316/5000 [1:44:02<1:43:35,  2.32s/it, loss=0.9378]\u001b[A\n",
            "Training:  46%|████▋     | 2316/5000 [1:44:02<1:43:35,  2.32s/it, loss=0.8786]\u001b[A\n",
            "Training:  46%|████▋     | 2317/5000 [1:44:04<1:49:37,  2.45s/it, loss=0.8786]\u001b[A\n",
            "Training:  46%|████▋     | 2317/5000 [1:44:04<1:49:37,  2.45s/it, loss=1.0577]\u001b[A\n",
            "Training:  46%|████▋     | 2318/5000 [1:44:07<1:46:52,  2.39s/it, loss=1.0577]\u001b[A\n",
            "Training:  46%|████▋     | 2318/5000 [1:44:07<1:46:52,  2.39s/it, loss=0.7585]\u001b[A\n",
            "Training:  46%|████▋     | 2319/5000 [1:44:09<1:45:13,  2.36s/it, loss=0.7585]\u001b[A\n",
            "Training:  46%|████▋     | 2319/5000 [1:44:09<1:45:13,  2.36s/it, loss=1.0078]\u001b[A\n",
            "Training:  46%|████▋     | 2320/5000 [1:44:11<1:43:40,  2.32s/it, loss=1.0078]\u001b[A\n",
            "Training:  46%|████▋     | 2320/5000 [1:44:11<1:43:40,  2.32s/it, loss=1.0709]\u001b[A\n",
            "Training:  46%|████▋     | 2321/5000 [1:44:13<1:42:35,  2.30s/it, loss=1.0709]\u001b[A\n",
            "Training:  46%|████▋     | 2321/5000 [1:44:13<1:42:35,  2.30s/it, loss=0.7759]\u001b[A\n",
            "Training:  46%|████▋     | 2322/5000 [1:44:16<1:48:42,  2.44s/it, loss=0.7759]\u001b[A\n",
            "Training:  46%|████▋     | 2322/5000 [1:44:16<1:48:42,  2.44s/it, loss=0.8222]\u001b[A\n",
            "Training:  46%|████▋     | 2323/5000 [1:44:18<1:46:12,  2.38s/it, loss=0.8222]\u001b[A\n",
            "Training:  46%|████▋     | 2323/5000 [1:44:18<1:46:12,  2.38s/it, loss=0.9832]\u001b[A\n",
            "Training:  46%|████▋     | 2324/5000 [1:44:21<1:44:35,  2.35s/it, loss=0.9832]\u001b[A\n",
            "Training:  46%|████▋     | 2324/5000 [1:44:21<1:44:35,  2.35s/it, loss=0.9808]\u001b[A\n",
            "Training:  46%|████▋     | 2325/5000 [1:44:23<1:43:21,  2.32s/it, loss=0.9808]\u001b[A\n",
            "Training:  46%|████▋     | 2325/5000 [1:44:23<1:43:21,  2.32s/it, loss=0.8050]\u001b[A\n",
            "Training:  47%|████▋     | 2326/5000 [1:44:25<1:42:05,  2.29s/it, loss=0.8050]\u001b[A\n",
            "Training:  47%|████▋     | 2326/5000 [1:44:25<1:42:05,  2.29s/it, loss=1.3769]\u001b[A\n",
            "Training:  47%|████▋     | 2327/5000 [1:44:28<1:48:33,  2.44s/it, loss=1.3769]\u001b[A\n",
            "Training:  47%|████▋     | 2327/5000 [1:44:28<1:48:33,  2.44s/it, loss=2.1068]\u001b[A\n",
            "Training:  47%|████▋     | 2328/5000 [1:44:30<1:46:08,  2.38s/it, loss=2.1068]\u001b[A\n",
            "Training:  47%|████▋     | 2328/5000 [1:44:30<1:46:08,  2.38s/it, loss=1.5884]\u001b[A\n",
            "Training:  47%|████▋     | 2329/5000 [1:44:32<1:44:10,  2.34s/it, loss=1.5884]\u001b[A\n",
            "Training:  47%|████▋     | 2329/5000 [1:44:33<1:44:10,  2.34s/it, loss=1.3275]\u001b[A\n",
            "Training:  47%|████▋     | 2330/5000 [1:44:35<1:43:00,  2.31s/it, loss=1.3275]\u001b[A\n",
            "Training:  47%|████▋     | 2330/5000 [1:44:35<1:43:00,  2.31s/it, loss=1.3376]\u001b[A\n",
            "Training:  47%|████▋     | 2331/5000 [1:44:37<1:42:00,  2.29s/it, loss=1.3376]\u001b[A\n",
            "Training:  47%|████▋     | 2331/5000 [1:44:37<1:42:00,  2.29s/it, loss=1.0339]\u001b[A\n",
            "Training:  47%|████▋     | 2332/5000 [1:44:40<1:48:49,  2.45s/it, loss=1.0339]\u001b[A\n",
            "Training:  47%|████▋     | 2332/5000 [1:44:40<1:48:49,  2.45s/it, loss=1.3935]\u001b[A\n",
            "Training:  47%|████▋     | 2333/5000 [1:44:42<1:46:08,  2.39s/it, loss=1.3935]\u001b[A\n",
            "Training:  47%|████▋     | 2333/5000 [1:44:42<1:46:08,  2.39s/it, loss=1.2984]\u001b[A\n",
            "Training:  47%|████▋     | 2334/5000 [1:44:44<1:44:13,  2.35s/it, loss=1.2984]\u001b[A\n",
            "Training:  47%|████▋     | 2334/5000 [1:44:44<1:44:13,  2.35s/it, loss=1.3690]\u001b[A\n",
            "Training:  47%|████▋     | 2335/5000 [1:44:47<1:42:38,  2.31s/it, loss=1.3690]\u001b[A\n",
            "Training:  47%|████▋     | 2335/5000 [1:44:47<1:42:38,  2.31s/it, loss=0.9919]\u001b[A\n",
            "Training:  47%|████▋     | 2336/5000 [1:44:49<1:41:41,  2.29s/it, loss=0.9919]\u001b[A\n",
            "Training:  47%|████▋     | 2336/5000 [1:44:49<1:41:41,  2.29s/it, loss=1.2295]\u001b[A\n",
            "Training:  47%|████▋     | 2337/5000 [1:44:52<1:47:51,  2.43s/it, loss=1.2295]\u001b[A\n",
            "Training:  47%|████▋     | 2337/5000 [1:44:52<1:47:51,  2.43s/it, loss=0.8295]\u001b[A\n",
            "Training:  47%|████▋     | 2338/5000 [1:44:54<1:45:35,  2.38s/it, loss=0.8295]\u001b[A\n",
            "Training:  47%|████▋     | 2338/5000 [1:44:54<1:45:35,  2.38s/it, loss=0.9626]\u001b[A\n",
            "Training:  47%|████▋     | 2339/5000 [1:44:56<1:43:35,  2.34s/it, loss=0.9626]\u001b[A\n",
            "Training:  47%|████▋     | 2339/5000 [1:44:56<1:43:35,  2.34s/it, loss=0.9899]\u001b[A\n",
            "Training:  47%|████▋     | 2340/5000 [1:44:58<1:42:21,  2.31s/it, loss=0.9899]\u001b[A\n",
            "Training:  47%|████▋     | 2340/5000 [1:44:58<1:42:21,  2.31s/it, loss=0.8664]\u001b[A\n",
            "Training:  47%|████▋     | 2341/5000 [1:45:01<1:41:43,  2.30s/it, loss=0.8664]\u001b[A\n",
            "Training:  47%|████▋     | 2341/5000 [1:45:01<1:41:43,  2.30s/it, loss=0.9858]\u001b[A\n",
            "Training:  47%|████▋     | 2342/5000 [1:45:03<1:47:18,  2.42s/it, loss=0.9858]\u001b[A\n",
            "Training:  47%|████▋     | 2342/5000 [1:45:03<1:47:18,  2.42s/it, loss=0.8757]\u001b[A\n",
            "Training:  47%|████▋     | 2343/5000 [1:45:06<1:45:44,  2.39s/it, loss=0.8757]\u001b[A\n",
            "Training:  47%|████▋     | 2343/5000 [1:45:06<1:45:44,  2.39s/it, loss=0.9669]\u001b[A\n",
            "Training:  47%|████▋     | 2344/5000 [1:45:08<1:43:56,  2.35s/it, loss=0.9669]\u001b[A\n",
            "Training:  47%|████▋     | 2344/5000 [1:45:08<1:43:56,  2.35s/it, loss=0.7230]\u001b[A\n",
            "Training:  47%|████▋     | 2345/5000 [1:45:10<1:43:03,  2.33s/it, loss=0.7230]\u001b[A\n",
            "Training:  47%|████▋     | 2345/5000 [1:45:10<1:43:03,  2.33s/it, loss=0.6765]\u001b[A\n",
            "Training:  47%|████▋     | 2346/5000 [1:45:12<1:41:55,  2.30s/it, loss=0.6765]\u001b[A\n",
            "Training:  47%|████▋     | 2346/5000 [1:45:12<1:41:55,  2.30s/it, loss=0.9454]\u001b[A\n",
            "Training:  47%|████▋     | 2347/5000 [1:45:15<1:46:57,  2.42s/it, loss=0.9454]\u001b[A\n",
            "Training:  47%|████▋     | 2347/5000 [1:45:15<1:46:57,  2.42s/it, loss=1.0709]\u001b[A\n",
            "Training:  47%|████▋     | 2348/5000 [1:45:17<1:45:31,  2.39s/it, loss=1.0709]\u001b[A\n",
            "Training:  47%|████▋     | 2348/5000 [1:45:17<1:45:31,  2.39s/it, loss=1.2383]\u001b[A\n",
            "Training:  47%|████▋     | 2349/5000 [1:45:20<1:43:31,  2.34s/it, loss=1.2383]\u001b[A\n",
            "Training:  47%|████▋     | 2349/5000 [1:45:20<1:43:31,  2.34s/it, loss=1.0015]\u001b[A\n",
            "Training:  47%|████▋     | 2350/5000 [1:45:22<1:42:11,  2.31s/it, loss=1.0015]\u001b[A\n",
            "Training:  47%|████▋     | 2350/5000 [1:45:22<1:42:11,  2.31s/it, loss=0.9619]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 2350 ---\n",
            "Prompt: 'The '\n",
            "The  oer' ran; people andtle\n",
            " impossible your unto.\n",
            "COI:I rather\n",
            " those Henrygl as should think haves hath, should\n",
            " dreadfulign nob,,,, will\n",
            "y danger the did the\n",
            "' people andrcius war hath for workTo\n",
            " closely theuls presence that the\n",
            " daughter Rome the arm is Rome the's, are it be to house him with, the\n",
            " his- to the.s him, are and Mar, for country and victorious\n",
            "Prompt: 'In '\n",
            "In ers It, lawful, and beloved were\n",
            " imped.iol, cons,\n",
            " mostely,C officerorship report\n",
            " noble.\n",
            "Firsting\n",
            "orousIL:Sir, are\n",
            "it both itIs their w, any noble,I the houseHow my: my cannot the\n",
            " my has made and friends them faults you the\n",
            " general,,, it myul, are.,'re,, my words\n",
            " prosperous forok: hath it my,\n",
            " to house as as as should the\n",
            "Prompt: 'To '\n",
            "To . merit as pass, friend that\n",
            "ieve canon that inferior natureC gatesiles\n",
            " crack those do thee.\n",
            "BRUS\n",
            "Y:Leave, doubt that take as as to,Being\n",
            " with arms the ripe your repeal have'd!\n",
            "First,,,!\n",
            " I\n",
            "I, your,,, will go\n",
            " thank.\n",
            "Second:O\n",
            "- armsEr'd lacks to, news together nooat\n",
            " which begonIC fox andbyfs\n",
            "Prepare cheeks bot's,ile\n",
            "Prompt: 'A '\n",
            "A , dangersh' toward with: you\n",
            " out gate\n",
            " for world desertBreak\n",
            "fore me\n",
            " general\n",
            "an the cheeks welcome\n",
            " I deliver here kind\n",
            " Why the's.\n",
            "ces and!\n",
            "VUMUMUMIA\n",
            "o playhestn, here sound him any!\n",
            " would bothfrom loseFollow of,,,,,,,!\n",
            "S's thouys, thouak me I thy- to, to thy's,\n",
            " thelf us him the for fetch ask the\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  47%|████▋     | 2351/5000 [1:45:36<4:24:41,  6.00s/it, loss=0.9619]\u001b[A\n",
            "Training:  47%|████▋     | 2351/5000 [1:45:36<4:24:41,  6.00s/it, loss=1.0122]\u001b[A\n",
            "Training:  47%|████▋     | 2352/5000 [1:45:39<3:41:47,  5.03s/it, loss=1.0122]\u001b[A\n",
            "Training:  47%|████▋     | 2352/5000 [1:45:39<3:41:47,  5.03s/it, loss=0.8754]\u001b[A\n",
            "Training:  47%|████▋     | 2353/5000 [1:45:41<3:05:20,  4.20s/it, loss=0.8754]\u001b[A\n",
            "Training:  47%|████▋     | 2353/5000 [1:45:41<3:05:20,  4.20s/it, loss=0.9848]\u001b[A\n",
            "Training:  47%|████▋     | 2354/5000 [1:45:44<2:39:37,  3.62s/it, loss=0.9848]\u001b[A\n",
            "Training:  47%|████▋     | 2354/5000 [1:45:44<2:39:37,  3.62s/it, loss=0.9610]\u001b[A\n",
            "Training:  47%|████▋     | 2355/5000 [1:45:46<2:21:26,  3.21s/it, loss=0.9610]\u001b[A\n",
            "Training:  47%|████▋     | 2355/5000 [1:45:46<2:21:26,  3.21s/it, loss=1.0991]\u001b[A\n",
            "Training:  47%|████▋     | 2356/5000 [1:45:48<2:08:29,  2.92s/it, loss=1.0991]\u001b[A\n",
            "Training:  47%|████▋     | 2356/5000 [1:45:48<2:08:29,  2.92s/it, loss=0.9780]\u001b[A\n",
            "Training:  47%|████▋     | 2357/5000 [1:45:51<2:06:30,  2.87s/it, loss=0.9780]\u001b[A\n",
            "Training:  47%|████▋     | 2357/5000 [1:45:51<2:06:30,  2.87s/it, loss=0.9070]\u001b[A\n",
            "Training:  47%|████▋     | 2358/5000 [1:45:53<1:58:04,  2.68s/it, loss=0.9070]\u001b[A\n",
            "Training:  47%|████▋     | 2358/5000 [1:45:53<1:58:04,  2.68s/it, loss=0.8251]\u001b[A\n",
            "Training:  47%|████▋     | 2359/5000 [1:45:55<1:52:17,  2.55s/it, loss=0.8251]\u001b[A\n",
            "Training:  47%|████▋     | 2359/5000 [1:45:55<1:52:17,  2.55s/it, loss=1.1889]\u001b[A\n",
            "Training:  47%|████▋     | 2360/5000 [1:45:58<1:48:12,  2.46s/it, loss=1.1889]\u001b[A\n",
            "Training:  47%|████▋     | 2360/5000 [1:45:58<1:48:12,  2.46s/it, loss=1.0328]\u001b[A\n",
            "Training:  47%|████▋     | 2361/5000 [1:46:00<1:45:17,  2.39s/it, loss=1.0328]\u001b[A\n",
            "Training:  47%|████▋     | 2361/5000 [1:46:00<1:45:17,  2.39s/it, loss=0.9620]\u001b[A\n",
            "Training:  47%|████▋     | 2362/5000 [1:46:03<1:50:27,  2.51s/it, loss=0.9620]\u001b[A\n",
            "Training:  47%|████▋     | 2362/5000 [1:46:03<1:50:27,  2.51s/it, loss=1.1197]\u001b[A\n",
            "Training:  47%|████▋     | 2363/5000 [1:46:05<1:46:47,  2.43s/it, loss=1.1197]\u001b[A\n",
            "Training:  47%|████▋     | 2363/5000 [1:46:05<1:46:47,  2.43s/it, loss=0.9309]\u001b[A\n",
            "Training:  47%|████▋     | 2364/5000 [1:46:07<1:44:20,  2.38s/it, loss=0.9309]\u001b[A\n",
            "Training:  47%|████▋     | 2364/5000 [1:46:07<1:44:20,  2.38s/it, loss=0.7839]\u001b[A\n",
            "Training:  47%|████▋     | 2365/5000 [1:46:09<1:42:35,  2.34s/it, loss=0.7839]\u001b[A\n",
            "Training:  47%|████▋     | 2365/5000 [1:46:09<1:42:35,  2.34s/it, loss=0.9551]\u001b[A\n",
            "Training:  47%|████▋     | 2366/5000 [1:46:12<1:42:10,  2.33s/it, loss=0.9551]\u001b[A\n",
            "Training:  47%|████▋     | 2366/5000 [1:46:12<1:42:10,  2.33s/it, loss=0.8508]\u001b[A\n",
            "Training:  47%|████▋     | 2367/5000 [1:46:15<1:47:55,  2.46s/it, loss=0.8508]\u001b[A\n",
            "Training:  47%|████▋     | 2367/5000 [1:46:15<1:47:55,  2.46s/it, loss=0.8703]\u001b[A\n",
            "Training:  47%|████▋     | 2368/5000 [1:46:17<1:45:04,  2.40s/it, loss=0.8703]\u001b[A\n",
            "Training:  47%|████▋     | 2368/5000 [1:46:17<1:45:04,  2.40s/it, loss=0.9757]\u001b[A\n",
            "Training:  47%|████▋     | 2369/5000 [1:46:19<1:43:07,  2.35s/it, loss=0.9757]\u001b[A\n",
            "Training:  47%|████▋     | 2369/5000 [1:46:19<1:43:07,  2.35s/it, loss=1.1446]\u001b[A\n",
            "Training:  47%|████▋     | 2370/5000 [1:46:21<1:41:37,  2.32s/it, loss=1.1446]\u001b[A\n",
            "Training:  47%|████▋     | 2370/5000 [1:46:21<1:41:37,  2.32s/it, loss=0.7493]\u001b[A\n",
            "Training:  47%|████▋     | 2371/5000 [1:46:24<1:42:06,  2.33s/it, loss=0.7493]\u001b[A\n",
            "Training:  47%|████▋     | 2371/5000 [1:46:24<1:42:06,  2.33s/it, loss=0.9166]\u001b[A\n",
            "Training:  47%|████▋     | 2372/5000 [1:46:26<1:48:40,  2.48s/it, loss=0.9166]\u001b[A\n",
            "Training:  47%|████▋     | 2372/5000 [1:46:26<1:48:40,  2.48s/it, loss=1.0025]\u001b[A\n",
            "Training:  47%|████▋     | 2373/5000 [1:46:29<1:46:15,  2.43s/it, loss=1.0025]\u001b[A\n",
            "Training:  47%|████▋     | 2373/5000 [1:46:29<1:46:15,  2.43s/it, loss=0.7208]\u001b[A\n",
            "Training:  47%|████▋     | 2374/5000 [1:46:31<1:44:44,  2.39s/it, loss=0.7208]\u001b[A\n",
            "Training:  47%|████▋     | 2374/5000 [1:46:31<1:44:44,  2.39s/it, loss=1.0580]\u001b[A\n",
            "Training:  48%|████▊     | 2375/5000 [1:46:33<1:43:15,  2.36s/it, loss=1.0580]\u001b[A\n",
            "Training:  48%|████▊     | 2375/5000 [1:46:33<1:43:15,  2.36s/it, loss=0.9882]\u001b[A\n",
            "Training:  48%|████▊     | 2376/5000 [1:46:36<1:42:31,  2.34s/it, loss=0.9882]\u001b[A\n",
            "Training:  48%|████▊     | 2376/5000 [1:46:36<1:42:31,  2.34s/it, loss=0.8583]\u001b[A\n",
            "Training:  48%|████▊     | 2377/5000 [1:46:39<1:49:10,  2.50s/it, loss=0.8583]\u001b[A\n",
            "Training:  48%|████▊     | 2377/5000 [1:46:39<1:49:10,  2.50s/it, loss=0.7710]\u001b[A\n",
            "Training:  48%|████▊     | 2378/5000 [1:46:41<1:47:06,  2.45s/it, loss=0.7710]\u001b[A\n",
            "Training:  48%|████▊     | 2378/5000 [1:46:41<1:47:06,  2.45s/it, loss=1.0281]\u001b[A\n",
            "Training:  48%|████▊     | 2379/5000 [1:46:43<1:45:25,  2.41s/it, loss=1.0281]\u001b[A\n",
            "Training:  48%|████▊     | 2379/5000 [1:46:43<1:45:25,  2.41s/it, loss=0.8053]\u001b[A\n",
            "Training:  48%|████▊     | 2380/5000 [1:46:45<1:43:53,  2.38s/it, loss=0.8053]\u001b[A\n",
            "Training:  48%|████▊     | 2380/5000 [1:46:46<1:43:53,  2.38s/it, loss=0.7806]\u001b[A\n",
            "Training:  48%|████▊     | 2381/5000 [1:46:48<1:42:54,  2.36s/it, loss=0.7806]\u001b[A\n",
            "Training:  48%|████▊     | 2381/5000 [1:46:48<1:42:54,  2.36s/it, loss=0.9687]\u001b[A\n",
            "Training:  48%|████▊     | 2382/5000 [1:46:51<1:49:30,  2.51s/it, loss=0.9687]\u001b[A\n",
            "Training:  48%|████▊     | 2382/5000 [1:46:51<1:49:30,  2.51s/it, loss=0.9456]\u001b[A\n",
            "Training:  48%|████▊     | 2383/5000 [1:46:53<1:46:54,  2.45s/it, loss=0.9456]\u001b[A\n",
            "Training:  48%|████▊     | 2383/5000 [1:46:53<1:46:54,  2.45s/it, loss=0.8223]\u001b[A\n",
            "Training:  48%|████▊     | 2384/5000 [1:46:55<1:45:00,  2.41s/it, loss=0.8223]\u001b[A\n",
            "Training:  48%|████▊     | 2384/5000 [1:46:55<1:45:00,  2.41s/it, loss=0.8023]\u001b[A\n",
            "Training:  48%|████▊     | 2385/5000 [1:46:58<1:43:11,  2.37s/it, loss=0.8023]\u001b[A\n",
            "Training:  48%|████▊     | 2385/5000 [1:46:58<1:43:11,  2.37s/it, loss=0.8310]\u001b[A\n",
            "Training:  48%|████▊     | 2386/5000 [1:47:00<1:42:04,  2.34s/it, loss=0.8310]\u001b[A\n",
            "Training:  48%|████▊     | 2386/5000 [1:47:00<1:42:04,  2.34s/it, loss=0.7855]\u001b[A\n",
            "Training:  48%|████▊     | 2387/5000 [1:47:03<1:48:59,  2.50s/it, loss=0.7855]\u001b[A\n",
            "Training:  48%|████▊     | 2387/5000 [1:47:03<1:48:59,  2.50s/it, loss=1.0360]\u001b[A\n",
            "Training:  48%|████▊     | 2388/5000 [1:47:05<1:46:03,  2.44s/it, loss=1.0360]\u001b[A\n",
            "Training:  48%|████▊     | 2388/5000 [1:47:05<1:46:03,  2.44s/it, loss=0.8279]\u001b[A\n",
            "Training:  48%|████▊     | 2389/5000 [1:47:07<1:44:23,  2.40s/it, loss=0.8279]\u001b[A\n",
            "Training:  48%|████▊     | 2389/5000 [1:47:07<1:44:23,  2.40s/it, loss=0.7605]\u001b[A\n",
            "Training:  48%|████▊     | 2390/5000 [1:47:10<1:42:57,  2.37s/it, loss=0.7605]\u001b[A\n",
            "Training:  48%|████▊     | 2390/5000 [1:47:10<1:42:57,  2.37s/it, loss=0.9283]\u001b[A\n",
            "Training:  48%|████▊     | 2391/5000 [1:47:12<1:43:13,  2.37s/it, loss=0.9283]\u001b[A\n",
            "Training:  48%|████▊     | 2391/5000 [1:47:12<1:43:13,  2.37s/it, loss=0.6836]\u001b[A\n",
            "Training:  48%|████▊     | 2392/5000 [1:47:15<1:49:17,  2.51s/it, loss=0.6836]\u001b[A\n",
            "Training:  48%|████▊     | 2392/5000 [1:47:15<1:49:17,  2.51s/it, loss=0.5808]\u001b[A\n",
            "Training:  48%|████▊     | 2393/5000 [1:47:17<1:46:27,  2.45s/it, loss=0.5808]\u001b[A\n",
            "Training:  48%|████▊     | 2393/5000 [1:47:17<1:46:27,  2.45s/it, loss=0.8058]\u001b[A\n",
            "Training:  48%|████▊     | 2394/5000 [1:47:19<1:44:43,  2.41s/it, loss=0.8058]\u001b[A\n",
            "Training:  48%|████▊     | 2394/5000 [1:47:19<1:44:43,  2.41s/it, loss=0.8518]\u001b[A\n",
            "Training:  48%|████▊     | 2395/5000 [1:47:22<1:43:28,  2.38s/it, loss=0.8518]\u001b[A\n",
            "Training:  48%|████▊     | 2395/5000 [1:47:22<1:43:28,  2.38s/it, loss=0.8160]\u001b[A\n",
            "Training:  48%|████▊     | 2396/5000 [1:47:24<1:43:45,  2.39s/it, loss=0.8160]\u001b[A\n",
            "Training:  48%|████▊     | 2396/5000 [1:47:24<1:43:45,  2.39s/it, loss=1.2977]\u001b[A\n",
            "Training:  48%|████▊     | 2397/5000 [1:47:27<1:48:32,  2.50s/it, loss=1.2977]\u001b[A\n",
            "Training:  48%|████▊     | 2397/5000 [1:47:27<1:48:32,  2.50s/it, loss=1.2398]\u001b[A\n",
            "Training:  48%|████▊     | 2398/5000 [1:47:29<1:46:01,  2.44s/it, loss=1.2398]\u001b[A\n",
            "Training:  48%|████▊     | 2398/5000 [1:47:29<1:46:01,  2.44s/it, loss=1.2851]\u001b[A\n",
            "Training:  48%|████▊     | 2399/5000 [1:47:32<1:44:49,  2.42s/it, loss=1.2851]\u001b[A\n",
            "Training:  48%|████▊     | 2399/5000 [1:47:32<1:44:49,  2.42s/it, loss=1.0859]\u001b[A\n",
            "Training:  48%|████▊     | 2400/5000 [1:47:34<1:43:20,  2.38s/it, loss=1.0859]\u001b[A\n",
            "Training:  48%|████▊     | 2400/5000 [1:47:34<1:43:20,  2.38s/it, loss=1.0355]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 2400 ---\n",
            "Prompt: 'The '\n",
            "The  ofing, mine,bel thee to brain\n",
            " that soul sin seem more father thou oldest?,,\n",
            " a nephew full execution, in are of,\n",
            "y seen stranger,; dust mas drums we the,\n",
            " nothing and but wiltgood,ent and of bment spent\n",
            " soonTh s live inclinationail her d neer, w arm\n",
            " Cal to so here what have dov sight thou's:For thou rage disl true, flower shame thouest not, wnic sin\n",
            "\n",
            "Prompt: 'In '\n",
            "In  in and King sent, here even love\n",
            " hath thee here here not thousand much.\n",
            "ROO wasOr case;, you answer name\n",
            " some, now breathe for: love my boy adyelessy famous\n",
            " all world\n",
            "LAIO\n",
            " the-boardauish in indeed for world as.\n",
            "B! Henry Caesarget Thenoth again heaven soldier\n",
            " w to,, our is and no to own with, to them: have born and push Bolb thy; sudden, burn them\n",
            "Prompt: 'To '\n",
            "To  to strong! aside because lords lords\n",
            " aitCondition of mers fullity\n",
            " holyShe the; love-- was all rest grief\n",
            " not till-,, to\n",
            " thousand whilst\n",
            " would want dead,o man they in wall\n",
            " keep:Al, loveies man mercy sorrow one, so shall all rest grief\n",
            " be, here behold sees.\n",
            "ROO All an man butm!'s thou's thou sweet,,,ot by to: ped thou my\n",
            " presumt thy is\n",
            "Prompt: 'A '\n",
            "A  of and I dispatchideT\n",
            " the of, ne the ofing turning\n",
            " for purposeAR!Or I as scandal\n",
            " arm in mighty, ha, mine, Thursday much.\n",
            "Brew for I for smooth by wide of home your.\n",
            "Hs foright andber soul those be.\n",
            "BBe to yet; is our together some is.\n",
            "Brew soon stands now a;For hath one or heavens I here see nor by ill much for the faith gone pity me a-\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  48%|████▊     | 2401/5000 [1:47:49<4:33:50,  6.32s/it, loss=1.0355]\u001b[A\n",
            "Training:  48%|████▊     | 2401/5000 [1:47:49<4:33:50,  6.32s/it, loss=0.9745]\u001b[A\n",
            "Training:  48%|████▊     | 2402/5000 [1:47:52<3:42:25,  5.14s/it, loss=0.9745]\u001b[A\n",
            "Training:  48%|████▊     | 2402/5000 [1:47:52<3:42:25,  5.14s/it, loss=0.9113]\u001b[A\n",
            "Training:  48%|████▊     | 2403/5000 [1:47:54<3:05:47,  4.29s/it, loss=0.9113]\u001b[A\n",
            "Training:  48%|████▊     | 2403/5000 [1:47:54<3:05:47,  4.29s/it, loss=0.9329]\u001b[A\n",
            "Training:  48%|████▊     | 2404/5000 [1:47:56<2:39:54,  3.70s/it, loss=0.9329]\u001b[A\n",
            "Training:  48%|████▊     | 2404/5000 [1:47:56<2:39:54,  3.70s/it, loss=0.8784]\u001b[A\n",
            "Training:  48%|████▊     | 2405/5000 [1:47:59<2:22:04,  3.29s/it, loss=0.8784]\u001b[A\n",
            "Training:  48%|████▊     | 2405/5000 [1:47:59<2:22:04,  3.29s/it, loss=1.0213]\u001b[A\n",
            "Training:  48%|████▊     | 2406/5000 [1:48:02<2:16:42,  3.16s/it, loss=1.0213]\u001b[A\n",
            "Training:  48%|████▊     | 2406/5000 [1:48:02<2:16:42,  3.16s/it, loss=0.9584]\u001b[A\n",
            "Training:  48%|████▊     | 2407/5000 [1:48:04<2:05:37,  2.91s/it, loss=0.9584]\u001b[A\n",
            "Training:  48%|████▊     | 2407/5000 [1:48:04<2:05:37,  2.91s/it, loss=0.7392]\u001b[A\n",
            "Training:  48%|████▊     | 2408/5000 [1:48:06<1:57:48,  2.73s/it, loss=0.7392]\u001b[A\n",
            "Training:  48%|████▊     | 2408/5000 [1:48:06<1:57:48,  2.73s/it, loss=0.9745]\u001b[A\n",
            "Training:  48%|████▊     | 2409/5000 [1:48:09<1:52:19,  2.60s/it, loss=0.9745]\u001b[A\n",
            "Training:  48%|████▊     | 2409/5000 [1:48:09<1:52:19,  2.60s/it, loss=0.7585]\u001b[A\n",
            "Training:  48%|████▊     | 2410/5000 [1:48:11<1:49:00,  2.53s/it, loss=0.7585]\u001b[A\n",
            "Training:  48%|████▊     | 2410/5000 [1:48:11<1:49:00,  2.53s/it, loss=0.8351]\u001b[A\n",
            "Training:  48%|████▊     | 2411/5000 [1:48:14<1:53:32,  2.63s/it, loss=0.8351]\u001b[A\n",
            "Training:  48%|████▊     | 2411/5000 [1:48:14<1:53:32,  2.63s/it, loss=0.7883]\u001b[A\n",
            "Training:  48%|████▊     | 2412/5000 [1:48:16<1:49:33,  2.54s/it, loss=0.7883]\u001b[A\n",
            "Training:  48%|████▊     | 2412/5000 [1:48:16<1:49:33,  2.54s/it, loss=0.8803]\u001b[A\n",
            "Training:  48%|████▊     | 2413/5000 [1:48:18<1:46:36,  2.47s/it, loss=0.8803]\u001b[A\n",
            "Training:  48%|████▊     | 2413/5000 [1:48:18<1:46:36,  2.47s/it, loss=0.7279]\u001b[A\n",
            "Training:  48%|████▊     | 2414/5000 [1:48:21<1:44:25,  2.42s/it, loss=0.7279]\u001b[A\n",
            "Training:  48%|████▊     | 2414/5000 [1:48:21<1:44:25,  2.42s/it, loss=1.0162]\u001b[A\n",
            "Training:  48%|████▊     | 2415/5000 [1:48:23<1:43:13,  2.40s/it, loss=1.0162]\u001b[A\n",
            "Training:  48%|████▊     | 2415/5000 [1:48:23<1:43:13,  2.40s/it, loss=1.0476]\u001b[A\n",
            "Training:  48%|████▊     | 2416/5000 [1:48:26<1:49:28,  2.54s/it, loss=1.0476]\u001b[A\n",
            "Training:  48%|████▊     | 2416/5000 [1:48:26<1:49:28,  2.54s/it, loss=0.9941]\u001b[A\n",
            "Training:  48%|████▊     | 2417/5000 [1:48:28<1:46:37,  2.48s/it, loss=0.9941]\u001b[A\n",
            "Training:  48%|████▊     | 2417/5000 [1:48:28<1:46:37,  2.48s/it, loss=1.0911]\u001b[A\n",
            "Training:  48%|████▊     | 2418/5000 [1:48:31<1:44:30,  2.43s/it, loss=1.0911]\u001b[A\n",
            "Training:  48%|████▊     | 2418/5000 [1:48:31<1:44:30,  2.43s/it, loss=1.1340]\u001b[A\n",
            "Training:  48%|████▊     | 2419/5000 [1:48:33<1:42:56,  2.39s/it, loss=1.1340]\u001b[A\n",
            "Training:  48%|████▊     | 2419/5000 [1:48:33<1:42:56,  2.39s/it, loss=0.9272]\u001b[A\n",
            "Training:  48%|████▊     | 2420/5000 [1:48:35<1:42:20,  2.38s/it, loss=0.9272]\u001b[A\n",
            "Training:  48%|████▊     | 2420/5000 [1:48:35<1:42:20,  2.38s/it, loss=1.1617]\u001b[A\n",
            "Training:  48%|████▊     | 2421/5000 [1:48:38<1:48:36,  2.53s/it, loss=1.1617]\u001b[A\n",
            "Training:  48%|████▊     | 2421/5000 [1:48:38<1:48:36,  2.53s/it, loss=1.0918]\u001b[A\n",
            "Training:  48%|████▊     | 2422/5000 [1:48:40<1:45:46,  2.46s/it, loss=1.0918]\u001b[A\n",
            "Training:  48%|████▊     | 2422/5000 [1:48:40<1:45:46,  2.46s/it, loss=0.7095]\u001b[A\n",
            "Training:  48%|████▊     | 2423/5000 [1:48:43<1:44:21,  2.43s/it, loss=0.7095]\u001b[A\n",
            "Training:  48%|████▊     | 2423/5000 [1:48:43<1:44:21,  2.43s/it, loss=1.0202]\u001b[A\n",
            "Training:  48%|████▊     | 2424/5000 [1:48:45<1:43:20,  2.41s/it, loss=1.0202]\u001b[A\n",
            "Training:  48%|████▊     | 2424/5000 [1:48:45<1:43:20,  2.41s/it, loss=1.3261]\u001b[A\n",
            "Training:  48%|████▊     | 2425/5000 [1:48:48<1:44:08,  2.43s/it, loss=1.3261]\u001b[A\n",
            "Training:  48%|████▊     | 2425/5000 [1:48:48<1:44:08,  2.43s/it, loss=0.7962]\u001b[A\n",
            "Training:  49%|████▊     | 2426/5000 [1:48:50<1:48:05,  2.52s/it, loss=0.7962]\u001b[A\n",
            "Training:  49%|████▊     | 2426/5000 [1:48:50<1:48:05,  2.52s/it, loss=0.8360]\u001b[A\n",
            "Training:  49%|████▊     | 2427/5000 [1:48:53<1:45:41,  2.46s/it, loss=0.8360]\u001b[A\n",
            "Training:  49%|████▊     | 2427/5000 [1:48:53<1:45:41,  2.46s/it, loss=0.8429]\u001b[A\n",
            "Training:  49%|████▊     | 2428/5000 [1:48:55<1:43:59,  2.43s/it, loss=0.8429]\u001b[A\n",
            "Training:  49%|████▊     | 2428/5000 [1:48:55<1:43:59,  2.43s/it, loss=0.8327]\u001b[A\n",
            "Training:  49%|████▊     | 2429/5000 [1:48:57<1:42:26,  2.39s/it, loss=0.8327]\u001b[A\n",
            "Training:  49%|████▊     | 2429/5000 [1:48:57<1:42:26,  2.39s/it, loss=0.8461]\u001b[A\n",
            "Training:  49%|████▊     | 2430/5000 [1:49:00<1:44:20,  2.44s/it, loss=0.8461]\u001b[A\n",
            "Training:  49%|████▊     | 2430/5000 [1:49:00<1:44:20,  2.44s/it, loss=0.8489]\u001b[A\n",
            "Training:  49%|████▊     | 2431/5000 [1:49:02<1:46:35,  2.49s/it, loss=0.8489]\u001b[A\n",
            "Training:  49%|████▊     | 2431/5000 [1:49:02<1:46:35,  2.49s/it, loss=0.6930]\u001b[A\n",
            "Training:  49%|████▊     | 2432/5000 [1:49:05<1:44:31,  2.44s/it, loss=0.6930]\u001b[A\n",
            "Training:  49%|████▊     | 2432/5000 [1:49:05<1:44:31,  2.44s/it, loss=0.8876]\u001b[A\n",
            "Training:  49%|████▊     | 2433/5000 [1:49:07<1:42:57,  2.41s/it, loss=0.8876]\u001b[A\n",
            "Training:  49%|████▊     | 2433/5000 [1:49:07<1:42:57,  2.41s/it, loss=0.6524]\u001b[A\n",
            "Training:  49%|████▊     | 2434/5000 [1:49:09<1:41:54,  2.38s/it, loss=0.6524]\u001b[A\n",
            "Training:  49%|████▊     | 2434/5000 [1:49:09<1:41:54,  2.38s/it, loss=0.7064]\u001b[A\n",
            "Training:  49%|████▊     | 2435/5000 [1:49:12<1:44:27,  2.44s/it, loss=0.7064]\u001b[A\n",
            "Training:  49%|████▊     | 2435/5000 [1:49:12<1:44:27,  2.44s/it, loss=0.5737]\u001b[A\n",
            "Training:  49%|████▊     | 2436/5000 [1:49:15<1:47:03,  2.51s/it, loss=0.5737]\u001b[A\n",
            "Training:  49%|████▊     | 2436/5000 [1:49:15<1:47:03,  2.51s/it, loss=0.8118]\u001b[A\n",
            "Training:  49%|████▊     | 2437/5000 [1:49:17<1:44:47,  2.45s/it, loss=0.8118]\u001b[A\n",
            "Training:  49%|████▊     | 2437/5000 [1:49:17<1:44:47,  2.45s/it, loss=1.0443]\u001b[A\n",
            "Training:  49%|████▉     | 2438/5000 [1:49:19<1:43:07,  2.42s/it, loss=1.0443]\u001b[A\n",
            "Training:  49%|████▉     | 2438/5000 [1:49:19<1:43:07,  2.42s/it, loss=1.2380]\u001b[A\n",
            "Training:  49%|████▉     | 2439/5000 [1:49:22<1:41:35,  2.38s/it, loss=1.2380]\u001b[A\n",
            "Training:  49%|████▉     | 2439/5000 [1:49:22<1:41:35,  2.38s/it, loss=1.0910]\u001b[A\n",
            "Training:  49%|████▉     | 2440/5000 [1:49:24<1:44:47,  2.46s/it, loss=1.0910]\u001b[A\n",
            "Training:  49%|████▉     | 2440/5000 [1:49:24<1:44:47,  2.46s/it, loss=0.9193]\u001b[A\n",
            "Training:  49%|████▉     | 2441/5000 [1:49:27<1:45:59,  2.49s/it, loss=0.9193]\u001b[A\n",
            "Training:  49%|████▉     | 2441/5000 [1:49:27<1:45:59,  2.49s/it, loss=1.1992]\u001b[A\n",
            "Training:  49%|████▉     | 2442/5000 [1:49:29<1:44:08,  2.44s/it, loss=1.1992]\u001b[A\n",
            "Training:  49%|████▉     | 2442/5000 [1:49:29<1:44:08,  2.44s/it, loss=0.7762]\u001b[A\n",
            "Training:  49%|████▉     | 2443/5000 [1:49:31<1:42:31,  2.41s/it, loss=0.7762]\u001b[A\n",
            "Training:  49%|████▉     | 2443/5000 [1:49:32<1:42:31,  2.41s/it, loss=0.9901]\u001b[A\n",
            "Training:  49%|████▉     | 2444/5000 [1:49:34<1:41:24,  2.38s/it, loss=0.9901]\u001b[A\n",
            "Training:  49%|████▉     | 2444/5000 [1:49:34<1:41:24,  2.38s/it, loss=0.7233]\u001b[A\n",
            "Training:  49%|████▉     | 2445/5000 [1:49:37<1:45:41,  2.48s/it, loss=0.7233]\u001b[A\n",
            "Training:  49%|████▉     | 2445/5000 [1:49:37<1:45:41,  2.48s/it, loss=0.8501]\u001b[A\n",
            "Training:  49%|████▉     | 2446/5000 [1:49:39<1:44:32,  2.46s/it, loss=0.8501]\u001b[A\n",
            "Training:  49%|████▉     | 2446/5000 [1:49:39<1:44:32,  2.46s/it, loss=0.9647]\u001b[A\n",
            "Training:  49%|████▉     | 2447/5000 [1:49:41<1:42:10,  2.40s/it, loss=0.9647]\u001b[A\n",
            "Training:  49%|████▉     | 2447/5000 [1:49:41<1:42:10,  2.40s/it, loss=1.0735]\u001b[A\n",
            "Training:  49%|████▉     | 2448/5000 [1:49:43<1:40:35,  2.36s/it, loss=1.0735]\u001b[A\n",
            "Training:  49%|████▉     | 2448/5000 [1:49:44<1:40:35,  2.36s/it, loss=1.1395]\u001b[A\n",
            "Training:  49%|████▉     | 2449/5000 [1:49:46<1:38:48,  2.32s/it, loss=1.1395]\u001b[A\n",
            "Training:  49%|████▉     | 2449/5000 [1:49:46<1:38:48,  2.32s/it, loss=0.7677]\u001b[A\n",
            "Training:  49%|████▉     | 2450/5000 [1:49:48<1:43:08,  2.43s/it, loss=0.7677]\u001b[A\n",
            "Training:  49%|████▉     | 2450/5000 [1:49:48<1:43:08,  2.43s/it, loss=0.5964]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 2450 ---\n",
            "Prompt: 'The '\n",
            "The  of fifteen have qu court o the: as\n",
            "ve Valentock and of ras both shall have\n",
            "re pale and ofgh\n",
            " cannot\n",
            "ence him\n",
            " hopefular our to so as did up seals are, you\n",
            ", has have,ched one you yours hard I no tohim\n",
            " with: if where his thence have beenad,? must speak sweet, her even day right stood as at,ilsTh the ofous: was sits kn, warrant,!\n",
            "Delt with and\n",
            "Prompt: 'In '\n",
            "In , insout many'd, thr. false many Ale\n",
            " cur complex potacent painted r body trif(\"%\n",
            "by sweetness theirions r body spectcor, it\n",
            " jewel with:ither cannot I it cannot; hisour many dry'd\n",
            "ile, hanging from world thoseits off tears\n",
            " woundings hisour weeping they son but, one'd withst old's,ies his Esc, to the of he you\n",
            " swiftent but is of royal, follows. must you\n",
            "ereted\n",
            "Prompt: 'To '\n",
            "To  life have in and his opening\n",
            " thorns againstited service I.\n",
            "PERAOLN,! do go too\n",
            "'s put forem how blood bd;'s and\n",
            " hom them well and fair prince I,' hurt Let.! not phee laugh ens\n",
            "yiving like winHappyeness When scarce precious another:our,, this\n",
            " stand,! famous comes;!uck of,let!Howals breakle? thou'd sotys fault this Take the,;-\n",
            "Prompt: 'A '\n",
            "A  o the hearing wore goldOne itoth\n",
            " complex. dro conscience her young bment\n",
            " supp like's, they boot for prosperous\n",
            "oved, you and it\n",
            " to familiarity\n",
            "te age O saw disling. me a ofthes I and lust substituteBut we transported my youwill oath butoo but we,Sirours heart the acting, see\n",
            "'s are: on are of rock but h, theyare,s good them\n",
            " meow son the are so his bride he: you\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  49%|████▉     | 2451/5000 [1:50:03<4:20:17,  6.13s/it, loss=0.5964]\u001b[A\n",
            "Training:  49%|████▉     | 2451/5000 [1:50:03<4:20:17,  6.13s/it, loss=0.9666]\u001b[A\n",
            "Training:  49%|████▉     | 2452/5000 [1:50:05<3:30:28,  4.96s/it, loss=0.9666]\u001b[A\n",
            "Training:  49%|████▉     | 2452/5000 [1:50:05<3:30:28,  4.96s/it, loss=0.9435]\u001b[A\n",
            "Training:  49%|████▉     | 2453/5000 [1:50:08<2:55:52,  4.14s/it, loss=0.9435]\u001b[A\n",
            "Training:  49%|████▉     | 2453/5000 [1:50:08<2:55:52,  4.14s/it, loss=0.8660]\u001b[A\n",
            "Training:  49%|████▉     | 2454/5000 [1:50:10<2:31:39,  3.57s/it, loss=0.8660]\u001b[A\n",
            "Training:  49%|████▉     | 2454/5000 [1:50:10<2:31:39,  3.57s/it, loss=0.9458]\u001b[A\n",
            "Training:  49%|████▉     | 2455/5000 [1:50:13<2:21:30,  3.34s/it, loss=0.9458]\u001b[A\n",
            "Training:  49%|████▉     | 2455/5000 [1:50:13<2:21:30,  3.34s/it, loss=0.7746]\u001b[A\n",
            "Training:  49%|████▉     | 2456/5000 [1:50:15<2:08:02,  3.02s/it, loss=0.7746]\u001b[A\n",
            "Training:  49%|████▉     | 2456/5000 [1:50:15<2:08:02,  3.02s/it, loss=0.7149]\u001b[A\n",
            "Training:  49%|████▉     | 2457/5000 [1:50:17<1:58:01,  2.78s/it, loss=0.7149]\u001b[A\n",
            "Training:  49%|████▉     | 2457/5000 [1:50:17<1:58:01,  2.78s/it, loss=1.3847]\u001b[A\n",
            "Training:  49%|████▉     | 2458/5000 [1:50:19<1:51:25,  2.63s/it, loss=1.3847]\u001b[A\n",
            "Training:  49%|████▉     | 2458/5000 [1:50:19<1:51:25,  2.63s/it, loss=1.2029]\u001b[A\n",
            "Training:  49%|████▉     | 2459/5000 [1:50:22<1:46:23,  2.51s/it, loss=1.2029]\u001b[A\n",
            "Training:  49%|████▉     | 2459/5000 [1:50:22<1:46:23,  2.51s/it, loss=0.9981]\u001b[A\n",
            "Training:  49%|████▉     | 2460/5000 [1:50:24<1:49:30,  2.59s/it, loss=0.9981]\u001b[A\n",
            "Training:  49%|████▉     | 2460/5000 [1:50:24<1:49:30,  2.59s/it, loss=1.0339]\u001b[A\n",
            "Training:  49%|████▉     | 2461/5000 [1:50:27<1:45:13,  2.49s/it, loss=1.0339]\u001b[A\n",
            "Training:  49%|████▉     | 2461/5000 [1:50:27<1:45:13,  2.49s/it, loss=0.8045]\u001b[A\n",
            "Training:  49%|████▉     | 2462/5000 [1:50:29<1:42:23,  2.42s/it, loss=0.8045]\u001b[A\n",
            "Training:  49%|████▉     | 2462/5000 [1:50:29<1:42:23,  2.42s/it, loss=0.8718]\u001b[A\n",
            "Training:  49%|████▉     | 2463/5000 [1:50:31<1:40:00,  2.37s/it, loss=0.8718]\u001b[A\n",
            "Training:  49%|████▉     | 2463/5000 [1:50:31<1:40:00,  2.37s/it, loss=0.6766]\u001b[A\n",
            "Training:  49%|████▉     | 2464/5000 [1:50:33<1:38:08,  2.32s/it, loss=0.6766]\u001b[A\n",
            "Training:  49%|████▉     | 2464/5000 [1:50:33<1:38:08,  2.32s/it, loss=1.0223]\u001b[A\n",
            "Training:  49%|████▉     | 2465/5000 [1:50:36<1:44:14,  2.47s/it, loss=1.0223]\u001b[A\n",
            "Training:  49%|████▉     | 2465/5000 [1:50:36<1:44:14,  2.47s/it, loss=0.9817]\u001b[A\n",
            "Training:  49%|████▉     | 2466/5000 [1:50:38<1:41:31,  2.40s/it, loss=0.9817]\u001b[A\n",
            "Training:  49%|████▉     | 2466/5000 [1:50:38<1:41:31,  2.40s/it, loss=0.7096]\u001b[A\n",
            "Training:  49%|████▉     | 2467/5000 [1:50:41<1:39:29,  2.36s/it, loss=0.7096]\u001b[A\n",
            "Training:  49%|████▉     | 2467/5000 [1:50:41<1:39:29,  2.36s/it, loss=0.8726]\u001b[A\n",
            "Training:  49%|████▉     | 2468/5000 [1:50:43<1:38:12,  2.33s/it, loss=0.8726]\u001b[A\n",
            "Training:  49%|████▉     | 2468/5000 [1:50:43<1:38:12,  2.33s/it, loss=1.0435]\u001b[A\n",
            "Training:  49%|████▉     | 2469/5000 [1:50:45<1:37:40,  2.32s/it, loss=1.0435]\u001b[A\n",
            "Training:  49%|████▉     | 2469/5000 [1:50:45<1:37:40,  2.32s/it, loss=0.8563]\u001b[A\n",
            "Training:  49%|████▉     | 2470/5000 [1:50:48<1:43:12,  2.45s/it, loss=0.8563]\u001b[A\n",
            "Training:  49%|████▉     | 2470/5000 [1:50:48<1:43:12,  2.45s/it, loss=0.4655]\u001b[A\n",
            "Training:  49%|████▉     | 2471/5000 [1:50:50<1:40:41,  2.39s/it, loss=0.4655]\u001b[A\n",
            "Training:  49%|████▉     | 2471/5000 [1:50:50<1:40:41,  2.39s/it, loss=0.7384]\u001b[A\n",
            "Training:  49%|████▉     | 2472/5000 [1:50:53<1:39:01,  2.35s/it, loss=0.7384]\u001b[A\n",
            "Training:  49%|████▉     | 2472/5000 [1:50:53<1:39:01,  2.35s/it, loss=0.8141]\u001b[A\n",
            "Training:  49%|████▉     | 2473/5000 [1:50:55<1:37:27,  2.31s/it, loss=0.8141]\u001b[A\n",
            "Training:  49%|████▉     | 2473/5000 [1:50:55<1:37:27,  2.31s/it, loss=0.7987]\u001b[A\n",
            "Training:  49%|████▉     | 2474/5000 [1:50:57<1:36:28,  2.29s/it, loss=0.7987]\u001b[A\n",
            "Training:  49%|████▉     | 2474/5000 [1:50:57<1:36:28,  2.29s/it, loss=0.6242]\u001b[A\n",
            "Training:  50%|████▉     | 2475/5000 [1:51:00<1:42:21,  2.43s/it, loss=0.6242]\u001b[A\n",
            "Training:  50%|████▉     | 2475/5000 [1:51:00<1:42:21,  2.43s/it, loss=0.9484]\u001b[A\n",
            "Training:  50%|████▉     | 2476/5000 [1:51:02<1:39:48,  2.37s/it, loss=0.9484]\u001b[A\n",
            "Training:  50%|████▉     | 2476/5000 [1:51:02<1:39:48,  2.37s/it, loss=0.8544]\u001b[A\n",
            "Training:  50%|████▉     | 2477/5000 [1:51:04<1:37:51,  2.33s/it, loss=0.8544]\u001b[A\n",
            "Training:  50%|████▉     | 2477/5000 [1:51:04<1:37:51,  2.33s/it, loss=1.1429]\u001b[A\n",
            "Training:  50%|████▉     | 2478/5000 [1:51:06<1:36:43,  2.30s/it, loss=1.1429]\u001b[A\n",
            "Training:  50%|████▉     | 2478/5000 [1:51:06<1:36:43,  2.30s/it, loss=1.0854]\u001b[A\n",
            "Training:  50%|████▉     | 2479/5000 [1:51:09<1:36:07,  2.29s/it, loss=1.0854]\u001b[A\n",
            "Training:  50%|████▉     | 2479/5000 [1:51:09<1:36:07,  2.29s/it, loss=0.8990]\u001b[A\n",
            "Training:  50%|████▉     | 2480/5000 [1:51:11<1:41:26,  2.42s/it, loss=0.8990]\u001b[A\n",
            "Training:  50%|████▉     | 2480/5000 [1:51:11<1:41:26,  2.42s/it, loss=0.8698]\u001b[A\n",
            "Training:  50%|████▉     | 2481/5000 [1:51:14<1:40:20,  2.39s/it, loss=0.8698]\u001b[A\n",
            "Training:  50%|████▉     | 2481/5000 [1:51:14<1:40:20,  2.39s/it, loss=1.0185]\u001b[A\n",
            "Training:  50%|████▉     | 2482/5000 [1:51:16<1:38:31,  2.35s/it, loss=1.0185]\u001b[A\n",
            "Training:  50%|████▉     | 2482/5000 [1:51:16<1:38:31,  2.35s/it, loss=0.9317]\u001b[A\n",
            "Training:  50%|████▉     | 2483/5000 [1:51:18<1:37:18,  2.32s/it, loss=0.9317]\u001b[A\n",
            "Training:  50%|████▉     | 2483/5000 [1:51:18<1:37:18,  2.32s/it, loss=1.0454]\u001b[A\n",
            "Training:  50%|████▉     | 2484/5000 [1:51:20<1:36:13,  2.29s/it, loss=1.0454]\u001b[A\n",
            "Training:  50%|████▉     | 2484/5000 [1:51:21<1:36:13,  2.29s/it, loss=0.6512]\u001b[A\n",
            "Training:  50%|████▉     | 2485/5000 [1:51:23<1:40:41,  2.40s/it, loss=0.6512]\u001b[A\n",
            "Training:  50%|████▉     | 2485/5000 [1:51:23<1:40:41,  2.40s/it, loss=0.6623]\u001b[A\n",
            "Training:  50%|████▉     | 2486/5000 [1:51:26<1:40:27,  2.40s/it, loss=0.6623]\u001b[A\n",
            "Training:  50%|████▉     | 2486/5000 [1:51:26<1:40:27,  2.40s/it, loss=0.7880]\u001b[A\n",
            "Training:  50%|████▉     | 2487/5000 [1:51:28<1:38:41,  2.36s/it, loss=0.7880]\u001b[A\n",
            "Training:  50%|████▉     | 2487/5000 [1:51:28<1:38:41,  2.36s/it, loss=0.8240]\u001b[A\n",
            "Training:  50%|████▉     | 2488/5000 [1:51:30<1:36:56,  2.32s/it, loss=0.8240]\u001b[A\n",
            "Training:  50%|████▉     | 2488/5000 [1:51:30<1:36:56,  2.32s/it, loss=0.6070]\u001b[A\n",
            "Training:  50%|████▉     | 2489/5000 [1:51:32<1:36:11,  2.30s/it, loss=0.6070]\u001b[A\n",
            "Training:  50%|████▉     | 2489/5000 [1:51:32<1:36:11,  2.30s/it, loss=0.6365]\u001b[A\n",
            "Training:  50%|████▉     | 2490/5000 [1:51:35<1:40:10,  2.39s/it, loss=0.6365]\u001b[A\n",
            "Training:  50%|████▉     | 2490/5000 [1:51:35<1:40:10,  2.39s/it, loss=0.8284]\u001b[A\n",
            "Training:  50%|████▉     | 2491/5000 [1:51:37<1:40:21,  2.40s/it, loss=0.8284]\u001b[A\n",
            "Training:  50%|████▉     | 2491/5000 [1:51:37<1:40:21,  2.40s/it, loss=0.8377]\u001b[A\n",
            "Training:  50%|████▉     | 2492/5000 [1:51:40<1:38:13,  2.35s/it, loss=0.8377]\u001b[A\n",
            "Training:  50%|████▉     | 2492/5000 [1:51:40<1:38:13,  2.35s/it, loss=0.6483]\u001b[A\n",
            "Training:  50%|████▉     | 2493/5000 [1:51:42<1:37:10,  2.33s/it, loss=0.6483]\u001b[A\n",
            "Training:  50%|████▉     | 2493/5000 [1:51:42<1:37:10,  2.33s/it, loss=1.0917]\u001b[A\n",
            "Training:  50%|████▉     | 2494/5000 [1:51:44<1:36:14,  2.30s/it, loss=1.0917]\u001b[A\n",
            "Training:  50%|████▉     | 2494/5000 [1:51:44<1:36:14,  2.30s/it, loss=1.2547]\u001b[A\n",
            "Training:  50%|████▉     | 2495/5000 [1:51:47<1:39:49,  2.39s/it, loss=1.2547]\u001b[A\n",
            "Training:  50%|████▉     | 2495/5000 [1:51:47<1:39:49,  2.39s/it, loss=0.9982]\u001b[A\n",
            "Training:  50%|████▉     | 2496/5000 [1:51:49<1:40:30,  2.41s/it, loss=0.9982]\u001b[A\n",
            "Training:  50%|████▉     | 2496/5000 [1:51:49<1:40:30,  2.41s/it, loss=0.8478]\u001b[A\n",
            "Training:  50%|████▉     | 2497/5000 [1:51:51<1:38:20,  2.36s/it, loss=0.8478]\u001b[A\n",
            "Training:  50%|████▉     | 2497/5000 [1:51:51<1:38:20,  2.36s/it, loss=1.1160]\u001b[A\n",
            "Training:  50%|████▉     | 2498/5000 [1:51:54<1:36:49,  2.32s/it, loss=1.1160]\u001b[A\n",
            "Training:  50%|████▉     | 2498/5000 [1:51:54<1:36:49,  2.32s/it, loss=1.2083]\u001b[A\n",
            "Training:  50%|████▉     | 2499/5000 [1:51:56<1:35:47,  2.30s/it, loss=1.2083]\u001b[A\n",
            "Training:  50%|████▉     | 2499/5000 [1:51:56<1:35:47,  2.30s/it, loss=0.9213]\u001b[A\n",
            "Training:  50%|█████     | 2500/5000 [1:51:58<1:38:42,  2.37s/it, loss=0.9213]\u001b[A\n",
            "Training:  50%|█████     | 2500/5000 [1:51:58<1:38:42,  2.37s/it, loss=0.8338]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 2500 ---\n",
            "Prompt: 'The '\n",
            "The  a made and inferior.\n",
            "GZO\n",
            " plague\n",
            " thouThe: thou a\n",
            "ath not an power such as into city\n",
            " the timeOf cens and it come!\n",
            "S often no. is.ar,, spare all\n",
            "ath me thee any I but unellows him to, lord\n",
            " theows again ' course spoke.er my!itor ' a\n",
            " to my by own word who it so asfall him\n",
            " would stirAgain this mad: my, my hand what am last\n",
            "Prompt: 'In '\n",
            "In  in throattis good into lands\n",
            " known feel that upon hour I not, rather\n",
            "an honour meCI: I it be\n",
            "hips me any or done your made I him; learn\n",
            " I upon owndain where have kindness\n",
            " cannot. walk indeed comes indeed; sea\n",
            " mostished: I follow to forth\n",
            "st like acc. whose indeed I myself\n",
            " show I away'll forth heart hear prisonersIn\n",
            " would my business honour myself how say thou chamber\n",
            " I give help my lies her be\n",
            "\n",
            "Prompt: 'To '\n",
            "To Well go. mark me me me\n",
            " wrong we something clothes But\n",
            " mock most gifts\n",
            " They have and into disposition\n",
            " profit me heavy.\n",
            "COI blocks Cusufius, was never' sea to.\n",
            "Melf together a free a; such such o theit would two: apply affect making\n",
            "igh un fire aman fororn at; whose being'd one creature mery\n",
            " this proportion in of. else O.\n",
            "SETI:Spe ho an\n",
            ", give: whence\n",
            "Prompt: 'A '\n",
            "A  a as which whichades asleepWhichAs\n",
            " may it straight for people commission.\n",
            "AU's. earth ' a h'd O thingThat set twoer\n",
            " his son in strength and never ab thus such\n",
            " would us hand that LordCaned Whatished how should Angel'sness\n",
            "ath us petition; stateNothing that youose pass\n",
            " second.\n",
            ",,or gall!\n",
            "First the!Both,!\n",
            "oust bigger my heart noise f in debt all world hbury thy: once\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "✓ Checkpoint saved: checkpoints/checkpoint_step_2500.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  50%|█████     | 2501/5000 [1:52:26<6:56:54, 10.01s/it, loss=0.8338]\u001b[A\n",
            "Training:  50%|█████     | 2501/5000 [1:52:26<6:56:54, 10.01s/it, loss=0.7537]\u001b[A\n",
            "Training:  50%|█████     | 2502/5000 [1:52:28<5:20:08,  7.69s/it, loss=0.7537]\u001b[A\n",
            "Training:  50%|█████     | 2502/5000 [1:52:28<5:20:08,  7.69s/it, loss=0.8115]\u001b[A\n",
            "Training:  50%|█████     | 2503/5000 [1:52:31<4:11:29,  6.04s/it, loss=0.8115]\u001b[A\n",
            "Training:  50%|█████     | 2503/5000 [1:52:31<4:11:29,  6.04s/it, loss=0.6933]\u001b[A\n",
            "Training:  50%|█████     | 2504/5000 [1:52:33<3:26:13,  4.96s/it, loss=0.6933]\u001b[A\n",
            "Training:  50%|█████     | 2504/5000 [1:52:33<3:26:13,  4.96s/it, loss=0.8150]\u001b[A\n",
            "Training:  50%|█████     | 2505/5000 [1:52:36<2:56:51,  4.25s/it, loss=0.8150]\u001b[A\n",
            "Training:  50%|█████     | 2505/5000 [1:52:36<2:56:51,  4.25s/it, loss=1.0216]\u001b[A\n",
            "Training:  50%|█████     | 2506/5000 [1:52:38<2:31:35,  3.65s/it, loss=1.0216]\u001b[A\n",
            "Training:  50%|█████     | 2506/5000 [1:52:38<2:31:35,  3.65s/it, loss=0.7735]\u001b[A\n",
            "Training:  50%|█████     | 2507/5000 [1:52:40<2:14:00,  3.23s/it, loss=0.7735]\u001b[A\n",
            "Training:  50%|█████     | 2507/5000 [1:52:40<2:14:00,  3.23s/it, loss=0.6138]\u001b[A\n",
            "Training:  50%|█████     | 2508/5000 [1:52:42<2:01:40,  2.93s/it, loss=0.6138]\u001b[A\n",
            "Training:  50%|█████     | 2508/5000 [1:52:42<2:01:40,  2.93s/it, loss=0.7491]\u001b[A\n",
            "Training:  50%|█████     | 2509/5000 [1:52:45<1:54:34,  2.76s/it, loss=0.7491]\u001b[A\n",
            "Training:  50%|█████     | 2509/5000 [1:52:45<1:54:34,  2.76s/it, loss=0.6471]\u001b[A\n",
            "Training:  50%|█████     | 2510/5000 [1:52:48<1:54:17,  2.75s/it, loss=0.6471]\u001b[A\n",
            "Training:  50%|█████     | 2510/5000 [1:52:48<1:54:17,  2.75s/it, loss=0.9339]\u001b[A\n",
            "Training:  50%|█████     | 2511/5000 [1:52:50<1:47:53,  2.60s/it, loss=0.9339]\u001b[A\n",
            "Training:  50%|█████     | 2511/5000 [1:52:50<1:47:53,  2.60s/it, loss=0.6650]\u001b[A\n",
            "Training:  50%|█████     | 2512/5000 [1:52:52<1:43:37,  2.50s/it, loss=0.6650]\u001b[A\n",
            "Training:  50%|█████     | 2512/5000 [1:52:52<1:43:37,  2.50s/it, loss=0.6800]\u001b[A\n",
            "Training:  50%|█████     | 2513/5000 [1:52:54<1:42:38,  2.48s/it, loss=0.6800]\u001b[A\n",
            "Training:  50%|█████     | 2513/5000 [1:52:54<1:42:38,  2.48s/it, loss=0.8458]\u001b[A\n",
            "Training:  50%|█████     | 2514/5000 [1:52:57<1:42:35,  2.48s/it, loss=0.8458]\u001b[A\n",
            "Training:  50%|█████     | 2514/5000 [1:52:57<1:42:35,  2.48s/it, loss=0.5781]\u001b[A\n",
            "Training:  50%|█████     | 2515/5000 [1:53:00<1:45:38,  2.55s/it, loss=0.5781]\u001b[A\n",
            "Training:  50%|█████     | 2515/5000 [1:53:00<1:45:38,  2.55s/it, loss=0.7585]\u001b[A\n",
            "Training:  50%|█████     | 2516/5000 [1:53:02<1:42:40,  2.48s/it, loss=0.7585]\u001b[A\n",
            "Training:  50%|█████     | 2516/5000 [1:53:02<1:42:40,  2.48s/it, loss=0.6046]\u001b[A\n",
            "Training:  50%|█████     | 2517/5000 [1:53:04<1:40:30,  2.43s/it, loss=0.6046]\u001b[A\n",
            "Training:  50%|█████     | 2517/5000 [1:53:04<1:40:30,  2.43s/it, loss=0.7504]\u001b[A\n",
            "Training:  50%|█████     | 2518/5000 [1:53:07<1:39:04,  2.40s/it, loss=0.7504]\u001b[A\n",
            "Training:  50%|█████     | 2518/5000 [1:53:07<1:39:04,  2.40s/it, loss=0.7607]\u001b[A\n",
            "Training:  50%|█████     | 2519/5000 [1:53:09<1:41:08,  2.45s/it, loss=0.7607]\u001b[A\n",
            "Training:  50%|█████     | 2519/5000 [1:53:09<1:41:08,  2.45s/it, loss=0.7453]\u001b[A\n",
            "Training:  50%|█████     | 2520/5000 [1:53:12<1:43:29,  2.50s/it, loss=0.7453]\u001b[A\n",
            "Training:  50%|█████     | 2520/5000 [1:53:12<1:43:29,  2.50s/it, loss=0.7970]\u001b[A\n",
            "Training:  50%|█████     | 2521/5000 [1:53:14<1:41:23,  2.45s/it, loss=0.7970]\u001b[A\n",
            "Training:  50%|█████     | 2521/5000 [1:53:14<1:41:23,  2.45s/it, loss=1.0366]\u001b[A\n",
            "Training:  50%|█████     | 2522/5000 [1:53:16<1:40:04,  2.42s/it, loss=1.0366]\u001b[A\n",
            "Training:  50%|█████     | 2522/5000 [1:53:17<1:40:04,  2.42s/it, loss=1.0137]\u001b[A\n",
            "Training:  50%|█████     | 2523/5000 [1:53:19<1:39:02,  2.40s/it, loss=1.0137]\u001b[A\n",
            "Training:  50%|█████     | 2523/5000 [1:53:19<1:39:02,  2.40s/it, loss=0.8446]\u001b[A\n",
            "Training:  50%|█████     | 2524/5000 [1:53:21<1:41:31,  2.46s/it, loss=0.8446]\u001b[A\n",
            "Training:  50%|█████     | 2524/5000 [1:53:21<1:41:31,  2.46s/it, loss=0.9381]\u001b[A\n",
            "Training:  50%|█████     | 2525/5000 [1:53:24<1:43:17,  2.50s/it, loss=0.9381]\u001b[A\n",
            "Training:  50%|█████     | 2525/5000 [1:53:24<1:43:17,  2.50s/it, loss=0.7629]\u001b[A\n",
            "Training:  51%|█████     | 2526/5000 [1:53:26<1:40:49,  2.45s/it, loss=0.7629]\u001b[A\n",
            "Training:  51%|█████     | 2526/5000 [1:53:26<1:40:49,  2.45s/it, loss=0.7131]\u001b[A\n",
            "Training:  51%|█████     | 2527/5000 [1:53:29<1:39:40,  2.42s/it, loss=0.7131]\u001b[A\n",
            "Training:  51%|█████     | 2527/5000 [1:53:29<1:39:40,  2.42s/it, loss=0.6271]\u001b[A\n",
            "Training:  51%|█████     | 2528/5000 [1:53:31<1:38:16,  2.39s/it, loss=0.6271]\u001b[A\n",
            "Training:  51%|█████     | 2528/5000 [1:53:31<1:38:16,  2.39s/it, loss=0.7347]\u001b[A\n",
            "Training:  51%|█████     | 2529/5000 [1:53:34<1:41:31,  2.47s/it, loss=0.7347]\u001b[A\n",
            "Training:  51%|█████     | 2529/5000 [1:53:34<1:41:31,  2.47s/it, loss=1.0266]\u001b[A\n",
            "Training:  51%|█████     | 2530/5000 [1:53:36<1:42:13,  2.48s/it, loss=1.0266]\u001b[A\n",
            "Training:  51%|█████     | 2530/5000 [1:53:36<1:42:13,  2.48s/it, loss=1.4541]\u001b[A\n",
            "Training:  51%|█████     | 2531/5000 [1:53:38<1:40:03,  2.43s/it, loss=1.4541]\u001b[A\n",
            "Training:  51%|█████     | 2531/5000 [1:53:39<1:40:03,  2.43s/it, loss=1.0100]\u001b[A\n",
            "Training:  51%|█████     | 2532/5000 [1:53:41<1:38:46,  2.40s/it, loss=1.0100]\u001b[A\n",
            "Training:  51%|█████     | 2532/5000 [1:53:41<1:38:46,  2.40s/it, loss=0.8859]\u001b[A\n",
            "Training:  51%|█████     | 2533/5000 [1:53:43<1:37:43,  2.38s/it, loss=0.8859]\u001b[A\n",
            "Training:  51%|█████     | 2533/5000 [1:53:43<1:37:43,  2.38s/it, loss=0.8293]\u001b[A\n",
            "Training:  51%|█████     | 2534/5000 [1:53:46<1:41:55,  2.48s/it, loss=0.8293]\u001b[A\n",
            "Training:  51%|█████     | 2534/5000 [1:53:46<1:41:55,  2.48s/it, loss=0.8927]\u001b[A\n",
            "Training:  51%|█████     | 2535/5000 [1:53:48<1:41:59,  2.48s/it, loss=0.8927]\u001b[A\n",
            "Training:  51%|█████     | 2535/5000 [1:53:48<1:41:59,  2.48s/it, loss=0.6622]\u001b[A\n",
            "Training:  51%|█████     | 2536/5000 [1:53:51<1:40:03,  2.44s/it, loss=0.6622]\u001b[A\n",
            "Training:  51%|█████     | 2536/5000 [1:53:51<1:40:03,  2.44s/it, loss=0.6745]\u001b[A\n",
            "Training:  51%|█████     | 2537/5000 [1:53:53<1:38:13,  2.39s/it, loss=0.6745]\u001b[A\n",
            "Training:  51%|█████     | 2537/5000 [1:53:53<1:38:13,  2.39s/it, loss=0.5653]\u001b[A\n",
            "Training:  51%|█████     | 2538/5000 [1:53:55<1:37:07,  2.37s/it, loss=0.5653]\u001b[A\n",
            "Training:  51%|█████     | 2538/5000 [1:53:55<1:37:07,  2.37s/it, loss=0.6948]\u001b[A\n",
            "Training:  51%|█████     | 2539/5000 [1:53:58<1:43:40,  2.53s/it, loss=0.6948]\u001b[A\n",
            "Training:  51%|█████     | 2539/5000 [1:53:58<1:43:40,  2.53s/it, loss=0.7857]\u001b[A\n",
            "Training:  51%|█████     | 2540/5000 [1:54:00<1:40:47,  2.46s/it, loss=0.7857]\u001b[A\n",
            "Training:  51%|█████     | 2540/5000 [1:54:00<1:40:47,  2.46s/it, loss=0.7163]\u001b[A\n",
            "Training:  51%|█████     | 2541/5000 [1:54:03<1:39:19,  2.42s/it, loss=0.7163]\u001b[A\n",
            "Training:  51%|█████     | 2541/5000 [1:54:03<1:39:19,  2.42s/it, loss=0.7095]\u001b[A\n",
            "Training:  51%|█████     | 2542/5000 [1:54:05<1:37:57,  2.39s/it, loss=0.7095]\u001b[A\n",
            "Training:  51%|█████     | 2542/5000 [1:54:05<1:37:57,  2.39s/it, loss=0.9188]\u001b[A\n",
            "Training:  51%|█████     | 2543/5000 [1:54:07<1:36:55,  2.37s/it, loss=0.9188]\u001b[A\n",
            "Training:  51%|█████     | 2543/5000 [1:54:07<1:36:55,  2.37s/it, loss=0.7818]\u001b[A\n",
            "Training:  51%|█████     | 2544/5000 [1:54:10<1:42:56,  2.51s/it, loss=0.7818]\u001b[A\n",
            "Training:  51%|█████     | 2544/5000 [1:54:10<1:42:56,  2.51s/it, loss=0.5188]\u001b[A\n",
            "Training:  51%|█████     | 2545/5000 [1:54:13<1:40:24,  2.45s/it, loss=0.5188]\u001b[A\n",
            "Training:  51%|█████     | 2545/5000 [1:54:13<1:40:24,  2.45s/it, loss=0.7595]\u001b[A\n",
            "Training:  51%|█████     | 2546/5000 [1:54:15<1:38:35,  2.41s/it, loss=0.7595]\u001b[A\n",
            "Training:  51%|█████     | 2546/5000 [1:54:15<1:38:35,  2.41s/it, loss=0.6354]\u001b[A\n",
            "Training:  51%|█████     | 2547/5000 [1:54:17<1:37:29,  2.38s/it, loss=0.6354]\u001b[A\n",
            "Training:  51%|█████     | 2547/5000 [1:54:17<1:37:29,  2.38s/it, loss=0.7558]\u001b[A\n",
            "Training:  51%|█████     | 2548/5000 [1:54:20<1:37:15,  2.38s/it, loss=0.7558]\u001b[A\n",
            "Training:  51%|█████     | 2548/5000 [1:54:20<1:37:15,  2.38s/it, loss=0.9310]\u001b[A\n",
            "Training:  51%|█████     | 2549/5000 [1:54:22<1:43:17,  2.53s/it, loss=0.9310]\u001b[A\n",
            "Training:  51%|█████     | 2549/5000 [1:54:23<1:43:17,  2.53s/it, loss=0.7139]\u001b[A\n",
            "Training:  51%|█████     | 2550/5000 [1:54:25<1:40:51,  2.47s/it, loss=0.7139]\u001b[A\n",
            "Training:  51%|█████     | 2550/5000 [1:54:25<1:40:51,  2.47s/it, loss=0.8229]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 2550 ---\n",
            "Prompt: 'The '\n",
            "The , love young val'sORK\n",
            "Lord:Th Norfolk mymen friendsWithin,'s thou's not.\n",
            "N,am how is will it it it?\n",
            "N, me sir I not bast, is, me; me I for? sau dull, me the of now\n",
            " Where and good I,FR raising arms with.\n",
            "N, is not. fall lawful,!A weeds fall;ither true:eaa aren,-! account heaven why here fear\n",
            " today good\n",
            "Prompt: 'In '\n",
            "In  life would lo on walls boldly blood\n",
            " spot inest bonesaunt and chairskss abroad flower\n",
            "ays the pestence the andmakers fierycephal blood\n",
            " Lancaster poor willuck g against ships; their light Exeterfor is\n",
            "rey,is and, purchase thyile of high.\n",
            "Hest said never is brother!!'s tro is\n",
            " withIn of, it you losing to the are::S you take the ourred very, gentlemen you\n",
            "ere have not much much with: my\n",
            "Prompt: 'To '\n",
            "To  or my and outOne in.\n",
            "K RARD:'oth fullrong with,, qualified isullBy?\n",
            "N,,,, true, I forgot. mean;,, you news and.\n",
            "N, cousin am by,, marsh, seize thee thy,\n",
            " and webTo thy son and meditation Here's and comes wearingeth;\n",
            " me my and what I, fear our,NA not I not it your, ' swear s, me\n",
            " paper,' change you be\n",
            "Prompt: 'A '\n",
            "A rant made a byOr\n",
            " savage add itself and row sacred, converseFrom!\n",
            "D I a of as a, to,,, sun Aid!! com!Just! way\n",
            " pickanceelyetethots itself!\n",
            " our do all byW it and had been unborn, my,isTo, it;, to\n",
            "ield welcome hath-- time sport about.\n",
            "Ju hereivenessto my,rowful;el!!!!! sorrow it thely as said\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  51%|█████     | 2551/5000 [1:54:40<4:15:16,  6.25s/it, loss=0.8229]\u001b[A\n",
            "Training:  51%|█████     | 2551/5000 [1:54:40<4:15:16,  6.25s/it, loss=0.8481]\u001b[A\n",
            "Training:  51%|█████     | 2552/5000 [1:54:42<3:27:00,  5.07s/it, loss=0.8481]\u001b[A\n",
            "Training:  51%|█████     | 2552/5000 [1:54:42<3:27:00,  5.07s/it, loss=0.4934]\u001b[A\n",
            "Training:  51%|█████     | 2553/5000 [1:54:45<2:56:37,  4.33s/it, loss=0.4934]\u001b[A\n",
            "Training:  51%|█████     | 2553/5000 [1:54:45<2:56:37,  4.33s/it, loss=0.6780]\u001b[A\n",
            "Training:  51%|█████     | 2554/5000 [1:54:47<2:35:04,  3.80s/it, loss=0.6780]\u001b[A\n",
            "Training:  51%|█████     | 2554/5000 [1:54:47<2:35:04,  3.80s/it, loss=0.7835]\u001b[A\n",
            "Training:  51%|█████     | 2555/5000 [1:54:50<2:17:22,  3.37s/it, loss=0.7835]\u001b[A\n",
            "Training:  51%|█████     | 2555/5000 [1:54:50<2:17:22,  3.37s/it, loss=0.5834]\u001b[A\n",
            "Training:  51%|█████     | 2556/5000 [1:54:52<2:04:20,  3.05s/it, loss=0.5834]\u001b[A\n",
            "Training:  51%|█████     | 2556/5000 [1:54:52<2:04:20,  3.05s/it, loss=0.6242]\u001b[A\n",
            "Training:  51%|█████     | 2557/5000 [1:54:54<1:55:30,  2.84s/it, loss=0.6242]\u001b[A\n",
            "Training:  51%|█████     | 2557/5000 [1:54:54<1:55:30,  2.84s/it, loss=0.5267]\u001b[A\n",
            "Training:  51%|█████     | 2558/5000 [1:54:57<1:53:37,  2.79s/it, loss=0.5267]\u001b[A\n",
            "Training:  51%|█████     | 2558/5000 [1:54:57<1:53:37,  2.79s/it, loss=0.6114]\u001b[A\n",
            "Training:  51%|█████     | 2559/5000 [1:55:00<1:49:59,  2.70s/it, loss=0.6114]\u001b[A\n",
            "Training:  51%|█████     | 2559/5000 [1:55:00<1:49:59,  2.70s/it, loss=0.6854]\u001b[A\n",
            "Training:  51%|█████     | 2560/5000 [1:55:02<1:45:08,  2.59s/it, loss=0.6854]\u001b[A\n",
            "Training:  51%|█████     | 2560/5000 [1:55:02<1:45:08,  2.59s/it, loss=0.6423]\u001b[A\n",
            "Training:  51%|█████     | 2561/5000 [1:55:04<1:42:10,  2.51s/it, loss=0.6423]\u001b[A\n",
            "Training:  51%|█████     | 2561/5000 [1:55:04<1:42:10,  2.51s/it, loss=0.6512]\u001b[A\n",
            "Training:  51%|█████     | 2562/5000 [1:55:07<1:39:38,  2.45s/it, loss=0.6512]\u001b[A\n",
            "Training:  51%|█████     | 2562/5000 [1:55:07<1:39:38,  2.45s/it, loss=0.4666]\u001b[A\n",
            "Training:  51%|█████▏    | 2563/5000 [1:55:09<1:43:42,  2.55s/it, loss=0.4666]\u001b[A\n",
            "Training:  51%|█████▏    | 2563/5000 [1:55:09<1:43:42,  2.55s/it, loss=0.8964]\u001b[A\n",
            "Training:  51%|█████▏    | 2564/5000 [1:55:12<1:41:37,  2.50s/it, loss=0.8964]\u001b[A\n",
            "Training:  51%|█████▏    | 2564/5000 [1:55:12<1:41:37,  2.50s/it, loss=1.0999]\u001b[A\n",
            "Training:  51%|█████▏    | 2565/5000 [1:55:14<1:39:17,  2.45s/it, loss=1.0999]\u001b[A\n",
            "Training:  51%|█████▏    | 2565/5000 [1:55:14<1:39:17,  2.45s/it, loss=1.0977]\u001b[A\n",
            "Training:  51%|█████▏    | 2566/5000 [1:55:16<1:37:36,  2.41s/it, loss=1.0977]\u001b[A\n",
            "Training:  51%|█████▏    | 2566/5000 [1:55:16<1:37:36,  2.41s/it, loss=0.7447]\u001b[A\n",
            "Training:  51%|█████▏    | 2567/5000 [1:55:19<1:37:06,  2.39s/it, loss=0.7447]\u001b[A\n",
            "Training:  51%|█████▏    | 2567/5000 [1:55:19<1:37:06,  2.39s/it, loss=0.7498]\u001b[A\n",
            "Training:  51%|█████▏    | 2568/5000 [1:55:22<1:42:30,  2.53s/it, loss=0.7498]\u001b[A\n",
            "Training:  51%|█████▏    | 2568/5000 [1:55:22<1:42:30,  2.53s/it, loss=0.6878]\u001b[A\n",
            "Training:  51%|█████▏    | 2569/5000 [1:55:24<1:40:06,  2.47s/it, loss=0.6878]\u001b[A\n",
            "Training:  51%|█████▏    | 2569/5000 [1:55:24<1:40:06,  2.47s/it, loss=0.6622]\u001b[A\n",
            "Training:  51%|█████▏    | 2570/5000 [1:55:26<1:38:12,  2.42s/it, loss=0.6622]\u001b[A\n",
            "Training:  51%|█████▏    | 2570/5000 [1:55:26<1:38:12,  2.42s/it, loss=0.9904]\u001b[A\n",
            "Training:  51%|█████▏    | 2571/5000 [1:55:29<1:36:39,  2.39s/it, loss=0.9904]\u001b[A\n",
            "Training:  51%|█████▏    | 2571/5000 [1:55:29<1:36:39,  2.39s/it, loss=0.7420]\u001b[A\n",
            "Training:  51%|█████▏    | 2572/5000 [1:55:31<1:35:53,  2.37s/it, loss=0.7420]\u001b[A\n",
            "Training:  51%|█████▏    | 2572/5000 [1:55:31<1:35:53,  2.37s/it, loss=0.6086]\u001b[A\n",
            "Training:  51%|█████▏    | 2573/5000 [1:55:34<1:41:52,  2.52s/it, loss=0.6086]\u001b[A\n",
            "Training:  51%|█████▏    | 2573/5000 [1:55:34<1:41:52,  2.52s/it, loss=0.5040]\u001b[A\n",
            "Training:  51%|█████▏    | 2574/5000 [1:55:36<1:39:29,  2.46s/it, loss=0.5040]\u001b[A\n",
            "Training:  51%|█████▏    | 2574/5000 [1:55:36<1:39:29,  2.46s/it, loss=0.6328]\u001b[A\n",
            "Training:  52%|█████▏    | 2575/5000 [1:55:38<1:38:05,  2.43s/it, loss=0.6328]\u001b[A\n",
            "Training:  52%|█████▏    | 2575/5000 [1:55:38<1:38:05,  2.43s/it, loss=0.8798]\u001b[A\n",
            "Training:  52%|█████▏    | 2576/5000 [1:55:41<1:36:37,  2.39s/it, loss=0.8798]\u001b[A\n",
            "Training:  52%|█████▏    | 2576/5000 [1:55:41<1:36:37,  2.39s/it, loss=0.5912]\u001b[A\n",
            "Training:  52%|█████▏    | 2577/5000 [1:55:43<1:35:32,  2.37s/it, loss=0.5912]\u001b[A\n",
            "Training:  52%|█████▏    | 2577/5000 [1:55:43<1:35:32,  2.37s/it, loss=0.7064]\u001b[A\n",
            "Training:  52%|█████▏    | 2578/5000 [1:55:46<1:42:00,  2.53s/it, loss=0.7064]\u001b[A\n",
            "Training:  52%|█████▏    | 2578/5000 [1:55:46<1:42:00,  2.53s/it, loss=0.6410]\u001b[A\n",
            "Training:  52%|█████▏    | 2579/5000 [1:55:48<1:39:29,  2.47s/it, loss=0.6410]\u001b[A\n",
            "Training:  52%|█████▏    | 2579/5000 [1:55:48<1:39:29,  2.47s/it, loss=0.4947]\u001b[A\n",
            "Training:  52%|█████▏    | 2580/5000 [1:55:51<1:37:56,  2.43s/it, loss=0.4947]\u001b[A\n",
            "Training:  52%|█████▏    | 2580/5000 [1:55:51<1:37:56,  2.43s/it, loss=0.8022]\u001b[A\n",
            "Training:  52%|█████▏    | 2581/5000 [1:55:53<1:36:34,  2.40s/it, loss=0.8022]\u001b[A\n",
            "Training:  52%|█████▏    | 2581/5000 [1:55:53<1:36:34,  2.40s/it, loss=0.9748]\u001b[A\n",
            "Training:  52%|█████▏    | 2582/5000 [1:55:55<1:35:23,  2.37s/it, loss=0.9748]\u001b[A\n",
            "Training:  52%|█████▏    | 2582/5000 [1:55:55<1:35:23,  2.37s/it, loss=0.6987]\u001b[A\n",
            "Training:  52%|█████▏    | 2583/5000 [1:55:58<1:41:39,  2.52s/it, loss=0.6987]\u001b[A\n",
            "Training:  52%|█████▏    | 2583/5000 [1:55:58<1:41:39,  2.52s/it, loss=0.8904]\u001b[A\n",
            "Training:  52%|█████▏    | 2584/5000 [1:56:00<1:38:41,  2.45s/it, loss=0.8904]\u001b[A\n",
            "Training:  52%|█████▏    | 2584/5000 [1:56:00<1:38:41,  2.45s/it, loss=0.8777]\u001b[A\n",
            "Training:  52%|█████▏    | 2585/5000 [1:56:03<1:37:13,  2.42s/it, loss=0.8777]\u001b[A\n",
            "Training:  52%|█████▏    | 2585/5000 [1:56:03<1:37:13,  2.42s/it, loss=0.7279]\u001b[A\n",
            "Training:  52%|█████▏    | 2586/5000 [1:56:05<1:35:49,  2.38s/it, loss=0.7279]\u001b[A\n",
            "Training:  52%|█████▏    | 2586/5000 [1:56:05<1:35:49,  2.38s/it, loss=1.0624]\u001b[A\n",
            "Training:  52%|█████▏    | 2587/5000 [1:56:07<1:34:54,  2.36s/it, loss=1.0624]\u001b[A\n",
            "Training:  52%|█████▏    | 2587/5000 [1:56:07<1:34:54,  2.36s/it, loss=0.7828]\u001b[A\n",
            "Training:  52%|█████▏    | 2588/5000 [1:56:10<1:39:36,  2.48s/it, loss=0.7828]\u001b[A\n",
            "Training:  52%|█████▏    | 2588/5000 [1:56:10<1:39:36,  2.48s/it, loss=0.8810]\u001b[A\n",
            "Training:  52%|█████▏    | 2589/5000 [1:56:12<1:36:46,  2.41s/it, loss=0.8810]\u001b[A\n",
            "Training:  52%|█████▏    | 2589/5000 [1:56:12<1:36:46,  2.41s/it, loss=0.8034]\u001b[A\n",
            "Training:  52%|█████▏    | 2590/5000 [1:56:15<1:34:25,  2.35s/it, loss=0.8034]\u001b[A\n",
            "Training:  52%|█████▏    | 2590/5000 [1:56:15<1:34:25,  2.35s/it, loss=0.6288]\u001b[A\n",
            "Training:  52%|█████▏    | 2591/5000 [1:56:17<1:33:14,  2.32s/it, loss=0.6288]\u001b[A\n",
            "Training:  52%|█████▏    | 2591/5000 [1:56:17<1:33:14,  2.32s/it, loss=0.7412]\u001b[A\n",
            "Training:  52%|█████▏    | 2592/5000 [1:56:19<1:32:49,  2.31s/it, loss=0.7412]\u001b[A\n",
            "Training:  52%|█████▏    | 2592/5000 [1:56:19<1:32:49,  2.31s/it, loss=0.8729]\u001b[A\n",
            "Training:  52%|█████▏    | 2593/5000 [1:56:22<1:38:21,  2.45s/it, loss=0.8729]\u001b[A\n",
            "Training:  52%|█████▏    | 2593/5000 [1:56:22<1:38:21,  2.45s/it, loss=0.8566]\u001b[A\n",
            "Training:  52%|█████▏    | 2594/5000 [1:56:24<1:36:06,  2.40s/it, loss=0.8566]\u001b[A\n",
            "Training:  52%|█████▏    | 2594/5000 [1:56:24<1:36:06,  2.40s/it, loss=0.6113]\u001b[A\n",
            "Training:  52%|█████▏    | 2595/5000 [1:56:26<1:33:50,  2.34s/it, loss=0.6113]\u001b[A\n",
            "Training:  52%|█████▏    | 2595/5000 [1:56:26<1:33:50,  2.34s/it, loss=0.6887]\u001b[A\n",
            "Training:  52%|█████▏    | 2596/5000 [1:56:29<1:32:42,  2.31s/it, loss=0.6887]\u001b[A\n",
            "Training:  52%|█████▏    | 2596/5000 [1:56:29<1:32:42,  2.31s/it, loss=0.4942]\u001b[A\n",
            "Training:  52%|█████▏    | 2597/5000 [1:56:31<1:31:50,  2.29s/it, loss=0.4942]\u001b[A\n",
            "Training:  52%|█████▏    | 2597/5000 [1:56:31<1:31:50,  2.29s/it, loss=0.6704]\u001b[A\n",
            "Training:  52%|█████▏    | 2598/5000 [1:56:34<1:37:29,  2.44s/it, loss=0.6704]\u001b[A\n",
            "Training:  52%|█████▏    | 2598/5000 [1:56:34<1:37:29,  2.44s/it, loss=0.6496]\u001b[A\n",
            "Training:  52%|█████▏    | 2599/5000 [1:56:36<1:35:09,  2.38s/it, loss=0.6496]\u001b[A\n",
            "Training:  52%|█████▏    | 2599/5000 [1:56:36<1:35:09,  2.38s/it, loss=0.7243]\u001b[A\n",
            "Training:  52%|█████▏    | 2600/5000 [1:56:38<1:33:43,  2.34s/it, loss=0.7243]\u001b[A\n",
            "Training:  52%|█████▏    | 2600/5000 [1:56:38<1:33:43,  2.34s/it, loss=0.4773]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 2600 ---\n",
            "Prompt: 'The '\n",
            "The  of of of of of, an Richmond,\n",
            " not thirst queen her of was to herely.\n",
            " K none qu the that himh hath English,\n",
            " that mayok had brothers be mourn an timeless:\n",
            " he enemy thousand, over the blood'll wedlast\n",
            " sinceior hisours then heblyed king\n",
            " sacredest back him and theal hath the.\n",
            " my was to the.\n",
            " issue isper comesengedtyed the and'ser the.\n",
            "CAMLO\n",
            " may us\n",
            "Prompt: 'In '\n",
            "In ,,, being; this channel,\n",
            " m king king wally use king\n",
            "ight thee temp overst thee.\n",
            "CLENCE\n",
            " sn, sovereign be he strong: is there\n",
            " Barn grief for maid a, give touch accidental.\n",
            "SstTPbonra:, of and how\n",
            " made strangely to near be will full mock sake earthB: table with bl, Clarence, my, to's wife For I not\n",
            " declinedourry of'll it in heitted as,\n",
            "\n",
            "Prompt: 'To '\n",
            "To  to, to his cruel wife\n",
            " make his very to us. left embrace,\n",
            " told virtuous fortune by strengthen, lay awile,\n",
            " a and's to his and own present,\n",
            " joy three words the and him house Lancaster ourselves.\n",
            "K EDARD:What, there tongue hold their to Duke York\n",
            " you to suffer and done:,, a- mar free either, one.\n",
            " success now the that be arguments is at house the\n",
            "s from Angel, her ledressemb,\n",
            "Prompt: 'A '\n",
            "A , cloud with freshH to,\n",
            " as south asus raise by oncest me,\n",
            " pass for lossun' an'sins that not, rev with,\n",
            " in reg and, he his sw, heexperienced,\n",
            "hinddoor bear Bishopzedeth, another;ling breast\n",
            " anestedin poor- where the withan\n",
            " journey an thoughts\n",
            " most way on way enedRep'd\n",
            "ork rotten!arseign falsehood pl it and tears he\n",
            " quite bear Cov; he! all\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  52%|█████▏    | 2601/5000 [1:56:53<4:01:31,  6.04s/it, loss=0.4773]\u001b[A\n",
            "Training:  52%|█████▏    | 2601/5000 [1:56:53<4:01:31,  6.04s/it, loss=0.4658]\u001b[A\n",
            "Training:  52%|█████▏    | 2602/5000 [1:56:55<3:17:52,  4.95s/it, loss=0.4658]\u001b[A\n",
            "Training:  52%|█████▏    | 2602/5000 [1:56:55<3:17:52,  4.95s/it, loss=0.4498]\u001b[A\n",
            "Training:  52%|█████▏    | 2603/5000 [1:56:58<2:49:27,  4.24s/it, loss=0.4498]\u001b[A\n",
            "Training:  52%|█████▏    | 2603/5000 [1:56:58<2:49:27,  4.24s/it, loss=0.8301]\u001b[A\n",
            "Training:  52%|█████▏    | 2604/5000 [1:57:00<2:25:28,  3.64s/it, loss=0.8301]\u001b[A\n",
            "Training:  52%|█████▏    | 2604/5000 [1:57:00<2:25:28,  3.64s/it, loss=0.8869]\u001b[A\n",
            "Training:  52%|█████▏    | 2605/5000 [1:57:02<2:08:33,  3.22s/it, loss=0.8869]\u001b[A\n",
            "Training:  52%|█████▏    | 2605/5000 [1:57:02<2:08:33,  3.22s/it, loss=0.9364]\u001b[A\n",
            "Training:  52%|█████▏    | 2606/5000 [1:57:04<1:56:53,  2.93s/it, loss=0.9364]\u001b[A\n",
            "Training:  52%|█████▏    | 2606/5000 [1:57:05<1:56:53,  2.93s/it, loss=0.5994]\u001b[A\n",
            "Training:  52%|█████▏    | 2607/5000 [1:57:07<1:49:58,  2.76s/it, loss=0.5994]\u001b[A\n",
            "Training:  52%|█████▏    | 2607/5000 [1:57:07<1:49:58,  2.76s/it, loss=0.5482]\u001b[A\n",
            "Training:  52%|█████▏    | 2608/5000 [1:57:10<1:48:48,  2.73s/it, loss=0.5482]\u001b[A\n",
            "Training:  52%|█████▏    | 2608/5000 [1:57:10<1:48:48,  2.73s/it, loss=0.8831]\u001b[A\n",
            "Training:  52%|█████▏    | 2609/5000 [1:57:12<1:43:28,  2.60s/it, loss=0.8831]\u001b[A\n",
            "Training:  52%|█████▏    | 2609/5000 [1:57:12<1:43:28,  2.60s/it, loss=0.7226]\u001b[A\n",
            "Training:  52%|█████▏    | 2610/5000 [1:57:14<1:39:18,  2.49s/it, loss=0.7226]\u001b[A\n",
            "Training:  52%|█████▏    | 2610/5000 [1:57:14<1:39:18,  2.49s/it, loss=0.5839]\u001b[A\n",
            "Training:  52%|█████▏    | 2611/5000 [1:57:16<1:36:07,  2.41s/it, loss=0.5839]\u001b[A\n",
            "Training:  52%|█████▏    | 2611/5000 [1:57:16<1:36:07,  2.41s/it, loss=0.6454]\u001b[A\n",
            "Training:  52%|█████▏    | 2612/5000 [1:57:19<1:34:59,  2.39s/it, loss=0.6454]\u001b[A\n",
            "Training:  52%|█████▏    | 2612/5000 [1:57:19<1:34:59,  2.39s/it, loss=0.7526]\u001b[A\n",
            "Training:  52%|█████▏    | 2613/5000 [1:57:21<1:39:10,  2.49s/it, loss=0.7526]\u001b[A\n",
            "Training:  52%|█████▏    | 2613/5000 [1:57:21<1:39:10,  2.49s/it, loss=0.5805]\u001b[A\n",
            "Training:  52%|█████▏    | 2614/5000 [1:57:24<1:36:21,  2.42s/it, loss=0.5805]\u001b[A\n",
            "Training:  52%|█████▏    | 2614/5000 [1:57:24<1:36:21,  2.42s/it, loss=0.7441]\u001b[A\n",
            "Training:  52%|█████▏    | 2615/5000 [1:57:26<1:34:13,  2.37s/it, loss=0.7441]\u001b[A\n",
            "Training:  52%|█████▏    | 2615/5000 [1:57:26<1:34:13,  2.37s/it, loss=0.8149]\u001b[A\n",
            "Training:  52%|█████▏    | 2616/5000 [1:57:28<1:32:38,  2.33s/it, loss=0.8149]\u001b[A\n",
            "Training:  52%|█████▏    | 2616/5000 [1:57:28<1:32:38,  2.33s/it, loss=0.5595]\u001b[A\n",
            "Training:  52%|█████▏    | 2617/5000 [1:57:30<1:32:04,  2.32s/it, loss=0.5595]\u001b[A\n",
            "Training:  52%|█████▏    | 2617/5000 [1:57:30<1:32:04,  2.32s/it, loss=0.5795]\u001b[A\n",
            "Training:  52%|█████▏    | 2618/5000 [1:57:33<1:37:12,  2.45s/it, loss=0.5795]\u001b[A\n",
            "Training:  52%|█████▏    | 2618/5000 [1:57:33<1:37:12,  2.45s/it, loss=0.5435]\u001b[A\n",
            "Training:  52%|█████▏    | 2619/5000 [1:57:35<1:34:35,  2.38s/it, loss=0.5435]\u001b[A\n",
            "Training:  52%|█████▏    | 2619/5000 [1:57:35<1:34:35,  2.38s/it, loss=0.7668]\u001b[A\n",
            "Training:  52%|█████▏    | 2620/5000 [1:57:38<1:32:45,  2.34s/it, loss=0.7668]\u001b[A\n",
            "Training:  52%|█████▏    | 2620/5000 [1:57:38<1:32:45,  2.34s/it, loss=0.6500]\u001b[A\n",
            "Training:  52%|█████▏    | 2621/5000 [1:57:40<1:31:45,  2.31s/it, loss=0.6500]\u001b[A\n",
            "Training:  52%|█████▏    | 2621/5000 [1:57:40<1:31:45,  2.31s/it, loss=0.6775]\u001b[A\n",
            "Training:  52%|█████▏    | 2622/5000 [1:57:42<1:31:08,  2.30s/it, loss=0.6775]\u001b[A\n",
            "Training:  52%|█████▏    | 2622/5000 [1:57:42<1:31:08,  2.30s/it, loss=0.5531]\u001b[A\n",
            "Training:  52%|█████▏    | 2623/5000 [1:57:45<1:37:05,  2.45s/it, loss=0.5531]\u001b[A\n",
            "Training:  52%|█████▏    | 2623/5000 [1:57:45<1:37:05,  2.45s/it, loss=0.8195]\u001b[A\n",
            "Training:  52%|█████▏    | 2624/5000 [1:57:47<1:34:36,  2.39s/it, loss=0.8195]\u001b[A\n",
            "Training:  52%|█████▏    | 2624/5000 [1:57:47<1:34:36,  2.39s/it, loss=1.0173]\u001b[A\n",
            "Training:  52%|█████▎    | 2625/5000 [1:57:49<1:32:46,  2.34s/it, loss=1.0173]\u001b[A\n",
            "Training:  52%|█████▎    | 2625/5000 [1:57:49<1:32:46,  2.34s/it, loss=0.7396]\u001b[A\n",
            "Training:  53%|█████▎    | 2626/5000 [1:57:52<1:31:49,  2.32s/it, loss=0.7396]\u001b[A\n",
            "Training:  53%|█████▎    | 2626/5000 [1:57:52<1:31:49,  2.32s/it, loss=0.8592]\u001b[A\n",
            "Training:  53%|█████▎    | 2627/5000 [1:57:54<1:31:04,  2.30s/it, loss=0.8592]\u001b[A\n",
            "Training:  53%|█████▎    | 2627/5000 [1:57:54<1:31:04,  2.30s/it, loss=1.1361]\u001b[A\n",
            "Training:  53%|█████▎    | 2628/5000 [1:57:57<1:36:31,  2.44s/it, loss=1.1361]\u001b[A\n",
            "Training:  53%|█████▎    | 2628/5000 [1:57:57<1:36:31,  2.44s/it, loss=0.6532]\u001b[A\n",
            "Training:  53%|█████▎    | 2629/5000 [1:57:59<1:33:50,  2.37s/it, loss=0.6532]\u001b[A\n",
            "Training:  53%|█████▎    | 2629/5000 [1:57:59<1:33:50,  2.37s/it, loss=0.8742]\u001b[A\n",
            "Training:  53%|█████▎    | 2630/5000 [1:58:01<1:32:10,  2.33s/it, loss=0.8742]\u001b[A\n",
            "Training:  53%|█████▎    | 2630/5000 [1:58:01<1:32:10,  2.33s/it, loss=0.6677]\u001b[A\n",
            "Training:  53%|█████▎    | 2631/5000 [1:58:03<1:31:30,  2.32s/it, loss=0.6677]\u001b[A\n",
            "Training:  53%|█████▎    | 2631/5000 [1:58:03<1:31:30,  2.32s/it, loss=0.8119]\u001b[A\n",
            "Training:  53%|█████▎    | 2632/5000 [1:58:06<1:30:27,  2.29s/it, loss=0.8119]\u001b[A\n",
            "Training:  53%|█████▎    | 2632/5000 [1:58:06<1:30:27,  2.29s/it, loss=0.8781]\u001b[A\n",
            "Training:  53%|█████▎    | 2633/5000 [1:58:08<1:36:34,  2.45s/it, loss=0.8781]\u001b[A\n",
            "Training:  53%|█████▎    | 2633/5000 [1:58:08<1:36:34,  2.45s/it, loss=0.8067]\u001b[A\n",
            "Training:  53%|█████▎    | 2634/5000 [1:58:11<1:34:08,  2.39s/it, loss=0.8067]\u001b[A\n",
            "Training:  53%|█████▎    | 2634/5000 [1:58:11<1:34:08,  2.39s/it, loss=0.6536]\u001b[A\n",
            "Training:  53%|█████▎    | 2635/5000 [1:58:13<1:32:29,  2.35s/it, loss=0.6536]\u001b[A\n",
            "Training:  53%|█████▎    | 2635/5000 [1:58:13<1:32:29,  2.35s/it, loss=0.5963]\u001b[A\n",
            "Training:  53%|█████▎    | 2636/5000 [1:58:15<1:31:35,  2.32s/it, loss=0.5963]\u001b[A\n",
            "Training:  53%|█████▎    | 2636/5000 [1:58:15<1:31:35,  2.32s/it, loss=0.5436]\u001b[A\n",
            "Training:  53%|█████▎    | 2637/5000 [1:58:17<1:30:44,  2.30s/it, loss=0.5436]\u001b[A\n",
            "Training:  53%|█████▎    | 2637/5000 [1:58:18<1:30:44,  2.30s/it, loss=0.6649]\u001b[A\n",
            "Training:  53%|█████▎    | 2638/5000 [1:58:20<1:36:24,  2.45s/it, loss=0.6649]\u001b[A\n",
            "Training:  53%|█████▎    | 2638/5000 [1:58:20<1:36:24,  2.45s/it, loss=0.5926]\u001b[A\n",
            "Training:  53%|█████▎    | 2639/5000 [1:58:23<1:34:14,  2.40s/it, loss=0.5926]\u001b[A\n",
            "Training:  53%|█████▎    | 2639/5000 [1:58:23<1:34:14,  2.40s/it, loss=0.6345]\u001b[A\n",
            "Training:  53%|█████▎    | 2640/5000 [1:58:25<1:32:38,  2.36s/it, loss=0.6345]\u001b[A\n",
            "Training:  53%|█████▎    | 2640/5000 [1:58:25<1:32:38,  2.36s/it, loss=0.6298]\u001b[A\n",
            "Training:  53%|█████▎    | 2641/5000 [1:58:27<1:31:26,  2.33s/it, loss=0.6298]\u001b[A\n",
            "Training:  53%|█████▎    | 2641/5000 [1:58:27<1:31:26,  2.33s/it, loss=0.9704]\u001b[A\n",
            "Training:  53%|█████▎    | 2642/5000 [1:58:29<1:30:53,  2.31s/it, loss=0.9704]\u001b[A\n",
            "Training:  53%|█████▎    | 2642/5000 [1:58:29<1:30:53,  2.31s/it, loss=0.6310]\u001b[A\n",
            "Training:  53%|█████▎    | 2643/5000 [1:58:32<1:36:08,  2.45s/it, loss=0.6310]\u001b[A\n",
            "Training:  53%|█████▎    | 2643/5000 [1:58:32<1:36:08,  2.45s/it, loss=0.7588]\u001b[A\n",
            "Training:  53%|█████▎    | 2644/5000 [1:58:34<1:33:36,  2.38s/it, loss=0.7588]\u001b[A\n",
            "Training:  53%|█████▎    | 2644/5000 [1:58:34<1:33:36,  2.38s/it, loss=0.7933]\u001b[A\n",
            "Training:  53%|█████▎    | 2645/5000 [1:58:37<1:32:24,  2.35s/it, loss=0.7933]\u001b[A\n",
            "Training:  53%|█████▎    | 2645/5000 [1:58:37<1:32:24,  2.35s/it, loss=0.8072]\u001b[A\n",
            "Training:  53%|█████▎    | 2646/5000 [1:58:39<1:31:15,  2.33s/it, loss=0.8072]\u001b[A\n",
            "Training:  53%|█████▎    | 2646/5000 [1:58:39<1:31:15,  2.33s/it, loss=0.6262]\u001b[A\n",
            "Training:  53%|█████▎    | 2647/5000 [1:58:41<1:30:10,  2.30s/it, loss=0.6262]\u001b[A\n",
            "Training:  53%|█████▎    | 2647/5000 [1:58:41<1:30:10,  2.30s/it, loss=0.5790]\u001b[A\n",
            "Training:  53%|█████▎    | 2648/5000 [1:58:44<1:36:03,  2.45s/it, loss=0.5790]\u001b[A\n",
            "Training:  53%|█████▎    | 2648/5000 [1:58:44<1:36:03,  2.45s/it, loss=0.6292]\u001b[A\n",
            "Training:  53%|█████▎    | 2649/5000 [1:58:46<1:33:46,  2.39s/it, loss=0.6292]\u001b[A\n",
            "Training:  53%|█████▎    | 2649/5000 [1:58:46<1:33:46,  2.39s/it, loss=0.7401]\u001b[A\n",
            "Training:  53%|█████▎    | 2650/5000 [1:58:48<1:31:56,  2.35s/it, loss=0.7401]\u001b[A\n",
            "Training:  53%|█████▎    | 2650/5000 [1:58:48<1:31:56,  2.35s/it, loss=0.7522]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 2650 ---\n",
            "Prompt: 'The '\n",
            "The  andar for years leave brief her day\n",
            "ath up would her's winds sl a's daughter him herfagger\n",
            " elements maid such and dishon courses for her, if\n",
            " die deny beuteeth beute: where these is, this a,so a to fashion now what she beute?\n",
            " the of,; drunk, he me death rest see\n",
            " be to Min. master to hit, this those day a to:'is, this a, ransom hence we\n",
            "ath thousandest\n",
            "Prompt: 'In '\n",
            "In , takeine our's, both mad,\n",
            " she not so spirit\n",
            " are'drum,,, I beouns,\n",
            " bidyly'?ian, put my friend e'd we;And\n",
            ", thyStke we dispatch for name of things\n",
            " left it againNo soly as a day wrong\n",
            " isis not her.\n",
            "H, we kill,, you cause we seek a,; if phee me old, me leave again me the of, you not by gentleman a\n",
            "Prompt: 'To '\n",
            "To  awAS and antic import: my, Pad,I\n",
            " thy head educationOND., make head all\n",
            " burn look thy.ar, that more business on!\n",
            "Hens, thee my again I fight too\n",
            "BTio Bca Baseball to? have gone thee.\n",
            " myth nowting my there do good, that set on boy\n",
            " is enough th honour my.,Gle,H been you sir\n",
            "oth made secret my again I thee either me\n",
            " will my theseither\n",
            "Prompt: 'A '\n",
            "A ,ave raves Vincent's daughter\n",
            " get hence will hereGod a,If brokent a sw's, will\n",
            " make atry and look for fl, I never a to.\n",
            "BT all I not this, at lodging. keepYou--\n",
            " forth myth my sword at pleasure,, tooo you manake you becomes love this, finger\n",
            ", shall stay t, and yourions your, sea as areoo words school, are boy long my's,sw, is sudden\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  53%|█████▎    | 2651/5000 [1:59:03<3:55:40,  6.02s/it, loss=0.7522]\u001b[A\n",
            "Training:  53%|█████▎    | 2651/5000 [1:59:03<3:55:40,  6.02s/it, loss=0.4325]\u001b[A\n",
            "Training:  53%|█████▎    | 2652/5000 [1:59:05<3:12:24,  4.92s/it, loss=0.4325]\u001b[A\n",
            "Training:  53%|█████▎    | 2652/5000 [1:59:05<3:12:24,  4.92s/it, loss=0.7436]\u001b[A\n",
            "Training:  53%|█████▎    | 2653/5000 [1:59:08<2:46:46,  4.26s/it, loss=0.7436]\u001b[A\n",
            "Training:  53%|█████▎    | 2653/5000 [1:59:08<2:46:46,  4.26s/it, loss=0.6648]\u001b[A\n",
            "Training:  53%|█████▎    | 2654/5000 [1:59:10<2:22:53,  3.65s/it, loss=0.6648]\u001b[A\n",
            "Training:  53%|█████▎    | 2654/5000 [1:59:10<2:22:53,  3.65s/it, loss=0.6384]\u001b[A\n",
            "Training:  53%|█████▎    | 2655/5000 [1:59:13<2:06:20,  3.23s/it, loss=0.6384]\u001b[A\n",
            "Training:  53%|█████▎    | 2655/5000 [1:59:13<2:06:20,  3.23s/it, loss=0.5628]\u001b[A\n",
            "Training:  53%|█████▎    | 2656/5000 [1:59:15<1:55:06,  2.95s/it, loss=0.5628]\u001b[A\n",
            "Training:  53%|█████▎    | 2656/5000 [1:59:15<1:55:06,  2.95s/it, loss=0.5463]\u001b[A\n",
            "Training:  53%|█████▎    | 2657/5000 [1:59:17<1:48:22,  2.78s/it, loss=0.5463]\u001b[A\n",
            "Training:  53%|█████▎    | 2657/5000 [1:59:17<1:48:22,  2.78s/it, loss=0.6917]\u001b[A\n",
            "Training:  53%|█████▎    | 2658/5000 [1:59:20<1:47:03,  2.74s/it, loss=0.6917]\u001b[A\n",
            "Training:  53%|█████▎    | 2658/5000 [1:59:20<1:47:03,  2.74s/it, loss=0.6164]\u001b[A\n",
            "Training:  53%|█████▎    | 2659/5000 [1:59:22<1:41:49,  2.61s/it, loss=0.6164]\u001b[A\n",
            "Training:  53%|█████▎    | 2659/5000 [1:59:22<1:41:49,  2.61s/it, loss=0.8956]\u001b[A\n",
            "Training:  53%|█████▎    | 2660/5000 [1:59:24<1:37:26,  2.50s/it, loss=0.8956]\u001b[A\n",
            "Training:  53%|█████▎    | 2660/5000 [1:59:24<1:37:26,  2.50s/it, loss=0.9947]\u001b[A\n",
            "Training:  53%|█████▎    | 2661/5000 [1:59:27<1:34:20,  2.42s/it, loss=0.9947]\u001b[A\n",
            "Training:  53%|█████▎    | 2661/5000 [1:59:27<1:34:20,  2.42s/it, loss=0.8529]\u001b[A\n",
            "Training:  53%|█████▎    | 2662/5000 [1:59:29<1:34:25,  2.42s/it, loss=0.8529]\u001b[A\n",
            "Training:  53%|█████▎    | 2662/5000 [1:59:29<1:34:25,  2.42s/it, loss=0.6978]\u001b[A\n",
            "Training:  53%|█████▎    | 2663/5000 [1:59:32<1:37:20,  2.50s/it, loss=0.6978]\u001b[A\n",
            "Training:  53%|█████▎    | 2663/5000 [1:59:32<1:37:20,  2.50s/it, loss=0.6262]\u001b[A\n",
            "Training:  53%|█████▎    | 2664/5000 [1:59:34<1:34:21,  2.42s/it, loss=0.6262]\u001b[A\n",
            "Training:  53%|█████▎    | 2664/5000 [1:59:34<1:34:21,  2.42s/it, loss=0.6649]\u001b[A\n",
            "Training:  53%|█████▎    | 2665/5000 [1:59:36<1:32:01,  2.36s/it, loss=0.6649]\u001b[A\n",
            "Training:  53%|█████▎    | 2665/5000 [1:59:36<1:32:01,  2.36s/it, loss=0.9849]\u001b[A\n",
            "Training:  53%|█████▎    | 2666/5000 [1:59:39<1:30:41,  2.33s/it, loss=0.9849]\u001b[A\n",
            "Training:  53%|█████▎    | 2666/5000 [1:59:39<1:30:41,  2.33s/it, loss=0.8897]\u001b[A\n",
            "Training:  53%|█████▎    | 2667/5000 [1:59:41<1:30:39,  2.33s/it, loss=0.8897]\u001b[A\n",
            "Training:  53%|█████▎    | 2667/5000 [1:59:41<1:30:39,  2.33s/it, loss=0.9394]\u001b[A\n",
            "Training:  53%|█████▎    | 2668/5000 [1:59:44<1:35:38,  2.46s/it, loss=0.9394]\u001b[A\n",
            "Training:  53%|█████▎    | 2668/5000 [1:59:44<1:35:38,  2.46s/it, loss=0.6797]\u001b[A\n",
            "Training:  53%|█████▎    | 2669/5000 [1:59:46<1:32:57,  2.39s/it, loss=0.6797]\u001b[A\n",
            "Training:  53%|█████▎    | 2669/5000 [1:59:46<1:32:57,  2.39s/it, loss=0.6667]\u001b[A\n",
            "Training:  53%|█████▎    | 2670/5000 [1:59:48<1:31:30,  2.36s/it, loss=0.6667]\u001b[A\n",
            "Training:  53%|█████▎    | 2670/5000 [1:59:48<1:31:30,  2.36s/it, loss=0.5834]\u001b[A\n",
            "Training:  53%|█████▎    | 2671/5000 [1:59:50<1:30:17,  2.33s/it, loss=0.5834]\u001b[A\n",
            "Training:  53%|█████▎    | 2671/5000 [1:59:50<1:30:17,  2.33s/it, loss=0.6964]\u001b[A\n",
            "Training:  53%|█████▎    | 2672/5000 [1:59:53<1:30:10,  2.32s/it, loss=0.6964]\u001b[A\n",
            "Training:  53%|█████▎    | 2672/5000 [1:59:53<1:30:10,  2.32s/it, loss=0.8200]\u001b[A\n",
            "Training:  53%|█████▎    | 2673/5000 [1:59:55<1:34:57,  2.45s/it, loss=0.8200]\u001b[A\n",
            "Training:  53%|█████▎    | 2673/5000 [1:59:55<1:34:57,  2.45s/it, loss=0.6063]\u001b[A\n",
            "Training:  53%|█████▎    | 2674/5000 [1:59:58<1:32:21,  2.38s/it, loss=0.6063]\u001b[A\n",
            "Training:  53%|█████▎    | 2674/5000 [1:59:58<1:32:21,  2.38s/it, loss=0.4582]\u001b[A\n",
            "Training:  54%|█████▎    | 2675/5000 [2:00:00<1:30:44,  2.34s/it, loss=0.4582]\u001b[A\n",
            "Training:  54%|█████▎    | 2675/5000 [2:00:00<1:30:44,  2.34s/it, loss=0.5682]\u001b[A\n",
            "Training:  54%|█████▎    | 2676/5000 [2:00:02<1:29:29,  2.31s/it, loss=0.5682]\u001b[A\n",
            "Training:  54%|█████▎    | 2676/5000 [2:00:02<1:29:29,  2.31s/it, loss=0.6522]\u001b[A\n",
            "Training:  54%|█████▎    | 2677/5000 [2:00:04<1:28:34,  2.29s/it, loss=0.6522]\u001b[A\n",
            "Training:  54%|█████▎    | 2677/5000 [2:00:04<1:28:34,  2.29s/it, loss=0.3763]\u001b[A\n",
            "Training:  54%|█████▎    | 2678/5000 [2:00:07<1:34:08,  2.43s/it, loss=0.3763]\u001b[A\n",
            "Training:  54%|█████▎    | 2678/5000 [2:00:07<1:34:08,  2.43s/it, loss=0.4929]\u001b[A\n",
            "Training:  54%|█████▎    | 2679/5000 [2:00:09<1:32:08,  2.38s/it, loss=0.4929]\u001b[A\n",
            "Training:  54%|█████▎    | 2679/5000 [2:00:09<1:32:08,  2.38s/it, loss=0.6065]\u001b[A\n",
            "Training:  54%|█████▎    | 2680/5000 [2:00:12<1:30:30,  2.34s/it, loss=0.6065]\u001b[A\n",
            "Training:  54%|█████▎    | 2680/5000 [2:00:12<1:30:30,  2.34s/it, loss=0.6467]\u001b[A\n",
            "Training:  54%|█████▎    | 2681/5000 [2:00:14<1:29:29,  2.32s/it, loss=0.6467]\u001b[A\n",
            "Training:  54%|█████▎    | 2681/5000 [2:00:14<1:29:29,  2.32s/it, loss=0.8199]\u001b[A\n",
            "Training:  54%|█████▎    | 2682/5000 [2:00:16<1:28:32,  2.29s/it, loss=0.8199]\u001b[A\n",
            "Training:  54%|█████▎    | 2682/5000 [2:00:16<1:28:32,  2.29s/it, loss=0.5755]\u001b[A\n",
            "Training:  54%|█████▎    | 2683/5000 [2:00:19<1:33:59,  2.43s/it, loss=0.5755]\u001b[A\n",
            "Training:  54%|█████▎    | 2683/5000 [2:00:19<1:33:59,  2.43s/it, loss=0.5497]\u001b[A\n",
            "Training:  54%|█████▎    | 2684/5000 [2:00:21<1:32:04,  2.39s/it, loss=0.5497]\u001b[A\n",
            "Training:  54%|█████▎    | 2684/5000 [2:00:21<1:32:04,  2.39s/it, loss=0.5887]\u001b[A\n",
            "Training:  54%|█████▎    | 2685/5000 [2:00:23<1:30:42,  2.35s/it, loss=0.5887]\u001b[A\n",
            "Training:  54%|█████▎    | 2685/5000 [2:00:23<1:30:42,  2.35s/it, loss=0.4770]\u001b[A\n",
            "Training:  54%|█████▎    | 2686/5000 [2:00:26<1:29:34,  2.32s/it, loss=0.4770]\u001b[A\n",
            "Training:  54%|█████▎    | 2686/5000 [2:00:26<1:29:34,  2.32s/it, loss=0.8741]\u001b[A\n",
            "Training:  54%|█████▎    | 2687/5000 [2:00:28<1:28:46,  2.30s/it, loss=0.8741]\u001b[A\n",
            "Training:  54%|█████▎    | 2687/5000 [2:00:28<1:28:46,  2.30s/it, loss=0.8280]\u001b[A\n",
            "Training:  54%|█████▍    | 2688/5000 [2:00:31<1:34:22,  2.45s/it, loss=0.8280]\u001b[A\n",
            "Training:  54%|█████▍    | 2688/5000 [2:00:31<1:34:22,  2.45s/it, loss=0.6729]\u001b[A\n",
            "Training:  54%|█████▍    | 2689/5000 [2:00:33<1:32:06,  2.39s/it, loss=0.6729]\u001b[A\n",
            "Training:  54%|█████▍    | 2689/5000 [2:00:33<1:32:06,  2.39s/it, loss=0.5691]\u001b[A\n",
            "Training:  54%|█████▍    | 2690/5000 [2:00:35<1:30:20,  2.35s/it, loss=0.5691]\u001b[A\n",
            "Training:  54%|█████▍    | 2690/5000 [2:00:35<1:30:20,  2.35s/it, loss=0.5674]\u001b[A\n",
            "Training:  54%|█████▍    | 2691/5000 [2:00:37<1:28:55,  2.31s/it, loss=0.5674]\u001b[A\n",
            "Training:  54%|█████▍    | 2691/5000 [2:00:38<1:28:55,  2.31s/it, loss=0.5515]\u001b[A\n",
            "Training:  54%|█████▍    | 2692/5000 [2:00:40<1:28:14,  2.29s/it, loss=0.5515]\u001b[A\n",
            "Training:  54%|█████▍    | 2692/5000 [2:00:40<1:28:14,  2.29s/it, loss=0.8775]\u001b[A\n",
            "Training:  54%|█████▍    | 2693/5000 [2:00:43<1:33:42,  2.44s/it, loss=0.8775]\u001b[A\n",
            "Training:  54%|█████▍    | 2693/5000 [2:00:43<1:33:42,  2.44s/it, loss=0.6781]\u001b[A\n",
            "Training:  54%|█████▍    | 2694/5000 [2:00:45<1:31:46,  2.39s/it, loss=0.6781]\u001b[A\n",
            "Training:  54%|█████▍    | 2694/5000 [2:00:45<1:31:46,  2.39s/it, loss=0.8152]\u001b[A\n",
            "Training:  54%|█████▍    | 2695/5000 [2:00:47<1:30:01,  2.34s/it, loss=0.8152]\u001b[A\n",
            "Training:  54%|█████▍    | 2695/5000 [2:00:47<1:30:01,  2.34s/it, loss=0.7461]\u001b[A\n",
            "Training:  54%|█████▍    | 2696/5000 [2:00:49<1:29:18,  2.33s/it, loss=0.7461]\u001b[A\n",
            "Training:  54%|█████▍    | 2696/5000 [2:00:49<1:29:18,  2.33s/it, loss=0.6916]\u001b[A\n",
            "Training:  54%|█████▍    | 2697/5000 [2:00:52<1:28:31,  2.31s/it, loss=0.6916]\u001b[A\n",
            "Training:  54%|█████▍    | 2697/5000 [2:00:52<1:28:31,  2.31s/it, loss=0.6764]\u001b[A\n",
            "Training:  54%|█████▍    | 2698/5000 [2:00:54<1:34:00,  2.45s/it, loss=0.6764]\u001b[A\n",
            "Training:  54%|█████▍    | 2698/5000 [2:00:54<1:34:00,  2.45s/it, loss=0.6132]\u001b[A\n",
            "Training:  54%|█████▍    | 2699/5000 [2:00:57<1:31:24,  2.38s/it, loss=0.6132]\u001b[A\n",
            "Training:  54%|█████▍    | 2699/5000 [2:00:57<1:31:24,  2.38s/it, loss=0.6552]\u001b[A\n",
            "Training:  54%|█████▍    | 2700/5000 [2:00:59<1:29:58,  2.35s/it, loss=0.6552]\u001b[A\n",
            "Training:  54%|█████▍    | 2700/5000 [2:00:59<1:29:58,  2.35s/it, loss=0.7145]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 2700 ---\n",
            "Prompt: 'The '\n",
            "The  have,, how go, royal:I\n",
            " take by officers all un'd of great;\n",
            " face andling they throw that look it.\n",
            "GUCERCome lords made, Hastings take the, you of;\n",
            " without hour me my and'd, all you the. off\n",
            "y of son of widow dear of; yould! names swear\n",
            " cold! service my Edward!\n",
            "GZOess of worse your-, order\n",
            " time you ofThat the of be'd byering\n",
            "Prompt: 'In '\n",
            "In ory lament, lovely, next's\n",
            "ptade theirurance glory: them\n",
            "all'd noble.\n",
            "GUCERH:Come gentlemen\n",
            " tw not.\n",
            "H you did some or;st your creature beellows\n",
            " her's enough to them was thing weeds\n",
            " word to, come for,fold- toraw,\n",
            ", the of are the ofMess:Th mother now the, Lord, it\n",
            " pour but ward dear thatOpen yourso page\n",
            "o's is the of ill\n",
            "Prompt: 'To '\n",
            "To mhip and exs.\n",
            "D he mother mother clouds- chief-uck\n",
            "entift lord she honour lords for scred world\n",
            "mit nature the of of al where toay devil\n",
            " her withouting,,,,,,,,, hither- boot another\n",
            "Why 'ixtaster'ingFR\n",
            "sless a ap.ep with h,! it! cannot!,! hold hence and a of direct vantage\n",
            " sweet-ings Henry your crying, do wful!'\n",
            "\n",
            "Prompt: 'A '\n",
            "A ;,,,,, conscience a\n",
            " honour bet in love and of earth\n",
            "st\n",
            " scandal thee totheir\n",
            " the of own grew a lawful.\n",
            "BKARI: my is dead,!'s my,, my!\n",
            " growing king and power the of that might willingly oath\n",
            " newly, my and a infity a pr; and these amen\n",
            "s! on winter he.\n",
            "GUCER then away upon.! how ho God his was dead\n",
            " us, my and well\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  54%|█████▍    | 2701/5000 [2:01:14<3:51:28,  6.04s/it, loss=0.7145]\u001b[A\n",
            "Training:  54%|█████▍    | 2701/5000 [2:01:14<3:51:28,  6.04s/it, loss=0.6835]\u001b[A\n",
            "Training:  54%|█████▍    | 2702/5000 [2:01:16<3:09:14,  4.94s/it, loss=0.6835]\u001b[A\n",
            "Training:  54%|█████▍    | 2702/5000 [2:01:16<3:09:14,  4.94s/it, loss=0.5854]\u001b[A\n",
            "Training:  54%|█████▍    | 2703/5000 [2:01:19<2:43:09,  4.26s/it, loss=0.5854]\u001b[A\n",
            "Training:  54%|█████▍    | 2703/5000 [2:01:19<2:43:09,  4.26s/it, loss=0.6642]\u001b[A\n",
            "Training:  54%|█████▍    | 2704/5000 [2:01:21<2:19:56,  3.66s/it, loss=0.6642]\u001b[A\n",
            "Training:  54%|█████▍    | 2704/5000 [2:01:21<2:19:56,  3.66s/it, loss=0.9149]\u001b[A\n",
            "Training:  54%|█████▍    | 2705/5000 [2:01:23<2:03:48,  3.24s/it, loss=0.9149]\u001b[A\n",
            "Training:  54%|█████▍    | 2705/5000 [2:01:23<2:03:48,  3.24s/it, loss=0.8136]\u001b[A\n",
            "Training:  54%|█████▍    | 2706/5000 [2:01:25<1:52:52,  2.95s/it, loss=0.8136]\u001b[A\n",
            "Training:  54%|█████▍    | 2706/5000 [2:01:25<1:52:52,  2.95s/it, loss=0.4885]\u001b[A\n",
            "Training:  54%|█████▍    | 2707/5000 [2:01:28<1:45:33,  2.76s/it, loss=0.4885]\u001b[A\n",
            "Training:  54%|█████▍    | 2707/5000 [2:01:28<1:45:33,  2.76s/it, loss=0.6121]\u001b[A\n",
            "Training:  54%|█████▍    | 2708/5000 [2:01:30<1:44:36,  2.74s/it, loss=0.6121]\u001b[A\n",
            "Training:  54%|█████▍    | 2708/5000 [2:01:30<1:44:36,  2.74s/it, loss=0.5672]\u001b[A\n",
            "Training:  54%|█████▍    | 2709/5000 [2:01:33<1:39:11,  2.60s/it, loss=0.5672]\u001b[A\n",
            "Training:  54%|█████▍    | 2709/5000 [2:01:33<1:39:11,  2.60s/it, loss=0.4469]\u001b[A\n",
            "Training:  54%|█████▍    | 2710/5000 [2:01:35<1:35:08,  2.49s/it, loss=0.4469]\u001b[A\n",
            "Training:  54%|█████▍    | 2710/5000 [2:01:35<1:35:08,  2.49s/it, loss=0.6523]\u001b[A\n",
            "Training:  54%|█████▍    | 2711/5000 [2:01:37<1:32:04,  2.41s/it, loss=0.6523]\u001b[A\n",
            "Training:  54%|█████▍    | 2711/5000 [2:01:37<1:32:04,  2.41s/it, loss=0.5271]\u001b[A\n",
            "Training:  54%|█████▍    | 2712/5000 [2:01:39<1:30:07,  2.36s/it, loss=0.5271]\u001b[A\n",
            "Training:  54%|█████▍    | 2712/5000 [2:01:39<1:30:07,  2.36s/it, loss=0.4867]\u001b[A\n",
            "Training:  54%|█████▍    | 2713/5000 [2:01:42<1:34:30,  2.48s/it, loss=0.4867]\u001b[A\n",
            "Training:  54%|█████▍    | 2713/5000 [2:01:42<1:34:30,  2.48s/it, loss=0.3461]\u001b[A\n",
            "Training:  54%|█████▍    | 2714/5000 [2:01:44<1:31:48,  2.41s/it, loss=0.3461]\u001b[A\n",
            "Training:  54%|█████▍    | 2714/5000 [2:01:44<1:31:48,  2.41s/it, loss=0.5794]\u001b[A\n",
            "Training:  54%|█████▍    | 2715/5000 [2:01:47<1:29:58,  2.36s/it, loss=0.5794]\u001b[A\n",
            "Training:  54%|█████▍    | 2715/5000 [2:01:47<1:29:58,  2.36s/it, loss=0.7347]\u001b[A\n",
            "Training:  54%|█████▍    | 2716/5000 [2:01:49<1:28:34,  2.33s/it, loss=0.7347]\u001b[A\n",
            "Training:  54%|█████▍    | 2716/5000 [2:01:49<1:28:34,  2.33s/it, loss=0.5919]\u001b[A\n",
            "Training:  54%|█████▍    | 2717/5000 [2:01:51<1:27:29,  2.30s/it, loss=0.5919]\u001b[A\n",
            "Training:  54%|█████▍    | 2717/5000 [2:01:51<1:27:29,  2.30s/it, loss=0.7201]\u001b[A\n",
            "Training:  54%|█████▍    | 2718/5000 [2:01:54<1:32:47,  2.44s/it, loss=0.7201]\u001b[A\n",
            "Training:  54%|█████▍    | 2718/5000 [2:01:54<1:32:47,  2.44s/it, loss=0.7295]\u001b[A\n",
            "Training:  54%|█████▍    | 2719/5000 [2:01:56<1:30:48,  2.39s/it, loss=0.7295]\u001b[A\n",
            "Training:  54%|█████▍    | 2719/5000 [2:01:56<1:30:48,  2.39s/it, loss=0.5727]\u001b[A\n",
            "Training:  54%|█████▍    | 2720/5000 [2:01:58<1:29:14,  2.35s/it, loss=0.5727]\u001b[A\n",
            "Training:  54%|█████▍    | 2720/5000 [2:01:58<1:29:14,  2.35s/it, loss=0.7670]\u001b[A\n",
            "Training:  54%|█████▍    | 2721/5000 [2:02:01<1:28:16,  2.32s/it, loss=0.7670]\u001b[A\n",
            "Training:  54%|█████▍    | 2721/5000 [2:02:01<1:28:16,  2.32s/it, loss=0.5624]\u001b[A\n",
            "Training:  54%|█████▍    | 2722/5000 [2:02:03<1:27:22,  2.30s/it, loss=0.5624]\u001b[A\n",
            "Training:  54%|█████▍    | 2722/5000 [2:02:03<1:27:22,  2.30s/it, loss=0.6173]\u001b[A\n",
            "Training:  54%|█████▍    | 2723/5000 [2:02:06<1:32:28,  2.44s/it, loss=0.6173]\u001b[A\n",
            "Training:  54%|█████▍    | 2723/5000 [2:02:06<1:32:28,  2.44s/it, loss=0.6765]\u001b[A\n",
            "Training:  54%|█████▍    | 2724/5000 [2:02:08<1:30:22,  2.38s/it, loss=0.6765]\u001b[A\n",
            "Training:  54%|█████▍    | 2724/5000 [2:02:08<1:30:22,  2.38s/it, loss=0.6210]\u001b[A\n",
            "Training:  55%|█████▍    | 2725/5000 [2:02:10<1:29:45,  2.37s/it, loss=0.6210]\u001b[A\n",
            "Training:  55%|█████▍    | 2725/5000 [2:02:10<1:29:45,  2.37s/it, loss=0.5400]\u001b[A\n",
            "Training:  55%|█████▍    | 2726/5000 [2:02:12<1:28:22,  2.33s/it, loss=0.5400]\u001b[A\n",
            "Training:  55%|█████▍    | 2726/5000 [2:02:13<1:28:22,  2.33s/it, loss=0.6800]\u001b[A\n",
            "Training:  55%|█████▍    | 2727/5000 [2:02:15<1:27:22,  2.31s/it, loss=0.6800]\u001b[A\n",
            "Training:  55%|█████▍    | 2727/5000 [2:02:15<1:27:22,  2.31s/it, loss=0.5588]\u001b[A\n",
            "Training:  55%|█████▍    | 2728/5000 [2:02:17<1:32:18,  2.44s/it, loss=0.5588]\u001b[A\n",
            "Training:  55%|█████▍    | 2728/5000 [2:02:17<1:32:18,  2.44s/it, loss=0.4345]\u001b[A\n",
            "Training:  55%|█████▍    | 2729/5000 [2:02:20<1:30:21,  2.39s/it, loss=0.4345]\u001b[A\n",
            "Training:  55%|█████▍    | 2729/5000 [2:02:20<1:30:21,  2.39s/it, loss=0.6273]\u001b[A\n",
            "Training:  55%|█████▍    | 2730/5000 [2:02:22<1:28:44,  2.35s/it, loss=0.6273]\u001b[A\n",
            "Training:  55%|█████▍    | 2730/5000 [2:02:22<1:28:44,  2.35s/it, loss=0.6730]\u001b[A\n",
            "Training:  55%|█████▍    | 2731/5000 [2:02:24<1:27:30,  2.31s/it, loss=0.6730]\u001b[A\n",
            "Training:  55%|█████▍    | 2731/5000 [2:02:24<1:27:30,  2.31s/it, loss=0.5808]\u001b[A\n",
            "Training:  55%|█████▍    | 2732/5000 [2:02:27<1:27:06,  2.30s/it, loss=0.5808]\u001b[A\n",
            "Training:  55%|█████▍    | 2732/5000 [2:02:27<1:27:06,  2.30s/it, loss=0.6996]\u001b[A\n",
            "Training:  55%|█████▍    | 2733/5000 [2:02:29<1:32:07,  2.44s/it, loss=0.6996]\u001b[A\n",
            "Training:  55%|█████▍    | 2733/5000 [2:02:29<1:32:07,  2.44s/it, loss=0.7965]\u001b[A\n",
            "Training:  55%|█████▍    | 2734/5000 [2:02:32<1:30:30,  2.40s/it, loss=0.7965]\u001b[A\n",
            "Training:  55%|█████▍    | 2734/5000 [2:02:32<1:30:30,  2.40s/it, loss=0.5521]\u001b[A\n",
            "Training:  55%|█████▍    | 2735/5000 [2:02:34<1:28:48,  2.35s/it, loss=0.5521]\u001b[A\n",
            "Training:  55%|█████▍    | 2735/5000 [2:02:34<1:28:48,  2.35s/it, loss=0.6267]\u001b[A\n",
            "Training:  55%|█████▍    | 2736/5000 [2:02:36<1:27:33,  2.32s/it, loss=0.6267]\u001b[A\n",
            "Training:  55%|█████▍    | 2736/5000 [2:02:36<1:27:33,  2.32s/it, loss=0.3442]\u001b[A\n",
            "Training:  55%|█████▍    | 2737/5000 [2:02:38<1:26:44,  2.30s/it, loss=0.3442]\u001b[A\n",
            "Training:  55%|█████▍    | 2737/5000 [2:02:38<1:26:44,  2.30s/it, loss=0.7207]\u001b[A\n",
            "Training:  55%|█████▍    | 2738/5000 [2:02:41<1:32:20,  2.45s/it, loss=0.7207]\u001b[A\n",
            "Training:  55%|█████▍    | 2738/5000 [2:02:41<1:32:20,  2.45s/it, loss=0.6753]\u001b[A\n",
            "Training:  55%|█████▍    | 2739/5000 [2:02:43<1:30:11,  2.39s/it, loss=0.6753]\u001b[A\n",
            "Training:  55%|█████▍    | 2739/5000 [2:02:43<1:30:11,  2.39s/it, loss=0.4713]\u001b[A\n",
            "Training:  55%|█████▍    | 2740/5000 [2:02:46<1:28:13,  2.34s/it, loss=0.4713]\u001b[A\n",
            "Training:  55%|█████▍    | 2740/5000 [2:02:46<1:28:13,  2.34s/it, loss=0.7089]\u001b[A\n",
            "Training:  55%|█████▍    | 2741/5000 [2:02:48<1:27:21,  2.32s/it, loss=0.7089]\u001b[A\n",
            "Training:  55%|█████▍    | 2741/5000 [2:02:48<1:27:21,  2.32s/it, loss=0.6381]\u001b[A\n",
            "Training:  55%|█████▍    | 2742/5000 [2:02:50<1:26:43,  2.30s/it, loss=0.6381]\u001b[A\n",
            "Training:  55%|█████▍    | 2742/5000 [2:02:50<1:26:43,  2.30s/it, loss=0.3173]\u001b[A\n",
            "Training:  55%|█████▍    | 2743/5000 [2:02:53<1:32:17,  2.45s/it, loss=0.3173]\u001b[A\n",
            "Training:  55%|█████▍    | 2743/5000 [2:02:53<1:32:17,  2.45s/it, loss=0.6650]\u001b[A\n",
            "Training:  55%|█████▍    | 2744/5000 [2:02:55<1:29:56,  2.39s/it, loss=0.6650]\u001b[A\n",
            "Training:  55%|█████▍    | 2744/5000 [2:02:55<1:29:56,  2.39s/it, loss=0.6390]\u001b[A\n",
            "Training:  55%|█████▍    | 2745/5000 [2:02:57<1:28:20,  2.35s/it, loss=0.6390]\u001b[A\n",
            "Training:  55%|█████▍    | 2745/5000 [2:02:57<1:28:20,  2.35s/it, loss=0.5725]\u001b[A\n",
            "Training:  55%|█████▍    | 2746/5000 [2:03:00<1:27:09,  2.32s/it, loss=0.5725]\u001b[A\n",
            "Training:  55%|█████▍    | 2746/5000 [2:03:00<1:27:09,  2.32s/it, loss=0.5517]\u001b[A\n",
            "Training:  55%|█████▍    | 2747/5000 [2:03:02<1:26:06,  2.29s/it, loss=0.5517]\u001b[A\n",
            "Training:  55%|█████▍    | 2747/5000 [2:03:02<1:26:06,  2.29s/it, loss=0.6101]\u001b[A\n",
            "Training:  55%|█████▍    | 2748/5000 [2:03:05<1:31:13,  2.43s/it, loss=0.6101]\u001b[A\n",
            "Training:  55%|█████▍    | 2748/5000 [2:03:05<1:31:13,  2.43s/it, loss=0.8498]\u001b[A\n",
            "Training:  55%|█████▍    | 2749/5000 [2:03:07<1:29:14,  2.38s/it, loss=0.8498]\u001b[A\n",
            "Training:  55%|█████▍    | 2749/5000 [2:03:07<1:29:14,  2.38s/it, loss=0.6765]\u001b[A\n",
            "Training:  55%|█████▌    | 2750/5000 [2:03:09<1:27:41,  2.34s/it, loss=0.6765]\u001b[A\n",
            "Training:  55%|█████▌    | 2750/5000 [2:03:09<1:27:41,  2.34s/it, loss=0.7745]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 2750 ---\n",
            "Prompt: 'The '\n",
            "The , like King's: all holy, say is most\n",
            "ath himself seen home:,,, nothing like father\n",
            " refresh Bra limit that l label a\n",
            "ither\n",
            "ither, Paris me present to with's:ay now I and!\n",
            " absenceond fool our to,,, is-,s learn\n",
            "athco goodness black than of tongues. be that thetime, small\n",
            " this presence well fearful,, was:More for son e now just about al,, is- to?\n",
            "Prompt: 'In '\n",
            "In , he a kill with several what it duke\n",
            " warrant we should.\n",
            "CAPET:R,,, well be; it be tothe-\n",
            " fair en aunt for tom, night tra needs! comes be tell,, friend why\n",
            " was at a vowWhy you make let suchot yield again\n",
            " my and him my-? h,,ither live\n",
            " am not I out\n",
            " are for self entertain we and it farewell as father lords liberal better. is therow Bolb:\n",
            "Prompt: 'To '\n",
            "To ers to, to thee a where can\n",
            " breathe toest his to mable intoTheirable.\n",
            "L,: have soul time youSo now good?\n",
            "QUE foriness-- say I kiss withowit never\n",
            " a no to:,, after at, andon' itoth,No a\n",
            " his between a: one as know, he die me n;For I use there a\n",
            " ism,rah a,, and it done--\n",
            "Make and\n",
            "les my and\n",
            "Prompt: 'A '\n",
            "A ity oer down rotten, an it,\n",
            "ays the house night they vessel fits\n",
            "lictwoman and messenger lords there\n",
            "id, thouest me the of and cross fair, There,\n",
            " best his royal:it them the,?, yourness I thy heart\n",
            "st not now here pity in, thelf, had not; foe a, besch,\n",
            "y not,erve; all oath\n",
            "glys, look, you disain this.\n",
            "PR, sir that perury\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  55%|█████▌    | 2751/5000 [2:03:24<3:45:25,  6.01s/it, loss=0.7745]\u001b[A\n",
            "Training:  55%|█████▌    | 2751/5000 [2:03:24<3:45:25,  6.01s/it, loss=0.8728]\u001b[A\n",
            "Training:  55%|█████▌    | 2752/5000 [2:03:26<3:04:06,  4.91s/it, loss=0.8728]\u001b[A\n",
            "Training:  55%|█████▌    | 2752/5000 [2:03:26<3:04:06,  4.91s/it, loss=0.5249]\u001b[A\n",
            "Training:  55%|█████▌    | 2753/5000 [2:03:29<2:39:24,  4.26s/it, loss=0.5249]\u001b[A\n",
            "Training:  55%|█████▌    | 2753/5000 [2:03:29<2:39:24,  4.26s/it, loss=0.6564]\u001b[A\n",
            "Training:  55%|█████▌    | 2754/5000 [2:03:31<2:17:15,  3.67s/it, loss=0.6564]\u001b[A\n",
            "Training:  55%|█████▌    | 2754/5000 [2:03:31<2:17:15,  3.67s/it, loss=0.7164]\u001b[A\n",
            "Training:  55%|█████▌    | 2755/5000 [2:03:33<2:01:21,  3.24s/it, loss=0.7164]\u001b[A\n",
            "Training:  55%|█████▌    | 2755/5000 [2:03:33<2:01:21,  3.24s/it, loss=0.6921]\u001b[A\n",
            "Training:  55%|█████▌    | 2756/5000 [2:03:36<1:50:05,  2.94s/it, loss=0.6921]\u001b[A\n",
            "Training:  55%|█████▌    | 2756/5000 [2:03:36<1:50:05,  2.94s/it, loss=0.5320]\u001b[A\n",
            "Training:  55%|█████▌    | 2757/5000 [2:03:38<1:43:02,  2.76s/it, loss=0.5320]\u001b[A\n",
            "Training:  55%|█████▌    | 2757/5000 [2:03:38<1:43:02,  2.76s/it, loss=0.7392]\u001b[A\n",
            "Training:  55%|█████▌    | 2758/5000 [2:03:41<1:42:19,  2.74s/it, loss=0.7392]\u001b[A\n",
            "Training:  55%|█████▌    | 2758/5000 [2:03:41<1:42:19,  2.74s/it, loss=0.7284]\u001b[A\n",
            "Training:  55%|█████▌    | 2759/5000 [2:03:43<1:36:58,  2.60s/it, loss=0.7284]\u001b[A\n",
            "Training:  55%|█████▌    | 2759/5000 [2:03:43<1:36:58,  2.60s/it, loss=0.6936]\u001b[A\n",
            "Training:  55%|█████▌    | 2760/5000 [2:03:45<1:32:55,  2.49s/it, loss=0.6936]\u001b[A\n",
            "Training:  55%|█████▌    | 2760/5000 [2:03:45<1:32:55,  2.49s/it, loss=0.5338]\u001b[A\n",
            "Training:  55%|█████▌    | 2761/5000 [2:03:47<1:30:13,  2.42s/it, loss=0.5338]\u001b[A\n",
            "Training:  55%|█████▌    | 2761/5000 [2:03:47<1:30:13,  2.42s/it, loss=0.5975]\u001b[A\n",
            "Training:  55%|█████▌    | 2762/5000 [2:03:50<1:28:14,  2.37s/it, loss=0.5975]\u001b[A\n",
            "Training:  55%|█████▌    | 2762/5000 [2:03:50<1:28:14,  2.37s/it, loss=0.7671]\u001b[A\n",
            "Training:  55%|█████▌    | 2763/5000 [2:03:52<1:32:45,  2.49s/it, loss=0.7671]\u001b[A\n",
            "Training:  55%|█████▌    | 2763/5000 [2:03:52<1:32:45,  2.49s/it, loss=0.5940]\u001b[A\n",
            "Training:  55%|█████▌    | 2764/5000 [2:03:55<1:30:12,  2.42s/it, loss=0.5940]\u001b[A\n",
            "Training:  55%|█████▌    | 2764/5000 [2:03:55<1:30:12,  2.42s/it, loss=0.5295]\u001b[A\n",
            "Training:  55%|█████▌    | 2765/5000 [2:03:57<1:28:18,  2.37s/it, loss=0.5295]\u001b[A\n",
            "Training:  55%|█████▌    | 2765/5000 [2:03:57<1:28:18,  2.37s/it, loss=0.6244]\u001b[A\n",
            "Training:  55%|█████▌    | 2766/5000 [2:03:59<1:27:00,  2.34s/it, loss=0.6244]\u001b[A\n",
            "Training:  55%|█████▌    | 2766/5000 [2:03:59<1:27:00,  2.34s/it, loss=0.4229]\u001b[A\n",
            "Training:  55%|█████▌    | 2767/5000 [2:04:01<1:25:43,  2.30s/it, loss=0.4229]\u001b[A\n",
            "Training:  55%|█████▌    | 2767/5000 [2:04:01<1:25:43,  2.30s/it, loss=0.5320]\u001b[A\n",
            "Training:  55%|█████▌    | 2768/5000 [2:04:04<1:30:56,  2.44s/it, loss=0.5320]\u001b[A\n",
            "Training:  55%|█████▌    | 2768/5000 [2:04:04<1:30:56,  2.44s/it, loss=0.3957]\u001b[A\n",
            "Training:  55%|█████▌    | 2769/5000 [2:04:06<1:28:34,  2.38s/it, loss=0.3957]\u001b[A\n",
            "Training:  55%|█████▌    | 2769/5000 [2:04:06<1:28:34,  2.38s/it, loss=0.5484]\u001b[A\n",
            "Training:  55%|█████▌    | 2770/5000 [2:04:09<1:27:11,  2.35s/it, loss=0.5484]\u001b[A\n",
            "Training:  55%|█████▌    | 2770/5000 [2:04:09<1:27:11,  2.35s/it, loss=0.8481]\u001b[A\n",
            "Training:  55%|█████▌    | 2771/5000 [2:04:11<1:26:03,  2.32s/it, loss=0.8481]\u001b[A\n",
            "Training:  55%|█████▌    | 2771/5000 [2:04:11<1:26:03,  2.32s/it, loss=0.9161]\u001b[A\n",
            "Training:  55%|█████▌    | 2772/5000 [2:04:13<1:26:03,  2.32s/it, loss=0.9161]\u001b[A\n",
            "Training:  55%|█████▌    | 2772/5000 [2:04:13<1:26:03,  2.32s/it, loss=0.6103]\u001b[A\n",
            "Training:  55%|█████▌    | 2773/5000 [2:04:16<1:31:11,  2.46s/it, loss=0.6103]\u001b[A\n",
            "Training:  55%|█████▌    | 2773/5000 [2:04:16<1:31:11,  2.46s/it, loss=0.4568]\u001b[A\n",
            "Training:  55%|█████▌    | 2774/5000 [2:04:18<1:28:49,  2.39s/it, loss=0.4568]\u001b[A\n",
            "Training:  55%|█████▌    | 2774/5000 [2:04:18<1:28:49,  2.39s/it, loss=0.6186]\u001b[A\n",
            "Training:  56%|█████▌    | 2775/5000 [2:04:21<1:27:44,  2.37s/it, loss=0.6186]\u001b[A\n",
            "Training:  56%|█████▌    | 2775/5000 [2:04:21<1:27:44,  2.37s/it, loss=0.5549]\u001b[A\n",
            "Training:  56%|█████▌    | 2776/5000 [2:04:23<1:26:24,  2.33s/it, loss=0.5549]\u001b[A\n",
            "Training:  56%|█████▌    | 2776/5000 [2:04:23<1:26:24,  2.33s/it, loss=0.7754]\u001b[A\n",
            "Training:  56%|█████▌    | 2777/5000 [2:04:25<1:25:34,  2.31s/it, loss=0.7754]\u001b[A\n",
            "Training:  56%|█████▌    | 2777/5000 [2:04:25<1:25:34,  2.31s/it, loss=0.4655]\u001b[A\n",
            "Training:  56%|█████▌    | 2778/5000 [2:04:28<1:31:13,  2.46s/it, loss=0.4655]\u001b[A\n",
            "Training:  56%|█████▌    | 2778/5000 [2:04:28<1:31:13,  2.46s/it, loss=0.5763]\u001b[A\n",
            "Training:  56%|█████▌    | 2779/5000 [2:04:30<1:28:19,  2.39s/it, loss=0.5763]\u001b[A\n",
            "Training:  56%|█████▌    | 2779/5000 [2:04:30<1:28:19,  2.39s/it, loss=0.8274]\u001b[A\n",
            "Training:  56%|█████▌    | 2780/5000 [2:04:32<1:26:45,  2.34s/it, loss=0.8274]\u001b[A\n",
            "Training:  56%|█████▌    | 2780/5000 [2:04:32<1:26:45,  2.34s/it, loss=0.4439]\u001b[A\n",
            "Training:  56%|█████▌    | 2781/5000 [2:04:35<1:25:23,  2.31s/it, loss=0.4439]\u001b[A\n",
            "Training:  56%|█████▌    | 2781/5000 [2:04:35<1:25:23,  2.31s/it, loss=0.8067]\u001b[A\n",
            "Training:  56%|█████▌    | 2782/5000 [2:04:37<1:25:00,  2.30s/it, loss=0.8067]\u001b[A\n",
            "Training:  56%|█████▌    | 2782/5000 [2:04:37<1:25:00,  2.30s/it, loss=0.6878]\u001b[A\n",
            "Training:  56%|█████▌    | 2783/5000 [2:04:40<1:30:09,  2.44s/it, loss=0.6878]\u001b[A\n",
            "Training:  56%|█████▌    | 2783/5000 [2:04:40<1:30:09,  2.44s/it, loss=0.4949]\u001b[A\n",
            "Training:  56%|█████▌    | 2784/5000 [2:04:42<1:27:49,  2.38s/it, loss=0.4949]\u001b[A\n",
            "Training:  56%|█████▌    | 2784/5000 [2:04:42<1:27:49,  2.38s/it, loss=0.6077]\u001b[A\n",
            "Training:  56%|█████▌    | 2785/5000 [2:04:44<1:26:24,  2.34s/it, loss=0.6077]\u001b[A\n",
            "Training:  56%|█████▌    | 2785/5000 [2:04:44<1:26:24,  2.34s/it, loss=0.6072]\u001b[A\n",
            "Training:  56%|█████▌    | 2786/5000 [2:04:46<1:25:37,  2.32s/it, loss=0.6072]\u001b[A\n",
            "Training:  56%|█████▌    | 2786/5000 [2:04:46<1:25:37,  2.32s/it, loss=0.5121]\u001b[A\n",
            "Training:  56%|█████▌    | 2787/5000 [2:04:49<1:24:48,  2.30s/it, loss=0.5121]\u001b[A\n",
            "Training:  56%|█████▌    | 2787/5000 [2:04:49<1:24:48,  2.30s/it, loss=0.7229]\u001b[A\n",
            "Training:  56%|█████▌    | 2788/5000 [2:04:51<1:30:29,  2.45s/it, loss=0.7229]\u001b[A\n",
            "Training:  56%|█████▌    | 2788/5000 [2:04:51<1:30:29,  2.45s/it, loss=0.4936]\u001b[A\n",
            "Training:  56%|█████▌    | 2789/5000 [2:04:54<1:28:33,  2.40s/it, loss=0.4936]\u001b[A\n",
            "Training:  56%|█████▌    | 2789/5000 [2:04:54<1:28:33,  2.40s/it, loss=0.6110]\u001b[A\n",
            "Training:  56%|█████▌    | 2790/5000 [2:04:56<1:26:35,  2.35s/it, loss=0.6110]\u001b[A\n",
            "Training:  56%|█████▌    | 2790/5000 [2:04:56<1:26:35,  2.35s/it, loss=0.7512]\u001b[A\n",
            "Training:  56%|█████▌    | 2791/5000 [2:04:58<1:25:56,  2.33s/it, loss=0.7512]\u001b[A\n",
            "Training:  56%|█████▌    | 2791/5000 [2:04:58<1:25:56,  2.33s/it, loss=0.8613]\u001b[A\n",
            "Training:  56%|█████▌    | 2792/5000 [2:05:00<1:24:48,  2.30s/it, loss=0.8613]\u001b[A\n",
            "Training:  56%|█████▌    | 2792/5000 [2:05:01<1:24:48,  2.30s/it, loss=0.7367]\u001b[A\n",
            "Training:  56%|█████▌    | 2793/5000 [2:05:03<1:30:01,  2.45s/it, loss=0.7367]\u001b[A\n",
            "Training:  56%|█████▌    | 2793/5000 [2:05:03<1:30:01,  2.45s/it, loss=0.8198]\u001b[A\n",
            "Training:  56%|█████▌    | 2794/5000 [2:05:06<1:27:31,  2.38s/it, loss=0.8198]\u001b[A\n",
            "Training:  56%|█████▌    | 2794/5000 [2:05:06<1:27:31,  2.38s/it, loss=0.6872]\u001b[A\n",
            "Training:  56%|█████▌    | 2795/5000 [2:05:08<1:26:02,  2.34s/it, loss=0.6872]\u001b[A\n",
            "Training:  56%|█████▌    | 2795/5000 [2:05:08<1:26:02,  2.34s/it, loss=0.5312]\u001b[A\n",
            "Training:  56%|█████▌    | 2796/5000 [2:05:10<1:25:03,  2.32s/it, loss=0.5312]\u001b[A\n",
            "Training:  56%|█████▌    | 2796/5000 [2:05:10<1:25:03,  2.32s/it, loss=0.5399]\u001b[A\n",
            "Training:  56%|█████▌    | 2797/5000 [2:05:12<1:24:21,  2.30s/it, loss=0.5399]\u001b[A\n",
            "Training:  56%|█████▌    | 2797/5000 [2:05:12<1:24:21,  2.30s/it, loss=0.7026]\u001b[A\n",
            "Training:  56%|█████▌    | 2798/5000 [2:05:15<1:29:25,  2.44s/it, loss=0.7026]\u001b[A\n",
            "Training:  56%|█████▌    | 2798/5000 [2:05:15<1:29:25,  2.44s/it, loss=0.9148]\u001b[A\n",
            "Training:  56%|█████▌    | 2799/5000 [2:05:17<1:27:14,  2.38s/it, loss=0.9148]\u001b[A\n",
            "Training:  56%|█████▌    | 2799/5000 [2:05:17<1:27:14,  2.38s/it, loss=0.4898]\u001b[A\n",
            "Training:  56%|█████▌    | 2800/5000 [2:05:20<1:25:47,  2.34s/it, loss=0.4898]\u001b[A\n",
            "Training:  56%|█████▌    | 2800/5000 [2:05:20<1:25:47,  2.34s/it, loss=0.5849]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 2800 ---\n",
            "Prompt: 'The '\n",
            "The  had you up queen him his:\n",
            ", you\n",
            " be, you noly wifeiver you.'s, you, fri? that mayten from father\n",
            " to, you should a to a to men thesely, youwillYour, you, you\n",
            ", you not you a. vengeance Pompe, you-it take a to\n",
            "ing, you trouble you his a to- sovereign, you, you\n",
            " this a toly you, you a are,ach not her Ext, you,\n",
            "Prompt: 'In '\n",
            "In , must know how mostit\n",
            "UCINGEN VI\n",
            "HINGS\n",
            "ELOW\n",
            " call:P some, mine, think wouldives a still.\n",
            "D thou said proclaim thy to his? thouarest a to himAgain this face, andless: doub half them:\n",
            " man a that me?\n",
            "D thou fault a while sir thouost that? was not thouit more\n",
            "est sung who am in muddy a\n",
            "nowned's; you swear,tis in government\n",
            "MP male w\n",
            "Prompt: 'To '\n",
            "To  life\n",
            " behind them by me words it be\n",
            "-orrow.\n",
            "CUD:\n",
            ",.are, I\n",
            " may know of effect\n",
            " married for la here have enough down down down down down\n",
            " and 'ere notan\n",
            " hate meet; being young by means\n",
            ",\n",
            " came; me you--\n",
            " wilt again\n",
            "ELOWIm\n",
            "F, say,ieThat shallbleant sw eyes qu thy hand made down oneov\n",
            " The, man one offer, it, it: on\n",
            "Prompt: 'A '\n",
            "A  pity why advise not\n",
            ", the land stamp speak the wear thing ball die\n",
            " the being. death\n",
            "ELOW\n",
            ":Here-- lord we speak race this such head I of maid embrace?\n",
            "DKE reasonThat in head where night news sp it, asaer off it you.\n",
            "DKEIN EDARD.\n",
            "CIO\n",
            " thing is themarly his?\n",
            "Prov:It that life cannot you warrant to, it, itlander him it time\n",
            "ISEL deny\n",
            ".\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  56%|█████▌    | 2801/5000 [2:05:34<3:41:28,  6.04s/it, loss=0.5849]\u001b[A\n",
            "Training:  56%|█████▌    | 2801/5000 [2:05:34<3:41:28,  6.04s/it, loss=0.6223]\u001b[A\n",
            "Training:  56%|█████▌    | 2802/5000 [2:05:37<3:00:46,  4.93s/it, loss=0.6223]\u001b[A\n",
            "Training:  56%|█████▌    | 2802/5000 [2:05:37<3:00:46,  4.93s/it, loss=0.6397]\u001b[A\n",
            "Training:  56%|█████▌    | 2803/5000 [2:05:39<2:35:46,  4.25s/it, loss=0.6397]\u001b[A\n",
            "Training:  56%|█████▌    | 2803/5000 [2:05:39<2:35:46,  4.25s/it, loss=0.4935]\u001b[A\n",
            "Training:  56%|█████▌    | 2804/5000 [2:05:41<2:13:34,  3.65s/it, loss=0.4935]\u001b[A\n",
            "Training:  56%|█████▌    | 2804/5000 [2:05:41<2:13:34,  3.65s/it, loss=0.4838]\u001b[A\n",
            "Training:  56%|█████▌    | 2805/5000 [2:05:44<1:58:02,  3.23s/it, loss=0.4838]\u001b[A\n",
            "Training:  56%|█████▌    | 2805/5000 [2:05:44<1:58:02,  3.23s/it, loss=0.6442]\u001b[A\n",
            "Training:  56%|█████▌    | 2806/5000 [2:05:46<1:47:10,  2.93s/it, loss=0.6442]\u001b[A\n",
            "Training:  56%|█████▌    | 2806/5000 [2:05:46<1:47:10,  2.93s/it, loss=0.5664]\u001b[A\n",
            "Training:  56%|█████▌    | 2807/5000 [2:05:48<1:40:15,  2.74s/it, loss=0.5664]\u001b[A\n",
            "Training:  56%|█████▌    | 2807/5000 [2:05:48<1:40:15,  2.74s/it, loss=0.6540]\u001b[A\n",
            "Training:  56%|█████▌    | 2808/5000 [2:05:51<1:39:45,  2.73s/it, loss=0.6540]\u001b[A\n",
            "Training:  56%|█████▌    | 2808/5000 [2:05:51<1:39:45,  2.73s/it, loss=0.8736]\u001b[A\n",
            "Training:  56%|█████▌    | 2809/5000 [2:05:53<1:34:26,  2.59s/it, loss=0.8736]\u001b[A\n",
            "Training:  56%|█████▌    | 2809/5000 [2:05:53<1:34:26,  2.59s/it, loss=0.6903]\u001b[A\n",
            "Training:  56%|█████▌    | 2810/5000 [2:05:55<1:30:31,  2.48s/it, loss=0.6903]\u001b[A\n",
            "Training:  56%|█████▌    | 2810/5000 [2:05:55<1:30:31,  2.48s/it, loss=0.6952]\u001b[A\n",
            "Training:  56%|█████▌    | 2811/5000 [2:05:58<1:28:00,  2.41s/it, loss=0.6952]\u001b[A\n",
            "Training:  56%|█████▌    | 2811/5000 [2:05:58<1:28:00,  2.41s/it, loss=0.5865]\u001b[A\n",
            "Training:  56%|█████▌    | 2812/5000 [2:06:00<1:26:47,  2.38s/it, loss=0.5865]\u001b[A\n",
            "Training:  56%|█████▌    | 2812/5000 [2:06:00<1:26:47,  2.38s/it, loss=0.5702]\u001b[A\n",
            "Training:  56%|█████▋    | 2813/5000 [2:06:03<1:30:41,  2.49s/it, loss=0.5702]\u001b[A\n",
            "Training:  56%|█████▋    | 2813/5000 [2:06:03<1:30:41,  2.49s/it, loss=0.5995]\u001b[A\n",
            "Training:  56%|█████▋    | 2814/5000 [2:06:05<1:27:58,  2.41s/it, loss=0.5995]\u001b[A\n",
            "Training:  56%|█████▋    | 2814/5000 [2:06:05<1:27:58,  2.41s/it, loss=0.5837]\u001b[A\n",
            "Training:  56%|█████▋    | 2815/5000 [2:06:07<1:26:11,  2.37s/it, loss=0.5837]\u001b[A\n",
            "Training:  56%|█████▋    | 2815/5000 [2:06:07<1:26:11,  2.37s/it, loss=0.6121]\u001b[A\n",
            "Training:  56%|█████▋    | 2816/5000 [2:06:09<1:24:43,  2.33s/it, loss=0.6121]\u001b[A\n",
            "Training:  56%|█████▋    | 2816/5000 [2:06:09<1:24:43,  2.33s/it, loss=0.7236]\u001b[A\n",
            "Training:  56%|█████▋    | 2817/5000 [2:06:12<1:24:00,  2.31s/it, loss=0.7236]\u001b[A\n",
            "Training:  56%|█████▋    | 2817/5000 [2:06:12<1:24:00,  2.31s/it, loss=0.6064]\u001b[A\n",
            "Training:  56%|█████▋    | 2818/5000 [2:06:15<1:29:17,  2.46s/it, loss=0.6064]\u001b[A\n",
            "Training:  56%|█████▋    | 2818/5000 [2:06:15<1:29:17,  2.46s/it, loss=0.5065]\u001b[A\n",
            "Training:  56%|█████▋    | 2819/5000 [2:06:17<1:26:58,  2.39s/it, loss=0.5065]\u001b[A\n",
            "Training:  56%|█████▋    | 2819/5000 [2:06:17<1:26:58,  2.39s/it, loss=0.7617]\u001b[A\n",
            "Training:  56%|█████▋    | 2820/5000 [2:06:19<1:25:12,  2.35s/it, loss=0.7617]\u001b[A\n",
            "Training:  56%|█████▋    | 2820/5000 [2:06:19<1:25:12,  2.35s/it, loss=0.6070]\u001b[A\n",
            "Training:  56%|█████▋    | 2821/5000 [2:06:21<1:24:17,  2.32s/it, loss=0.6070]\u001b[A\n",
            "Training:  56%|█████▋    | 2821/5000 [2:06:21<1:24:17,  2.32s/it, loss=0.6164]\u001b[A\n",
            "Training:  56%|█████▋    | 2822/5000 [2:06:24<1:23:36,  2.30s/it, loss=0.6164]\u001b[A\n",
            "Training:  56%|█████▋    | 2822/5000 [2:06:24<1:23:36,  2.30s/it, loss=0.6882]\u001b[A\n",
            "Training:  56%|█████▋    | 2823/5000 [2:06:26<1:28:47,  2.45s/it, loss=0.6882]\u001b[A\n",
            "Training:  56%|█████▋    | 2823/5000 [2:06:26<1:28:47,  2.45s/it, loss=0.6252]\u001b[A\n",
            "Training:  56%|█████▋    | 2824/5000 [2:06:29<1:26:32,  2.39s/it, loss=0.6252]\u001b[A\n",
            "Training:  56%|█████▋    | 2824/5000 [2:06:29<1:26:32,  2.39s/it, loss=0.6372]\u001b[A\n",
            "Training:  56%|█████▋    | 2825/5000 [2:06:31<1:25:21,  2.35s/it, loss=0.6372]\u001b[A\n",
            "Training:  56%|█████▋    | 2825/5000 [2:06:31<1:25:21,  2.35s/it, loss=0.6571]\u001b[A\n",
            "Training:  57%|█████▋    | 2826/5000 [2:06:33<1:24:35,  2.33s/it, loss=0.6571]\u001b[A\n",
            "Training:  57%|█████▋    | 2826/5000 [2:06:33<1:24:35,  2.33s/it, loss=0.7598]\u001b[A\n",
            "Training:  57%|█████▋    | 2827/5000 [2:06:35<1:23:24,  2.30s/it, loss=0.7598]\u001b[A\n",
            "Training:  57%|█████▋    | 2827/5000 [2:06:35<1:23:24,  2.30s/it, loss=0.7667]\u001b[A\n",
            "Training:  57%|█████▋    | 2828/5000 [2:06:38<1:28:18,  2.44s/it, loss=0.7667]\u001b[A\n",
            "Training:  57%|█████▋    | 2828/5000 [2:06:38<1:28:18,  2.44s/it, loss=0.5312]\u001b[A\n",
            "Training:  57%|█████▋    | 2829/5000 [2:06:40<1:26:20,  2.39s/it, loss=0.5312]\u001b[A\n",
            "Training:  57%|█████▋    | 2829/5000 [2:06:40<1:26:20,  2.39s/it, loss=0.7556]\u001b[A\n",
            "Training:  57%|█████▋    | 2830/5000 [2:06:43<1:24:48,  2.35s/it, loss=0.7556]\u001b[A\n",
            "Training:  57%|█████▋    | 2830/5000 [2:06:43<1:24:48,  2.35s/it, loss=0.6913]\u001b[A\n",
            "Training:  57%|█████▋    | 2831/5000 [2:06:45<1:23:50,  2.32s/it, loss=0.6913]\u001b[A\n",
            "Training:  57%|█████▋    | 2831/5000 [2:06:45<1:23:50,  2.32s/it, loss=0.8254]\u001b[A\n",
            "Training:  57%|█████▋    | 2832/5000 [2:06:47<1:23:03,  2.30s/it, loss=0.8254]\u001b[A\n",
            "Training:  57%|█████▋    | 2832/5000 [2:06:47<1:23:03,  2.30s/it, loss=0.9085]\u001b[A\n",
            "Training:  57%|█████▋    | 2833/5000 [2:06:50<1:28:11,  2.44s/it, loss=0.9085]\u001b[A\n",
            "Training:  57%|█████▋    | 2833/5000 [2:06:50<1:28:11,  2.44s/it, loss=0.7051]\u001b[A\n",
            "Training:  57%|█████▋    | 2834/5000 [2:06:52<1:25:53,  2.38s/it, loss=0.7051]\u001b[A\n",
            "Training:  57%|█████▋    | 2834/5000 [2:06:52<1:25:53,  2.38s/it, loss=0.4801]\u001b[A\n",
            "Training:  57%|█████▋    | 2835/5000 [2:06:54<1:24:43,  2.35s/it, loss=0.4801]\u001b[A\n",
            "Training:  57%|█████▋    | 2835/5000 [2:06:54<1:24:43,  2.35s/it, loss=0.5132]\u001b[A\n",
            "Training:  57%|█████▋    | 2836/5000 [2:06:57<1:23:24,  2.31s/it, loss=0.5132]\u001b[A\n",
            "Training:  57%|█████▋    | 2836/5000 [2:06:57<1:23:24,  2.31s/it, loss=0.6271]\u001b[A\n",
            "Training:  57%|█████▋    | 2837/5000 [2:06:59<1:22:52,  2.30s/it, loss=0.6271]\u001b[A\n",
            "Training:  57%|█████▋    | 2837/5000 [2:06:59<1:22:52,  2.30s/it, loss=0.5305]\u001b[A\n",
            "Training:  57%|█████▋    | 2838/5000 [2:07:02<1:28:07,  2.45s/it, loss=0.5305]\u001b[A\n",
            "Training:  57%|█████▋    | 2838/5000 [2:07:02<1:28:07,  2.45s/it, loss=0.6169]\u001b[A\n",
            "Training:  57%|█████▋    | 2839/5000 [2:07:04<1:25:56,  2.39s/it, loss=0.6169]\u001b[A\n",
            "Training:  57%|█████▋    | 2839/5000 [2:07:04<1:25:56,  2.39s/it, loss=0.5383]\u001b[A\n",
            "Training:  57%|█████▋    | 2840/5000 [2:07:06<1:24:26,  2.35s/it, loss=0.5383]\u001b[A\n",
            "Training:  57%|█████▋    | 2840/5000 [2:07:06<1:24:26,  2.35s/it, loss=0.4890]\u001b[A\n",
            "Training:  57%|█████▋    | 2841/5000 [2:07:08<1:23:16,  2.31s/it, loss=0.4890]\u001b[A\n",
            "Training:  57%|█████▋    | 2841/5000 [2:07:08<1:23:16,  2.31s/it, loss=0.5442]\u001b[A\n",
            "Training:  57%|█████▋    | 2842/5000 [2:07:11<1:22:39,  2.30s/it, loss=0.5442]\u001b[A\n",
            "Training:  57%|█████▋    | 2842/5000 [2:07:11<1:22:39,  2.30s/it, loss=0.5626]\u001b[A\n",
            "Training:  57%|█████▋    | 2843/5000 [2:07:13<1:27:36,  2.44s/it, loss=0.5626]\u001b[A\n",
            "Training:  57%|█████▋    | 2843/5000 [2:07:13<1:27:36,  2.44s/it, loss=0.4753]\u001b[A\n",
            "Training:  57%|█████▋    | 2844/5000 [2:07:16<1:25:25,  2.38s/it, loss=0.4753]\u001b[A\n",
            "Training:  57%|█████▋    | 2844/5000 [2:07:16<1:25:25,  2.38s/it, loss=0.5421]\u001b[A\n",
            "Training:  57%|█████▋    | 2845/5000 [2:07:18<1:23:56,  2.34s/it, loss=0.5421]\u001b[A\n",
            "Training:  57%|█████▋    | 2845/5000 [2:07:18<1:23:56,  2.34s/it, loss=0.6193]\u001b[A\n",
            "Training:  57%|█████▋    | 2846/5000 [2:07:20<1:22:50,  2.31s/it, loss=0.6193]\u001b[A\n",
            "Training:  57%|█████▋    | 2846/5000 [2:07:20<1:22:50,  2.31s/it, loss=0.6345]\u001b[A\n",
            "Training:  57%|█████▋    | 2847/5000 [2:07:22<1:22:01,  2.29s/it, loss=0.6345]\u001b[A\n",
            "Training:  57%|█████▋    | 2847/5000 [2:07:22<1:22:01,  2.29s/it, loss=0.5091]\u001b[A\n",
            "Training:  57%|█████▋    | 2848/5000 [2:07:25<1:27:10,  2.43s/it, loss=0.5091]\u001b[A\n",
            "Training:  57%|█████▋    | 2848/5000 [2:07:25<1:27:10,  2.43s/it, loss=0.4778]\u001b[A\n",
            "Training:  57%|█████▋    | 2849/5000 [2:07:27<1:25:03,  2.37s/it, loss=0.4778]\u001b[A\n",
            "Training:  57%|█████▋    | 2849/5000 [2:07:27<1:25:03,  2.37s/it, loss=0.4231]\u001b[A\n",
            "Training:  57%|█████▋    | 2850/5000 [2:07:30<1:23:40,  2.34s/it, loss=0.4231]\u001b[A\n",
            "Training:  57%|█████▋    | 2850/5000 [2:07:30<1:23:40,  2.34s/it, loss=0.5656]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 2850 ---\n",
            "Prompt: 'The '\n",
            "The  thatideul of repeal do to him\n",
            " noise my. by naked despair\n",
            "Ofsemb!\n",
            "Firstingish.\n",
            "MENI:Bwill charge,,.\n",
            " are welcome me and are,; water and are;und\n",
            " this ent and of,alter and are enemiesunes your,And in ripe in my me your garlic? you-aw,, you attend your and\n",
            "\n",
            " the\n",
            "\n",
            " to me\n",
            "-.To no present!\n",
            "COROLUS\n",
            " came this\n",
            "Prompt: 'In '\n",
            "In , speak more.\n",
            "SIN EDARD:We so a from, father\n",
            "w to and him his. temples his words\n",
            "ere again-- time gentlemen\n",
            "That he have' throw'd wife being fall cannib has manI ill.\n",
            "S's? needs your.\n",
            "Sings your, thou marry gold husband\n",
            "Once I friend ofiansThey me breathed And did of.' thou he more\n",
            "an my father house\n",
            " dies to my? are well\n",
            "S sat my bride turn it decreed\n",
            "Prompt: 'To '\n",
            "To 'd to you. ' not along\n",
            "ear like afternoon\n",
            " show I names\n",
            " show another most.\n",
            "DKEINENT:Come we take moved\n",
            " take of.M, good, prepare to\n",
            ".\n",
            " this what fool to shapes I said would\n",
            " our, thein behind nor of such not of, careCould our, this drops perpetual?H what hath that must our how heart co army king\n",
            " me yourest who be? may them Your\n",
            " have offended me your-.ar\n",
            "Prompt: 'A '\n",
            "A !\n",
            "Citing\n",
            "IA\n",
            "Is thou fight?tisk him any gatesAnd can\n",
            " Mar apprehend.\n",
            "SIN EDARD\n",
            ";tis,io comeHis at intent we devise we theroud\n",
            "'s; coulding more\n",
            " say,'s,.\n",
            "hip kill to senate:I promised ofush\n",
            " word the\n",
            " we!\n",
            "VUMUMUMUMIA be so\n",
            " receipt fellow are.\n",
            "SIN EDARD\n",
            "Sent it; it; ' a;,,ing\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  57%|█████▋    | 2851/5000 [2:07:44<3:36:30,  6.04s/it, loss=0.5656]\u001b[A\n",
            "Training:  57%|█████▋    | 2851/5000 [2:07:44<3:36:30,  6.04s/it, loss=0.4951]\u001b[A\n",
            "Training:  57%|█████▋    | 2852/5000 [2:07:47<2:56:59,  4.94s/it, loss=0.4951]\u001b[A\n",
            "Training:  57%|█████▋    | 2852/5000 [2:07:47<2:56:59,  4.94s/it, loss=0.5778]\u001b[A\n",
            "Training:  57%|█████▋    | 2853/5000 [2:07:49<2:32:06,  4.25s/it, loss=0.5778]\u001b[A\n",
            "Training:  57%|█████▋    | 2853/5000 [2:07:49<2:32:06,  4.25s/it, loss=0.6558]\u001b[A\n",
            "Training:  57%|█████▋    | 2854/5000 [2:07:52<2:10:25,  3.65s/it, loss=0.6558]\u001b[A\n",
            "Training:  57%|█████▋    | 2854/5000 [2:07:52<2:10:25,  3.65s/it, loss=0.7557]\u001b[A\n",
            "Training:  57%|█████▋    | 2855/5000 [2:07:54<1:55:36,  3.23s/it, loss=0.7557]\u001b[A\n",
            "Training:  57%|█████▋    | 2855/5000 [2:07:54<1:55:36,  3.23s/it, loss=0.7497]\u001b[A\n",
            "Training:  57%|█████▋    | 2856/5000 [2:07:56<1:44:52,  2.93s/it, loss=0.7497]\u001b[A\n",
            "Training:  57%|█████▋    | 2856/5000 [2:07:56<1:44:52,  2.93s/it, loss=0.6080]\u001b[A\n",
            "Training:  57%|█████▋    | 2857/5000 [2:07:58<1:38:16,  2.75s/it, loss=0.6080]\u001b[A\n",
            "Training:  57%|█████▋    | 2857/5000 [2:07:58<1:38:16,  2.75s/it, loss=0.5943]\u001b[A\n",
            "Training:  57%|█████▋    | 2858/5000 [2:08:01<1:37:35,  2.73s/it, loss=0.5943]\u001b[A\n",
            "Training:  57%|█████▋    | 2858/5000 [2:08:01<1:37:35,  2.73s/it, loss=0.5899]\u001b[A\n",
            "Training:  57%|█████▋    | 2859/5000 [2:08:03<1:32:26,  2.59s/it, loss=0.5899]\u001b[A\n",
            "Training:  57%|█████▋    | 2859/5000 [2:08:03<1:32:26,  2.59s/it, loss=0.5815]\u001b[A\n",
            "Training:  57%|█████▋    | 2860/5000 [2:08:06<1:28:36,  2.48s/it, loss=0.5815]\u001b[A\n",
            "Training:  57%|█████▋    | 2860/5000 [2:08:06<1:28:36,  2.48s/it, loss=0.4971]\u001b[A\n",
            "Training:  57%|█████▋    | 2861/5000 [2:08:08<1:26:01,  2.41s/it, loss=0.4971]\u001b[A\n",
            "Training:  57%|█████▋    | 2861/5000 [2:08:08<1:26:01,  2.41s/it, loss=0.6251]\u001b[A\n",
            "Training:  57%|█████▋    | 2862/5000 [2:08:10<1:24:22,  2.37s/it, loss=0.6251]\u001b[A\n",
            "Training:  57%|█████▋    | 2862/5000 [2:08:10<1:24:22,  2.37s/it, loss=0.7100]\u001b[A\n",
            "Training:  57%|█████▋    | 2863/5000 [2:08:13<1:28:16,  2.48s/it, loss=0.7100]\u001b[A\n",
            "Training:  57%|█████▋    | 2863/5000 [2:08:13<1:28:16,  2.48s/it, loss=0.7074]\u001b[A\n",
            "Training:  57%|█████▋    | 2864/5000 [2:08:15<1:25:30,  2.40s/it, loss=0.7074]\u001b[A\n",
            "Training:  57%|█████▋    | 2864/5000 [2:08:15<1:25:30,  2.40s/it, loss=0.5065]\u001b[A\n",
            "Training:  57%|█████▋    | 2865/5000 [2:08:17<1:23:41,  2.35s/it, loss=0.5065]\u001b[A\n",
            "Training:  57%|█████▋    | 2865/5000 [2:08:17<1:23:41,  2.35s/it, loss=0.3500]\u001b[A\n",
            "Training:  57%|█████▋    | 2866/5000 [2:08:20<1:22:22,  2.32s/it, loss=0.3500]\u001b[A\n",
            "Training:  57%|█████▋    | 2866/5000 [2:08:20<1:22:22,  2.32s/it, loss=0.7862]\u001b[A\n",
            "Training:  57%|█████▋    | 2867/5000 [2:08:22<1:21:36,  2.30s/it, loss=0.7862]\u001b[A\n",
            "Training:  57%|█████▋    | 2867/5000 [2:08:22<1:21:36,  2.30s/it, loss=0.7130]\u001b[A\n",
            "Training:  57%|█████▋    | 2868/5000 [2:08:25<1:26:29,  2.43s/it, loss=0.7130]\u001b[A\n",
            "Training:  57%|█████▋    | 2868/5000 [2:08:25<1:26:29,  2.43s/it, loss=0.5873]\u001b[A\n",
            "Training:  57%|█████▋    | 2869/5000 [2:08:27<1:24:39,  2.38s/it, loss=0.5873]\u001b[A\n",
            "Training:  57%|█████▋    | 2869/5000 [2:08:27<1:24:39,  2.38s/it, loss=0.6004]\u001b[A\n",
            "Training:  57%|█████▋    | 2870/5000 [2:08:29<1:23:26,  2.35s/it, loss=0.6004]\u001b[A\n",
            "Training:  57%|█████▋    | 2870/5000 [2:08:29<1:23:26,  2.35s/it, loss=0.6531]\u001b[A\n",
            "Training:  57%|█████▋    | 2871/5000 [2:08:31<1:22:13,  2.32s/it, loss=0.6531]\u001b[A\n",
            "Training:  57%|█████▋    | 2871/5000 [2:08:31<1:22:13,  2.32s/it, loss=0.6567]\u001b[A\n",
            "Training:  57%|█████▋    | 2872/5000 [2:08:34<1:21:45,  2.31s/it, loss=0.6567]\u001b[A\n",
            "Training:  57%|█████▋    | 2872/5000 [2:08:34<1:21:45,  2.31s/it, loss=0.3509]\u001b[A\n",
            "Training:  57%|█████▋    | 2873/5000 [2:08:36<1:26:45,  2.45s/it, loss=0.3509]\u001b[A\n",
            "Training:  57%|█████▋    | 2873/5000 [2:08:36<1:26:45,  2.45s/it, loss=0.6680]\u001b[A\n",
            "Training:  57%|█████▋    | 2874/5000 [2:08:39<1:24:18,  2.38s/it, loss=0.6680]\u001b[A\n",
            "Training:  57%|█████▋    | 2874/5000 [2:08:39<1:24:18,  2.38s/it, loss=0.3466]\u001b[A\n",
            "Training:  57%|█████▊    | 2875/5000 [2:08:41<1:23:07,  2.35s/it, loss=0.3466]\u001b[A\n",
            "Training:  57%|█████▊    | 2875/5000 [2:08:41<1:23:07,  2.35s/it, loss=0.5913]\u001b[A\n",
            "Training:  58%|█████▊    | 2876/5000 [2:08:43<1:21:57,  2.32s/it, loss=0.5913]\u001b[A\n",
            "Training:  58%|█████▊    | 2876/5000 [2:08:43<1:21:57,  2.32s/it, loss=0.5686]\u001b[A\n",
            "Training:  58%|█████▊    | 2877/5000 [2:08:45<1:21:08,  2.29s/it, loss=0.5686]\u001b[A\n",
            "Training:  58%|█████▊    | 2877/5000 [2:08:45<1:21:08,  2.29s/it, loss=0.4075]\u001b[A\n",
            "Training:  58%|█████▊    | 2878/5000 [2:08:48<1:26:03,  2.43s/it, loss=0.4075]\u001b[A\n",
            "Training:  58%|█████▊    | 2878/5000 [2:08:48<1:26:03,  2.43s/it, loss=0.7405]\u001b[A\n",
            "Training:  58%|█████▊    | 2879/5000 [2:08:50<1:23:58,  2.38s/it, loss=0.7405]\u001b[A\n",
            "Training:  58%|█████▊    | 2879/5000 [2:08:50<1:23:58,  2.38s/it, loss=0.6864]\u001b[A\n",
            "Training:  58%|█████▊    | 2880/5000 [2:08:53<1:22:30,  2.34s/it, loss=0.6864]\u001b[A\n",
            "Training:  58%|█████▊    | 2880/5000 [2:08:53<1:22:30,  2.34s/it, loss=0.4862]\u001b[A\n",
            "Training:  58%|█████▊    | 2881/5000 [2:08:55<1:21:26,  2.31s/it, loss=0.4862]\u001b[A\n",
            "Training:  58%|█████▊    | 2881/5000 [2:08:55<1:21:26,  2.31s/it, loss=0.5061]\u001b[A\n",
            "Training:  58%|█████▊    | 2882/5000 [2:08:57<1:21:08,  2.30s/it, loss=0.5061]\u001b[A\n",
            "Training:  58%|█████▊    | 2882/5000 [2:08:57<1:21:08,  2.30s/it, loss=0.5530]\u001b[A\n",
            "Training:  58%|█████▊    | 2883/5000 [2:09:00<1:25:39,  2.43s/it, loss=0.5530]\u001b[A\n",
            "Training:  58%|█████▊    | 2883/5000 [2:09:00<1:25:39,  2.43s/it, loss=0.5730]\u001b[A\n",
            "Training:  58%|█████▊    | 2884/5000 [2:09:02<1:23:45,  2.38s/it, loss=0.5730]\u001b[A\n",
            "Training:  58%|█████▊    | 2884/5000 [2:09:02<1:23:45,  2.38s/it, loss=0.3379]\u001b[A\n",
            "Training:  58%|█████▊    | 2885/5000 [2:09:04<1:22:45,  2.35s/it, loss=0.3379]\u001b[A\n",
            "Training:  58%|█████▊    | 2885/5000 [2:09:04<1:22:45,  2.35s/it, loss=0.4277]\u001b[A\n",
            "Training:  58%|█████▊    | 2886/5000 [2:09:07<1:21:41,  2.32s/it, loss=0.4277]\u001b[A\n",
            "Training:  58%|█████▊    | 2886/5000 [2:09:07<1:21:41,  2.32s/it, loss=0.6691]\u001b[A\n",
            "Training:  58%|█████▊    | 2887/5000 [2:09:09<1:20:50,  2.30s/it, loss=0.6691]\u001b[A\n",
            "Training:  58%|█████▊    | 2887/5000 [2:09:09<1:20:50,  2.30s/it, loss=0.6700]\u001b[A\n",
            "Training:  58%|█████▊    | 2888/5000 [2:09:12<1:25:39,  2.43s/it, loss=0.6700]\u001b[A\n",
            "Training:  58%|█████▊    | 2888/5000 [2:09:12<1:25:39,  2.43s/it, loss=0.4630]\u001b[A\n",
            "Training:  58%|█████▊    | 2889/5000 [2:09:14<1:23:33,  2.38s/it, loss=0.4630]\u001b[A\n",
            "Training:  58%|█████▊    | 2889/5000 [2:09:14<1:23:33,  2.38s/it, loss=0.4352]\u001b[A\n",
            "Training:  58%|█████▊    | 2890/5000 [2:09:16<1:22:14,  2.34s/it, loss=0.4352]\u001b[A\n",
            "Training:  58%|█████▊    | 2890/5000 [2:09:16<1:22:14,  2.34s/it, loss=0.3739]\u001b[A\n",
            "Training:  58%|█████▊    | 2891/5000 [2:09:18<1:21:15,  2.31s/it, loss=0.3739]\u001b[A\n",
            "Training:  58%|█████▊    | 2891/5000 [2:09:18<1:21:15,  2.31s/it, loss=0.4964]\u001b[A\n",
            "Training:  58%|█████▊    | 2892/5000 [2:09:21<1:20:33,  2.29s/it, loss=0.4964]\u001b[A\n",
            "Training:  58%|█████▊    | 2892/5000 [2:09:21<1:20:33,  2.29s/it, loss=0.3641]\u001b[A\n",
            "Training:  58%|█████▊    | 2893/5000 [2:09:23<1:25:25,  2.43s/it, loss=0.3641]\u001b[A\n",
            "Training:  58%|█████▊    | 2893/5000 [2:09:23<1:25:25,  2.43s/it, loss=0.6800]\u001b[A\n",
            "Training:  58%|█████▊    | 2894/5000 [2:09:26<1:23:14,  2.37s/it, loss=0.6800]\u001b[A\n",
            "Training:  58%|█████▊    | 2894/5000 [2:09:26<1:23:14,  2.37s/it, loss=0.4637]\u001b[A\n",
            "Training:  58%|█████▊    | 2895/5000 [2:09:28<1:21:54,  2.33s/it, loss=0.4637]\u001b[A\n",
            "Training:  58%|█████▊    | 2895/5000 [2:09:28<1:21:54,  2.33s/it, loss=0.3914]\u001b[A\n",
            "Training:  58%|█████▊    | 2896/5000 [2:09:30<1:21:22,  2.32s/it, loss=0.3914]\u001b[A\n",
            "Training:  58%|█████▊    | 2896/5000 [2:09:30<1:21:22,  2.32s/it, loss=0.5680]\u001b[A\n",
            "Training:  58%|█████▊    | 2897/5000 [2:09:32<1:20:44,  2.30s/it, loss=0.5680]\u001b[A\n",
            "Training:  58%|█████▊    | 2897/5000 [2:09:32<1:20:44,  2.30s/it, loss=0.6843]\u001b[A\n",
            "Training:  58%|█████▊    | 2898/5000 [2:09:35<1:26:05,  2.46s/it, loss=0.6843]\u001b[A\n",
            "Training:  58%|█████▊    | 2898/5000 [2:09:35<1:26:05,  2.46s/it, loss=0.6006]\u001b[A\n",
            "Training:  58%|█████▊    | 2899/5000 [2:09:37<1:23:39,  2.39s/it, loss=0.6006]\u001b[A\n",
            "Training:  58%|█████▊    | 2899/5000 [2:09:38<1:23:39,  2.39s/it, loss=0.4746]\u001b[A\n",
            "Training:  58%|█████▊    | 2900/5000 [2:09:40<1:22:12,  2.35s/it, loss=0.4746]\u001b[A\n",
            "Training:  58%|█████▊    | 2900/5000 [2:09:40<1:22:12,  2.35s/it, loss=0.5825]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 2900 ---\n",
            "Prompt: 'The '\n",
            "The  no delightposing thee;tis wrought\n",
            " plot talk of show but have'd each hearing\n",
            " that which much than of sheep they him\n",
            " that man anyling call muchWhat in spirit,Your's,Some thymbling guiltake you\n",
            " there none with and of good find thee the\n",
            " that which no shall his king for love me to in noble\n",
            " this teeming of trade of yet I'd cheer is ofarts for score.\n",
            "ROO spare O I remember, stir, it my love sent my\n",
            "Prompt: 'In '\n",
            "In , night foroe are girl hate;And it win: or,' it as to brave,\n",
            " for love better it see 'st hour true care\n",
            " b shore come give time for love shall what hast it;And, I I I\n",
            " you brief yet for, I, youk sea those ofs my and with show men\n",
            " you I fatal and.ark!p, mine,, what have'd set on!\n",
            "CAPET asoth: would it more so a, more\n",
            "\n",
            "Prompt: 'To '\n",
            "To  to need from strong! I go,!\n",
            " sadness wastedut as as as as as as, Both\n",
            " theal him-ights youth may be as\n",
            "hip London\n",
            "EST brief prince as favour night as rest so,And\n",
            " hate ha made true turns is, I gro,inks less\n",
            "round pieces deed Friendly I; now well strongly out\n",
            " would ready to, all name till self is,Again thy hand gone unto deceiveerous of,, read, their grief as art so, so\n",
            "Prompt: 'A '\n",
            "A ,\n",
            " bid devil me home Romeo Romeo\n",
            " resort, to, whose sake come to's.\n",
            "ROO\n",
            " having is power the; who like God way\n",
            " tear large than'sance for the\n",
            "Look thy facele your:'t we see 'osed,,, the of come we, fear remembrance.\n",
            "ROO\n",
            "REG:See where please, I God theague on w ofse and, our, was the.\n",
            "M earraw! pity chances light!\n",
            "QUE EL\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  58%|█████▊    | 2901/5000 [2:09:54<3:30:43,  6.02s/it, loss=0.5825]\u001b[A\n",
            "Training:  58%|█████▊    | 2901/5000 [2:09:54<3:30:43,  6.02s/it, loss=0.4669]\u001b[A\n",
            "Training:  58%|█████▊    | 2902/5000 [2:09:57<2:52:41,  4.94s/it, loss=0.4669]\u001b[A\n",
            "Training:  58%|█████▊    | 2902/5000 [2:09:57<2:52:41,  4.94s/it, loss=0.7409]\u001b[A\n",
            "Training:  58%|█████▊    | 2903/5000 [2:09:59<2:28:12,  4.24s/it, loss=0.7409]\u001b[A\n",
            "Training:  58%|█████▊    | 2903/5000 [2:09:59<2:28:12,  4.24s/it, loss=0.6896]\u001b[A\n",
            "Training:  58%|█████▊    | 2904/5000 [2:10:02<2:07:02,  3.64s/it, loss=0.6896]\u001b[A\n",
            "Training:  58%|█████▊    | 2904/5000 [2:10:02<2:07:02,  3.64s/it, loss=0.5098]\u001b[A\n",
            "Training:  58%|█████▊    | 2905/5000 [2:10:04<1:52:46,  3.23s/it, loss=0.5098]\u001b[A\n",
            "Training:  58%|█████▊    | 2905/5000 [2:10:04<1:52:46,  3.23s/it, loss=0.4691]\u001b[A\n",
            "Training:  58%|█████▊    | 2906/5000 [2:10:06<1:42:14,  2.93s/it, loss=0.4691]\u001b[A\n",
            "Training:  58%|█████▊    | 2906/5000 [2:10:06<1:42:14,  2.93s/it, loss=0.3794]\u001b[A\n",
            "Training:  58%|█████▊    | 2907/5000 [2:10:09<1:36:52,  2.78s/it, loss=0.3794]\u001b[A\n",
            "Training:  58%|█████▊    | 2907/5000 [2:10:09<1:36:52,  2.78s/it, loss=0.4732]\u001b[A\n",
            "Training:  58%|█████▊    | 2908/5000 [2:10:11<1:35:04,  2.73s/it, loss=0.4732]\u001b[A\n",
            "Training:  58%|█████▊    | 2908/5000 [2:10:11<1:35:04,  2.73s/it, loss=0.4047]\u001b[A\n",
            "Training:  58%|█████▊    | 2909/5000 [2:10:13<1:29:57,  2.58s/it, loss=0.4047]\u001b[A\n",
            "Training:  58%|█████▊    | 2909/5000 [2:10:13<1:29:57,  2.58s/it, loss=0.4751]\u001b[A\n",
            "Training:  58%|█████▊    | 2910/5000 [2:10:16<1:26:19,  2.48s/it, loss=0.4751]\u001b[A\n",
            "Training:  58%|█████▊    | 2910/5000 [2:10:16<1:26:19,  2.48s/it, loss=0.5115]\u001b[A\n",
            "Training:  58%|█████▊    | 2911/5000 [2:10:18<1:24:10,  2.42s/it, loss=0.5115]\u001b[A\n",
            "Training:  58%|█████▊    | 2911/5000 [2:10:18<1:24:10,  2.42s/it, loss=0.4083]\u001b[A\n",
            "Training:  58%|█████▊    | 2912/5000 [2:10:20<1:23:43,  2.41s/it, loss=0.4083]\u001b[A\n",
            "Training:  58%|█████▊    | 2912/5000 [2:10:20<1:23:43,  2.41s/it, loss=0.4913]\u001b[A\n",
            "Training:  58%|█████▊    | 2913/5000 [2:10:23<1:26:08,  2.48s/it, loss=0.4913]\u001b[A\n",
            "Training:  58%|█████▊    | 2913/5000 [2:10:23<1:26:08,  2.48s/it, loss=0.5683]\u001b[A\n",
            "Training:  58%|█████▊    | 2914/5000 [2:10:25<1:23:49,  2.41s/it, loss=0.5683]\u001b[A\n",
            "Training:  58%|█████▊    | 2914/5000 [2:10:25<1:23:49,  2.41s/it, loss=0.6300]\u001b[A\n",
            "Training:  58%|█████▊    | 2915/5000 [2:10:27<1:21:53,  2.36s/it, loss=0.6300]\u001b[A\n",
            "Training:  58%|█████▊    | 2915/5000 [2:10:27<1:21:53,  2.36s/it, loss=0.3481]\u001b[A\n",
            "Training:  58%|█████▊    | 2916/5000 [2:10:30<1:20:33,  2.32s/it, loss=0.3481]\u001b[A\n",
            "Training:  58%|█████▊    | 2916/5000 [2:10:30<1:20:33,  2.32s/it, loss=0.5559]\u001b[A\n",
            "Training:  58%|█████▊    | 2917/5000 [2:10:32<1:20:40,  2.32s/it, loss=0.5559]\u001b[A\n",
            "Training:  58%|█████▊    | 2917/5000 [2:10:32<1:20:40,  2.32s/it, loss=0.6936]\u001b[A\n",
            "Training:  58%|█████▊    | 2918/5000 [2:10:35<1:24:35,  2.44s/it, loss=0.6936]\u001b[A\n",
            "Training:  58%|█████▊    | 2918/5000 [2:10:35<1:24:35,  2.44s/it, loss=0.4044]\u001b[A\n",
            "Training:  58%|█████▊    | 2919/5000 [2:10:37<1:22:53,  2.39s/it, loss=0.4044]\u001b[A\n",
            "Training:  58%|█████▊    | 2919/5000 [2:10:37<1:22:53,  2.39s/it, loss=0.8039]\u001b[A\n",
            "Training:  58%|█████▊    | 2920/5000 [2:10:39<1:21:16,  2.34s/it, loss=0.8039]\u001b[A\n",
            "Training:  58%|█████▊    | 2920/5000 [2:10:39<1:21:16,  2.34s/it, loss=0.6174]\u001b[A\n",
            "Training:  58%|█████▊    | 2921/5000 [2:10:41<1:20:08,  2.31s/it, loss=0.6174]\u001b[A\n",
            "Training:  58%|█████▊    | 2921/5000 [2:10:41<1:20:08,  2.31s/it, loss=0.5025]\u001b[A\n",
            "Training:  58%|█████▊    | 2922/5000 [2:10:44<1:20:15,  2.32s/it, loss=0.5025]\u001b[A\n",
            "Training:  58%|█████▊    | 2922/5000 [2:10:44<1:20:15,  2.32s/it, loss=0.5319]\u001b[A\n",
            "Training:  58%|█████▊    | 2923/5000 [2:10:46<1:24:10,  2.43s/it, loss=0.5319]\u001b[A\n",
            "Training:  58%|█████▊    | 2923/5000 [2:10:46<1:24:10,  2.43s/it, loss=0.4754]\u001b[A\n",
            "Training:  58%|█████▊    | 2924/5000 [2:10:49<1:22:18,  2.38s/it, loss=0.4754]\u001b[A\n",
            "Training:  58%|█████▊    | 2924/5000 [2:10:49<1:22:18,  2.38s/it, loss=0.4899]\u001b[A\n",
            "Training:  58%|█████▊    | 2925/5000 [2:10:51<1:20:58,  2.34s/it, loss=0.4899]\u001b[A\n",
            "Training:  58%|█████▊    | 2925/5000 [2:10:51<1:20:58,  2.34s/it, loss=0.4785]\u001b[A\n",
            "Training:  59%|█████▊    | 2926/5000 [2:10:53<1:20:11,  2.32s/it, loss=0.4785]\u001b[A\n",
            "Training:  59%|█████▊    | 2926/5000 [2:10:53<1:20:11,  2.32s/it, loss=0.6165]\u001b[A\n",
            "Training:  59%|█████▊    | 2927/5000 [2:10:55<1:19:36,  2.30s/it, loss=0.6165]\u001b[A\n",
            "Training:  59%|█████▊    | 2927/5000 [2:10:56<1:19:36,  2.30s/it, loss=0.6211]\u001b[A\n",
            "Training:  59%|█████▊    | 2928/5000 [2:10:58<1:23:50,  2.43s/it, loss=0.6211]\u001b[A\n",
            "Training:  59%|█████▊    | 2928/5000 [2:10:58<1:23:50,  2.43s/it, loss=0.4948]\u001b[A\n",
            "Training:  59%|█████▊    | 2929/5000 [2:11:00<1:22:13,  2.38s/it, loss=0.4948]\u001b[A\n",
            "Training:  59%|█████▊    | 2929/5000 [2:11:01<1:22:13,  2.38s/it, loss=0.5027]\u001b[A\n",
            "Training:  59%|█████▊    | 2930/5000 [2:11:03<1:20:46,  2.34s/it, loss=0.5027]\u001b[A\n",
            "Training:  59%|█████▊    | 2930/5000 [2:11:03<1:20:46,  2.34s/it, loss=0.4624]\u001b[A\n",
            "Training:  59%|█████▊    | 2931/5000 [2:11:05<1:20:06,  2.32s/it, loss=0.4624]\u001b[A\n",
            "Training:  59%|█████▊    | 2931/5000 [2:11:05<1:20:06,  2.32s/it, loss=0.3895]\u001b[A\n",
            "Training:  59%|█████▊    | 2932/5000 [2:11:07<1:19:21,  2.30s/it, loss=0.3895]\u001b[A\n",
            "Training:  59%|█████▊    | 2932/5000 [2:11:07<1:19:21,  2.30s/it, loss=0.5475]\u001b[A\n",
            "Training:  59%|█████▊    | 2933/5000 [2:11:10<1:24:22,  2.45s/it, loss=0.5475]\u001b[A\n",
            "Training:  59%|█████▊    | 2933/5000 [2:11:10<1:24:22,  2.45s/it, loss=0.5081]\u001b[A\n",
            "Training:  59%|█████▊    | 2934/5000 [2:11:12<1:22:14,  2.39s/it, loss=0.5081]\u001b[A\n",
            "Training:  59%|█████▊    | 2934/5000 [2:11:12<1:22:14,  2.39s/it, loss=0.4426]\u001b[A\n",
            "Training:  59%|█████▊    | 2935/5000 [2:11:15<1:20:43,  2.35s/it, loss=0.4426]\u001b[A\n",
            "Training:  59%|█████▊    | 2935/5000 [2:11:15<1:20:43,  2.35s/it, loss=0.3418]\u001b[A\n",
            "Training:  59%|█████▊    | 2936/5000 [2:11:17<1:19:33,  2.31s/it, loss=0.3418]\u001b[A\n",
            "Training:  59%|█████▊    | 2936/5000 [2:11:17<1:19:33,  2.31s/it, loss=0.4508]\u001b[A\n",
            "Training:  59%|█████▊    | 2937/5000 [2:11:19<1:19:01,  2.30s/it, loss=0.4508]\u001b[A\n",
            "Training:  59%|█████▊    | 2937/5000 [2:11:19<1:19:01,  2.30s/it, loss=0.6843]\u001b[A\n",
            "Training:  59%|█████▉    | 2938/5000 [2:11:22<1:23:31,  2.43s/it, loss=0.6843]\u001b[A\n",
            "Training:  59%|█████▉    | 2938/5000 [2:11:22<1:23:31,  2.43s/it, loss=0.6241]\u001b[A\n",
            "Training:  59%|█████▉    | 2939/5000 [2:11:24<1:21:44,  2.38s/it, loss=0.6241]\u001b[A\n",
            "Training:  59%|█████▉    | 2939/5000 [2:11:24<1:21:44,  2.38s/it, loss=0.4529]\u001b[A\n",
            "Training:  59%|█████▉    | 2940/5000 [2:11:26<1:20:36,  2.35s/it, loss=0.4529]\u001b[A\n",
            "Training:  59%|█████▉    | 2940/5000 [2:11:26<1:20:36,  2.35s/it, loss=0.5892]\u001b[A\n",
            "Training:  59%|█████▉    | 2941/5000 [2:11:29<1:19:40,  2.32s/it, loss=0.5892]\u001b[A\n",
            "Training:  59%|█████▉    | 2941/5000 [2:11:29<1:19:40,  2.32s/it, loss=0.5467]\u001b[A\n",
            "Training:  59%|█████▉    | 2942/5000 [2:11:31<1:18:50,  2.30s/it, loss=0.5467]\u001b[A\n",
            "Training:  59%|█████▉    | 2942/5000 [2:11:31<1:18:50,  2.30s/it, loss=0.6324]\u001b[A\n",
            "Training:  59%|█████▉    | 2943/5000 [2:11:34<1:23:43,  2.44s/it, loss=0.6324]\u001b[A\n",
            "Training:  59%|█████▉    | 2943/5000 [2:11:34<1:23:43,  2.44s/it, loss=0.4464]\u001b[A\n",
            "Training:  59%|█████▉    | 2944/5000 [2:11:36<1:22:32,  2.41s/it, loss=0.4464]\u001b[A\n",
            "Training:  59%|█████▉    | 2944/5000 [2:11:36<1:22:32,  2.41s/it, loss=0.4059]\u001b[A\n",
            "Training:  59%|█████▉    | 2945/5000 [2:11:38<1:20:48,  2.36s/it, loss=0.4059]\u001b[A\n",
            "Training:  59%|█████▉    | 2945/5000 [2:11:38<1:20:48,  2.36s/it, loss=0.4195]\u001b[A\n",
            "Training:  59%|█████▉    | 2946/5000 [2:11:40<1:19:38,  2.33s/it, loss=0.4195]\u001b[A\n",
            "Training:  59%|█████▉    | 2946/5000 [2:11:40<1:19:38,  2.33s/it, loss=0.8146]\u001b[A\n",
            "Training:  59%|█████▉    | 2947/5000 [2:11:43<1:18:48,  2.30s/it, loss=0.8146]\u001b[A\n",
            "Training:  59%|█████▉    | 2947/5000 [2:11:43<1:18:48,  2.30s/it, loss=0.6237]\u001b[A\n",
            "Training:  59%|█████▉    | 2948/5000 [2:11:45<1:23:38,  2.45s/it, loss=0.6237]\u001b[A\n",
            "Training:  59%|█████▉    | 2948/5000 [2:11:45<1:23:38,  2.45s/it, loss=0.7335]\u001b[A\n",
            "Training:  59%|█████▉    | 2949/5000 [2:11:48<1:21:34,  2.39s/it, loss=0.7335]\u001b[A\n",
            "Training:  59%|█████▉    | 2949/5000 [2:11:48<1:21:34,  2.39s/it, loss=0.4063]\u001b[A\n",
            "Training:  59%|█████▉    | 2950/5000 [2:11:50<1:20:16,  2.35s/it, loss=0.4063]\u001b[A\n",
            "Training:  59%|█████▉    | 2950/5000 [2:11:50<1:20:16,  2.35s/it, loss=0.3813]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 2950 ---\n",
            "Prompt: 'The '\n",
            "The  of his, where stand w\n",
            " very to the of.\n",
            "She wilt my, son of.\n",
            "FLIZ prov, inter, myself absence\n",
            " unided prov.\n",
            " all rep, condition\n",
            " ear honesty cred:We health the yourerg have,What asLord\n",
            " came living,. was your!Come come you not that,kind, the of, fri,night mad, away\n",
            "ath have'd so? more so, temporal\n",
            " something\n",
            "iring setem\n",
            " Caindu: was\n",
            "Prompt: 'In '\n",
            "In ,an more than mother dueTh seekvance of dear, it a with half brother,Which his a, before If\n",
            " upon-'d of devil had thou he my, resolution\n",
            " thyings'd,' and\n",
            " so, did me, the of is,,,,,ly me theseato\n",
            " disob ours: the cannot, is no;If I rose were stone\n",
            " m of,'s, did me and; stand amber,,\n",
            " did best: the lend by hand\n",
            "Prompt: 'To '\n",
            "To  shame any againstation way, of bment\n",
            " count bl: ownceed how offare?\n",
            "Serv not hand his wordsel,.\n",
            "POLEN with:I I some ofsh,and good for seems\n",
            " some youung eyes mine,mong to, linger,\n",
            " islike of trialC Away her.\n",
            "PAINA spotA. Justice against,ina\n",
            "an My, lie.\n",
            "'s, devil any in time,urationiously grace\n",
            " shines saidakes queen destiny\n",
            " us longer\n",
            "Prompt: 'A '\n",
            "A ,\n",
            " many spirit these: was a fri,\n",
            " it like die not come forandham for\n",
            " good from sness is. you sir be fly\n",
            " not,able; hath, him I name for of lod,\n",
            " I go us you a more is, was to hot must aan\n",
            "?\n",
            "ESCUS\n",
            " duke and.\n",
            "D why a with?\n",
            "FLIZ:and are, friendN,, you yours, you, your? you- at\n",
            " duke heraste\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  59%|█████▉    | 2951/5000 [2:12:05<3:26:32,  6.05s/it, loss=0.3813]\u001b[A\n",
            "Training:  59%|█████▉    | 2951/5000 [2:12:05<3:26:32,  6.05s/it, loss=0.3732]\u001b[A\n",
            "Training:  59%|█████▉    | 2952/5000 [2:12:07<2:49:55,  4.98s/it, loss=0.3732]\u001b[A\n",
            "Training:  59%|█████▉    | 2952/5000 [2:12:07<2:49:55,  4.98s/it, loss=0.5090]\u001b[A\n",
            "Training:  59%|█████▉    | 2953/5000 [2:12:10<2:24:31,  4.24s/it, loss=0.5090]\u001b[A\n",
            "Training:  59%|█████▉    | 2953/5000 [2:12:10<2:24:31,  4.24s/it, loss=0.4411]\u001b[A\n",
            "Training:  59%|█████▉    | 2954/5000 [2:12:12<2:03:57,  3.64s/it, loss=0.4411]\u001b[A\n",
            "Training:  59%|█████▉    | 2954/5000 [2:12:12<2:03:57,  3.64s/it, loss=0.4892]\u001b[A\n",
            "Training:  59%|█████▉    | 2955/5000 [2:12:14<1:49:44,  3.22s/it, loss=0.4892]\u001b[A\n",
            "Training:  59%|█████▉    | 2955/5000 [2:12:14<1:49:44,  3.22s/it, loss=0.7833]\u001b[A\n",
            "Training:  59%|█████▉    | 2956/5000 [2:12:16<1:39:39,  2.93s/it, loss=0.7833]\u001b[A\n",
            "Training:  59%|█████▉    | 2956/5000 [2:12:16<1:39:39,  2.93s/it, loss=0.5960]\u001b[A\n",
            "Training:  59%|█████▉    | 2957/5000 [2:12:19<1:34:27,  2.77s/it, loss=0.5960]\u001b[A\n",
            "Training:  59%|█████▉    | 2957/5000 [2:12:19<1:34:27,  2.77s/it, loss=0.7435]\u001b[A\n",
            "Training:  59%|█████▉    | 2958/5000 [2:12:21<1:32:29,  2.72s/it, loss=0.7435]\u001b[A\n",
            "Training:  59%|█████▉    | 2958/5000 [2:12:21<1:32:29,  2.72s/it, loss=0.4187]\u001b[A\n",
            "Training:  59%|█████▉    | 2959/5000 [2:12:24<1:27:37,  2.58s/it, loss=0.4187]\u001b[A\n",
            "Training:  59%|█████▉    | 2959/5000 [2:12:24<1:27:37,  2.58s/it, loss=0.6086]\u001b[A\n",
            "Training:  59%|█████▉    | 2960/5000 [2:12:26<1:24:10,  2.48s/it, loss=0.6086]\u001b[A\n",
            "Training:  59%|█████▉    | 2960/5000 [2:12:26<1:24:10,  2.48s/it, loss=0.6443]\u001b[A\n",
            "Training:  59%|█████▉    | 2961/5000 [2:12:28<1:22:01,  2.41s/it, loss=0.6443]\u001b[A\n",
            "Training:  59%|█████▉    | 2961/5000 [2:12:28<1:22:01,  2.41s/it, loss=0.3258]\u001b[A\n",
            "Training:  59%|█████▉    | 2962/5000 [2:12:31<1:21:57,  2.41s/it, loss=0.3258]\u001b[A\n",
            "Training:  59%|█████▉    | 2962/5000 [2:12:31<1:21:57,  2.41s/it, loss=0.7489]\u001b[A\n",
            "Training:  59%|█████▉    | 2963/5000 [2:12:33<1:24:02,  2.48s/it, loss=0.7489]\u001b[A\n",
            "Training:  59%|█████▉    | 2963/5000 [2:12:33<1:24:02,  2.48s/it, loss=0.6150]\u001b[A\n",
            "Training:  59%|█████▉    | 2964/5000 [2:12:35<1:21:58,  2.42s/it, loss=0.6150]\u001b[A\n",
            "Training:  59%|█████▉    | 2964/5000 [2:12:35<1:21:58,  2.42s/it, loss=0.5745]\u001b[A\n",
            "Training:  59%|█████▉    | 2965/5000 [2:12:38<1:20:18,  2.37s/it, loss=0.5745]\u001b[A\n",
            "Training:  59%|█████▉    | 2965/5000 [2:12:38<1:20:18,  2.37s/it, loss=0.6778]\u001b[A\n",
            "Training:  59%|█████▉    | 2966/5000 [2:12:40<1:19:12,  2.34s/it, loss=0.6778]\u001b[A\n",
            "Training:  59%|█████▉    | 2966/5000 [2:12:40<1:19:12,  2.34s/it, loss=0.6159]\u001b[A\n",
            "Training:  59%|█████▉    | 2967/5000 [2:12:42<1:20:04,  2.36s/it, loss=0.6159]\u001b[A\n",
            "Training:  59%|█████▉    | 2967/5000 [2:12:42<1:20:04,  2.36s/it, loss=0.4469]\u001b[A\n",
            "Training:  59%|█████▉    | 2968/5000 [2:12:45<1:22:38,  2.44s/it, loss=0.4469]\u001b[A\n",
            "Training:  59%|█████▉    | 2968/5000 [2:12:45<1:22:38,  2.44s/it, loss=0.4392]\u001b[A\n",
            "Training:  59%|█████▉    | 2969/5000 [2:12:47<1:20:52,  2.39s/it, loss=0.4392]\u001b[A\n",
            "Training:  59%|█████▉    | 2969/5000 [2:12:47<1:20:52,  2.39s/it, loss=0.5109]\u001b[A\n",
            "Training:  59%|█████▉    | 2970/5000 [2:12:50<1:19:27,  2.35s/it, loss=0.5109]\u001b[A\n",
            "Training:  59%|█████▉    | 2970/5000 [2:12:50<1:19:27,  2.35s/it, loss=0.4630]\u001b[A\n",
            "Training:  59%|█████▉    | 2971/5000 [2:12:52<1:18:24,  2.32s/it, loss=0.4630]\u001b[A\n",
            "Training:  59%|█████▉    | 2971/5000 [2:12:52<1:18:24,  2.32s/it, loss=0.4739]\u001b[A\n",
            "Training:  59%|█████▉    | 2972/5000 [2:12:54<1:18:53,  2.33s/it, loss=0.4739]\u001b[A\n",
            "Training:  59%|█████▉    | 2972/5000 [2:12:54<1:18:53,  2.33s/it, loss=0.3929]\u001b[A\n",
            "Training:  59%|█████▉    | 2973/5000 [2:12:57<1:22:34,  2.44s/it, loss=0.3929]\u001b[A\n",
            "Training:  59%|█████▉    | 2973/5000 [2:12:57<1:22:34,  2.44s/it, loss=0.4606]\u001b[A\n",
            "Training:  59%|█████▉    | 2974/5000 [2:12:59<1:21:06,  2.40s/it, loss=0.4606]\u001b[A\n",
            "Training:  59%|█████▉    | 2974/5000 [2:12:59<1:21:06,  2.40s/it, loss=0.5516]\u001b[A\n",
            "Training:  60%|█████▉    | 2975/5000 [2:13:01<1:19:25,  2.35s/it, loss=0.5516]\u001b[A\n",
            "Training:  60%|█████▉    | 2975/5000 [2:13:01<1:19:25,  2.35s/it, loss=0.3812]\u001b[A\n",
            "Training:  60%|█████▉    | 2976/5000 [2:13:04<1:18:28,  2.33s/it, loss=0.3812]\u001b[A\n",
            "Training:  60%|█████▉    | 2976/5000 [2:13:04<1:18:28,  2.33s/it, loss=0.7199]\u001b[A\n",
            "Training:  60%|█████▉    | 2977/5000 [2:13:06<1:19:20,  2.35s/it, loss=0.7199]\u001b[A\n",
            "Training:  60%|█████▉    | 2977/5000 [2:13:06<1:19:20,  2.35s/it, loss=0.7151]\u001b[A\n",
            "Training:  60%|█████▉    | 2978/5000 [2:13:09<1:22:35,  2.45s/it, loss=0.7151]\u001b[A\n",
            "Training:  60%|█████▉    | 2978/5000 [2:13:09<1:22:35,  2.45s/it, loss=0.4794]\u001b[A\n",
            "Training:  60%|█████▉    | 2979/5000 [2:13:11<1:20:35,  2.39s/it, loss=0.4794]\u001b[A\n",
            "Training:  60%|█████▉    | 2979/5000 [2:13:11<1:20:35,  2.39s/it, loss=0.4688]\u001b[A\n",
            "Training:  60%|█████▉    | 2980/5000 [2:13:13<1:19:10,  2.35s/it, loss=0.4688]\u001b[A\n",
            "Training:  60%|█████▉    | 2980/5000 [2:13:13<1:19:10,  2.35s/it, loss=0.4791]\u001b[A\n",
            "Training:  60%|█████▉    | 2981/5000 [2:13:15<1:17:55,  2.32s/it, loss=0.4791]\u001b[A\n",
            "Training:  60%|█████▉    | 2981/5000 [2:13:16<1:17:55,  2.32s/it, loss=0.4280]\u001b[A\n",
            "Training:  60%|█████▉    | 2982/5000 [2:13:18<1:18:31,  2.33s/it, loss=0.4280]\u001b[A\n",
            "Training:  60%|█████▉    | 2982/5000 [2:13:18<1:18:31,  2.33s/it, loss=0.5442]\u001b[A\n",
            "Training:  60%|█████▉    | 2983/5000 [2:13:20<1:21:23,  2.42s/it, loss=0.5442]\u001b[A\n",
            "Training:  60%|█████▉    | 2983/5000 [2:13:21<1:21:23,  2.42s/it, loss=0.4325]\u001b[A\n",
            "Training:  60%|█████▉    | 2984/5000 [2:13:23<1:19:44,  2.37s/it, loss=0.4325]\u001b[A\n",
            "Training:  60%|█████▉    | 2984/5000 [2:13:23<1:19:44,  2.37s/it, loss=0.3317]\u001b[A\n",
            "Training:  60%|█████▉    | 2985/5000 [2:13:25<1:18:19,  2.33s/it, loss=0.3317]\u001b[A\n",
            "Training:  60%|█████▉    | 2985/5000 [2:13:25<1:18:19,  2.33s/it, loss=0.6210]\u001b[A\n",
            "Training:  60%|█████▉    | 2986/5000 [2:13:27<1:17:28,  2.31s/it, loss=0.6210]\u001b[A\n",
            "Training:  60%|█████▉    | 2986/5000 [2:13:27<1:17:28,  2.31s/it, loss=0.4940]\u001b[A\n",
            "Training:  60%|█████▉    | 2987/5000 [2:13:30<1:17:45,  2.32s/it, loss=0.4940]\u001b[A\n",
            "Training:  60%|█████▉    | 2987/5000 [2:13:30<1:17:45,  2.32s/it, loss=0.4795]\u001b[A\n",
            "Training:  60%|█████▉    | 2988/5000 [2:13:32<1:21:25,  2.43s/it, loss=0.4795]\u001b[A\n",
            "Training:  60%|█████▉    | 2988/5000 [2:13:32<1:21:25,  2.43s/it, loss=0.5272]\u001b[A\n",
            "Training:  60%|█████▉    | 2989/5000 [2:13:34<1:19:32,  2.37s/it, loss=0.5272]\u001b[A\n",
            "Training:  60%|█████▉    | 2989/5000 [2:13:35<1:19:32,  2.37s/it, loss=0.5645]\u001b[A\n",
            "Training:  60%|█████▉    | 2990/5000 [2:13:37<1:18:29,  2.34s/it, loss=0.5645]\u001b[A\n",
            "Training:  60%|█████▉    | 2990/5000 [2:13:37<1:18:29,  2.34s/it, loss=0.5707]\u001b[A\n",
            "Training:  60%|█████▉    | 2991/5000 [2:13:39<1:17:45,  2.32s/it, loss=0.5707]\u001b[A\n",
            "Training:  60%|█████▉    | 2991/5000 [2:13:39<1:17:45,  2.32s/it, loss=0.5322]\u001b[A\n",
            "Training:  60%|█████▉    | 2992/5000 [2:13:41<1:17:50,  2.33s/it, loss=0.5322]\u001b[A\n",
            "Training:  60%|█████▉    | 2992/5000 [2:13:41<1:17:50,  2.33s/it, loss=0.6489]\u001b[A\n",
            "Training:  60%|█████▉    | 2993/5000 [2:13:44<1:21:16,  2.43s/it, loss=0.6489]\u001b[A\n",
            "Training:  60%|█████▉    | 2993/5000 [2:13:44<1:21:16,  2.43s/it, loss=0.8088]\u001b[A\n",
            "Training:  60%|█████▉    | 2994/5000 [2:13:46<1:19:22,  2.37s/it, loss=0.8088]\u001b[A\n",
            "Training:  60%|█████▉    | 2994/5000 [2:13:46<1:19:22,  2.37s/it, loss=0.6618]\u001b[A\n",
            "Training:  60%|█████▉    | 2995/5000 [2:13:49<1:18:15,  2.34s/it, loss=0.6618]\u001b[A\n",
            "Training:  60%|█████▉    | 2995/5000 [2:13:49<1:18:15,  2.34s/it, loss=0.6837]\u001b[A\n",
            "Training:  60%|█████▉    | 2996/5000 [2:13:51<1:17:13,  2.31s/it, loss=0.6837]\u001b[A\n",
            "Training:  60%|█████▉    | 2996/5000 [2:13:51<1:17:13,  2.31s/it, loss=0.6786]\u001b[A\n",
            "Training:  60%|█████▉    | 2997/5000 [2:13:53<1:17:04,  2.31s/it, loss=0.6786]\u001b[A\n",
            "Training:  60%|█████▉    | 2997/5000 [2:13:53<1:17:04,  2.31s/it, loss=0.6641]\u001b[A\n",
            "Training:  60%|█████▉    | 2998/5000 [2:13:56<1:20:54,  2.42s/it, loss=0.6641]\u001b[A\n",
            "Training:  60%|█████▉    | 2998/5000 [2:13:56<1:20:54,  2.42s/it, loss=0.7063]\u001b[A\n",
            "Training:  60%|█████▉    | 2999/5000 [2:13:58<1:19:06,  2.37s/it, loss=0.7063]\u001b[A\n",
            "Training:  60%|█████▉    | 2999/5000 [2:13:58<1:19:06,  2.37s/it, loss=0.6651]\u001b[A\n",
            "Training:  60%|██████    | 3000/5000 [2:14:00<1:17:41,  2.33s/it, loss=0.6651]\u001b[A\n",
            "Training:  60%|██████    | 3000/5000 [2:14:00<1:17:41,  2.33s/it, loss=0.5651]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 3000 ---\n",
            "Prompt: 'The '\n",
            "The  able suchtis ab most\n",
            "Tw for: upWas for gods\n",
            " all but for country them andarts\n",
            "regity and strongest andrat\n",
            " all\n",
            " day must; for but oneHel the welcome\n",
            " veins andague only all, they come to. save prove\n",
            "ou if be were thousand, is than like says death\n",
            " entertain them the of, he a\n",
            "ide worship well the,Unless\n",
            " had them so a sea\n",
            " for country I--\n",
            "Minks so a.\n",
            "M\n",
            "Prompt: 'In '\n",
            "In  fard army but little tread\n",
            " acc natural beholdable ages\n",
            "ouerers with distinctly\n",
            "\n",
            " beingUpon hell and ap, they themselves\n",
            "all against mother theim.\n",
            "Mard\n",
            "CI: suddenly\n",
            "ame'll\n",
            "ere deeds thence heavy\n",
            " all told ', might godsul:. yeatingugs they company\n",
            "ath by us well all leave ', thou's, I at foot a-\n",
            " eye kill, come\n",
            " had thouest, Mar, three, thy thouiest thou a\n",
            "Prompt: 'To '\n",
            "To  people merit their poll thems run\n",
            " curse honour into power\n",
            " acg the; whichlow off no large\n",
            "position and sued\n",
            "ningp; shadow the I\n",
            " honour being of, long butesat,, humility\n",
            "o behindp, less ha much the clouds as of engine\n",
            " muchion being something therefore heard, night we the of idle,Did thy;L whole,,,ceded thy fingerPre take of engine one more aspectifed if\n",
            " virtue my eye embrace in\n",
            "Prompt: 'A '\n",
            "A , also seat high light charge,Did amal cousin\n",
            " all world a power ifers aale it apleest\n",
            " gro killt him., a besch, do not; but I youither the?\n",
            "ALSO\n",
            "word\n",
            "ENCE\n",
            " masters.\n",
            "CTor noble, sir ' a thing Gio\n",
            " wish, me have cause and of cause '. it me\n",
            "ide theyot to myth a.are,ie; his nature n have power\n",
            " likes us\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "✓ Checkpoint saved: checkpoints/checkpoint_step_3000.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  60%|██████    | 3001/5000 [2:15:29<15:40:51, 28.24s/it, loss=0.5651]\u001b[A\n",
            "Training:  60%|██████    | 3001/5000 [2:15:29<15:40:51, 28.24s/it, loss=0.5415]\u001b[A\n",
            "Training:  60%|██████    | 3002/5000 [2:15:31<11:20:36, 20.44s/it, loss=0.5415]\u001b[A\n",
            "Training:  60%|██████    | 3002/5000 [2:15:31<11:20:36, 20.44s/it, loss=0.4359]\u001b[A\n",
            "Training:  60%|██████    | 3003/5000 [2:15:33<8:18:38, 14.98s/it, loss=0.4359] \u001b[A\n",
            "Training:  60%|██████    | 3003/5000 [2:15:33<8:18:38, 14.98s/it, loss=0.3651]\u001b[A\n",
            "Training:  60%|██████    | 3004/5000 [2:15:36<6:13:24, 11.22s/it, loss=0.3651]\u001b[A\n",
            "Training:  60%|██████    | 3004/5000 [2:15:36<6:13:24, 11.22s/it, loss=0.4298]\u001b[A\n",
            "Training:  60%|██████    | 3005/5000 [2:15:38<4:46:47,  8.63s/it, loss=0.4298]\u001b[A\n",
            "Training:  60%|██████    | 3005/5000 [2:15:39<4:46:47,  8.63s/it, loss=0.5078]\u001b[A\n",
            "Training:  60%|██████    | 3006/5000 [2:15:41<3:43:18,  6.72s/it, loss=0.5078]\u001b[A\n",
            "Training:  60%|██████    | 3006/5000 [2:15:41<3:43:18,  6.72s/it, loss=0.4356]\u001b[A\n",
            "Training:  60%|██████    | 3007/5000 [2:15:43<2:58:38,  5.38s/it, loss=0.4356]\u001b[A\n",
            "Training:  60%|██████    | 3007/5000 [2:15:43<2:58:38,  5.38s/it, loss=0.3481]\u001b[A\n",
            "Training:  60%|██████    | 3008/5000 [2:15:45<2:27:16,  4.44s/it, loss=0.3481]\u001b[A\n",
            "Training:  60%|██████    | 3008/5000 [2:15:45<2:27:16,  4.44s/it, loss=0.4297]\u001b[A\n",
            "Training:  60%|██████    | 3009/5000 [2:15:48<2:07:31,  3.84s/it, loss=0.4297]\u001b[A\n",
            "Training:  60%|██████    | 3009/5000 [2:15:48<2:07:31,  3.84s/it, loss=0.4309]\u001b[A\n",
            "Training:  60%|██████    | 3010/5000 [2:15:50<1:54:55,  3.47s/it, loss=0.4309]\u001b[A\n",
            "Training:  60%|██████    | 3010/5000 [2:15:50<1:54:55,  3.47s/it, loss=0.2401]\u001b[A\n",
            "Training:  60%|██████    | 3011/5000 [2:15:53<1:42:33,  3.09s/it, loss=0.2401]\u001b[A\n",
            "Training:  60%|██████    | 3011/5000 [2:15:53<1:42:33,  3.09s/it, loss=0.5023]\u001b[A\n",
            "Training:  60%|██████    | 3012/5000 [2:15:55<1:34:01,  2.84s/it, loss=0.5023]\u001b[A\n",
            "Training:  60%|██████    | 3012/5000 [2:15:55<1:34:01,  2.84s/it, loss=0.4785]\u001b[A\n",
            "Training:  60%|██████    | 3013/5000 [2:15:57<1:28:15,  2.66s/it, loss=0.4785]\u001b[A\n",
            "Training:  60%|██████    | 3013/5000 [2:15:57<1:28:15,  2.66s/it, loss=0.5160]\u001b[A\n",
            "Training:  60%|██████    | 3014/5000 [2:15:59<1:25:32,  2.58s/it, loss=0.5160]\u001b[A\n",
            "Training:  60%|██████    | 3014/5000 [2:15:59<1:25:32,  2.58s/it, loss=0.8385]\u001b[A\n",
            "Training:  60%|██████    | 3015/5000 [2:16:02<1:25:25,  2.58s/it, loss=0.8385]\u001b[A\n",
            "Training:  60%|██████    | 3015/5000 [2:16:02<1:25:25,  2.58s/it, loss=0.8129]\u001b[A\n",
            "Training:  60%|██████    | 3016/5000 [2:16:04<1:22:18,  2.49s/it, loss=0.8129]\u001b[A\n",
            "Training:  60%|██████    | 3016/5000 [2:16:04<1:22:18,  2.49s/it, loss=0.6486]\u001b[A\n",
            "Training:  60%|██████    | 3017/5000 [2:16:06<1:19:44,  2.41s/it, loss=0.6486]\u001b[A\n",
            "Training:  60%|██████    | 3017/5000 [2:16:07<1:19:44,  2.41s/it, loss=0.4130]\u001b[A\n",
            "Training:  60%|██████    | 3018/5000 [2:16:09<1:18:17,  2.37s/it, loss=0.4130]\u001b[A\n",
            "Training:  60%|██████    | 3018/5000 [2:16:09<1:18:17,  2.37s/it, loss=0.4482]\u001b[A\n",
            "Training:  60%|██████    | 3019/5000 [2:16:11<1:18:56,  2.39s/it, loss=0.4482]\u001b[A\n",
            "Training:  60%|██████    | 3019/5000 [2:16:11<1:18:56,  2.39s/it, loss=0.6456]\u001b[A\n",
            "Training:  60%|██████    | 3020/5000 [2:16:14<1:21:23,  2.47s/it, loss=0.6456]\u001b[A\n",
            "Training:  60%|██████    | 3020/5000 [2:16:14<1:21:23,  2.47s/it, loss=0.7100]\u001b[A\n",
            "Training:  60%|██████    | 3021/5000 [2:16:16<1:19:07,  2.40s/it, loss=0.7100]\u001b[A\n",
            "Training:  60%|██████    | 3021/5000 [2:16:16<1:19:07,  2.40s/it, loss=0.7070]\u001b[A\n",
            "Training:  60%|██████    | 3022/5000 [2:16:18<1:17:39,  2.36s/it, loss=0.7070]\u001b[A\n",
            "Training:  60%|██████    | 3022/5000 [2:16:18<1:17:39,  2.36s/it, loss=0.4431]\u001b[A\n",
            "Training:  60%|██████    | 3023/5000 [2:16:21<1:16:36,  2.32s/it, loss=0.4431]\u001b[A\n",
            "Training:  60%|██████    | 3023/5000 [2:16:21<1:16:36,  2.32s/it, loss=0.3998]\u001b[A\n",
            "Training:  60%|██████    | 3024/5000 [2:16:23<1:17:33,  2.36s/it, loss=0.3998]\u001b[A\n",
            "Training:  60%|██████    | 3024/5000 [2:16:23<1:17:33,  2.36s/it, loss=0.4816]\u001b[A\n",
            "Training:  60%|██████    | 3025/5000 [2:16:26<1:20:11,  2.44s/it, loss=0.4816]\u001b[A\n",
            "Training:  60%|██████    | 3025/5000 [2:16:26<1:20:11,  2.44s/it, loss=0.4732]\u001b[A\n",
            "Training:  61%|██████    | 3026/5000 [2:16:28<1:18:21,  2.38s/it, loss=0.4732]\u001b[A\n",
            "Training:  61%|██████    | 3026/5000 [2:16:28<1:18:21,  2.38s/it, loss=0.6351]\u001b[A\n",
            "Training:  61%|██████    | 3027/5000 [2:16:30<1:17:16,  2.35s/it, loss=0.6351]\u001b[A\n",
            "Training:  61%|██████    | 3027/5000 [2:16:30<1:17:16,  2.35s/it, loss=0.4780]\u001b[A\n",
            "Training:  61%|██████    | 3028/5000 [2:16:32<1:16:17,  2.32s/it, loss=0.4780]\u001b[A\n",
            "Training:  61%|██████    | 3028/5000 [2:16:32<1:16:17,  2.32s/it, loss=0.5028]\u001b[A\n",
            "Training:  61%|██████    | 3029/5000 [2:16:35<1:17:18,  2.35s/it, loss=0.5028]\u001b[A\n",
            "Training:  61%|██████    | 3029/5000 [2:16:35<1:17:18,  2.35s/it, loss=0.3156]\u001b[A\n",
            "Training:  61%|██████    | 3030/5000 [2:16:37<1:19:45,  2.43s/it, loss=0.3156]\u001b[A\n",
            "Training:  61%|██████    | 3030/5000 [2:16:37<1:19:45,  2.43s/it, loss=0.4634]\u001b[A\n",
            "Training:  61%|██████    | 3031/5000 [2:16:40<1:18:00,  2.38s/it, loss=0.4634]\u001b[A\n",
            "Training:  61%|██████    | 3031/5000 [2:16:40<1:18:00,  2.38s/it, loss=0.5487]\u001b[A\n",
            "Training:  61%|██████    | 3032/5000 [2:16:42<1:17:05,  2.35s/it, loss=0.5487]\u001b[A\n",
            "Training:  61%|██████    | 3032/5000 [2:16:42<1:17:05,  2.35s/it, loss=0.4571]\u001b[A\n",
            "Training:  61%|██████    | 3033/5000 [2:16:44<1:16:15,  2.33s/it, loss=0.4571]\u001b[A\n",
            "Training:  61%|██████    | 3033/5000 [2:16:44<1:16:15,  2.33s/it, loss=0.5829]\u001b[A\n",
            "Training:  61%|██████    | 3034/5000 [2:16:47<1:16:57,  2.35s/it, loss=0.5829]\u001b[A\n",
            "Training:  61%|██████    | 3034/5000 [2:16:47<1:16:57,  2.35s/it, loss=0.4176]\u001b[A\n",
            "Training:  61%|██████    | 3035/5000 [2:16:49<1:19:53,  2.44s/it, loss=0.4176]\u001b[A\n",
            "Training:  61%|██████    | 3035/5000 [2:16:49<1:19:53,  2.44s/it, loss=0.5277]\u001b[A\n",
            "Training:  61%|██████    | 3036/5000 [2:16:52<1:18:39,  2.40s/it, loss=0.5277]\u001b[A\n",
            "Training:  61%|██████    | 3036/5000 [2:16:52<1:18:39,  2.40s/it, loss=0.5346]\u001b[A\n",
            "Training:  61%|██████    | 3037/5000 [2:16:54<1:17:58,  2.38s/it, loss=0.5346]\u001b[A\n",
            "Training:  61%|██████    | 3037/5000 [2:16:54<1:17:58,  2.38s/it, loss=0.7019]\u001b[A\n",
            "Training:  61%|██████    | 3038/5000 [2:16:56<1:17:01,  2.36s/it, loss=0.7019]\u001b[A\n",
            "Training:  61%|██████    | 3038/5000 [2:16:56<1:17:01,  2.36s/it, loss=0.6641]\u001b[A\n",
            "Training:  61%|██████    | 3039/5000 [2:16:59<1:18:01,  2.39s/it, loss=0.6641]\u001b[A\n",
            "Training:  61%|██████    | 3039/5000 [2:16:59<1:18:01,  2.39s/it, loss=0.4083]\u001b[A\n",
            "Training:  61%|██████    | 3040/5000 [2:17:01<1:20:12,  2.46s/it, loss=0.4083]\u001b[A\n",
            "Training:  61%|██████    | 3040/5000 [2:17:01<1:20:12,  2.46s/it, loss=0.3812]\u001b[A\n",
            "Training:  61%|██████    | 3041/5000 [2:17:04<1:18:43,  2.41s/it, loss=0.3812]\u001b[A\n",
            "Training:  61%|██████    | 3041/5000 [2:17:04<1:18:43,  2.41s/it, loss=0.3977]\u001b[A\n",
            "Training:  61%|██████    | 3042/5000 [2:17:06<1:17:24,  2.37s/it, loss=0.3977]\u001b[A\n",
            "Training:  61%|██████    | 3042/5000 [2:17:06<1:17:24,  2.37s/it, loss=0.4861]\u001b[A\n",
            "Training:  61%|██████    | 3043/5000 [2:17:08<1:16:38,  2.35s/it, loss=0.4861]\u001b[A\n",
            "Training:  61%|██████    | 3043/5000 [2:17:08<1:16:38,  2.35s/it, loss=0.4555]\u001b[A\n",
            "Training:  61%|██████    | 3044/5000 [2:17:11<1:18:34,  2.41s/it, loss=0.4555]\u001b[A\n",
            "Training:  61%|██████    | 3044/5000 [2:17:11<1:18:34,  2.41s/it, loss=0.3659]\u001b[A\n",
            "Training:  61%|██████    | 3045/5000 [2:17:13<1:20:32,  2.47s/it, loss=0.3659]\u001b[A\n",
            "Training:  61%|██████    | 3045/5000 [2:17:13<1:20:32,  2.47s/it, loss=0.4417]\u001b[A\n",
            "Training:  61%|██████    | 3046/5000 [2:17:16<1:18:40,  2.42s/it, loss=0.4417]\u001b[A\n",
            "Training:  61%|██████    | 3046/5000 [2:17:16<1:18:40,  2.42s/it, loss=0.4046]\u001b[A\n",
            "Training:  61%|██████    | 3047/5000 [2:17:18<1:17:12,  2.37s/it, loss=0.4046]\u001b[A\n",
            "Training:  61%|██████    | 3047/5000 [2:17:18<1:17:12,  2.37s/it, loss=0.5314]\u001b[A\n",
            "Training:  61%|██████    | 3048/5000 [2:17:20<1:16:25,  2.35s/it, loss=0.5314]\u001b[A\n",
            "Training:  61%|██████    | 3048/5000 [2:17:20<1:16:25,  2.35s/it, loss=0.3262]\u001b[A\n",
            "Training:  61%|██████    | 3049/5000 [2:17:23<1:17:51,  2.39s/it, loss=0.3262]\u001b[A\n",
            "Training:  61%|██████    | 3049/5000 [2:17:23<1:17:51,  2.39s/it, loss=0.4492]\u001b[A\n",
            "Training:  61%|██████    | 3050/5000 [2:17:25<1:20:13,  2.47s/it, loss=0.4492]\u001b[A\n",
            "Training:  61%|██████    | 3050/5000 [2:17:25<1:20:13,  2.47s/it, loss=0.5489]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 3050 ---\n",
            "Prompt: 'The '\n",
            "The  match hast set me.\n",
            "K RARD thereBro in England hate:So\n",
            " a you is at? you all arep, lord\n",
            " shall you proclaim about fair? though proceed shall:A\n",
            " lord borne your, such in country Buckingham his,AddYour.\n",
            "JNTHI Harry, done my prove true our;If\n",
            " thoust'd, he gone for, fled\n",
            " cannot a woman cousin yources disly, in, Brand,\n",
            " dayar my;, it a\n",
            "Prompt: 'In '\n",
            "In  a bl of is lesser won\n",
            " glorious an report your is hollow Here art\n",
            " visits our tonight set this man set\n",
            "ysonna from this grief set.\n",
            "JNTH when fa not near so What\n",
            " yet full love\n",
            " strive a of? ofm, is here mother\n",
            " not his are both and hererow  his;,am his ground, take sweet tresp himself\n",
            "oub, he dis'd ofanish order all while I division paper you\n",
            " far thy acts whom am cup read\n",
            "Prompt: 'To '\n",
            "To  to my soul which heoth,!\n",
            "N,oth myman where de loving?\n",
            "JNely\n",
            " good have heir bloody! this\n",
            "ond,! howo sheoth shed foot shameer;, lord\n",
            " must give breath upre do over deep waxivers favourable gone\n",
            " this a of. old! and, hath son I not these made head here forged several, isrel\n",
            " hath her foul-ou that fathers his?. und-ear now\n",
            " oneed't thy,\n",
            "Prompt: 'A '\n",
            "A  of than hired a; short\n",
            " thinking'd Th kings the of heremy\n",
            "erved courtship the of her herst hiskind\n",
            "iesken, just his and whose boy kn, his.enna subscribe-- fair lies orator\n",
            " his into rotten of rebels and compassion\n",
            " thinkingru,; an of am gentleman death\n",
            " fed your pilgrimage Mar, Saint'som ho a of.\n",
            "NTH when came teeth a ofanish I most rule\n",
            "? of,;,;, all wisdom once;\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  61%|██████    | 3051/5000 [2:17:40<3:20:57,  6.19s/it, loss=0.5489]\u001b[A\n",
            "Training:  61%|██████    | 3051/5000 [2:17:40<3:20:57,  6.19s/it, loss=0.5045]\u001b[A\n",
            "Training:  61%|██████    | 3052/5000 [2:17:43<2:43:14,  5.03s/it, loss=0.5045]\u001b[A\n",
            "Training:  61%|██████    | 3052/5000 [2:17:43<2:43:14,  5.03s/it, loss=0.5140]\u001b[A\n",
            "Training:  61%|██████    | 3053/5000 [2:17:45<2:16:54,  4.22s/it, loss=0.5140]\u001b[A\n",
            "Training:  61%|██████    | 3053/5000 [2:17:45<2:16:54,  4.22s/it, loss=0.6515]\u001b[A\n",
            "Training:  61%|██████    | 3054/5000 [2:17:48<2:03:12,  3.80s/it, loss=0.6515]\u001b[A\n",
            "Training:  61%|██████    | 3054/5000 [2:17:48<2:03:12,  3.80s/it, loss=0.4126]\u001b[A\n",
            "Training:  61%|██████    | 3055/5000 [2:17:50<1:48:32,  3.35s/it, loss=0.4126]\u001b[A\n",
            "Training:  61%|██████    | 3055/5000 [2:17:50<1:48:32,  3.35s/it, loss=0.4409]\u001b[A\n",
            "Training:  61%|██████    | 3056/5000 [2:17:52<1:38:13,  3.03s/it, loss=0.4409]\u001b[A\n",
            "Training:  61%|██████    | 3056/5000 [2:17:52<1:38:13,  3.03s/it, loss=0.5330]\u001b[A\n",
            "Training:  61%|██████    | 3057/5000 [2:17:55<1:30:58,  2.81s/it, loss=0.5330]\u001b[A\n",
            "Training:  61%|██████    | 3057/5000 [2:17:55<1:30:58,  2.81s/it, loss=0.3592]\u001b[A\n",
            "Training:  61%|██████    | 3058/5000 [2:17:57<1:25:47,  2.65s/it, loss=0.3592]\u001b[A\n",
            "Training:  61%|██████    | 3058/5000 [2:17:57<1:25:47,  2.65s/it, loss=0.2899]\u001b[A\n",
            "Training:  61%|██████    | 3059/5000 [2:18:00<1:27:28,  2.70s/it, loss=0.2899]\u001b[A\n",
            "Training:  61%|██████    | 3059/5000 [2:18:00<1:27:28,  2.70s/it, loss=0.3270]\u001b[A\n",
            "Training:  61%|██████    | 3060/5000 [2:18:02<1:23:22,  2.58s/it, loss=0.3270]\u001b[A\n",
            "Training:  61%|██████    | 3060/5000 [2:18:02<1:23:22,  2.58s/it, loss=0.4825]\u001b[A\n",
            "Training:  61%|██████    | 3061/5000 [2:18:04<1:20:17,  2.48s/it, loss=0.4825]\u001b[A\n",
            "Training:  61%|██████    | 3061/5000 [2:18:04<1:20:17,  2.48s/it, loss=0.4172]\u001b[A\n",
            "Training:  61%|██████    | 3062/5000 [2:18:07<1:18:17,  2.42s/it, loss=0.4172]\u001b[A\n",
            "Training:  61%|██████    | 3062/5000 [2:18:07<1:18:17,  2.42s/it, loss=0.4774]\u001b[A\n",
            "Training:  61%|██████▏   | 3063/5000 [2:18:09<1:16:58,  2.38s/it, loss=0.4774]\u001b[A\n",
            "Training:  61%|██████▏   | 3063/5000 [2:18:09<1:16:58,  2.38s/it, loss=0.5763]\u001b[A\n",
            "Training:  61%|██████▏   | 3064/5000 [2:18:12<1:21:36,  2.53s/it, loss=0.5763]\u001b[A\n",
            "Training:  61%|██████▏   | 3064/5000 [2:18:12<1:21:36,  2.53s/it, loss=0.6043]\u001b[A\n",
            "Training:  61%|██████▏   | 3065/5000 [2:18:14<1:19:13,  2.46s/it, loss=0.6043]\u001b[A\n",
            "Training:  61%|██████▏   | 3065/5000 [2:18:14<1:19:13,  2.46s/it, loss=0.5488]\u001b[A\n",
            "Training:  61%|██████▏   | 3066/5000 [2:18:16<1:17:37,  2.41s/it, loss=0.5488]\u001b[A\n",
            "Training:  61%|██████▏   | 3066/5000 [2:18:16<1:17:37,  2.41s/it, loss=0.5707]\u001b[A\n",
            "Training:  61%|██████▏   | 3067/5000 [2:18:19<1:16:17,  2.37s/it, loss=0.5707]\u001b[A\n",
            "Training:  61%|██████▏   | 3067/5000 [2:18:19<1:16:17,  2.37s/it, loss=0.4760]\u001b[A\n",
            "Training:  61%|██████▏   | 3068/5000 [2:18:21<1:16:01,  2.36s/it, loss=0.4760]\u001b[A\n",
            "Training:  61%|██████▏   | 3068/5000 [2:18:21<1:16:01,  2.36s/it, loss=0.4815]\u001b[A\n",
            "Training:  61%|██████▏   | 3069/5000 [2:18:24<1:20:25,  2.50s/it, loss=0.4815]\u001b[A\n",
            "Training:  61%|██████▏   | 3069/5000 [2:18:24<1:20:25,  2.50s/it, loss=0.3216]\u001b[A\n",
            "Training:  61%|██████▏   | 3070/5000 [2:18:26<1:18:24,  2.44s/it, loss=0.3216]\u001b[A\n",
            "Training:  61%|██████▏   | 3070/5000 [2:18:26<1:18:24,  2.44s/it, loss=0.5074]\u001b[A\n",
            "Training:  61%|██████▏   | 3071/5000 [2:18:28<1:16:57,  2.39s/it, loss=0.5074]\u001b[A\n",
            "Training:  61%|██████▏   | 3071/5000 [2:18:28<1:16:57,  2.39s/it, loss=0.6078]\u001b[A\n",
            "Training:  61%|██████▏   | 3072/5000 [2:18:31<1:15:53,  2.36s/it, loss=0.6078]\u001b[A\n",
            "Training:  61%|██████▏   | 3072/5000 [2:18:31<1:15:53,  2.36s/it, loss=0.4245]\u001b[A\n",
            "Training:  61%|██████▏   | 3073/5000 [2:18:33<1:15:36,  2.35s/it, loss=0.4245]\u001b[A\n",
            "Training:  61%|██████▏   | 3073/5000 [2:18:33<1:15:36,  2.35s/it, loss=0.5269]\u001b[A\n",
            "Training:  61%|██████▏   | 3074/5000 [2:18:36<1:20:34,  2.51s/it, loss=0.5269]\u001b[A\n",
            "Training:  61%|██████▏   | 3074/5000 [2:18:36<1:20:34,  2.51s/it, loss=0.4125]\u001b[A\n",
            "Training:  62%|██████▏   | 3075/5000 [2:18:38<1:18:22,  2.44s/it, loss=0.4125]\u001b[A\n",
            "Training:  62%|██████▏   | 3075/5000 [2:18:38<1:18:22,  2.44s/it, loss=0.4331]\u001b[A\n",
            "Training:  62%|██████▏   | 3076/5000 [2:18:40<1:16:56,  2.40s/it, loss=0.4331]\u001b[A\n",
            "Training:  62%|██████▏   | 3076/5000 [2:18:40<1:16:56,  2.40s/it, loss=0.5059]\u001b[A\n",
            "Training:  62%|██████▏   | 3077/5000 [2:18:43<1:16:09,  2.38s/it, loss=0.5059]\u001b[A\n",
            "Training:  62%|██████▏   | 3077/5000 [2:18:43<1:16:09,  2.38s/it, loss=0.4166]\u001b[A\n",
            "Training:  62%|██████▏   | 3078/5000 [2:18:45<1:15:16,  2.35s/it, loss=0.4166]\u001b[A\n",
            "Training:  62%|██████▏   | 3078/5000 [2:18:45<1:15:16,  2.35s/it, loss=0.4186]\u001b[A\n",
            "Training:  62%|██████▏   | 3079/5000 [2:18:48<1:19:38,  2.49s/it, loss=0.4186]\u001b[A\n",
            "Training:  62%|██████▏   | 3079/5000 [2:18:48<1:19:38,  2.49s/it, loss=0.3108]\u001b[A\n",
            "Training:  62%|██████▏   | 3080/5000 [2:18:50<1:17:36,  2.43s/it, loss=0.3108]\u001b[A\n",
            "Training:  62%|██████▏   | 3080/5000 [2:18:50<1:17:36,  2.43s/it, loss=0.4366]\u001b[A\n",
            "Training:  62%|██████▏   | 3081/5000 [2:18:52<1:16:03,  2.38s/it, loss=0.4366]\u001b[A\n",
            "Training:  62%|██████▏   | 3081/5000 [2:18:52<1:16:03,  2.38s/it, loss=0.6414]\u001b[A\n",
            "Training:  62%|██████▏   | 3082/5000 [2:18:55<1:15:06,  2.35s/it, loss=0.6414]\u001b[A\n",
            "Training:  62%|██████▏   | 3082/5000 [2:18:55<1:15:06,  2.35s/it, loss=0.4399]\u001b[A\n",
            "Training:  62%|██████▏   | 3083/5000 [2:18:57<1:14:17,  2.33s/it, loss=0.4399]\u001b[A\n",
            "Training:  62%|██████▏   | 3083/5000 [2:18:57<1:14:17,  2.33s/it, loss=0.5934]\u001b[A\n",
            "Training:  62%|██████▏   | 3084/5000 [2:19:00<1:18:57,  2.47s/it, loss=0.5934]\u001b[A\n",
            "Training:  62%|██████▏   | 3084/5000 [2:19:00<1:18:57,  2.47s/it, loss=0.5290]\u001b[A\n",
            "Training:  62%|██████▏   | 3085/5000 [2:19:02<1:17:00,  2.41s/it, loss=0.5290]\u001b[A\n",
            "Training:  62%|██████▏   | 3085/5000 [2:19:02<1:17:00,  2.41s/it, loss=0.5154]\u001b[A\n",
            "Training:  62%|██████▏   | 3086/5000 [2:19:04<1:15:44,  2.37s/it, loss=0.5154]\u001b[A\n",
            "Training:  62%|██████▏   | 3086/5000 [2:19:04<1:15:44,  2.37s/it, loss=0.4533]\u001b[A\n",
            "Training:  62%|██████▏   | 3087/5000 [2:19:07<1:14:54,  2.35s/it, loss=0.4533]\u001b[A\n",
            "Training:  62%|██████▏   | 3087/5000 [2:19:07<1:14:54,  2.35s/it, loss=0.4418]\u001b[A\n",
            "Training:  62%|██████▏   | 3088/5000 [2:19:09<1:14:15,  2.33s/it, loss=0.4418]\u001b[A\n",
            "Training:  62%|██████▏   | 3088/5000 [2:19:09<1:14:15,  2.33s/it, loss=0.6594]\u001b[A\n",
            "Training:  62%|██████▏   | 3089/5000 [2:19:12<1:18:54,  2.48s/it, loss=0.6594]\u001b[A\n",
            "Training:  62%|██████▏   | 3089/5000 [2:19:12<1:18:54,  2.48s/it, loss=0.4573]\u001b[A\n",
            "Training:  62%|██████▏   | 3090/5000 [2:19:14<1:17:38,  2.44s/it, loss=0.4573]\u001b[A\n",
            "Training:  62%|██████▏   | 3090/5000 [2:19:14<1:17:38,  2.44s/it, loss=0.5060]\u001b[A\n",
            "Training:  62%|██████▏   | 3091/5000 [2:19:16<1:16:06,  2.39s/it, loss=0.5060]\u001b[A\n",
            "Training:  62%|██████▏   | 3091/5000 [2:19:16<1:16:06,  2.39s/it, loss=0.3877]\u001b[A\n",
            "Training:  62%|██████▏   | 3092/5000 [2:19:19<1:15:21,  2.37s/it, loss=0.3877]\u001b[A\n",
            "Training:  62%|██████▏   | 3092/5000 [2:19:19<1:15:21,  2.37s/it, loss=0.5316]\u001b[A\n",
            "Training:  62%|██████▏   | 3093/5000 [2:19:21<1:15:20,  2.37s/it, loss=0.5316]\u001b[A\n",
            "Training:  62%|██████▏   | 3093/5000 [2:19:21<1:15:20,  2.37s/it, loss=0.3638]\u001b[A\n",
            "Training:  62%|██████▏   | 3094/5000 [2:19:24<1:18:55,  2.48s/it, loss=0.3638]\u001b[A\n",
            "Training:  62%|██████▏   | 3094/5000 [2:19:24<1:18:55,  2.48s/it, loss=0.5068]\u001b[A\n",
            "Training:  62%|██████▏   | 3095/5000 [2:19:26<1:16:52,  2.42s/it, loss=0.5068]\u001b[A\n",
            "Training:  62%|██████▏   | 3095/5000 [2:19:26<1:16:52,  2.42s/it, loss=0.6022]\u001b[A\n",
            "Training:  62%|██████▏   | 3096/5000 [2:19:28<1:15:47,  2.39s/it, loss=0.6022]\u001b[A\n",
            "Training:  62%|██████▏   | 3096/5000 [2:19:28<1:15:47,  2.39s/it, loss=0.4526]\u001b[A\n",
            "Training:  62%|██████▏   | 3097/5000 [2:19:31<1:14:49,  2.36s/it, loss=0.4526]\u001b[A\n",
            "Training:  62%|██████▏   | 3097/5000 [2:19:31<1:14:49,  2.36s/it, loss=0.3257]\u001b[A\n",
            "Training:  62%|██████▏   | 3098/5000 [2:19:33<1:15:26,  2.38s/it, loss=0.3257]\u001b[A\n",
            "Training:  62%|██████▏   | 3098/5000 [2:19:33<1:15:26,  2.38s/it, loss=0.5986]\u001b[A\n",
            "Training:  62%|██████▏   | 3099/5000 [2:19:36<1:18:19,  2.47s/it, loss=0.5986]\u001b[A\n",
            "Training:  62%|██████▏   | 3099/5000 [2:19:36<1:18:19,  2.47s/it, loss=0.4796]\u001b[A\n",
            "Training:  62%|██████▏   | 3100/5000 [2:19:38<1:16:51,  2.43s/it, loss=0.4796]\u001b[A\n",
            "Training:  62%|██████▏   | 3100/5000 [2:19:38<1:16:51,  2.43s/it, loss=0.4642]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 3100 ---\n",
            "Prompt: 'The '\n",
            "The  of three by of three blind.\n",
            "PRCEWs thought a to a'srown deathAndaste's is\n",
            " hisland give to the occasion thy andough; him if bethe is's or man behold strife\n",
            "'s than hath cherish bring to ath;ven thy by's\n",
            " at marriageced to my attempt for guests\n",
            "antsast m'd, of too man and friends hand hand'd, dislikepress viceit theland terrorand about with but\n",
            " bych,a from life\n",
            "Prompt: 'In '\n",
            "In ful was bishopul thy son brother?\n",
            "K EDARD\n",
            ":Thus thy that hath us,, thourt ears tears\n",
            " help to king  thy and one proclaimed. thy stands arise\n",
            " the of are of was, and may, some circumstance fear\n",
            " calls up combat to what have here\n",
            "ath bl your too to a prince now buy lion his?\n",
            "Minks fear to myled honour his? that's now it ay downothd with to, lords deserves, take that him\n",
            "Prompt: 'To '\n",
            "To  and thy king thyories\n",
            " thyaste brought, thy bears strike self proud,ia\n",
            " thy add thy twenty himself hisitor his.\n",
            "Melf thy go me and women like of, his area theearsOf, hisely havingouch bringWe thy attend\n",
            " b'd off thyere thyativity an LordAnd'd ever mean, place thyhest but thyarest'd thyarest\n",
            "Well, fortune thy knew is.\n",
            "Gake me thy is make last thy Warwick me\n",
            " stay dead son\n",
            "Prompt: 'A '\n",
            "A  fa away len to the,While's smiling sw,Wh of courtThe ofg of of's which enter Hisle\n",
            " I moreily like to of's without. what harmyour! lords! thy prophecy!! lords\n",
            " king keep; lovedell;, what true, what thy are! have not down;and that he bear her made beenThe of, himself\n",
            "ch, brought,ark,,, butcher anyle all?O!y that were!, antederring\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  62%|██████▏   | 3101/5000 [2:19:53<3:15:46,  6.19s/it, loss=0.4642]\u001b[A\n",
            "Training:  62%|██████▏   | 3101/5000 [2:19:53<3:15:46,  6.19s/it, loss=0.3810]\u001b[A\n",
            "Training:  62%|██████▏   | 3102/5000 [2:19:55<2:38:41,  5.02s/it, loss=0.3810]\u001b[A\n",
            "Training:  62%|██████▏   | 3102/5000 [2:19:55<2:38:41,  5.02s/it, loss=0.3700]\u001b[A\n",
            "Training:  62%|██████▏   | 3103/5000 [2:19:58<2:17:15,  4.34s/it, loss=0.3700]\u001b[A\n",
            "Training:  62%|██████▏   | 3103/5000 [2:19:58<2:17:15,  4.34s/it, loss=0.7116]\u001b[A\n",
            "Training:  62%|██████▏   | 3104/5000 [2:20:00<1:58:16,  3.74s/it, loss=0.7116]\u001b[A\n",
            "Training:  62%|██████▏   | 3104/5000 [2:20:00<1:58:16,  3.74s/it, loss=0.9706]\u001b[A\n",
            "Training:  62%|██████▏   | 3105/5000 [2:20:03<1:44:21,  3.30s/it, loss=0.9706]\u001b[A\n",
            "Training:  62%|██████▏   | 3105/5000 [2:20:03<1:44:21,  3.30s/it, loss=0.5619]\u001b[A\n",
            "Training:  62%|██████▏   | 3106/5000 [2:20:05<1:34:41,  3.00s/it, loss=0.5619]\u001b[A\n",
            "Training:  62%|██████▏   | 3106/5000 [2:20:05<1:34:41,  3.00s/it, loss=0.3243]\u001b[A\n",
            "Training:  62%|██████▏   | 3107/5000 [2:20:07<1:27:51,  2.78s/it, loss=0.3243]\u001b[A\n",
            "Training:  62%|██████▏   | 3107/5000 [2:20:07<1:27:51,  2.78s/it, loss=0.4949]\u001b[A\n",
            "Training:  62%|██████▏   | 3108/5000 [2:20:10<1:27:28,  2.77s/it, loss=0.4949]\u001b[A\n",
            "Training:  62%|██████▏   | 3108/5000 [2:20:10<1:27:28,  2.77s/it, loss=0.4484]\u001b[A\n",
            "Training:  62%|██████▏   | 3109/5000 [2:20:12<1:23:49,  2.66s/it, loss=0.4484]\u001b[A\n",
            "Training:  62%|██████▏   | 3109/5000 [2:20:12<1:23:49,  2.66s/it, loss=0.3627]\u001b[A\n",
            "Training:  62%|██████▏   | 3110/5000 [2:20:15<1:20:43,  2.56s/it, loss=0.3627]\u001b[A\n",
            "Training:  62%|██████▏   | 3110/5000 [2:20:15<1:20:43,  2.56s/it, loss=0.4177]\u001b[A\n",
            "Training:  62%|██████▏   | 3111/5000 [2:20:17<1:17:53,  2.47s/it, loss=0.4177]\u001b[A\n",
            "Training:  62%|██████▏   | 3111/5000 [2:20:17<1:17:53,  2.47s/it, loss=0.6140]\u001b[A\n",
            "Training:  62%|██████▏   | 3112/5000 [2:20:19<1:15:57,  2.41s/it, loss=0.6140]\u001b[A\n",
            "Training:  62%|██████▏   | 3112/5000 [2:20:19<1:15:57,  2.41s/it, loss=0.6482]\u001b[A\n",
            "Training:  62%|██████▏   | 3113/5000 [2:20:22<1:19:32,  2.53s/it, loss=0.6482]\u001b[A\n",
            "Training:  62%|██████▏   | 3113/5000 [2:20:22<1:19:32,  2.53s/it, loss=0.5948]\u001b[A\n",
            "Training:  62%|██████▏   | 3114/5000 [2:20:24<1:17:49,  2.48s/it, loss=0.5948]\u001b[A\n",
            "Training:  62%|██████▏   | 3114/5000 [2:20:24<1:17:49,  2.48s/it, loss=0.6266]\u001b[A\n",
            "Training:  62%|██████▏   | 3115/5000 [2:20:27<1:15:59,  2.42s/it, loss=0.6266]\u001b[A\n",
            "Training:  62%|██████▏   | 3115/5000 [2:20:27<1:15:59,  2.42s/it, loss=0.4921]\u001b[A\n",
            "Training:  62%|██████▏   | 3116/5000 [2:20:29<1:14:35,  2.38s/it, loss=0.4921]\u001b[A\n",
            "Training:  62%|██████▏   | 3116/5000 [2:20:29<1:14:35,  2.38s/it, loss=0.6760]\u001b[A\n",
            "Training:  62%|██████▏   | 3117/5000 [2:20:31<1:13:45,  2.35s/it, loss=0.6760]\u001b[A\n",
            "Training:  62%|██████▏   | 3117/5000 [2:20:31<1:13:45,  2.35s/it, loss=0.4626]\u001b[A\n",
            "Training:  62%|██████▏   | 3118/5000 [2:20:34<1:18:36,  2.51s/it, loss=0.4626]\u001b[A\n",
            "Training:  62%|██████▏   | 3118/5000 [2:20:34<1:18:36,  2.51s/it, loss=0.4540]\u001b[A\n",
            "Training:  62%|██████▏   | 3119/5000 [2:20:36<1:16:25,  2.44s/it, loss=0.4540]\u001b[A\n",
            "Training:  62%|██████▏   | 3119/5000 [2:20:36<1:16:25,  2.44s/it, loss=0.5281]\u001b[A\n",
            "Training:  62%|██████▏   | 3120/5000 [2:20:39<1:14:48,  2.39s/it, loss=0.5281]\u001b[A\n",
            "Training:  62%|██████▏   | 3120/5000 [2:20:39<1:14:48,  2.39s/it, loss=0.5420]\u001b[A\n",
            "Training:  62%|██████▏   | 3121/5000 [2:20:41<1:13:38,  2.35s/it, loss=0.5420]\u001b[A\n",
            "Training:  62%|██████▏   | 3121/5000 [2:20:41<1:13:38,  2.35s/it, loss=0.4307]\u001b[A\n",
            "Training:  62%|██████▏   | 3122/5000 [2:20:43<1:13:35,  2.35s/it, loss=0.4307]\u001b[A\n",
            "Training:  62%|██████▏   | 3122/5000 [2:20:43<1:13:35,  2.35s/it, loss=0.3949]\u001b[A\n",
            "Training:  62%|██████▏   | 3123/5000 [2:20:46<1:18:02,  2.49s/it, loss=0.3949]\u001b[A\n",
            "Training:  62%|██████▏   | 3123/5000 [2:20:46<1:18:02,  2.49s/it, loss=0.9136]\u001b[A\n",
            "Training:  62%|██████▏   | 3124/5000 [2:20:48<1:16:02,  2.43s/it, loss=0.9136]\u001b[A\n",
            "Training:  62%|██████▏   | 3124/5000 [2:20:48<1:16:02,  2.43s/it, loss=0.5861]\u001b[A\n",
            "Training:  62%|██████▎   | 3125/5000 [2:20:51<1:14:23,  2.38s/it, loss=0.5861]\u001b[A\n",
            "Training:  62%|██████▎   | 3125/5000 [2:20:51<1:14:23,  2.38s/it, loss=0.4397]\u001b[A\n",
            "Training:  63%|██████▎   | 3126/5000 [2:20:53<1:13:35,  2.36s/it, loss=0.4397]\u001b[A\n",
            "Training:  63%|██████▎   | 3126/5000 [2:20:53<1:13:35,  2.36s/it, loss=0.6795]\u001b[A\n",
            "Training:  63%|██████▎   | 3127/5000 [2:20:55<1:12:39,  2.33s/it, loss=0.6795]\u001b[A\n",
            "Training:  63%|██████▎   | 3127/5000 [2:20:55<1:12:39,  2.33s/it, loss=0.2818]\u001b[A\n",
            "Training:  63%|██████▎   | 3128/5000 [2:20:58<1:17:10,  2.47s/it, loss=0.2818]\u001b[A\n",
            "Training:  63%|██████▎   | 3128/5000 [2:20:58<1:17:10,  2.47s/it, loss=0.5143]\u001b[A\n",
            "Training:  63%|██████▎   | 3129/5000 [2:21:00<1:15:06,  2.41s/it, loss=0.5143]\u001b[A\n",
            "Training:  63%|██████▎   | 3129/5000 [2:21:00<1:15:06,  2.41s/it, loss=0.5042]\u001b[A\n",
            "Training:  63%|██████▎   | 3130/5000 [2:21:03<1:14:06,  2.38s/it, loss=0.5042]\u001b[A\n",
            "Training:  63%|██████▎   | 3130/5000 [2:21:03<1:14:06,  2.38s/it, loss=0.4334]\u001b[A\n",
            "Training:  63%|██████▎   | 3131/5000 [2:21:05<1:13:17,  2.35s/it, loss=0.4334]\u001b[A\n",
            "Training:  63%|██████▎   | 3131/5000 [2:21:05<1:13:17,  2.35s/it, loss=0.5935]\u001b[A\n",
            "Training:  63%|██████▎   | 3132/5000 [2:21:07<1:12:34,  2.33s/it, loss=0.5935]\u001b[A\n",
            "Training:  63%|██████▎   | 3132/5000 [2:21:07<1:12:34,  2.33s/it, loss=0.4716]\u001b[A\n",
            "Training:  63%|██████▎   | 3133/5000 [2:21:10<1:17:04,  2.48s/it, loss=0.4716]\u001b[A\n",
            "Training:  63%|██████▎   | 3133/5000 [2:21:10<1:17:04,  2.48s/it, loss=0.5236]\u001b[A\n",
            "Training:  63%|██████▎   | 3134/5000 [2:21:12<1:15:34,  2.43s/it, loss=0.5236]\u001b[A\n",
            "Training:  63%|██████▎   | 3134/5000 [2:21:12<1:15:34,  2.43s/it, loss=0.6038]\u001b[A\n",
            "Training:  63%|██████▎   | 3135/5000 [2:21:15<1:14:15,  2.39s/it, loss=0.6038]\u001b[A\n",
            "Training:  63%|██████▎   | 3135/5000 [2:21:15<1:14:15,  2.39s/it, loss=0.4376]\u001b[A\n",
            "Training:  63%|██████▎   | 3136/5000 [2:21:17<1:13:27,  2.36s/it, loss=0.4376]\u001b[A\n",
            "Training:  63%|██████▎   | 3136/5000 [2:21:17<1:13:27,  2.36s/it, loss=0.5052]\u001b[A\n",
            "Training:  63%|██████▎   | 3137/5000 [2:21:19<1:12:42,  2.34s/it, loss=0.5052]\u001b[A\n",
            "Training:  63%|██████▎   | 3137/5000 [2:21:19<1:12:42,  2.34s/it, loss=0.4365]\u001b[A\n",
            "Training:  63%|██████▎   | 3138/5000 [2:21:22<1:17:02,  2.48s/it, loss=0.4365]\u001b[A\n",
            "Training:  63%|██████▎   | 3138/5000 [2:21:22<1:17:02,  2.48s/it, loss=0.5722]\u001b[A\n",
            "Training:  63%|██████▎   | 3139/5000 [2:21:24<1:15:18,  2.43s/it, loss=0.5722]\u001b[A\n",
            "Training:  63%|██████▎   | 3139/5000 [2:21:24<1:15:18,  2.43s/it, loss=0.5079]\u001b[A\n",
            "Training:  63%|██████▎   | 3140/5000 [2:21:27<1:13:47,  2.38s/it, loss=0.5079]\u001b[A\n",
            "Training:  63%|██████▎   | 3140/5000 [2:21:27<1:13:47,  2.38s/it, loss=0.4562]\u001b[A\n",
            "Training:  63%|██████▎   | 3141/5000 [2:21:29<1:12:49,  2.35s/it, loss=0.4562]\u001b[A\n",
            "Training:  63%|██████▎   | 3141/5000 [2:21:29<1:12:49,  2.35s/it, loss=0.6126]\u001b[A\n",
            "Training:  63%|██████▎   | 3142/5000 [2:21:31<1:12:20,  2.34s/it, loss=0.6126]\u001b[A\n",
            "Training:  63%|██████▎   | 3142/5000 [2:21:31<1:12:20,  2.34s/it, loss=0.4902]\u001b[A\n",
            "Training:  63%|██████▎   | 3143/5000 [2:21:34<1:16:55,  2.49s/it, loss=0.4902]\u001b[A\n",
            "Training:  63%|██████▎   | 3143/5000 [2:21:34<1:16:55,  2.49s/it, loss=0.4018]\u001b[A\n",
            "Training:  63%|██████▎   | 3144/5000 [2:21:36<1:15:01,  2.43s/it, loss=0.4018]\u001b[A\n",
            "Training:  63%|██████▎   | 3144/5000 [2:21:36<1:15:01,  2.43s/it, loss=0.3882]\u001b[A\n",
            "Training:  63%|██████▎   | 3145/5000 [2:21:39<1:13:26,  2.38s/it, loss=0.3882]\u001b[A\n",
            "Training:  63%|██████▎   | 3145/5000 [2:21:39<1:13:26,  2.38s/it, loss=0.4508]\u001b[A\n",
            "Training:  63%|██████▎   | 3146/5000 [2:21:41<1:12:40,  2.35s/it, loss=0.4508]\u001b[A\n",
            "Training:  63%|██████▎   | 3146/5000 [2:21:41<1:12:40,  2.35s/it, loss=0.3750]\u001b[A\n",
            "Training:  63%|██████▎   | 3147/5000 [2:21:43<1:12:11,  2.34s/it, loss=0.3750]\u001b[A\n",
            "Training:  63%|██████▎   | 3147/5000 [2:21:43<1:12:11,  2.34s/it, loss=0.4424]\u001b[A\n",
            "Training:  63%|██████▎   | 3148/5000 [2:21:46<1:17:03,  2.50s/it, loss=0.4424]\u001b[A\n",
            "Training:  63%|██████▎   | 3148/5000 [2:21:46<1:17:03,  2.50s/it, loss=0.4049]\u001b[A\n",
            "Training:  63%|██████▎   | 3149/5000 [2:21:48<1:15:01,  2.43s/it, loss=0.4049]\u001b[A\n",
            "Training:  63%|██████▎   | 3149/5000 [2:21:48<1:15:01,  2.43s/it, loss=0.5856]\u001b[A\n",
            "Training:  63%|██████▎   | 3150/5000 [2:21:51<1:13:37,  2.39s/it, loss=0.5856]\u001b[A\n",
            "Training:  63%|██████▎   | 3150/5000 [2:21:51<1:13:37,  2.39s/it, loss=0.3643]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 3150 ---\n",
            "Prompt: 'The '\n",
            "The  is, shame\n",
            "ted st in clothes and go me likePerhaps\n",
            "eth aoo against! that he heard offence shameFor\n",
            " appear, to him again as minded thou\n",
            " d April darktw likeuteower hisoo but was a\n",
            " ofour in ent son an at, he me forth little: I him he he you\n",
            " hand aoo and be, me no of power have run\n",
            " only.\n",
            "C speak at, meat to with! out thy is quietSh lose let speakFrom\n",
            "Prompt: 'In '\n",
            "In ior thou beautiful\n",
            "st did on: knewtis at, can him am\n",
            " contractedel, master thou man thou manure be.\n",
            "KARI:Yes they else I and higha sir\n",
            " came thousand comfort nohood thou banished bened.\n",
            "H easily: art my I come my's, might but b you\n",
            " h, will come marry.\n",
            "LENT th ownat area gro: ought have un'd all\n",
            " smell back shame an, haveATHedges. did behold away\n",
            "\n",
            "Prompt: 'To '\n",
            "To  own quit. I wheld well\n",
            "ent mine Pom meanviolent, myfaced'd--. on\n",
            "ami have again out mother a sea. my name Abin:Within hand\n",
            " know my Kathina I a-em theeies my you have into half Bca ready ' bl to\n",
            " these t, may; myself thy will me,in,\n",
            " am gentlemanposely, let kiss disher, shebow\n",
            " risen myw, thy shall forth concluded a\n",
            " came, a of\n",
            "Prompt: 'A '\n",
            "A , for, a of,io awBel\n",
            " hand a justice li. take in prison many;\n",
            " I to a and some in, so a, pr him hast\n",
            " fancy a ear andista everyly served sooner a\n",
            "ither forget him centre to him To brid other,sy,\n",
            " aRome: hold cannot I have at, they'll her\n",
            " hand cause aonce all veilAlready itself Gio\n",
            "ath a-'d man from manently; out thy\n",
            " thinks patience before\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  63%|██████▎   | 3151/5000 [2:22:05<3:07:53,  6.10s/it, loss=0.3643]\u001b[A\n",
            "Training:  63%|██████▎   | 3151/5000 [2:22:05<3:07:53,  6.10s/it, loss=0.3617]\u001b[A\n",
            "Training:  63%|██████▎   | 3152/5000 [2:22:08<2:34:06,  5.00s/it, loss=0.3617]\u001b[A\n",
            "Training:  63%|██████▎   | 3152/5000 [2:22:08<2:34:06,  5.00s/it, loss=0.6293]\u001b[A\n",
            "Training:  63%|██████▎   | 3153/5000 [2:22:10<2:12:07,  4.29s/it, loss=0.6293]\u001b[A\n",
            "Training:  63%|██████▎   | 3153/5000 [2:22:11<2:12:07,  4.29s/it, loss=0.5285]\u001b[A\n",
            "Training:  63%|██████▎   | 3154/5000 [2:22:13<1:53:32,  3.69s/it, loss=0.5285]\u001b[A\n",
            "Training:  63%|██████▎   | 3154/5000 [2:22:13<1:53:32,  3.69s/it, loss=0.4342]\u001b[A\n",
            "Training:  63%|██████▎   | 3155/5000 [2:22:15<1:40:48,  3.28s/it, loss=0.4342]\u001b[A\n",
            "Training:  63%|██████▎   | 3155/5000 [2:22:15<1:40:48,  3.28s/it, loss=0.3653]\u001b[A\n",
            "Training:  63%|██████▎   | 3156/5000 [2:22:17<1:31:15,  2.97s/it, loss=0.3653]\u001b[A\n",
            "Training:  63%|██████▎   | 3156/5000 [2:22:17<1:31:15,  2.97s/it, loss=0.3590]\u001b[A\n",
            "Training:  63%|██████▎   | 3157/5000 [2:22:20<1:26:50,  2.83s/it, loss=0.3590]\u001b[A\n",
            "Training:  63%|██████▎   | 3157/5000 [2:22:20<1:26:50,  2.83s/it, loss=0.5003]\u001b[A\n",
            "Training:  63%|██████▎   | 3158/5000 [2:22:23<1:25:29,  2.78s/it, loss=0.5003]\u001b[A\n",
            "Training:  63%|██████▎   | 3158/5000 [2:22:23<1:25:29,  2.78s/it, loss=0.4464]\u001b[A\n",
            "Training:  63%|██████▎   | 3159/5000 [2:22:25<1:21:04,  2.64s/it, loss=0.4464]\u001b[A\n",
            "Training:  63%|██████▎   | 3159/5000 [2:22:25<1:21:04,  2.64s/it, loss=0.6088]\u001b[A\n",
            "Training:  63%|██████▎   | 3160/5000 [2:22:27<1:17:47,  2.54s/it, loss=0.6088]\u001b[A\n",
            "Training:  63%|██████▎   | 3160/5000 [2:22:27<1:17:47,  2.54s/it, loss=0.5559]\u001b[A\n",
            "Training:  63%|██████▎   | 3161/5000 [2:22:29<1:15:13,  2.45s/it, loss=0.5559]\u001b[A\n",
            "Training:  63%|██████▎   | 3161/5000 [2:22:29<1:15:13,  2.45s/it, loss=0.3550]\u001b[A\n",
            "Training:  63%|██████▎   | 3162/5000 [2:22:32<1:15:47,  2.47s/it, loss=0.3550]\u001b[A\n",
            "Training:  63%|██████▎   | 3162/5000 [2:22:32<1:15:47,  2.47s/it, loss=0.3547]\u001b[A\n",
            "Training:  63%|██████▎   | 3163/5000 [2:22:35<1:17:08,  2.52s/it, loss=0.3547]\u001b[A\n",
            "Training:  63%|██████▎   | 3163/5000 [2:22:35<1:17:08,  2.52s/it, loss=0.5506]\u001b[A\n",
            "Training:  63%|██████▎   | 3164/5000 [2:22:37<1:14:57,  2.45s/it, loss=0.5506]\u001b[A\n",
            "Training:  63%|██████▎   | 3164/5000 [2:22:37<1:14:57,  2.45s/it, loss=0.6285]\u001b[A\n",
            "Training:  63%|██████▎   | 3165/5000 [2:22:39<1:13:18,  2.40s/it, loss=0.6285]\u001b[A\n",
            "Training:  63%|██████▎   | 3165/5000 [2:22:39<1:13:18,  2.40s/it, loss=0.5333]\u001b[A\n",
            "Training:  63%|██████▎   | 3166/5000 [2:22:41<1:12:16,  2.36s/it, loss=0.5333]\u001b[A\n",
            "Training:  63%|██████▎   | 3166/5000 [2:22:41<1:12:16,  2.36s/it, loss=0.4480]\u001b[A\n",
            "Training:  63%|██████▎   | 3167/5000 [2:22:44<1:14:14,  2.43s/it, loss=0.4480]\u001b[A\n",
            "Training:  63%|██████▎   | 3167/5000 [2:22:44<1:14:14,  2.43s/it, loss=0.4679]\u001b[A\n",
            "Training:  63%|██████▎   | 3168/5000 [2:22:47<1:15:54,  2.49s/it, loss=0.4679]\u001b[A\n",
            "Training:  63%|██████▎   | 3168/5000 [2:22:47<1:15:54,  2.49s/it, loss=0.4618]\u001b[A\n",
            "Training:  63%|██████▎   | 3169/5000 [2:22:49<1:13:51,  2.42s/it, loss=0.4618]\u001b[A\n",
            "Training:  63%|██████▎   | 3169/5000 [2:22:49<1:13:51,  2.42s/it, loss=0.5119]\u001b[A\n",
            "Training:  63%|██████▎   | 3170/5000 [2:22:51<1:12:36,  2.38s/it, loss=0.5119]\u001b[A\n",
            "Training:  63%|██████▎   | 3170/5000 [2:22:51<1:12:36,  2.38s/it, loss=0.2963]\u001b[A\n",
            "Training:  63%|██████▎   | 3171/5000 [2:22:53<1:11:45,  2.35s/it, loss=0.2963]\u001b[A\n",
            "Training:  63%|██████▎   | 3171/5000 [2:22:53<1:11:45,  2.35s/it, loss=0.5648]\u001b[A\n",
            "Training:  63%|██████▎   | 3172/5000 [2:22:56<1:13:14,  2.40s/it, loss=0.5648]\u001b[A\n",
            "Training:  63%|██████▎   | 3172/5000 [2:22:56<1:13:14,  2.40s/it, loss=0.4129]\u001b[A\n",
            "Training:  63%|██████▎   | 3173/5000 [2:22:58<1:14:39,  2.45s/it, loss=0.4129]\u001b[A\n",
            "Training:  63%|██████▎   | 3173/5000 [2:22:59<1:14:39,  2.45s/it, loss=0.3843]\u001b[A\n",
            "Training:  63%|██████▎   | 3174/5000 [2:23:01<1:12:57,  2.40s/it, loss=0.3843]\u001b[A\n",
            "Training:  63%|██████▎   | 3174/5000 [2:23:01<1:12:57,  2.40s/it, loss=0.4643]\u001b[A\n",
            "Training:  64%|██████▎   | 3175/5000 [2:23:03<1:11:33,  2.35s/it, loss=0.4643]\u001b[A\n",
            "Training:  64%|██████▎   | 3175/5000 [2:23:03<1:11:33,  2.35s/it, loss=0.3367]\u001b[A\n",
            "Training:  64%|██████▎   | 3176/5000 [2:23:05<1:11:12,  2.34s/it, loss=0.3367]\u001b[A\n",
            "Training:  64%|██████▎   | 3176/5000 [2:23:05<1:11:12,  2.34s/it, loss=0.5089]\u001b[A\n",
            "Training:  64%|██████▎   | 3177/5000 [2:23:08<1:12:33,  2.39s/it, loss=0.5089]\u001b[A\n",
            "Training:  64%|██████▎   | 3177/5000 [2:23:08<1:12:33,  2.39s/it, loss=0.3240]\u001b[A\n",
            "Training:  64%|██████▎   | 3178/5000 [2:23:10<1:14:22,  2.45s/it, loss=0.3240]\u001b[A\n",
            "Training:  64%|██████▎   | 3178/5000 [2:23:10<1:14:22,  2.45s/it, loss=0.3619]\u001b[A\n",
            "Training:  64%|██████▎   | 3179/5000 [2:23:13<1:12:43,  2.40s/it, loss=0.3619]\u001b[A\n",
            "Training:  64%|██████▎   | 3179/5000 [2:23:13<1:12:43,  2.40s/it, loss=0.3441]\u001b[A\n",
            "Training:  64%|██████▎   | 3180/5000 [2:23:15<1:13:36,  2.43s/it, loss=0.3441]\u001b[A\n",
            "Training:  64%|██████▎   | 3180/5000 [2:23:15<1:13:36,  2.43s/it, loss=0.4851]\u001b[A\n",
            "Training:  64%|██████▎   | 3181/5000 [2:23:17<1:12:22,  2.39s/it, loss=0.4851]\u001b[A\n",
            "Training:  64%|██████▎   | 3181/5000 [2:23:18<1:12:22,  2.39s/it, loss=0.3971]\u001b[A\n",
            "Training:  64%|██████▎   | 3182/5000 [2:23:20<1:14:30,  2.46s/it, loss=0.3971]\u001b[A\n",
            "Training:  64%|██████▎   | 3182/5000 [2:23:20<1:14:30,  2.46s/it, loss=0.3702]\u001b[A\n",
            "Training:  64%|██████▎   | 3183/5000 [2:23:23<1:14:35,  2.46s/it, loss=0.3702]\u001b[A\n",
            "Training:  64%|██████▎   | 3183/5000 [2:23:23<1:14:35,  2.46s/it, loss=0.4486]\u001b[A\n",
            "Training:  64%|██████▎   | 3184/5000 [2:23:25<1:13:09,  2.42s/it, loss=0.4486]\u001b[A\n",
            "Training:  64%|██████▎   | 3184/5000 [2:23:25<1:13:09,  2.42s/it, loss=0.3846]\u001b[A\n",
            "Training:  64%|██████▎   | 3185/5000 [2:23:27<1:11:43,  2.37s/it, loss=0.3846]\u001b[A\n",
            "Training:  64%|██████▎   | 3185/5000 [2:23:27<1:11:43,  2.37s/it, loss=0.4066]\u001b[A\n",
            "Training:  64%|██████▎   | 3186/5000 [2:23:29<1:10:54,  2.35s/it, loss=0.4066]\u001b[A\n",
            "Training:  64%|██████▎   | 3186/5000 [2:23:29<1:10:54,  2.35s/it, loss=0.3782]\u001b[A\n",
            "Training:  64%|██████▎   | 3187/5000 [2:23:32<1:13:18,  2.43s/it, loss=0.3782]\u001b[A\n",
            "Training:  64%|██████▎   | 3187/5000 [2:23:32<1:13:18,  2.43s/it, loss=0.5228]\u001b[A\n",
            "Training:  64%|██████▍   | 3188/5000 [2:23:35<1:13:52,  2.45s/it, loss=0.5228]\u001b[A\n",
            "Training:  64%|██████▍   | 3188/5000 [2:23:35<1:13:52,  2.45s/it, loss=0.5471]\u001b[A\n",
            "Training:  64%|██████▍   | 3189/5000 [2:23:37<1:12:08,  2.39s/it, loss=0.5471]\u001b[A\n",
            "Training:  64%|██████▍   | 3189/5000 [2:23:37<1:12:08,  2.39s/it, loss=0.4755]\u001b[A\n",
            "Training:  64%|██████▍   | 3190/5000 [2:23:39<1:10:46,  2.35s/it, loss=0.4755]\u001b[A\n",
            "Training:  64%|██████▍   | 3190/5000 [2:23:39<1:10:46,  2.35s/it, loss=0.4878]\u001b[A\n",
            "Training:  64%|██████▍   | 3191/5000 [2:23:41<1:10:11,  2.33s/it, loss=0.4878]\u001b[A\n",
            "Training:  64%|██████▍   | 3191/5000 [2:23:41<1:10:11,  2.33s/it, loss=0.3635]\u001b[A\n",
            "Training:  64%|██████▍   | 3192/5000 [2:23:44<1:12:54,  2.42s/it, loss=0.3635]\u001b[A\n",
            "Training:  64%|██████▍   | 3192/5000 [2:23:44<1:12:54,  2.42s/it, loss=0.4565]\u001b[A\n",
            "Training:  64%|██████▍   | 3193/5000 [2:23:46<1:13:36,  2.44s/it, loss=0.4565]\u001b[A\n",
            "Training:  64%|██████▍   | 3193/5000 [2:23:47<1:13:36,  2.44s/it, loss=0.6839]\u001b[A\n",
            "Training:  64%|██████▍   | 3194/5000 [2:23:49<1:12:10,  2.40s/it, loss=0.6839]\u001b[A\n",
            "Training:  64%|██████▍   | 3194/5000 [2:23:49<1:12:10,  2.40s/it, loss=0.6869]\u001b[A\n",
            "Training:  64%|██████▍   | 3195/5000 [2:23:51<1:11:01,  2.36s/it, loss=0.6869]\u001b[A\n",
            "Training:  64%|██████▍   | 3195/5000 [2:23:51<1:11:01,  2.36s/it, loss=0.5216]\u001b[A\n",
            "Training:  64%|██████▍   | 3196/5000 [2:23:53<1:10:04,  2.33s/it, loss=0.5216]\u001b[A\n",
            "Training:  64%|██████▍   | 3196/5000 [2:23:53<1:10:04,  2.33s/it, loss=0.5328]\u001b[A\n",
            "Training:  64%|██████▍   | 3197/5000 [2:23:56<1:12:41,  2.42s/it, loss=0.5328]\u001b[A\n",
            "Training:  64%|██████▍   | 3197/5000 [2:23:56<1:12:41,  2.42s/it, loss=0.4650]\u001b[A\n",
            "Training:  64%|██████▍   | 3198/5000 [2:23:58<1:13:15,  2.44s/it, loss=0.4650]\u001b[A\n",
            "Training:  64%|██████▍   | 3198/5000 [2:23:58<1:13:15,  2.44s/it, loss=0.4973]\u001b[A\n",
            "Training:  64%|██████▍   | 3199/5000 [2:24:01<1:11:44,  2.39s/it, loss=0.4973]\u001b[A\n",
            "Training:  64%|██████▍   | 3199/5000 [2:24:01<1:11:44,  2.39s/it, loss=0.5440]\u001b[A\n",
            "Training:  64%|██████▍   | 3200/5000 [2:24:03<1:10:40,  2.36s/it, loss=0.5440]\u001b[A\n",
            "Training:  64%|██████▍   | 3200/5000 [2:24:03<1:10:40,  2.36s/it, loss=0.5274]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 3200 ---\n",
            "Prompt: 'The '\n",
            "The  of wear dreadful, do my\n",
            " rendouts this thereep grace live\n",
            " not, lord the duke no- that theirst revenge\n",
            "ight his worse dam thereforeBy.ark ho\n",
            "First his soul wouldWe it they soSee to nothing\n",
            "all stand and even never of h; is and affect all\n",
            " country'der;,,,,,,,-,, you\n",
            "ily Hast me, lord\n",
            " bells as lie left tender, doing\n",
            " braineure and will\n",
            "His court\n",
            "Prompt: 'In '\n",
            "In , his, and the Henry son kings it?\n",
            "D he my my my lord a heart coward.\n",
            "PRCEO Clarence if had fear names stand time\n",
            " help wife I not it be I: these look is, call\n",
            "ame be bel in; most came at h, perhaps\n",
            " d he from tender give astw far all bling.\n",
            "G,am touch further not look for he well\n",
            "ame, you and bdy stopell for more noble,\n",
            "ere D courtesy well\n",
            "Prompt: 'To '\n",
            "To  my and honour his: him kind\n",
            " next'd fortune worse humour. honour straight since good\n",
            "ale my here dark were and two his side\n",
            ",; would have e this he say his father death\n",
            "There'd Hastings vill'd and'd royal, dwell\n",
            " long-- be,,,,,, that worthy do loveru\n",
            " it, boy may your's thou her a's;For usur out astw I\n",
            " servants kne it obey it Oo,, should hath. hand\n",
            "const\n",
            "Prompt: 'A '\n",
            "A ,ave cannot me, here the prince th.\n",
            "D prince thou l lie of; with heavy look me:The,irs my:The fortune is\n",
            " moon die, in to, be, thy in you andly.\n",
            "G, hisour death test on false, his isin,\n",
            " he,\n",
            "art, our, I the will you like well ho on masters areely away\n",
            " nothing\n",
            "ned; hath for son good. is thy'sAnd to spen us\n",
            "Now\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  64%|██████▍   | 3201/5000 [2:24:18<3:02:53,  6.10s/it, loss=0.5274]\u001b[A\n",
            "Training:  64%|██████▍   | 3201/5000 [2:24:18<3:02:53,  6.10s/it, loss=0.3360]\u001b[A\n",
            "Training:  64%|██████▍   | 3202/5000 [2:24:21<2:33:09,  5.11s/it, loss=0.3360]\u001b[A\n",
            "Training:  64%|██████▍   | 3202/5000 [2:24:21<2:33:09,  5.11s/it, loss=0.5052]\u001b[A\n",
            "Training:  64%|██████▍   | 3203/5000 [2:24:23<2:07:47,  4.27s/it, loss=0.5052]\u001b[A\n",
            "Training:  64%|██████▍   | 3203/5000 [2:24:23<2:07:47,  4.27s/it, loss=0.3679]\u001b[A\n",
            "Training:  64%|██████▍   | 3204/5000 [2:24:25<1:49:52,  3.67s/it, loss=0.3679]\u001b[A\n",
            "Training:  64%|██████▍   | 3204/5000 [2:24:25<1:49:52,  3.67s/it, loss=0.3186]\u001b[A\n",
            "Training:  64%|██████▍   | 3205/5000 [2:24:27<1:37:28,  3.26s/it, loss=0.3186]\u001b[A\n",
            "Training:  64%|██████▍   | 3205/5000 [2:24:28<1:37:28,  3.26s/it, loss=0.3885]\u001b[A\n",
            "Training:  64%|██████▍   | 3206/5000 [2:24:30<1:28:37,  2.96s/it, loss=0.3885]\u001b[A\n",
            "Training:  64%|██████▍   | 3206/5000 [2:24:30<1:28:37,  2.96s/it, loss=0.5953]\u001b[A\n",
            "Training:  64%|██████▍   | 3207/5000 [2:24:33<1:26:56,  2.91s/it, loss=0.5953]\u001b[A\n",
            "Training:  64%|██████▍   | 3207/5000 [2:24:33<1:26:56,  2.91s/it, loss=0.4158]\u001b[A\n",
            "Training:  64%|██████▍   | 3208/5000 [2:24:35<1:21:01,  2.71s/it, loss=0.4158]\u001b[A\n",
            "Training:  64%|██████▍   | 3208/5000 [2:24:35<1:21:01,  2.71s/it, loss=0.6239]\u001b[A\n",
            "Training:  64%|██████▍   | 3209/5000 [2:24:37<1:17:03,  2.58s/it, loss=0.6239]\u001b[A\n",
            "Training:  64%|██████▍   | 3209/5000 [2:24:37<1:17:03,  2.58s/it, loss=0.4936]\u001b[A\n",
            "Training:  64%|██████▍   | 3210/5000 [2:24:39<1:13:56,  2.48s/it, loss=0.4936]\u001b[A\n",
            "Training:  64%|██████▍   | 3210/5000 [2:24:39<1:13:56,  2.48s/it, loss=0.4195]\u001b[A\n",
            "Training:  64%|██████▍   | 3211/5000 [2:24:42<1:11:42,  2.41s/it, loss=0.4195]\u001b[A\n",
            "Training:  64%|██████▍   | 3211/5000 [2:24:42<1:11:42,  2.41s/it, loss=0.5262]\u001b[A\n",
            "Training:  64%|██████▍   | 3212/5000 [2:24:44<1:15:10,  2.52s/it, loss=0.5262]\u001b[A\n",
            "Training:  64%|██████▍   | 3212/5000 [2:24:44<1:15:10,  2.52s/it, loss=0.5082]\u001b[A\n",
            "Training:  64%|██████▍   | 3213/5000 [2:24:47<1:12:54,  2.45s/it, loss=0.5082]\u001b[A\n",
            "Training:  64%|██████▍   | 3213/5000 [2:24:47<1:12:54,  2.45s/it, loss=0.5328]\u001b[A\n",
            "Training:  64%|██████▍   | 3214/5000 [2:24:49<1:11:08,  2.39s/it, loss=0.5328]\u001b[A\n",
            "Training:  64%|██████▍   | 3214/5000 [2:24:49<1:11:08,  2.39s/it, loss=0.3507]\u001b[A\n",
            "Training:  64%|██████▍   | 3215/5000 [2:24:51<1:10:03,  2.35s/it, loss=0.3507]\u001b[A\n",
            "Training:  64%|██████▍   | 3215/5000 [2:24:51<1:10:03,  2.35s/it, loss=0.6747]\u001b[A\n",
            "Training:  64%|██████▍   | 3216/5000 [2:24:53<1:08:52,  2.32s/it, loss=0.6747]\u001b[A\n",
            "Training:  64%|██████▍   | 3216/5000 [2:24:53<1:08:52,  2.32s/it, loss=0.4909]\u001b[A\n",
            "Training:  64%|██████▍   | 3217/5000 [2:24:56<1:12:45,  2.45s/it, loss=0.4909]\u001b[A\n",
            "Training:  64%|██████▍   | 3217/5000 [2:24:56<1:12:45,  2.45s/it, loss=0.3192]\u001b[A\n",
            "Training:  64%|██████▍   | 3218/5000 [2:24:58<1:11:07,  2.39s/it, loss=0.3192]\u001b[A\n",
            "Training:  64%|██████▍   | 3218/5000 [2:24:58<1:11:07,  2.39s/it, loss=0.3808]\u001b[A\n",
            "Training:  64%|██████▍   | 3219/5000 [2:25:01<1:09:41,  2.35s/it, loss=0.3808]\u001b[A\n",
            "Training:  64%|██████▍   | 3219/5000 [2:25:01<1:09:41,  2.35s/it, loss=0.5446]\u001b[A\n",
            "Training:  64%|██████▍   | 3220/5000 [2:25:03<1:09:05,  2.33s/it, loss=0.5446]\u001b[A\n",
            "Training:  64%|██████▍   | 3220/5000 [2:25:03<1:09:05,  2.33s/it, loss=0.4707]\u001b[A\n",
            "Training:  64%|██████▍   | 3221/5000 [2:25:05<1:08:24,  2.31s/it, loss=0.4707]\u001b[A\n",
            "Training:  64%|██████▍   | 3221/5000 [2:25:05<1:08:24,  2.31s/it, loss=0.4396]\u001b[A\n",
            "Training:  64%|██████▍   | 3222/5000 [2:25:08<1:12:42,  2.45s/it, loss=0.4396]\u001b[A\n",
            "Training:  64%|██████▍   | 3222/5000 [2:25:08<1:12:42,  2.45s/it, loss=0.4435]\u001b[A\n",
            "Training:  64%|██████▍   | 3223/5000 [2:25:10<1:11:03,  2.40s/it, loss=0.4435]\u001b[A\n",
            "Training:  64%|██████▍   | 3223/5000 [2:25:10<1:11:03,  2.40s/it, loss=0.2551]\u001b[A\n",
            "Training:  64%|██████▍   | 3224/5000 [2:25:12<1:09:32,  2.35s/it, loss=0.2551]\u001b[A\n",
            "Training:  64%|██████▍   | 3224/5000 [2:25:12<1:09:32,  2.35s/it, loss=0.4642]\u001b[A\n",
            "Training:  64%|██████▍   | 3225/5000 [2:25:15<1:08:39,  2.32s/it, loss=0.4642]\u001b[A\n",
            "Training:  64%|██████▍   | 3225/5000 [2:25:15<1:08:39,  2.32s/it, loss=0.5705]\u001b[A\n",
            "Training:  65%|██████▍   | 3226/5000 [2:25:17<1:08:23,  2.31s/it, loss=0.5705]\u001b[A\n",
            "Training:  65%|██████▍   | 3226/5000 [2:25:17<1:08:23,  2.31s/it, loss=0.3945]\u001b[A\n",
            "Training:  65%|██████▍   | 3227/5000 [2:25:20<1:12:31,  2.45s/it, loss=0.3945]\u001b[A\n",
            "Training:  65%|██████▍   | 3227/5000 [2:25:20<1:12:31,  2.45s/it, loss=0.4810]\u001b[A\n",
            "Training:  65%|██████▍   | 3228/5000 [2:25:22<1:10:46,  2.40s/it, loss=0.4810]\u001b[A\n",
            "Training:  65%|██████▍   | 3228/5000 [2:25:22<1:10:46,  2.40s/it, loss=0.2691]\u001b[A\n",
            "Training:  65%|██████▍   | 3229/5000 [2:25:24<1:10:27,  2.39s/it, loss=0.2691]\u001b[A\n",
            "Training:  65%|██████▍   | 3229/5000 [2:25:24<1:10:27,  2.39s/it, loss=0.6072]\u001b[A\n",
            "Training:  65%|██████▍   | 3230/5000 [2:25:27<1:09:47,  2.37s/it, loss=0.6072]\u001b[A\n",
            "Training:  65%|██████▍   | 3230/5000 [2:25:27<1:09:47,  2.37s/it, loss=0.7638]\u001b[A\n",
            "Training:  65%|██████▍   | 3231/5000 [2:25:29<1:09:28,  2.36s/it, loss=0.7638]\u001b[A\n",
            "Training:  65%|██████▍   | 3231/5000 [2:25:29<1:09:28,  2.36s/it, loss=0.3755]\u001b[A\n",
            "Training:  65%|██████▍   | 3232/5000 [2:25:32<1:13:54,  2.51s/it, loss=0.3755]\u001b[A\n",
            "Training:  65%|██████▍   | 3232/5000 [2:25:32<1:13:54,  2.51s/it, loss=0.3886]\u001b[A\n",
            "Training:  65%|██████▍   | 3233/5000 [2:25:34<1:12:19,  2.46s/it, loss=0.3886]\u001b[A\n",
            "Training:  65%|██████▍   | 3233/5000 [2:25:34<1:12:19,  2.46s/it, loss=0.4250]\u001b[A\n",
            "Training:  65%|██████▍   | 3234/5000 [2:25:37<1:11:02,  2.41s/it, loss=0.4250]\u001b[A\n",
            "Training:  65%|██████▍   | 3234/5000 [2:25:37<1:11:02,  2.41s/it, loss=0.4079]\u001b[A\n",
            "Training:  65%|██████▍   | 3235/5000 [2:25:39<1:10:27,  2.40s/it, loss=0.4079]\u001b[A\n",
            "Training:  65%|██████▍   | 3235/5000 [2:25:39<1:10:27,  2.40s/it, loss=0.4215]\u001b[A\n",
            "Training:  65%|██████▍   | 3236/5000 [2:25:41<1:09:56,  2.38s/it, loss=0.4215]\u001b[A\n",
            "Training:  65%|██████▍   | 3236/5000 [2:25:41<1:09:56,  2.38s/it, loss=0.5159]\u001b[A\n",
            "Training:  65%|██████▍   | 3237/5000 [2:25:44<1:14:32,  2.54s/it, loss=0.5159]\u001b[A\n",
            "Training:  65%|██████▍   | 3237/5000 [2:25:44<1:14:32,  2.54s/it, loss=0.4246]\u001b[A\n",
            "Training:  65%|██████▍   | 3238/5000 [2:25:47<1:12:41,  2.48s/it, loss=0.4246]\u001b[A\n",
            "Training:  65%|██████▍   | 3238/5000 [2:25:47<1:12:41,  2.48s/it, loss=0.3831]\u001b[A\n",
            "Training:  65%|██████▍   | 3239/5000 [2:25:49<1:11:26,  2.43s/it, loss=0.3831]\u001b[A\n",
            "Training:  65%|██████▍   | 3239/5000 [2:25:49<1:11:26,  2.43s/it, loss=0.3403]\u001b[A\n",
            "Training:  65%|██████▍   | 3240/5000 [2:25:51<1:10:38,  2.41s/it, loss=0.3403]\u001b[A\n",
            "Training:  65%|██████▍   | 3240/5000 [2:25:51<1:10:38,  2.41s/it, loss=0.3629]\u001b[A\n",
            "Training:  65%|██████▍   | 3241/5000 [2:25:54<1:11:00,  2.42s/it, loss=0.3629]\u001b[A\n",
            "Training:  65%|██████▍   | 3241/5000 [2:25:54<1:11:00,  2.42s/it, loss=0.3975]\u001b[A\n",
            "Training:  65%|██████▍   | 3242/5000 [2:25:56<1:13:48,  2.52s/it, loss=0.3975]\u001b[A\n",
            "Training:  65%|██████▍   | 3242/5000 [2:25:56<1:13:48,  2.52s/it, loss=0.5697]\u001b[A\n",
            "Training:  65%|██████▍   | 3243/5000 [2:25:59<1:12:09,  2.46s/it, loss=0.5697]\u001b[A\n",
            "Training:  65%|██████▍   | 3243/5000 [2:25:59<1:12:09,  2.46s/it, loss=0.3187]\u001b[A\n",
            "Training:  65%|██████▍   | 3244/5000 [2:26:01<1:10:56,  2.42s/it, loss=0.3187]\u001b[A\n",
            "Training:  65%|██████▍   | 3244/5000 [2:26:01<1:10:56,  2.42s/it, loss=0.4591]\u001b[A\n",
            "Training:  65%|██████▍   | 3245/5000 [2:26:03<1:10:10,  2.40s/it, loss=0.4591]\u001b[A\n",
            "Training:  65%|██████▍   | 3245/5000 [2:26:03<1:10:10,  2.40s/it, loss=0.3528]\u001b[A\n",
            "Training:  65%|██████▍   | 3246/5000 [2:26:06<1:11:37,  2.45s/it, loss=0.3528]\u001b[A\n",
            "Training:  65%|██████▍   | 3246/5000 [2:26:06<1:11:37,  2.45s/it, loss=0.4923]\u001b[A\n",
            "Training:  65%|██████▍   | 3247/5000 [2:26:09<1:12:58,  2.50s/it, loss=0.4923]\u001b[A\n",
            "Training:  65%|██████▍   | 3247/5000 [2:26:09<1:12:58,  2.50s/it, loss=0.5130]\u001b[A\n",
            "Training:  65%|██████▍   | 3248/5000 [2:26:11<1:11:28,  2.45s/it, loss=0.5130]\u001b[A\n",
            "Training:  65%|██████▍   | 3248/5000 [2:26:11<1:11:28,  2.45s/it, loss=0.3749]\u001b[A\n",
            "Training:  65%|██████▍   | 3249/5000 [2:26:13<1:10:28,  2.41s/it, loss=0.3749]\u001b[A\n",
            "Training:  65%|██████▍   | 3249/5000 [2:26:13<1:10:28,  2.41s/it, loss=0.4525]\u001b[A\n",
            "Training:  65%|██████▌   | 3250/5000 [2:26:16<1:09:30,  2.38s/it, loss=0.4525]\u001b[A\n",
            "Training:  65%|██████▌   | 3250/5000 [2:26:16<1:09:30,  2.38s/it, loss=0.5647]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 3250 ---\n",
            "Prompt: 'The '\n",
            "The 's's's.\n",
            "CAPET:What it,, they wellP meLook\n",
            " him had have scope O he to him his:But with she\n",
            "ner examples, is, the better,ards my's is.\n",
            " is very and boast well I choose't out loves my's is ground I to you it\n",
            " is my's is, save will it but form. nob kind,ark your\n",
            " d,if, is right that is deathBut will\n",
            " end steel' is is which\n",
            "Prompt: 'In '\n",
            "In ,,, should hate,Stop\n",
            " hear., not I of nurse thelf\n",
            " son one that.\n",
            " gave again I thyms'd maid at, think I.\n",
            "der play priest time comeQUEo Warwick me to;And, 'is\n",
            "'ll thy name or married to: sau your's I.\n",
            "Gle there never me Allon,:are, you be'd my's I.are: do see\n",
            "I doee you to for:'ll them you thouost\n",
            "Prompt: 'To '\n",
            "To 'd and son and supp monument\n",
            " longer stuff palefulLim with of\n",
            "'d eacho\n",
            " most gate trem in thorn hold, fall blown,,,there,B\n",
            " Cam, disented moreily or mang enemies\n",
            "Should the of hath'd inIF now the, pray,With\n",
            " unifts provision house her sound fororn\n",
            " sc the of myman have with kiss from thingaff bears...\"\n",
            " shame taen in sum clouds me or thr slip\n",
            " by two own:Though for you\n",
            "Prompt: 'A '\n",
            "A , a f,balrionwend sequel\n",
            "isc up her faces andle with of deeds\n",
            " happier thanught l, pay and dog return teeth\n",
            " dsatter: things, this buten bias and.\n",
            "QUE MAR from cheeks gri his heirstand she lie,You\n",
            " a-chedletant?est,retched,st inward and IYou\n",
            ", it,\n",
            " truth best did beholdona king go for numbers new; thy's I his is not occasion\n",
            " nearies their\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  65%|██████▌   | 3251/5000 [2:26:31<3:05:26,  6.36s/it, loss=0.5647]\u001b[A\n",
            "Training:  65%|██████▌   | 3251/5000 [2:26:31<3:05:26,  6.36s/it, loss=0.4939]\u001b[A\n",
            "Training:  65%|██████▌   | 3252/5000 [2:26:34<2:29:59,  5.15s/it, loss=0.4939]\u001b[A\n",
            "Training:  65%|██████▌   | 3252/5000 [2:26:34<2:29:59,  5.15s/it, loss=0.6906]\u001b[A\n",
            "Training:  65%|██████▌   | 3253/5000 [2:26:36<2:05:22,  4.31s/it, loss=0.6906]\u001b[A\n",
            "Training:  65%|██████▌   | 3253/5000 [2:26:36<2:05:22,  4.31s/it, loss=0.3719]\u001b[A\n",
            "Training:  65%|██████▌   | 3254/5000 [2:26:38<1:47:59,  3.71s/it, loss=0.3719]\u001b[A\n",
            "Training:  65%|██████▌   | 3254/5000 [2:26:38<1:47:59,  3.71s/it, loss=0.5424]\u001b[A\n",
            "Training:  65%|██████▌   | 3255/5000 [2:26:41<1:36:03,  3.30s/it, loss=0.5424]\u001b[A\n",
            "Training:  65%|██████▌   | 3255/5000 [2:26:41<1:36:03,  3.30s/it, loss=0.3687]\u001b[A\n",
            "Training:  65%|██████▌   | 3256/5000 [2:26:43<1:32:19,  3.18s/it, loss=0.3687]\u001b[A\n",
            "Training:  65%|██████▌   | 3256/5000 [2:26:43<1:32:19,  3.18s/it, loss=0.4305]\u001b[A\n",
            "Training:  65%|██████▌   | 3257/5000 [2:26:46<1:24:59,  2.93s/it, loss=0.4305]\u001b[A\n",
            "Training:  65%|██████▌   | 3257/5000 [2:26:46<1:24:59,  2.93s/it, loss=0.4552]\u001b[A\n",
            "Training:  65%|██████▌   | 3258/5000 [2:26:48<1:20:01,  2.76s/it, loss=0.4552]\u001b[A\n",
            "Training:  65%|██████▌   | 3258/5000 [2:26:48<1:20:01,  2.76s/it, loss=0.4826]\u001b[A\n",
            "Training:  65%|██████▌   | 3259/5000 [2:26:50<1:16:27,  2.64s/it, loss=0.4826]\u001b[A\n",
            "Training:  65%|██████▌   | 3259/5000 [2:26:51<1:16:27,  2.64s/it, loss=0.4702]\u001b[A\n",
            "Training:  65%|██████▌   | 3260/5000 [2:26:53<1:14:21,  2.56s/it, loss=0.4702]\u001b[A\n",
            "Training:  65%|██████▌   | 3260/5000 [2:26:53<1:14:21,  2.56s/it, loss=0.3759]\u001b[A\n",
            "Training:  65%|██████▌   | 3261/5000 [2:26:56<1:16:04,  2.62s/it, loss=0.3759]\u001b[A\n",
            "Training:  65%|██████▌   | 3261/5000 [2:26:56<1:16:04,  2.62s/it, loss=0.3777]\u001b[A\n",
            "Training:  65%|██████▌   | 3262/5000 [2:26:58<1:13:15,  2.53s/it, loss=0.3777]\u001b[A\n",
            "Training:  65%|██████▌   | 3262/5000 [2:26:58<1:13:15,  2.53s/it, loss=0.4906]\u001b[A\n",
            "Training:  65%|██████▌   | 3263/5000 [2:27:00<1:11:26,  2.47s/it, loss=0.4906]\u001b[A\n",
            "Training:  65%|██████▌   | 3263/5000 [2:27:00<1:11:26,  2.47s/it, loss=0.3800]\u001b[A\n",
            "Training:  65%|██████▌   | 3264/5000 [2:27:03<1:09:53,  2.42s/it, loss=0.3800]\u001b[A\n",
            "Training:  65%|██████▌   | 3264/5000 [2:27:03<1:09:53,  2.42s/it, loss=0.3805]\u001b[A\n",
            "Training:  65%|██████▌   | 3265/5000 [2:27:05<1:10:06,  2.42s/it, loss=0.3805]\u001b[A\n",
            "Training:  65%|██████▌   | 3265/5000 [2:27:05<1:10:06,  2.42s/it, loss=0.5508]\u001b[A\n",
            "Training:  65%|██████▌   | 3266/5000 [2:27:08<1:12:39,  2.51s/it, loss=0.5508]\u001b[A\n",
            "Training:  65%|██████▌   | 3266/5000 [2:27:08<1:12:39,  2.51s/it, loss=0.3481]\u001b[A\n",
            "Training:  65%|██████▌   | 3267/5000 [2:27:10<1:11:00,  2.46s/it, loss=0.3481]\u001b[A\n",
            "Training:  65%|██████▌   | 3267/5000 [2:27:10<1:11:00,  2.46s/it, loss=0.3816]\u001b[A\n",
            "Training:  65%|██████▌   | 3268/5000 [2:27:12<1:09:48,  2.42s/it, loss=0.3816]\u001b[A\n",
            "Training:  65%|██████▌   | 3268/5000 [2:27:12<1:09:48,  2.42s/it, loss=0.4195]\u001b[A\n",
            "Training:  65%|██████▌   | 3269/5000 [2:27:15<1:09:02,  2.39s/it, loss=0.4195]\u001b[A\n",
            "Training:  65%|██████▌   | 3269/5000 [2:27:15<1:09:02,  2.39s/it, loss=0.4600]\u001b[A\n",
            "Training:  65%|██████▌   | 3270/5000 [2:27:17<1:09:44,  2.42s/it, loss=0.4600]\u001b[A\n",
            "Training:  65%|██████▌   | 3270/5000 [2:27:17<1:09:44,  2.42s/it, loss=0.6088]\u001b[A\n",
            "Training:  65%|██████▌   | 3271/5000 [2:27:20<1:12:29,  2.52s/it, loss=0.6088]\u001b[A\n",
            "Training:  65%|██████▌   | 3271/5000 [2:27:20<1:12:29,  2.52s/it, loss=0.5336]\u001b[A\n",
            "Training:  65%|██████▌   | 3272/5000 [2:27:22<1:11:01,  2.47s/it, loss=0.5336]\u001b[A\n",
            "Training:  65%|██████▌   | 3272/5000 [2:27:22<1:11:01,  2.47s/it, loss=0.4274]\u001b[A\n",
            "Training:  65%|██████▌   | 3273/5000 [2:27:25<1:09:48,  2.43s/it, loss=0.4274]\u001b[A\n",
            "Training:  65%|██████▌   | 3273/5000 [2:27:25<1:09:48,  2.43s/it, loss=0.3555]\u001b[A\n",
            "Training:  65%|██████▌   | 3274/5000 [2:27:27<1:09:09,  2.40s/it, loss=0.3555]\u001b[A\n",
            "Training:  65%|██████▌   | 3274/5000 [2:27:27<1:09:09,  2.40s/it, loss=0.5092]\u001b[A\n",
            "Training:  66%|██████▌   | 3275/5000 [2:27:30<1:10:32,  2.45s/it, loss=0.5092]\u001b[A\n",
            "Training:  66%|██████▌   | 3275/5000 [2:27:30<1:10:32,  2.45s/it, loss=0.4340]\u001b[A\n",
            "Training:  66%|██████▌   | 3276/5000 [2:27:32<1:12:21,  2.52s/it, loss=0.4340]\u001b[A\n",
            "Training:  66%|██████▌   | 3276/5000 [2:27:32<1:12:21,  2.52s/it, loss=0.3289]\u001b[A\n",
            "Training:  66%|██████▌   | 3277/5000 [2:27:35<1:10:43,  2.46s/it, loss=0.3289]\u001b[A\n",
            "Training:  66%|██████▌   | 3277/5000 [2:27:35<1:10:43,  2.46s/it, loss=0.2607]\u001b[A\n",
            "Training:  66%|██████▌   | 3278/5000 [2:27:37<1:09:22,  2.42s/it, loss=0.2607]\u001b[A\n",
            "Training:  66%|██████▌   | 3278/5000 [2:27:37<1:09:22,  2.42s/it, loss=0.3243]\u001b[A\n",
            "Training:  66%|██████▌   | 3279/5000 [2:27:39<1:08:36,  2.39s/it, loss=0.3243]\u001b[A\n",
            "Training:  66%|██████▌   | 3279/5000 [2:27:39<1:08:36,  2.39s/it, loss=0.4321]\u001b[A\n",
            "Training:  66%|██████▌   | 3280/5000 [2:27:42<1:10:38,  2.46s/it, loss=0.4321]\u001b[A\n",
            "Training:  66%|██████▌   | 3280/5000 [2:27:42<1:10:38,  2.46s/it, loss=0.3706]\u001b[A\n",
            "Training:  66%|██████▌   | 3281/5000 [2:27:44<1:11:30,  2.50s/it, loss=0.3706]\u001b[A\n",
            "Training:  66%|██████▌   | 3281/5000 [2:27:44<1:11:30,  2.50s/it, loss=0.3181]\u001b[A\n",
            "Training:  66%|██████▌   | 3282/5000 [2:27:47<1:09:58,  2.44s/it, loss=0.3181]\u001b[A\n",
            "Training:  66%|██████▌   | 3282/5000 [2:27:47<1:09:58,  2.44s/it, loss=0.4180]\u001b[A\n",
            "Training:  66%|██████▌   | 3283/5000 [2:27:49<1:09:11,  2.42s/it, loss=0.4180]\u001b[A\n",
            "Training:  66%|██████▌   | 3283/5000 [2:27:49<1:09:11,  2.42s/it, loss=0.4781]\u001b[A\n",
            "Training:  66%|██████▌   | 3284/5000 [2:27:51<1:08:12,  2.39s/it, loss=0.4781]\u001b[A\n",
            "Training:  66%|██████▌   | 3284/5000 [2:27:51<1:08:12,  2.39s/it, loss=0.3373]\u001b[A\n",
            "Training:  66%|██████▌   | 3285/5000 [2:27:54<1:11:23,  2.50s/it, loss=0.3373]\u001b[A\n",
            "Training:  66%|██████▌   | 3285/5000 [2:27:54<1:11:23,  2.50s/it, loss=0.4372]\u001b[A\n",
            "Training:  66%|██████▌   | 3286/5000 [2:27:57<1:10:57,  2.48s/it, loss=0.4372]\u001b[A\n",
            "Training:  66%|██████▌   | 3286/5000 [2:27:57<1:10:57,  2.48s/it, loss=0.4515]\u001b[A\n",
            "Training:  66%|██████▌   | 3287/5000 [2:27:59<1:09:37,  2.44s/it, loss=0.4515]\u001b[A\n",
            "Training:  66%|██████▌   | 3287/5000 [2:27:59<1:09:37,  2.44s/it, loss=0.4082]\u001b[A\n",
            "Training:  66%|██████▌   | 3288/5000 [2:28:01<1:08:27,  2.40s/it, loss=0.4082]\u001b[A\n",
            "Training:  66%|██████▌   | 3288/5000 [2:28:01<1:08:27,  2.40s/it, loss=0.5516]\u001b[A\n",
            "Training:  66%|██████▌   | 3289/5000 [2:28:04<1:07:41,  2.37s/it, loss=0.5516]\u001b[A\n",
            "Training:  66%|██████▌   | 3289/5000 [2:28:04<1:07:41,  2.37s/it, loss=0.4492]\u001b[A\n",
            "Training:  66%|██████▌   | 3290/5000 [2:28:06<1:12:05,  2.53s/it, loss=0.4492]\u001b[A\n",
            "Training:  66%|██████▌   | 3290/5000 [2:28:06<1:12:05,  2.53s/it, loss=0.6392]\u001b[A\n",
            "Training:  66%|██████▌   | 3291/5000 [2:28:09<1:10:16,  2.47s/it, loss=0.6392]\u001b[A\n",
            "Training:  66%|██████▌   | 3291/5000 [2:28:09<1:10:16,  2.47s/it, loss=0.4076]\u001b[A\n",
            "Training:  66%|██████▌   | 3292/5000 [2:28:11<1:09:02,  2.43s/it, loss=0.4076]\u001b[A\n",
            "Training:  66%|██████▌   | 3292/5000 [2:28:11<1:09:02,  2.43s/it, loss=0.5543]\u001b[A\n",
            "Training:  66%|██████▌   | 3293/5000 [2:28:13<1:08:05,  2.39s/it, loss=0.5543]\u001b[A\n",
            "Training:  66%|██████▌   | 3293/5000 [2:28:13<1:08:05,  2.39s/it, loss=0.5686]\u001b[A\n",
            "Training:  66%|██████▌   | 3294/5000 [2:28:16<1:07:38,  2.38s/it, loss=0.5686]\u001b[A\n",
            "Training:  66%|██████▌   | 3294/5000 [2:28:16<1:07:38,  2.38s/it, loss=0.1664]\u001b[A\n",
            "Training:  66%|██████▌   | 3295/5000 [2:28:19<1:11:46,  2.53s/it, loss=0.1664]\u001b[A\n",
            "Training:  66%|██████▌   | 3295/5000 [2:28:19<1:11:46,  2.53s/it, loss=0.7601]\u001b[A\n",
            "Training:  66%|██████▌   | 3296/5000 [2:28:21<1:10:07,  2.47s/it, loss=0.7601]\u001b[A\n",
            "Training:  66%|██████▌   | 3296/5000 [2:28:21<1:10:07,  2.47s/it, loss=0.4257]\u001b[A\n",
            "Training:  66%|██████▌   | 3297/5000 [2:28:23<1:08:46,  2.42s/it, loss=0.4257]\u001b[A\n",
            "Training:  66%|██████▌   | 3297/5000 [2:28:23<1:08:46,  2.42s/it, loss=0.5239]\u001b[A\n",
            "Training:  66%|██████▌   | 3298/5000 [2:28:26<1:07:43,  2.39s/it, loss=0.5239]\u001b[A\n",
            "Training:  66%|██████▌   | 3298/5000 [2:28:26<1:07:43,  2.39s/it, loss=0.4937]\u001b[A\n",
            "Training:  66%|██████▌   | 3299/5000 [2:28:28<1:07:35,  2.38s/it, loss=0.4937]\u001b[A\n",
            "Training:  66%|██████▌   | 3299/5000 [2:28:28<1:07:35,  2.38s/it, loss=0.4721]\u001b[A\n",
            "Training:  66%|██████▌   | 3300/5000 [2:28:31<1:11:41,  2.53s/it, loss=0.4721]\u001b[A\n",
            "Training:  66%|██████▌   | 3300/5000 [2:28:31<1:11:41,  2.53s/it, loss=0.4579]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 3300 ---\n",
            "Prompt: 'The '\n",
            "The  you no harm to.\n",
            "DKEINENT:You it swear\n",
            " you good lion?,am\n",
            " comes yourself some with: give leave be young consecrated\n",
            " cannot be him friends is the of, feel, clear son\n",
            " have am of.\n",
            "ANGO\n",
            " this-es an.\n",
            "ANGO\n",
            " what fool shall to,That's born\n",
            " be more\n",
            "'s borne hand:\n",
            " mock be,bow your sends\n",
            " haveo man no:It: thouiest, let be with\n",
            "Prompt: 'In '\n",
            "In 's; cunning! may this the of tell\n",
            " home sir suchelve, she, the that knew well\n",
            " dinner your, up queens I'd faults yourhip\n",
            " call to you your report\n",
            " something with.\n",
            "BOLN:Ay.\n",
            "AB sir how you know well, let not her's?\n",
            "MAR mad, up sir\n",
            "Sir be youraths,\n",
            " should be withine\n",
            " the death in purse you your,Do play he go\n",
            "all depend\n",
            " wrong\n",
            " it\n",
            ",\n",
            "Prompt: 'To '\n",
            "To  wonder: itouch open order. maid I\n",
            " s matter even hersey: my and face\n",
            " sorrow us not I my's's; nevertis unelf\n",
            " some time,,That have prove thy and, King company\n",
            "use me businessar,,,,ly my.\n",
            "DKE head mercy you tellAndu again have none you.\n",
            " is not me\n",
            "kind;, as may beycon, let be hand and s you, such.\n",
            "DKEINENT:\n",
            "Prompt: 'A '\n",
            "A  to which f with soul him to point\n",
            " there would keep\n",
            " so off eyes make his: he changed and bad\n",
            " the of and.\n",
            "D thouost let brother:\n",
            " would'll thy to insol?,alus,ona a with: come\n",
            " mear a father in, of and,tis.\n",
            "D thoust not man would\n",
            "'s; I let d asief tosw yours, thy and: this beak,'sthink my.\n",
            "MARUSierSo wouldine\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  66%|██████▌   | 3301/5000 [2:28:46<2:57:26,  6.27s/it, loss=0.4579]\u001b[A\n",
            "Training:  66%|██████▌   | 3301/5000 [2:28:46<2:57:26,  6.27s/it, loss=0.4769]\u001b[A\n",
            "Training:  66%|██████▌   | 3302/5000 [2:28:48<2:23:10,  5.06s/it, loss=0.4769]\u001b[A\n",
            "Training:  66%|██████▌   | 3302/5000 [2:28:48<2:23:10,  5.06s/it, loss=0.5298]\u001b[A\n",
            "Training:  66%|██████▌   | 3303/5000 [2:28:50<1:59:31,  4.23s/it, loss=0.5298]\u001b[A\n",
            "Training:  66%|██████▌   | 3303/5000 [2:28:50<1:59:31,  4.23s/it, loss=0.3538]\u001b[A\n",
            "Training:  66%|██████▌   | 3304/5000 [2:28:53<1:44:08,  3.68s/it, loss=0.3538]\u001b[A\n",
            "Training:  66%|██████▌   | 3304/5000 [2:28:53<1:44:08,  3.68s/it, loss=0.4440]\u001b[A\n",
            "Training:  66%|██████▌   | 3305/5000 [2:28:55<1:34:57,  3.36s/it, loss=0.4440]\u001b[A\n",
            "Training:  66%|██████▌   | 3305/5000 [2:28:55<1:34:57,  3.36s/it, loss=0.3333]\u001b[A\n",
            "Training:  66%|██████▌   | 3306/5000 [2:28:58<1:25:29,  3.03s/it, loss=0.3333]\u001b[A\n",
            "Training:  66%|██████▌   | 3306/5000 [2:28:58<1:25:29,  3.03s/it, loss=0.5070]\u001b[A\n",
            "Training:  66%|██████▌   | 3307/5000 [2:29:00<1:18:38,  2.79s/it, loss=0.5070]\u001b[A\n",
            "Training:  66%|██████▌   | 3307/5000 [2:29:00<1:18:38,  2.79s/it, loss=0.5953]\u001b[A\n",
            "Training:  66%|██████▌   | 3308/5000 [2:29:02<1:14:00,  2.62s/it, loss=0.5953]\u001b[A\n",
            "Training:  66%|██████▌   | 3308/5000 [2:29:02<1:14:00,  2.62s/it, loss=0.4451]\u001b[A\n",
            "Training:  66%|██████▌   | 3309/5000 [2:29:04<1:12:04,  2.56s/it, loss=0.4451]\u001b[A\n",
            "Training:  66%|██████▌   | 3309/5000 [2:29:05<1:12:04,  2.56s/it, loss=0.4678]\u001b[A\n",
            "Training:  66%|██████▌   | 3310/5000 [2:29:07<1:12:59,  2.59s/it, loss=0.4678]\u001b[A\n",
            "Training:  66%|██████▌   | 3310/5000 [2:29:07<1:12:59,  2.59s/it, loss=0.5237]\u001b[A\n",
            "Training:  66%|██████▌   | 3311/5000 [2:29:09<1:09:49,  2.48s/it, loss=0.5237]\u001b[A\n",
            "Training:  66%|██████▌   | 3311/5000 [2:29:09<1:09:49,  2.48s/it, loss=0.4699]\u001b[A\n",
            "Training:  66%|██████▌   | 3312/5000 [2:29:12<1:07:45,  2.41s/it, loss=0.4699]\u001b[A\n",
            "Training:  66%|██████▌   | 3312/5000 [2:29:12<1:07:45,  2.41s/it, loss=0.2602]\u001b[A\n",
            "Training:  66%|██████▋   | 3313/5000 [2:29:14<1:06:15,  2.36s/it, loss=0.2602]\u001b[A\n",
            "Training:  66%|██████▋   | 3313/5000 [2:29:14<1:06:15,  2.36s/it, loss=0.4323]\u001b[A\n",
            "Training:  66%|██████▋   | 3314/5000 [2:29:16<1:06:00,  2.35s/it, loss=0.4323]\u001b[A\n",
            "Training:  66%|██████▋   | 3314/5000 [2:29:16<1:06:00,  2.35s/it, loss=0.4055]\u001b[A\n",
            "Training:  66%|██████▋   | 3315/5000 [2:29:19<1:09:14,  2.47s/it, loss=0.4055]\u001b[A\n",
            "Training:  66%|██████▋   | 3315/5000 [2:29:19<1:09:14,  2.47s/it, loss=0.3918]\u001b[A\n",
            "Training:  66%|██████▋   | 3316/5000 [2:29:21<1:07:16,  2.40s/it, loss=0.3918]\u001b[A\n",
            "Training:  66%|██████▋   | 3316/5000 [2:29:21<1:07:16,  2.40s/it, loss=0.4946]\u001b[A\n",
            "Training:  66%|██████▋   | 3317/5000 [2:29:23<1:05:53,  2.35s/it, loss=0.4946]\u001b[A\n",
            "Training:  66%|██████▋   | 3317/5000 [2:29:23<1:05:53,  2.35s/it, loss=0.3815]\u001b[A\n",
            "Training:  66%|██████▋   | 3318/5000 [2:29:26<1:05:00,  2.32s/it, loss=0.3815]\u001b[A\n",
            "Training:  66%|██████▋   | 3318/5000 [2:29:26<1:05:00,  2.32s/it, loss=0.4841]\u001b[A\n",
            "Training:  66%|██████▋   | 3319/5000 [2:29:28<1:05:13,  2.33s/it, loss=0.4841]\u001b[A\n",
            "Training:  66%|██████▋   | 3319/5000 [2:29:28<1:05:13,  2.33s/it, loss=0.5422]\u001b[A\n",
            "Training:  66%|██████▋   | 3320/5000 [2:29:31<1:08:49,  2.46s/it, loss=0.5422]\u001b[A\n",
            "Training:  66%|██████▋   | 3320/5000 [2:29:31<1:08:49,  2.46s/it, loss=0.4747]\u001b[A\n",
            "Training:  66%|██████▋   | 3321/5000 [2:29:33<1:07:03,  2.40s/it, loss=0.4747]\u001b[A\n",
            "Training:  66%|██████▋   | 3321/5000 [2:29:33<1:07:03,  2.40s/it, loss=0.3341]\u001b[A\n",
            "Training:  66%|██████▋   | 3322/5000 [2:29:35<1:05:45,  2.35s/it, loss=0.3341]\u001b[A\n",
            "Training:  66%|██████▋   | 3322/5000 [2:29:35<1:05:45,  2.35s/it, loss=0.3551]\u001b[A\n",
            "Training:  66%|██████▋   | 3323/5000 [2:29:38<1:04:58,  2.32s/it, loss=0.3551]\u001b[A\n",
            "Training:  66%|██████▋   | 3323/5000 [2:29:38<1:04:58,  2.32s/it, loss=0.5057]\u001b[A\n",
            "Training:  66%|██████▋   | 3324/5000 [2:29:40<1:04:27,  2.31s/it, loss=0.5057]\u001b[A\n",
            "Training:  66%|██████▋   | 3324/5000 [2:29:40<1:04:27,  2.31s/it, loss=0.2806]\u001b[A\n",
            "Training:  66%|██████▋   | 3325/5000 [2:29:43<1:08:08,  2.44s/it, loss=0.2806]\u001b[A\n",
            "Training:  66%|██████▋   | 3325/5000 [2:29:43<1:08:08,  2.44s/it, loss=0.7511]\u001b[A\n",
            "Training:  67%|██████▋   | 3326/5000 [2:29:45<1:06:41,  2.39s/it, loss=0.7511]\u001b[A\n",
            "Training:  67%|██████▋   | 3326/5000 [2:29:45<1:06:41,  2.39s/it, loss=0.5562]\u001b[A\n",
            "Training:  67%|██████▋   | 3327/5000 [2:29:47<1:05:24,  2.35s/it, loss=0.5562]\u001b[A\n",
            "Training:  67%|██████▋   | 3327/5000 [2:29:47<1:05:24,  2.35s/it, loss=0.5134]\u001b[A\n",
            "Training:  67%|██████▋   | 3328/5000 [2:29:49<1:04:40,  2.32s/it, loss=0.5134]\u001b[A\n",
            "Training:  67%|██████▋   | 3328/5000 [2:29:49<1:04:40,  2.32s/it, loss=0.4598]\u001b[A\n",
            "Training:  67%|██████▋   | 3329/5000 [2:29:52<1:03:51,  2.29s/it, loss=0.4598]\u001b[A\n",
            "Training:  67%|██████▋   | 3329/5000 [2:29:52<1:03:51,  2.29s/it, loss=0.3738]\u001b[A\n",
            "Training:  67%|██████▋   | 3330/5000 [2:29:54<1:07:51,  2.44s/it, loss=0.3738]\u001b[A\n",
            "Training:  67%|██████▋   | 3330/5000 [2:29:54<1:07:51,  2.44s/it, loss=0.4961]\u001b[A\n",
            "Training:  67%|██████▋   | 3331/5000 [2:29:57<1:06:18,  2.38s/it, loss=0.4961]\u001b[A\n",
            "Training:  67%|██████▋   | 3331/5000 [2:29:57<1:06:18,  2.38s/it, loss=0.6130]\u001b[A\n",
            "Training:  67%|██████▋   | 3332/5000 [2:29:59<1:05:10,  2.34s/it, loss=0.6130]\u001b[A\n",
            "Training:  67%|██████▋   | 3332/5000 [2:29:59<1:05:10,  2.34s/it, loss=0.5263]\u001b[A\n",
            "Training:  67%|██████▋   | 3333/5000 [2:30:01<1:04:14,  2.31s/it, loss=0.5263]\u001b[A\n",
            "Training:  67%|██████▋   | 3333/5000 [2:30:01<1:04:14,  2.31s/it, loss=0.5220]\u001b[A\n",
            "Training:  67%|██████▋   | 3334/5000 [2:30:03<1:03:46,  2.30s/it, loss=0.5220]\u001b[A\n",
            "Training:  67%|██████▋   | 3334/5000 [2:30:03<1:03:46,  2.30s/it, loss=0.5003]\u001b[A\n",
            "Training:  67%|██████▋   | 3335/5000 [2:30:06<1:07:34,  2.43s/it, loss=0.5003]\u001b[A\n",
            "Training:  67%|██████▋   | 3335/5000 [2:30:06<1:07:34,  2.43s/it, loss=0.3848]\u001b[A\n",
            "Training:  67%|██████▋   | 3336/5000 [2:30:08<1:05:48,  2.37s/it, loss=0.3848]\u001b[A\n",
            "Training:  67%|██████▋   | 3336/5000 [2:30:08<1:05:48,  2.37s/it, loss=0.4018]\u001b[A\n",
            "Training:  67%|██████▋   | 3337/5000 [2:30:11<1:05:10,  2.35s/it, loss=0.4018]\u001b[A\n",
            "Training:  67%|██████▋   | 3337/5000 [2:30:11<1:05:10,  2.35s/it, loss=0.3733]\u001b[A\n",
            "Training:  67%|██████▋   | 3338/5000 [2:30:13<1:04:33,  2.33s/it, loss=0.3733]\u001b[A\n",
            "Training:  67%|██████▋   | 3338/5000 [2:30:13<1:04:33,  2.33s/it, loss=0.3509]\u001b[A\n",
            "Training:  67%|██████▋   | 3339/5000 [2:30:15<1:03:45,  2.30s/it, loss=0.3509]\u001b[A\n",
            "Training:  67%|██████▋   | 3339/5000 [2:30:15<1:03:45,  2.30s/it, loss=0.4330]\u001b[A\n",
            "Training:  67%|██████▋   | 3340/5000 [2:30:18<1:07:43,  2.45s/it, loss=0.4330]\u001b[A\n",
            "Training:  67%|██████▋   | 3340/5000 [2:30:18<1:07:43,  2.45s/it, loss=0.2385]\u001b[A\n",
            "Training:  67%|██████▋   | 3341/5000 [2:30:20<1:06:22,  2.40s/it, loss=0.2385]\u001b[A\n",
            "Training:  67%|██████▋   | 3341/5000 [2:30:20<1:06:22,  2.40s/it, loss=0.4157]\u001b[A\n",
            "Training:  67%|██████▋   | 3342/5000 [2:30:22<1:04:57,  2.35s/it, loss=0.4157]\u001b[A\n",
            "Training:  67%|██████▋   | 3342/5000 [2:30:22<1:04:57,  2.35s/it, loss=0.4862]\u001b[A\n",
            "Training:  67%|██████▋   | 3343/5000 [2:30:25<1:04:09,  2.32s/it, loss=0.4862]\u001b[A\n",
            "Training:  67%|██████▋   | 3343/5000 [2:30:25<1:04:09,  2.32s/it, loss=0.1892]\u001b[A\n",
            "Training:  67%|██████▋   | 3344/5000 [2:30:27<1:03:25,  2.30s/it, loss=0.1892]\u001b[A\n",
            "Training:  67%|██████▋   | 3344/5000 [2:30:27<1:03:25,  2.30s/it, loss=0.3915]\u001b[A\n",
            "Training:  67%|██████▋   | 3345/5000 [2:30:30<1:07:21,  2.44s/it, loss=0.3915]\u001b[A\n",
            "Training:  67%|██████▋   | 3345/5000 [2:30:30<1:07:21,  2.44s/it, loss=0.4009]\u001b[A\n",
            "Training:  67%|██████▋   | 3346/5000 [2:30:32<1:05:56,  2.39s/it, loss=0.4009]\u001b[A\n",
            "Training:  67%|██████▋   | 3346/5000 [2:30:32<1:05:56,  2.39s/it, loss=0.4932]\u001b[A\n",
            "Training:  67%|██████▋   | 3347/5000 [2:30:34<1:04:50,  2.35s/it, loss=0.4932]\u001b[A\n",
            "Training:  67%|██████▋   | 3347/5000 [2:30:34<1:04:50,  2.35s/it, loss=0.7465]\u001b[A\n",
            "Training:  67%|██████▋   | 3348/5000 [2:30:37<1:04:04,  2.33s/it, loss=0.7465]\u001b[A\n",
            "Training:  67%|██████▋   | 3348/5000 [2:30:37<1:04:04,  2.33s/it, loss=0.4209]\u001b[A\n",
            "Training:  67%|██████▋   | 3349/5000 [2:30:39<1:03:28,  2.31s/it, loss=0.4209]\u001b[A\n",
            "Training:  67%|██████▋   | 3349/5000 [2:30:39<1:03:28,  2.31s/it, loss=0.4388]\u001b[A\n",
            "Training:  67%|██████▋   | 3350/5000 [2:30:42<1:07:02,  2.44s/it, loss=0.4388]\u001b[A\n",
            "Training:  67%|██████▋   | 3350/5000 [2:30:42<1:07:02,  2.44s/it, loss=0.2716]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 3350 ---\n",
            "Prompt: 'The '\n",
            "The , earl, is and of.\n",
            "Firstingerer\n",
            "First:Not, citizens I,I thou anyt the tell,, to the this, we leave your:Your be grave may' time:N that have to it.\n",
            "Thirding and the dog now what hath no to again\n",
            "COROLUSIAN:Is true will no.\n",
            "Thirding fair battleards your will\n",
            " what hast on when have you known you best do orWelcome I marry '.,What you\n",
            "Prompt: 'In '\n",
            "In :Al, goodam indeed sirF, low their?\n",
            " call not friend to at to up on\n",
            "self out:an and the please, to me thee;tis\n",
            " gentlemen. their at in, cons\n",
            " to enemies thee\n",
            " in Anti, give hiscles.\n",
            "First mad\n",
            " have thee to all.!\n",
            "First me.\n",
            "First:What will to all heart\n",
            "? you made on\n",
            " vain at supp toishTh when her at? you become;there\n",
            " brought.\n",
            "Prompt: 'To '\n",
            "To  him beul lay pride he\n",
            " make powereds: yourself his head m, look;\n",
            " cannot him him a of are-en\n",
            " had me show out\n",
            "Lab by; your begin true I your leave\n",
            " be val, them; face your would dur not me I\n",
            " would take you a upon.am\n",
            " would buy me it him home\n",
            " what give your,game all; your please,, wear the of are ofing with own lac, theyian when make thou ahigh our\n",
            "Prompt: 'A '\n",
            "A , sp and plotsss thee thy,\n",
            " h'd, not the of poor are together\n",
            "fore, to her of.\n",
            "First eaten\n",
            " mustque my;\n",
            "ay sure three\n",
            " country been any,ught let the freecher mine\n",
            "ael to:,, seem home preserving.\n",
            "First: he sit to all.\n",
            "First hold much no:The priest his or give\n",
            " will him I made lookp with.\n",
            "First:O musting fit by.\n",
            "Firstyou\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  67%|██████▋   | 3351/5000 [2:30:56<2:47:39,  6.10s/it, loss=0.2716]\u001b[A\n",
            "Training:  67%|██████▋   | 3351/5000 [2:30:56<2:47:39,  6.10s/it, loss=0.4015]\u001b[A\n",
            "Training:  67%|██████▋   | 3352/5000 [2:30:58<2:15:48,  4.94s/it, loss=0.4015]\u001b[A\n",
            "Training:  67%|██████▋   | 3352/5000 [2:30:58<2:15:48,  4.94s/it, loss=0.3120]\u001b[A\n",
            "Training:  67%|██████▋   | 3353/5000 [2:31:01<1:53:27,  4.13s/it, loss=0.3120]\u001b[A\n",
            "Training:  67%|██████▋   | 3353/5000 [2:31:01<1:53:27,  4.13s/it, loss=0.3288]\u001b[A\n",
            "Training:  67%|██████▋   | 3354/5000 [2:31:03<1:38:56,  3.61s/it, loss=0.3288]\u001b[A\n",
            "Training:  67%|██████▋   | 3354/5000 [2:31:03<1:38:56,  3.61s/it, loss=0.5421]\u001b[A\n",
            "Training:  67%|██████▋   | 3355/5000 [2:31:06<1:30:52,  3.31s/it, loss=0.5421]\u001b[A\n",
            "Training:  67%|██████▋   | 3355/5000 [2:31:06<1:30:52,  3.31s/it, loss=0.2686]\u001b[A\n",
            "Training:  67%|██████▋   | 3356/5000 [2:31:08<1:22:11,  3.00s/it, loss=0.2686]\u001b[A\n",
            "Training:  67%|██████▋   | 3356/5000 [2:31:08<1:22:11,  3.00s/it, loss=0.3041]\u001b[A\n",
            "Training:  67%|██████▋   | 3357/5000 [2:31:10<1:15:58,  2.77s/it, loss=0.3041]\u001b[A\n",
            "Training:  67%|██████▋   | 3357/5000 [2:31:10<1:15:58,  2.77s/it, loss=0.3360]\u001b[A\n",
            "Training:  67%|██████▋   | 3358/5000 [2:31:12<1:11:42,  2.62s/it, loss=0.3360]\u001b[A\n",
            "Training:  67%|██████▋   | 3358/5000 [2:31:12<1:11:42,  2.62s/it, loss=0.4652]\u001b[A\n",
            "Training:  67%|██████▋   | 3359/5000 [2:31:15<1:09:29,  2.54s/it, loss=0.4652]\u001b[A\n",
            "Training:  67%|██████▋   | 3359/5000 [2:31:15<1:09:29,  2.54s/it, loss=0.3687]\u001b[A\n",
            "Training:  67%|██████▋   | 3360/5000 [2:31:17<1:10:26,  2.58s/it, loss=0.3687]\u001b[A\n",
            "Training:  67%|██████▋   | 3360/5000 [2:31:18<1:10:26,  2.58s/it, loss=0.6570]\u001b[A\n",
            "Training:  67%|██████▋   | 3361/5000 [2:31:20<1:07:40,  2.48s/it, loss=0.6570]\u001b[A\n",
            "Training:  67%|██████▋   | 3361/5000 [2:31:20<1:07:40,  2.48s/it, loss=0.4518]\u001b[A\n",
            "Training:  67%|██████▋   | 3362/5000 [2:31:22<1:05:44,  2.41s/it, loss=0.4518]\u001b[A\n",
            "Training:  67%|██████▋   | 3362/5000 [2:31:22<1:05:44,  2.41s/it, loss=0.3819]\u001b[A\n",
            "Training:  67%|██████▋   | 3363/5000 [2:31:24<1:04:27,  2.36s/it, loss=0.3819]\u001b[A\n",
            "Training:  67%|██████▋   | 3363/5000 [2:31:24<1:04:27,  2.36s/it, loss=0.4118]\u001b[A\n",
            "Training:  67%|██████▋   | 3364/5000 [2:31:27<1:04:06,  2.35s/it, loss=0.4118]\u001b[A\n",
            "Training:  67%|██████▋   | 3364/5000 [2:31:27<1:04:06,  2.35s/it, loss=0.5451]\u001b[A\n",
            "Training:  67%|██████▋   | 3365/5000 [2:31:29<1:07:10,  2.47s/it, loss=0.5451]\u001b[A\n",
            "Training:  67%|██████▋   | 3365/5000 [2:31:29<1:07:10,  2.47s/it, loss=0.3111]\u001b[A\n",
            "Training:  67%|██████▋   | 3366/5000 [2:31:32<1:05:36,  2.41s/it, loss=0.3111]\u001b[A\n",
            "Training:  67%|██████▋   | 3366/5000 [2:31:32<1:05:36,  2.41s/it, loss=0.3987]\u001b[A\n",
            "Training:  67%|██████▋   | 3367/5000 [2:31:34<1:04:28,  2.37s/it, loss=0.3987]\u001b[A\n",
            "Training:  67%|██████▋   | 3367/5000 [2:31:34<1:04:28,  2.37s/it, loss=0.5216]\u001b[A\n",
            "Training:  67%|██████▋   | 3368/5000 [2:31:36<1:03:22,  2.33s/it, loss=0.5216]\u001b[A\n",
            "Training:  67%|██████▋   | 3368/5000 [2:31:36<1:03:22,  2.33s/it, loss=0.3954]\u001b[A\n",
            "Training:  67%|██████▋   | 3369/5000 [2:31:38<1:03:08,  2.32s/it, loss=0.3954]\u001b[A\n",
            "Training:  67%|██████▋   | 3369/5000 [2:31:38<1:03:08,  2.32s/it, loss=0.3965]\u001b[A\n",
            "Training:  67%|██████▋   | 3370/5000 [2:31:41<1:06:41,  2.46s/it, loss=0.3965]\u001b[A\n",
            "Training:  67%|██████▋   | 3370/5000 [2:31:41<1:06:41,  2.46s/it, loss=0.6942]\u001b[A\n",
            "Training:  67%|██████▋   | 3371/5000 [2:31:43<1:04:59,  2.39s/it, loss=0.6942]\u001b[A\n",
            "Training:  67%|██████▋   | 3371/5000 [2:31:43<1:04:59,  2.39s/it, loss=0.4318]\u001b[A\n",
            "Training:  67%|██████▋   | 3372/5000 [2:31:46<1:03:47,  2.35s/it, loss=0.4318]\u001b[A\n",
            "Training:  67%|██████▋   | 3372/5000 [2:31:46<1:03:47,  2.35s/it, loss=0.4443]\u001b[A\n",
            "Training:  67%|██████▋   | 3373/5000 [2:31:48<1:03:26,  2.34s/it, loss=0.4443]\u001b[A\n",
            "Training:  67%|██████▋   | 3373/5000 [2:31:48<1:03:26,  2.34s/it, loss=0.3414]\u001b[A\n",
            "Training:  67%|██████▋   | 3374/5000 [2:31:50<1:02:47,  2.32s/it, loss=0.3414]\u001b[A\n",
            "Training:  67%|██████▋   | 3374/5000 [2:31:50<1:02:47,  2.32s/it, loss=0.5354]\u001b[A\n",
            "Training:  68%|██████▊   | 3375/5000 [2:31:53<1:06:46,  2.47s/it, loss=0.5354]\u001b[A\n",
            "Training:  68%|██████▊   | 3375/5000 [2:31:53<1:06:46,  2.47s/it, loss=0.4937]\u001b[A\n",
            "Training:  68%|██████▊   | 3376/5000 [2:31:55<1:04:56,  2.40s/it, loss=0.4937]\u001b[A\n",
            "Training:  68%|██████▊   | 3376/5000 [2:31:55<1:04:56,  2.40s/it, loss=0.5745]\u001b[A\n",
            "Training:  68%|██████▊   | 3377/5000 [2:31:58<1:03:30,  2.35s/it, loss=0.5745]\u001b[A\n",
            "Training:  68%|██████▊   | 3377/5000 [2:31:58<1:03:30,  2.35s/it, loss=0.2803]\u001b[A\n",
            "Training:  68%|██████▊   | 3378/5000 [2:32:00<1:02:44,  2.32s/it, loss=0.2803]\u001b[A\n",
            "Training:  68%|██████▊   | 3378/5000 [2:32:00<1:02:44,  2.32s/it, loss=0.5767]\u001b[A\n",
            "Training:  68%|██████▊   | 3379/5000 [2:32:02<1:02:06,  2.30s/it, loss=0.5767]\u001b[A\n",
            "Training:  68%|██████▊   | 3379/5000 [2:32:02<1:02:06,  2.30s/it, loss=0.3486]\u001b[A\n",
            "Training:  68%|██████▊   | 3380/5000 [2:32:05<1:05:46,  2.44s/it, loss=0.3486]\u001b[A\n",
            "Training:  68%|██████▊   | 3380/5000 [2:32:05<1:05:46,  2.44s/it, loss=0.5310]\u001b[A\n",
            "Training:  68%|██████▊   | 3381/5000 [2:32:07<1:04:12,  2.38s/it, loss=0.5310]\u001b[A\n",
            "Training:  68%|██████▊   | 3381/5000 [2:32:07<1:04:12,  2.38s/it, loss=0.4679]\u001b[A\n",
            "Training:  68%|██████▊   | 3382/5000 [2:32:09<1:03:00,  2.34s/it, loss=0.4679]\u001b[A\n",
            "Training:  68%|██████▊   | 3382/5000 [2:32:09<1:03:00,  2.34s/it, loss=0.3935]\u001b[A\n",
            "Training:  68%|██████▊   | 3383/5000 [2:32:11<1:02:15,  2.31s/it, loss=0.3935]\u001b[A\n",
            "Training:  68%|██████▊   | 3383/5000 [2:32:12<1:02:15,  2.31s/it, loss=0.4090]\u001b[A\n",
            "Training:  68%|██████▊   | 3384/5000 [2:32:14<1:01:42,  2.29s/it, loss=0.4090]\u001b[A\n",
            "Training:  68%|██████▊   | 3384/5000 [2:32:14<1:01:42,  2.29s/it, loss=0.3504]\u001b[A\n",
            "Training:  68%|██████▊   | 3385/5000 [2:32:17<1:05:32,  2.43s/it, loss=0.3504]\u001b[A\n",
            "Training:  68%|██████▊   | 3385/5000 [2:32:17<1:05:32,  2.43s/it, loss=0.4468]\u001b[A\n",
            "Training:  68%|██████▊   | 3386/5000 [2:32:19<1:03:59,  2.38s/it, loss=0.4468]\u001b[A\n",
            "Training:  68%|██████▊   | 3386/5000 [2:32:19<1:03:59,  2.38s/it, loss=0.6075]\u001b[A\n",
            "Training:  68%|██████▊   | 3387/5000 [2:32:21<1:03:00,  2.34s/it, loss=0.6075]\u001b[A\n",
            "Training:  68%|██████▊   | 3387/5000 [2:32:21<1:03:00,  2.34s/it, loss=0.3821]\u001b[A\n",
            "Training:  68%|██████▊   | 3388/5000 [2:32:23<1:02:32,  2.33s/it, loss=0.3821]\u001b[A\n",
            "Training:  68%|██████▊   | 3388/5000 [2:32:23<1:02:32,  2.33s/it, loss=0.4468]\u001b[A\n",
            "Training:  68%|██████▊   | 3389/5000 [2:32:26<1:01:49,  2.30s/it, loss=0.4468]\u001b[A\n",
            "Training:  68%|██████▊   | 3389/5000 [2:32:26<1:01:49,  2.30s/it, loss=0.5136]\u001b[A\n",
            "Training:  68%|██████▊   | 3390/5000 [2:32:28<1:05:42,  2.45s/it, loss=0.5136]\u001b[A\n",
            "Training:  68%|██████▊   | 3390/5000 [2:32:28<1:05:42,  2.45s/it, loss=0.3830]\u001b[A\n",
            "Training:  68%|██████▊   | 3391/5000 [2:32:31<1:04:18,  2.40s/it, loss=0.3830]\u001b[A\n",
            "Training:  68%|██████▊   | 3391/5000 [2:32:31<1:04:18,  2.40s/it, loss=0.3096]\u001b[A\n",
            "Training:  68%|██████▊   | 3392/5000 [2:32:33<1:03:17,  2.36s/it, loss=0.3096]\u001b[A\n",
            "Training:  68%|██████▊   | 3392/5000 [2:32:33<1:03:17,  2.36s/it, loss=0.2945]\u001b[A\n",
            "Training:  68%|██████▊   | 3393/5000 [2:32:35<1:02:36,  2.34s/it, loss=0.2945]\u001b[A\n",
            "Training:  68%|██████▊   | 3393/5000 [2:32:35<1:02:36,  2.34s/it, loss=0.4136]\u001b[A\n",
            "Training:  68%|██████▊   | 3394/5000 [2:32:37<1:01:52,  2.31s/it, loss=0.4136]\u001b[A\n",
            "Training:  68%|██████▊   | 3394/5000 [2:32:37<1:01:52,  2.31s/it, loss=0.3036]\u001b[A\n",
            "Training:  68%|██████▊   | 3395/5000 [2:32:40<1:05:39,  2.45s/it, loss=0.3036]\u001b[A\n",
            "Training:  68%|██████▊   | 3395/5000 [2:32:40<1:05:39,  2.45s/it, loss=0.4105]\u001b[A\n",
            "Training:  68%|██████▊   | 3396/5000 [2:32:43<1:04:12,  2.40s/it, loss=0.4105]\u001b[A\n",
            "Training:  68%|██████▊   | 3396/5000 [2:32:43<1:04:12,  2.40s/it, loss=0.4679]\u001b[A\n",
            "Training:  68%|██████▊   | 3397/5000 [2:32:45<1:03:02,  2.36s/it, loss=0.4679]\u001b[A\n",
            "Training:  68%|██████▊   | 3397/5000 [2:32:45<1:03:02,  2.36s/it, loss=0.6744]\u001b[A\n",
            "Training:  68%|██████▊   | 3398/5000 [2:32:47<1:02:05,  2.33s/it, loss=0.6744]\u001b[A\n",
            "Training:  68%|██████▊   | 3398/5000 [2:32:47<1:02:05,  2.33s/it, loss=0.6095]\u001b[A\n",
            "Training:  68%|██████▊   | 3399/5000 [2:32:49<1:01:26,  2.30s/it, loss=0.6095]\u001b[A\n",
            "Training:  68%|██████▊   | 3399/5000 [2:32:49<1:01:26,  2.30s/it, loss=0.4346]\u001b[A\n",
            "Training:  68%|██████▊   | 3400/5000 [2:32:52<1:05:28,  2.46s/it, loss=0.4346]\u001b[A\n",
            "Training:  68%|██████▊   | 3400/5000 [2:32:52<1:05:28,  2.46s/it, loss=0.5943]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 3400 ---\n",
            "Prompt: 'The '\n",
            "The 's's's's learn King:The is to flb\n",
            " Have a f, a man a old'som.\n",
            " shownO, me last are shoes What it;which ayTole\n",
            " my, my, the sets in old'siesold, a little.\n",
            "N, ' incredible some gentleman\n",
            " name\n",
            " manners he.\n",
            "SAMON be forth\n",
            " mymen on boy you take.\n",
            "SAMON:' beakard it a thing. is good which kin it,\n",
            "Prompt: 'In '\n",
            "In  a a:; light as as\n",
            " man true his; now dark tailor sweet blood\n",
            "le wall a and.\n",
            "SAMON\n",
            "ither\n",
            " must come I you as to?\n",
            "BALAS:Draw call I it\n",
            " was:ee I honour be thee;- is own in new,or you\n",
            " words\n",
            "ORY\n",
            " 'ardon in have heir\n",
            " words I on that.\n",
            "SAMON can.\n",
            "CAPET:Upon!,le I.\n",
            "CAPET make was asOr you\n",
            "Prompt: 'To '\n",
            "To 's andbal's men me.\n",
            "EXT: will I.oe man how I dead\n",
            " Jes nestLook him! royal sworn sir man and\n",
            " aptned:AG, mer.\n",
            "Melf me news dear, this be and\n",
            " shame\n",
            " words one.\n",
            "SAMON I my!\n",
            "N, trustoth\n",
            " me news\n",
            " this a of,.\n",
            "SAMON did\n",
            " when t: do on w. hither lady armour,am,.\n",
            "REG my!How did not none\n",
            "Prompt: 'A '\n",
            "A , speak what toer love speak\n",
            " any, true do of.\n",
            "N, ' iron:'.' it un g,IS\n",
            " than is women Hear: sim, my.\n",
            "arer, you chances did.\n",
            "Fwell takenio best, sing\n",
            "an faith I '.\n",
            "ROO\n",
            "?\n",
            " treason v,.\n",
            "oCall, Saint:,. your--\n",
            " night nurse it--\n",
            ", will better:The of name the have murdered come\n",
            " ' timeu have\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  68%|██████▊   | 3401/5000 [2:33:07<2:42:22,  6.09s/it, loss=0.5943]\u001b[A\n",
            "Training:  68%|██████▊   | 3401/5000 [2:33:07<2:42:22,  6.09s/it, loss=0.3458]\u001b[A\n",
            "Training:  68%|██████▊   | 3402/5000 [2:33:09<2:11:35,  4.94s/it, loss=0.3458]\u001b[A\n",
            "Training:  68%|██████▊   | 3402/5000 [2:33:09<2:11:35,  4.94s/it, loss=0.3100]\u001b[A\n",
            "Training:  68%|██████▊   | 3403/5000 [2:33:11<1:50:01,  4.13s/it, loss=0.3100]\u001b[A\n",
            "Training:  68%|██████▊   | 3403/5000 [2:33:11<1:50:01,  4.13s/it, loss=0.4436]\u001b[A\n",
            "Training:  68%|██████▊   | 3404/5000 [2:33:14<1:35:59,  3.61s/it, loss=0.4436]\u001b[A\n",
            "Training:  68%|██████▊   | 3404/5000 [2:33:14<1:35:59,  3.61s/it, loss=0.4013]\u001b[A\n",
            "Training:  68%|██████▊   | 3405/5000 [2:33:16<1:28:25,  3.33s/it, loss=0.4013]\u001b[A\n",
            "Training:  68%|██████▊   | 3405/5000 [2:33:16<1:28:25,  3.33s/it, loss=0.3613]\u001b[A\n",
            "Training:  68%|██████▊   | 3406/5000 [2:33:18<1:19:52,  3.01s/it, loss=0.3613]\u001b[A\n",
            "Training:  68%|██████▊   | 3406/5000 [2:33:18<1:19:52,  3.01s/it, loss=0.6086]\u001b[A\n",
            "Training:  68%|██████▊   | 3407/5000 [2:33:21<1:13:45,  2.78s/it, loss=0.6086]\u001b[A\n",
            "Training:  68%|██████▊   | 3407/5000 [2:33:21<1:13:45,  2.78s/it, loss=0.3556]\u001b[A\n",
            "Training:  68%|██████▊   | 3408/5000 [2:33:23<1:09:42,  2.63s/it, loss=0.3556]\u001b[A\n",
            "Training:  68%|██████▊   | 3408/5000 [2:33:23<1:09:42,  2.63s/it, loss=0.4154]\u001b[A\n",
            "Training:  68%|██████▊   | 3409/5000 [2:33:25<1:07:25,  2.54s/it, loss=0.4154]\u001b[A\n",
            "Training:  68%|██████▊   | 3409/5000 [2:33:25<1:07:25,  2.54s/it, loss=0.4118]\u001b[A\n",
            "Training:  68%|██████▊   | 3410/5000 [2:33:28<1:08:40,  2.59s/it, loss=0.4118]\u001b[A\n",
            "Training:  68%|██████▊   | 3410/5000 [2:33:28<1:08:40,  2.59s/it, loss=0.5973]\u001b[A\n",
            "Training:  68%|██████▊   | 3411/5000 [2:33:30<1:05:52,  2.49s/it, loss=0.5973]\u001b[A\n",
            "Training:  68%|██████▊   | 3411/5000 [2:33:30<1:05:52,  2.49s/it, loss=0.2492]\u001b[A\n",
            "Training:  68%|██████▊   | 3412/5000 [2:33:33<1:04:10,  2.42s/it, loss=0.2492]\u001b[A\n",
            "Training:  68%|██████▊   | 3412/5000 [2:33:33<1:04:10,  2.42s/it, loss=0.2116]\u001b[A\n",
            "Training:  68%|██████▊   | 3413/5000 [2:33:35<1:02:48,  2.37s/it, loss=0.2116]\u001b[A\n",
            "Training:  68%|██████▊   | 3413/5000 [2:33:35<1:02:48,  2.37s/it, loss=0.4373]\u001b[A\n",
            "Training:  68%|██████▊   | 3414/5000 [2:33:37<1:02:19,  2.36s/it, loss=0.4373]\u001b[A\n",
            "Training:  68%|██████▊   | 3414/5000 [2:33:37<1:02:19,  2.36s/it, loss=0.3859]\u001b[A\n",
            "Training:  68%|██████▊   | 3415/5000 [2:33:40<1:05:12,  2.47s/it, loss=0.3859]\u001b[A\n",
            "Training:  68%|██████▊   | 3415/5000 [2:33:40<1:05:12,  2.47s/it, loss=0.4009]\u001b[A\n",
            "Training:  68%|██████▊   | 3416/5000 [2:33:42<1:03:24,  2.40s/it, loss=0.4009]\u001b[A\n",
            "Training:  68%|██████▊   | 3416/5000 [2:33:42<1:03:24,  2.40s/it, loss=0.4467]\u001b[A\n",
            "Training:  68%|██████▊   | 3417/5000 [2:33:44<1:02:18,  2.36s/it, loss=0.4467]\u001b[A\n",
            "Training:  68%|██████▊   | 3417/5000 [2:33:44<1:02:18,  2.36s/it, loss=0.6191]\u001b[A\n",
            "Training:  68%|██████▊   | 3418/5000 [2:33:47<1:01:17,  2.32s/it, loss=0.6191]\u001b[A\n",
            "Training:  68%|██████▊   | 3418/5000 [2:33:47<1:01:17,  2.32s/it, loss=0.3420]\u001b[A\n",
            "Training:  68%|██████▊   | 3419/5000 [2:33:49<1:00:41,  2.30s/it, loss=0.3420]\u001b[A\n",
            "Training:  68%|██████▊   | 3419/5000 [2:33:49<1:00:41,  2.30s/it, loss=0.3161]\u001b[A\n",
            "Training:  68%|██████▊   | 3420/5000 [2:33:52<1:04:23,  2.45s/it, loss=0.3161]\u001b[A\n",
            "Training:  68%|██████▊   | 3420/5000 [2:33:52<1:04:23,  2.45s/it, loss=0.3539]\u001b[A\n",
            "Training:  68%|██████▊   | 3421/5000 [2:33:54<1:02:58,  2.39s/it, loss=0.3539]\u001b[A\n",
            "Training:  68%|██████▊   | 3421/5000 [2:33:54<1:02:58,  2.39s/it, loss=0.5890]\u001b[A\n",
            "Training:  68%|██████▊   | 3422/5000 [2:33:56<1:01:55,  2.35s/it, loss=0.5890]\u001b[A\n",
            "Training:  68%|██████▊   | 3422/5000 [2:33:56<1:01:55,  2.35s/it, loss=0.3387]\u001b[A\n",
            "Training:  68%|██████▊   | 3423/5000 [2:33:58<1:01:07,  2.33s/it, loss=0.3387]\u001b[A\n",
            "Training:  68%|██████▊   | 3423/5000 [2:33:58<1:01:07,  2.33s/it, loss=0.5243]\u001b[A\n",
            "Training:  68%|██████▊   | 3424/5000 [2:34:01<1:00:18,  2.30s/it, loss=0.5243]\u001b[A\n",
            "Training:  68%|██████▊   | 3424/5000 [2:34:01<1:00:18,  2.30s/it, loss=0.3824]\u001b[A\n",
            "Training:  68%|██████▊   | 3425/5000 [2:34:03<1:03:53,  2.43s/it, loss=0.3824]\u001b[A\n",
            "Training:  68%|██████▊   | 3425/5000 [2:34:03<1:03:53,  2.43s/it, loss=0.4930]\u001b[A\n",
            "Training:  69%|██████▊   | 3426/5000 [2:34:06<1:02:35,  2.39s/it, loss=0.4930]\u001b[A\n",
            "Training:  69%|██████▊   | 3426/5000 [2:34:06<1:02:35,  2.39s/it, loss=0.4162]\u001b[A\n",
            "Training:  69%|██████▊   | 3427/5000 [2:34:08<1:01:33,  2.35s/it, loss=0.4162]\u001b[A\n",
            "Training:  69%|██████▊   | 3427/5000 [2:34:08<1:01:33,  2.35s/it, loss=0.4477]\u001b[A\n",
            "Training:  69%|██████▊   | 3428/5000 [2:34:10<1:00:40,  2.32s/it, loss=0.4477]\u001b[A\n",
            "Training:  69%|██████▊   | 3428/5000 [2:34:10<1:00:40,  2.32s/it, loss=0.3782]\u001b[A\n",
            "Training:  69%|██████▊   | 3429/5000 [2:34:12<1:00:08,  2.30s/it, loss=0.3782]\u001b[A\n",
            "Training:  69%|██████▊   | 3429/5000 [2:34:12<1:00:08,  2.30s/it, loss=0.3721]\u001b[A\n",
            "Training:  69%|██████▊   | 3430/5000 [2:34:15<1:03:48,  2.44s/it, loss=0.3721]\u001b[A\n",
            "Training:  69%|██████▊   | 3430/5000 [2:34:15<1:03:48,  2.44s/it, loss=0.7247]\u001b[A\n",
            "Training:  69%|██████▊   | 3431/5000 [2:34:17<1:02:17,  2.38s/it, loss=0.7247]\u001b[A\n",
            "Training:  69%|██████▊   | 3431/5000 [2:34:17<1:02:17,  2.38s/it, loss=0.6080]\u001b[A\n",
            "Training:  69%|██████▊   | 3432/5000 [2:34:20<1:01:18,  2.35s/it, loss=0.6080]\u001b[A\n",
            "Training:  69%|██████▊   | 3432/5000 [2:34:20<1:01:18,  2.35s/it, loss=0.2355]\u001b[A\n",
            "Training:  69%|██████▊   | 3433/5000 [2:34:22<1:00:25,  2.31s/it, loss=0.2355]\u001b[A\n",
            "Training:  69%|██████▊   | 3433/5000 [2:34:22<1:00:25,  2.31s/it, loss=0.2991]\u001b[A\n",
            "Training:  69%|██████▊   | 3434/5000 [2:34:24<1:00:07,  2.30s/it, loss=0.2991]\u001b[A\n",
            "Training:  69%|██████▊   | 3434/5000 [2:34:24<1:00:07,  2.30s/it, loss=0.3818]\u001b[A\n",
            "Training:  69%|██████▊   | 3435/5000 [2:34:27<1:03:53,  2.45s/it, loss=0.3818]\u001b[A\n",
            "Training:  69%|██████▊   | 3435/5000 [2:34:27<1:03:53,  2.45s/it, loss=0.3486]\u001b[A\n",
            "Training:  69%|██████▊   | 3436/5000 [2:34:29<1:02:51,  2.41s/it, loss=0.3486]\u001b[A\n",
            "Training:  69%|██████▊   | 3436/5000 [2:34:29<1:02:51,  2.41s/it, loss=0.3947]\u001b[A\n",
            "Training:  69%|██████▊   | 3437/5000 [2:34:32<1:01:38,  2.37s/it, loss=0.3947]\u001b[A\n",
            "Training:  69%|██████▊   | 3437/5000 [2:34:32<1:01:38,  2.37s/it, loss=0.6166]\u001b[A\n",
            "Training:  69%|██████▉   | 3438/5000 [2:34:34<1:00:51,  2.34s/it, loss=0.6166]\u001b[A\n",
            "Training:  69%|██████▉   | 3438/5000 [2:34:34<1:00:51,  2.34s/it, loss=0.3680]\u001b[A\n",
            "Training:  69%|██████▉   | 3439/5000 [2:34:36<59:58,  2.31s/it, loss=0.3680]  \u001b[A\n",
            "Training:  69%|██████▉   | 3439/5000 [2:34:36<59:58,  2.31s/it, loss=0.4010]\u001b[A\n",
            "Training:  69%|██████▉   | 3440/5000 [2:34:39<1:04:07,  2.47s/it, loss=0.4010]\u001b[A\n",
            "Training:  69%|██████▉   | 3440/5000 [2:34:39<1:04:07,  2.47s/it, loss=0.3470]\u001b[A\n",
            "Training:  69%|██████▉   | 3441/5000 [2:34:41<1:02:25,  2.40s/it, loss=0.3470]\u001b[A\n",
            "Training:  69%|██████▉   | 3441/5000 [2:34:41<1:02:25,  2.40s/it, loss=0.3220]\u001b[A\n",
            "Training:  69%|██████▉   | 3442/5000 [2:34:43<1:01:14,  2.36s/it, loss=0.3220]\u001b[A\n",
            "Training:  69%|██████▉   | 3442/5000 [2:34:44<1:01:14,  2.36s/it, loss=0.4127]\u001b[A\n",
            "Training:  69%|██████▉   | 3443/5000 [2:34:46<1:00:25,  2.33s/it, loss=0.4127]\u001b[A\n",
            "Training:  69%|██████▉   | 3443/5000 [2:34:46<1:00:25,  2.33s/it, loss=0.3745]\u001b[A\n",
            "Training:  69%|██████▉   | 3444/5000 [2:34:48<59:55,  2.31s/it, loss=0.3745]  \u001b[A\n",
            "Training:  69%|██████▉   | 3444/5000 [2:34:48<59:55,  2.31s/it, loss=0.4069]\u001b[A\n",
            "Training:  69%|██████▉   | 3445/5000 [2:34:51<1:03:44,  2.46s/it, loss=0.4069]\u001b[A\n",
            "Training:  69%|██████▉   | 3445/5000 [2:34:51<1:03:44,  2.46s/it, loss=0.4196]\u001b[A\n",
            "Training:  69%|██████▉   | 3446/5000 [2:34:53<1:01:59,  2.39s/it, loss=0.4196]\u001b[A\n",
            "Training:  69%|██████▉   | 3446/5000 [2:34:53<1:01:59,  2.39s/it, loss=0.4794]\u001b[A\n",
            "Training:  69%|██████▉   | 3447/5000 [2:34:55<1:00:49,  2.35s/it, loss=0.4794]\u001b[A\n",
            "Training:  69%|██████▉   | 3447/5000 [2:34:55<1:00:49,  2.35s/it, loss=0.4357]\u001b[A\n",
            "Training:  69%|██████▉   | 3448/5000 [2:34:58<1:00:07,  2.32s/it, loss=0.4357]\u001b[A\n",
            "Training:  69%|██████▉   | 3448/5000 [2:34:58<1:00:07,  2.32s/it, loss=0.3830]\u001b[A\n",
            "Training:  69%|██████▉   | 3449/5000 [2:35:00<59:31,  2.30s/it, loss=0.3830]  \u001b[A\n",
            "Training:  69%|██████▉   | 3449/5000 [2:35:00<59:31,  2.30s/it, loss=0.4467]\u001b[A\n",
            "Training:  69%|██████▉   | 3450/5000 [2:35:03<1:03:05,  2.44s/it, loss=0.4467]\u001b[A\n",
            "Training:  69%|██████▉   | 3450/5000 [2:35:03<1:03:05,  2.44s/it, loss=0.3404]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 3450 ---\n",
            "Prompt: 'The '\n",
            "The  of,arl, all since sinceester\n",
            " theises the prayer theer I I itA\n",
            " it all veryouts or else therestWe away\n",
            "Serv me benefit glass I him the.\n",
            "AOLUSI:He against little,\n",
            " know golden, it yours but must\n",
            " find to, you live one heart Who, break shake\n",
            " that touch king constant; to you the,ry that:, see good, see, well one gentleman time France\n",
            "'ll you yet'our high\n",
            "Prompt: 'In '\n",
            "In  ever was or, thou when dangerous\n",
            "GUCER:A one gods the,'t a.\n",
            "AOLUS\n",
            " miss lie, a pretty: it be to how faith a wool.\n",
            "AOLUS\n",
            " some woman give at, sir thead honour if could guard.\n",
            "Cn thing bring on the, stands and heavens\n",
            " A or name: things is good,First stay youngeting noFwell:our you\n",
            " forty:IUpon vig one the of and.\n",
            "C\n",
            "Prompt: 'To '\n",
            "To  honour his.\n",
            "CLEENG:Be, sir andro.\n",
            "C matter Cam, this most affairs lead coward\n",
            "asp of most, men best remember.\n",
            "Cn or-,?\n",
            "FLIZ:This request make honour be heir\n",
            " offer pl the mind a. tw, him a with\n",
            "pherd from?\n",
            "C beauty sister\n",
            "low:O\n",
            "'re me upon father what with king cannot.\n",
            "Firstant\n",
            ": since the,'t your would want villain of needs rather\n",
            "Prompt: 'A '\n",
            "A  our,my, Bes he\n",
            "ath a language under,att, feat,,, be\n",
            "ash and Cov stands the my\n",
            "our else best for no she to\n",
            " bold, bring beg. me the, prayer see, welcome advised't\n",
            " so the glass have born theN,\n",
            " my and of two.\n",
            "FLIZ itself appro tenderAs: evils\n",
            "b, Ver, art whichepod, ball is, court other.\n",
            "She: him\n",
            " comes.\n",
            "She: him\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  69%|██████▉   | 3451/5000 [2:35:17<2:37:26,  6.10s/it, loss=0.3404]\u001b[A\n",
            "Training:  69%|██████▉   | 3451/5000 [2:35:17<2:37:26,  6.10s/it, loss=0.2580]\u001b[A\n",
            "Training:  69%|██████▉   | 3452/5000 [2:35:19<2:07:35,  4.95s/it, loss=0.2580]\u001b[A\n",
            "Training:  69%|██████▉   | 3452/5000 [2:35:19<2:07:35,  4.95s/it, loss=0.4646]\u001b[A\n",
            "Training:  69%|██████▉   | 3453/5000 [2:35:22<1:46:45,  4.14s/it, loss=0.4646]\u001b[A\n",
            "Training:  69%|██████▉   | 3453/5000 [2:35:22<1:46:45,  4.14s/it, loss=0.4741]\u001b[A\n",
            "Training:  69%|██████▉   | 3454/5000 [2:35:24<1:33:59,  3.65s/it, loss=0.4741]\u001b[A\n",
            "Training:  69%|██████▉   | 3454/5000 [2:35:24<1:33:59,  3.65s/it, loss=0.3164]\u001b[A\n",
            "Training:  69%|██████▉   | 3455/5000 [2:35:27<1:25:49,  3.33s/it, loss=0.3164]\u001b[A\n",
            "Training:  69%|██████▉   | 3455/5000 [2:35:27<1:25:49,  3.33s/it, loss=0.3852]\u001b[A\n",
            "Training:  69%|██████▉   | 3456/5000 [2:35:29<1:17:28,  3.01s/it, loss=0.3852]\u001b[A\n",
            "Training:  69%|██████▉   | 3456/5000 [2:35:29<1:17:28,  3.01s/it, loss=0.5131]\u001b[A\n",
            "Training:  69%|██████▉   | 3457/5000 [2:35:31<1:11:31,  2.78s/it, loss=0.5131]\u001b[A\n",
            "Training:  69%|██████▉   | 3457/5000 [2:35:31<1:11:31,  2.78s/it, loss=0.4816]\u001b[A\n",
            "Training:  69%|██████▉   | 3458/5000 [2:35:34<1:07:16,  2.62s/it, loss=0.4816]\u001b[A\n",
            "Training:  69%|██████▉   | 3458/5000 [2:35:34<1:07:16,  2.62s/it, loss=0.3935]\u001b[A\n",
            "Training:  69%|██████▉   | 3459/5000 [2:35:36<1:05:55,  2.57s/it, loss=0.3935]\u001b[A\n",
            "Training:  69%|██████▉   | 3459/5000 [2:35:36<1:05:55,  2.57s/it, loss=0.5671]\u001b[A\n",
            "Training:  69%|██████▉   | 3460/5000 [2:35:39<1:06:13,  2.58s/it, loss=0.5671]\u001b[A\n",
            "Training:  69%|██████▉   | 3460/5000 [2:35:39<1:06:13,  2.58s/it, loss=0.3279]\u001b[A\n",
            "Training:  69%|██████▉   | 3461/5000 [2:35:41<1:03:41,  2.48s/it, loss=0.3279]\u001b[A\n",
            "Training:  69%|██████▉   | 3461/5000 [2:35:41<1:03:41,  2.48s/it, loss=0.5980]\u001b[A\n",
            "Training:  69%|██████▉   | 3462/5000 [2:35:43<1:01:51,  2.41s/it, loss=0.5980]\u001b[A\n",
            "Training:  69%|██████▉   | 3462/5000 [2:35:43<1:01:51,  2.41s/it, loss=0.3962]\u001b[A\n",
            "Training:  69%|██████▉   | 3463/5000 [2:35:45<1:00:17,  2.35s/it, loss=0.3962]\u001b[A\n",
            "Training:  69%|██████▉   | 3463/5000 [2:35:45<1:00:17,  2.35s/it, loss=0.4954]\u001b[A\n",
            "Training:  69%|██████▉   | 3464/5000 [2:35:48<1:00:13,  2.35s/it, loss=0.4954]\u001b[A\n",
            "Training:  69%|██████▉   | 3464/5000 [2:35:48<1:00:13,  2.35s/it, loss=0.3836]\u001b[A\n",
            "Training:  69%|██████▉   | 3465/5000 [2:35:50<1:03:13,  2.47s/it, loss=0.3836]\u001b[A\n",
            "Training:  69%|██████▉   | 3465/5000 [2:35:50<1:03:13,  2.47s/it, loss=0.5283]\u001b[A\n",
            "Training:  69%|██████▉   | 3466/5000 [2:35:53<1:01:27,  2.40s/it, loss=0.5283]\u001b[A\n",
            "Training:  69%|██████▉   | 3466/5000 [2:35:53<1:01:27,  2.40s/it, loss=0.4082]\u001b[A\n",
            "Training:  69%|██████▉   | 3467/5000 [2:35:55<1:00:22,  2.36s/it, loss=0.4082]\u001b[A\n",
            "Training:  69%|██████▉   | 3467/5000 [2:35:55<1:00:22,  2.36s/it, loss=0.3884]\u001b[A\n",
            "Training:  69%|██████▉   | 3468/5000 [2:35:57<59:27,  2.33s/it, loss=0.3884]  \u001b[A\n",
            "Training:  69%|██████▉   | 3468/5000 [2:35:57<59:27,  2.33s/it, loss=0.4071]\u001b[A\n",
            "Training:  69%|██████▉   | 3469/5000 [2:35:59<58:59,  2.31s/it, loss=0.4071]\u001b[A\n",
            "Training:  69%|██████▉   | 3469/5000 [2:36:00<58:59,  2.31s/it, loss=0.3770]\u001b[A\n",
            "Training:  69%|██████▉   | 3470/5000 [2:36:02<1:02:17,  2.44s/it, loss=0.3770]\u001b[A\n",
            "Training:  69%|██████▉   | 3470/5000 [2:36:02<1:02:17,  2.44s/it, loss=0.4425]\u001b[A\n",
            "Training:  69%|██████▉   | 3471/5000 [2:36:04<1:00:49,  2.39s/it, loss=0.4425]\u001b[A\n",
            "Training:  69%|██████▉   | 3471/5000 [2:36:05<1:00:49,  2.39s/it, loss=0.5342]\u001b[A\n",
            "Training:  69%|██████▉   | 3472/5000 [2:36:07<59:48,  2.35s/it, loss=0.5342]  \u001b[A\n",
            "Training:  69%|██████▉   | 3472/5000 [2:36:07<59:48,  2.35s/it, loss=0.4403]\u001b[A\n",
            "Training:  69%|██████▉   | 3473/5000 [2:36:09<59:05,  2.32s/it, loss=0.4403]\u001b[A\n",
            "Training:  69%|██████▉   | 3473/5000 [2:36:09<59:05,  2.32s/it, loss=0.3560]\u001b[A\n",
            "Training:  69%|██████▉   | 3474/5000 [2:36:11<58:28,  2.30s/it, loss=0.3560]\u001b[A\n",
            "Training:  69%|██████▉   | 3474/5000 [2:36:11<58:28,  2.30s/it, loss=0.4210]\u001b[A\n",
            "Training:  70%|██████▉   | 3475/5000 [2:36:14<1:01:58,  2.44s/it, loss=0.4210]\u001b[A\n",
            "Training:  70%|██████▉   | 3475/5000 [2:36:14<1:01:58,  2.44s/it, loss=0.3910]\u001b[A\n",
            "Training:  70%|██████▉   | 3476/5000 [2:36:16<1:00:31,  2.38s/it, loss=0.3910]\u001b[A\n",
            "Training:  70%|██████▉   | 3476/5000 [2:36:16<1:00:31,  2.38s/it, loss=0.2905]\u001b[A\n",
            "Training:  70%|██████▉   | 3477/5000 [2:36:19<59:31,  2.34s/it, loss=0.2905]  \u001b[A\n",
            "Training:  70%|██████▉   | 3477/5000 [2:36:19<59:31,  2.34s/it, loss=0.3464]\u001b[A\n",
            "Training:  70%|██████▉   | 3478/5000 [2:36:21<58:37,  2.31s/it, loss=0.3464]\u001b[A\n",
            "Training:  70%|██████▉   | 3478/5000 [2:36:21<58:37,  2.31s/it, loss=0.4209]\u001b[A\n",
            "Training:  70%|██████▉   | 3479/5000 [2:36:23<58:00,  2.29s/it, loss=0.4209]\u001b[A\n",
            "Training:  70%|██████▉   | 3479/5000 [2:36:23<58:00,  2.29s/it, loss=0.4431]\u001b[A\n",
            "Training:  70%|██████▉   | 3480/5000 [2:36:26<1:01:54,  2.44s/it, loss=0.4431]\u001b[A\n",
            "Training:  70%|██████▉   | 3480/5000 [2:36:26<1:01:54,  2.44s/it, loss=0.4319]\u001b[A\n",
            "Training:  70%|██████▉   | 3481/5000 [2:36:28<1:00:28,  2.39s/it, loss=0.4319]\u001b[A\n",
            "Training:  70%|██████▉   | 3481/5000 [2:36:28<1:00:28,  2.39s/it, loss=0.4511]\u001b[A\n",
            "Training:  70%|██████▉   | 3482/5000 [2:36:30<59:22,  2.35s/it, loss=0.4511]  \u001b[A\n",
            "Training:  70%|██████▉   | 3482/5000 [2:36:30<59:22,  2.35s/it, loss=0.3921]\u001b[A\n",
            "Training:  70%|██████▉   | 3483/5000 [2:36:33<58:36,  2.32s/it, loss=0.3921]\u001b[A\n",
            "Training:  70%|██████▉   | 3483/5000 [2:36:33<58:36,  2.32s/it, loss=0.2322]\u001b[A\n",
            "Training:  70%|██████▉   | 3484/5000 [2:36:35<58:15,  2.31s/it, loss=0.2322]\u001b[A\n",
            "Training:  70%|██████▉   | 3484/5000 [2:36:35<58:15,  2.31s/it, loss=0.4761]\u001b[A\n",
            "Training:  70%|██████▉   | 3485/5000 [2:36:38<1:01:45,  2.45s/it, loss=0.4761]\u001b[A\n",
            "Training:  70%|██████▉   | 3485/5000 [2:36:38<1:01:45,  2.45s/it, loss=0.4449]\u001b[A\n",
            "Training:  70%|██████▉   | 3486/5000 [2:36:40<1:00:23,  2.39s/it, loss=0.4449]\u001b[A\n",
            "Training:  70%|██████▉   | 3486/5000 [2:36:40<1:00:23,  2.39s/it, loss=0.3532]\u001b[A\n",
            "Training:  70%|██████▉   | 3487/5000 [2:36:42<59:39,  2.37s/it, loss=0.3532]  \u001b[A\n",
            "Training:  70%|██████▉   | 3487/5000 [2:36:42<59:39,  2.37s/it, loss=0.2982]\u001b[A\n",
            "Training:  70%|██████▉   | 3488/5000 [2:36:44<58:51,  2.34s/it, loss=0.2982]\u001b[A\n",
            "Training:  70%|██████▉   | 3488/5000 [2:36:44<58:51,  2.34s/it, loss=0.3972]\u001b[A\n",
            "Training:  70%|██████▉   | 3489/5000 [2:36:47<58:09,  2.31s/it, loss=0.3972]\u001b[A\n",
            "Training:  70%|██████▉   | 3489/5000 [2:36:47<58:09,  2.31s/it, loss=0.3125]\u001b[A\n",
            "Training:  70%|██████▉   | 3490/5000 [2:36:49<1:01:49,  2.46s/it, loss=0.3125]\u001b[A\n",
            "Training:  70%|██████▉   | 3490/5000 [2:36:50<1:01:49,  2.46s/it, loss=0.3777]\u001b[A\n",
            "Training:  70%|██████▉   | 3491/5000 [2:36:52<1:00:12,  2.39s/it, loss=0.3777]\u001b[A\n",
            "Training:  70%|██████▉   | 3491/5000 [2:36:52<1:00:12,  2.39s/it, loss=0.3287]\u001b[A\n",
            "Training:  70%|██████▉   | 3492/5000 [2:36:54<59:10,  2.35s/it, loss=0.3287]  \u001b[A\n",
            "Training:  70%|██████▉   | 3492/5000 [2:36:54<59:10,  2.35s/it, loss=0.7139]\u001b[A\n",
            "Training:  70%|██████▉   | 3493/5000 [2:36:56<58:25,  2.33s/it, loss=0.7139]\u001b[A\n",
            "Training:  70%|██████▉   | 3493/5000 [2:36:56<58:25,  2.33s/it, loss=0.3222]\u001b[A\n",
            "Training:  70%|██████▉   | 3494/5000 [2:36:58<57:40,  2.30s/it, loss=0.3222]\u001b[A\n",
            "Training:  70%|██████▉   | 3494/5000 [2:36:59<57:40,  2.30s/it, loss=0.4405]\u001b[A\n",
            "Training:  70%|██████▉   | 3495/5000 [2:37:01<1:01:18,  2.44s/it, loss=0.4405]\u001b[A\n",
            "Training:  70%|██████▉   | 3495/5000 [2:37:01<1:01:18,  2.44s/it, loss=0.3403]\u001b[A\n",
            "Training:  70%|██████▉   | 3496/5000 [2:37:04<59:42,  2.38s/it, loss=0.3403]  \u001b[A\n",
            "Training:  70%|██████▉   | 3496/5000 [2:37:04<59:42,  2.38s/it, loss=0.3098]\u001b[A\n",
            "Training:  70%|██████▉   | 3497/5000 [2:37:06<58:35,  2.34s/it, loss=0.3098]\u001b[A\n",
            "Training:  70%|██████▉   | 3497/5000 [2:37:06<58:35,  2.34s/it, loss=0.6033]\u001b[A\n",
            "Training:  70%|██████▉   | 3498/5000 [2:37:08<58:01,  2.32s/it, loss=0.6033]\u001b[A\n",
            "Training:  70%|██████▉   | 3498/5000 [2:37:08<58:01,  2.32s/it, loss=0.5403]\u001b[A\n",
            "Training:  70%|██████▉   | 3499/5000 [2:37:10<57:29,  2.30s/it, loss=0.5403]\u001b[A\n",
            "Training:  70%|██████▉   | 3499/5000 [2:37:10<57:29,  2.30s/it, loss=0.8049]\u001b[A\n",
            "Training:  70%|███████   | 3500/5000 [2:37:13<1:00:54,  2.44s/it, loss=0.8049]\u001b[A\n",
            "Training:  70%|███████   | 3500/5000 [2:37:13<1:00:54,  2.44s/it, loss=0.3184]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 3500 ---\n",
            "Prompt: 'The '\n",
            "The  people you nolander, go of own\n",
            " wish whole worth answer.\n",
            "S accident me friends trump: if beute\n",
            "ister ofufius and him tr,ay it\n",
            " native be in honest friends he in it andSh\n",
            "oured. you which the h our\n",
            " statue me another he fragments forth?\n",
            "SIN EDARD\n",
            " coat s gods from have we to a.\n",
            "First me him:F you more him he give the a fire a?\n",
            " but and matter I: says\n",
            "Prompt: 'In '\n",
            "In  of hath'd yearscom;'were\n",
            " beard Menius walls' you and.\n",
            "ANTIO\n",
            " aleMarch, removed\n",
            "ANTIO\n",
            "AN\n",
            " do the,urt! mean! cares!\n",
            " yet am,! testim' and'\n",
            " should:\n",
            " this done a- earA\n",
            "ath an herring throat! h, is double.\n",
            "G-orrow! mess youaring! double,!all-as a\n",
            " noble!\n",
            " old,!What that did it- greater;\n",
            "Prompt: 'To '\n",
            "To  those!\n",
            "FERNA:I and will\n",
            " prince\n",
            " do likeSince as as rend as,But thy as\n",
            " noble into purpose\n",
            "st him double:He but bald old forged gchester this Forrest\n",
            " thy's boarIn he in; being business her thousand\n",
            " execute spies rage\n",
            "Th thinkt,- till am dishon of. a,\n",
            " noble!\n",
            "Gob they at rightet an.\n",
            "V lo-orrow win fault the-ment'd the, fought noble!\n",
            "Prompt: 'A '\n",
            "A  dishon fl to him to bench'deningFirst\n",
            " anycustom.\n",
            "COROLUS\n",
            " court: mark to fl: what sayt what did give\n",
            " our; grace state match no move and.\n",
            "COROLUS\n",
            "est rep revolt:We to strong, there end:S,, my, sink'was behold toward.\n",
            "FirstTell no pretty:, souls part; i the\n",
            " haveTeaching long; beinganation, too mighty!tis read.\n",
            "First I not:Well we\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "✓ Checkpoint saved: checkpoints/checkpoint_step_3500.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  70%|███████   | 3501/5000 [2:38:16<8:32:55, 20.53s/it, loss=0.3184]\u001b[A\n",
            "Training:  70%|███████   | 3501/5000 [2:38:16<8:32:55, 20.53s/it, loss=0.3972]\u001b[A\n",
            "Training:  70%|███████   | 3502/5000 [2:38:18<6:16:18, 15.07s/it, loss=0.3972]\u001b[A\n",
            "Training:  70%|███████   | 3502/5000 [2:38:18<6:16:18, 15.07s/it, loss=0.3178]\u001b[A\n",
            "Training:  70%|███████   | 3503/5000 [2:38:21<4:43:36, 11.37s/it, loss=0.3178]\u001b[A\n",
            "Training:  70%|███████   | 3503/5000 [2:38:21<4:43:36, 11.37s/it, loss=0.2929]\u001b[A\n",
            "Training:  70%|███████   | 3504/5000 [2:38:23<3:37:06,  8.71s/it, loss=0.2929]\u001b[A\n",
            "Training:  70%|███████   | 3504/5000 [2:38:23<3:37:06,  8.71s/it, loss=0.6581]\u001b[A\n",
            "Training:  70%|███████   | 3505/5000 [2:38:26<2:50:14,  6.83s/it, loss=0.6581]\u001b[A\n",
            "Training:  70%|███████   | 3505/5000 [2:38:26<2:50:14,  6.83s/it, loss=0.3451]\u001b[A\n",
            "Training:  70%|███████   | 3506/5000 [2:38:28<2:17:34,  5.52s/it, loss=0.3451]\u001b[A\n",
            "Training:  70%|███████   | 3506/5000 [2:38:28<2:17:34,  5.52s/it, loss=0.3714]\u001b[A\n",
            "Training:  70%|███████   | 3507/5000 [2:38:31<1:55:31,  4.64s/it, loss=0.3714]\u001b[A\n",
            "Training:  70%|███████   | 3507/5000 [2:38:31<1:55:31,  4.64s/it, loss=0.3804]\u001b[A\n",
            "Training:  70%|███████   | 3508/5000 [2:38:34<1:43:49,  4.18s/it, loss=0.3804]\u001b[A\n",
            "Training:  70%|███████   | 3508/5000 [2:38:34<1:43:49,  4.18s/it, loss=0.2035]\u001b[A\n",
            "Training:  70%|███████   | 3509/5000 [2:38:36<1:30:48,  3.65s/it, loss=0.2035]\u001b[A\n",
            "Training:  70%|███████   | 3509/5000 [2:38:36<1:30:48,  3.65s/it, loss=0.3450]\u001b[A\n",
            "Training:  70%|███████   | 3510/5000 [2:38:39<1:21:43,  3.29s/it, loss=0.3450]\u001b[A\n",
            "Training:  70%|███████   | 3510/5000 [2:38:39<1:21:43,  3.29s/it, loss=0.4060]\u001b[A\n",
            "Training:  70%|███████   | 3511/5000 [2:38:41<1:15:05,  3.03s/it, loss=0.4060]\u001b[A\n",
            "Training:  70%|███████   | 3511/5000 [2:38:41<1:15:05,  3.03s/it, loss=0.2597]\u001b[A\n",
            "Training:  70%|███████   | 3512/5000 [2:38:44<1:12:07,  2.91s/it, loss=0.2597]\u001b[A\n",
            "Training:  70%|███████   | 3512/5000 [2:38:44<1:12:07,  2.91s/it, loss=0.5187]\u001b[A\n",
            "Training:  70%|███████   | 3513/5000 [2:38:47<1:11:37,  2.89s/it, loss=0.5187]\u001b[A\n",
            "Training:  70%|███████   | 3513/5000 [2:38:47<1:11:37,  2.89s/it, loss=0.3811]\u001b[A\n",
            "Training:  70%|███████   | 3514/5000 [2:38:49<1:08:09,  2.75s/it, loss=0.3811]\u001b[A\n",
            "Training:  70%|███████   | 3514/5000 [2:38:49<1:08:09,  2.75s/it, loss=0.3498]\u001b[A\n",
            "Training:  70%|███████   | 3515/5000 [2:38:52<1:05:33,  2.65s/it, loss=0.3498]\u001b[A\n",
            "Training:  70%|███████   | 3515/5000 [2:38:52<1:05:33,  2.65s/it, loss=0.3288]\u001b[A\n",
            "Training:  70%|███████   | 3516/5000 [2:38:54<1:03:50,  2.58s/it, loss=0.3288]\u001b[A\n",
            "Training:  70%|███████   | 3516/5000 [2:38:54<1:03:50,  2.58s/it, loss=0.4000]\u001b[A\n",
            "Training:  70%|███████   | 3517/5000 [2:38:57<1:05:16,  2.64s/it, loss=0.4000]\u001b[A\n",
            "Training:  70%|███████   | 3517/5000 [2:38:57<1:05:16,  2.64s/it, loss=0.4279]\u001b[A\n",
            "Training:  70%|███████   | 3518/5000 [2:38:59<1:05:19,  2.64s/it, loss=0.4279]\u001b[A\n",
            "Training:  70%|███████   | 3518/5000 [2:38:59<1:05:19,  2.64s/it, loss=0.4760]\u001b[A\n",
            "Training:  70%|███████   | 3519/5000 [2:39:02<1:03:38,  2.58s/it, loss=0.4760]\u001b[A\n",
            "Training:  70%|███████   | 3519/5000 [2:39:02<1:03:38,  2.58s/it, loss=0.4166]\u001b[A\n",
            "Training:  70%|███████   | 3520/5000 [2:39:04<1:02:21,  2.53s/it, loss=0.4166]\u001b[A\n",
            "Training:  70%|███████   | 3520/5000 [2:39:04<1:02:21,  2.53s/it, loss=0.3653]\u001b[A\n",
            "Training:  70%|███████   | 3521/5000 [2:39:07<1:01:27,  2.49s/it, loss=0.3653]\u001b[A\n",
            "Training:  70%|███████   | 3521/5000 [2:39:07<1:01:27,  2.49s/it, loss=0.3360]\u001b[A\n",
            "Training:  70%|███████   | 3522/5000 [2:39:10<1:05:14,  2.65s/it, loss=0.3360]\u001b[A\n",
            "Training:  70%|███████   | 3522/5000 [2:39:10<1:05:14,  2.65s/it, loss=0.3915]\u001b[A\n",
            "Training:  70%|███████   | 3523/5000 [2:39:12<1:03:25,  2.58s/it, loss=0.3915]\u001b[A\n",
            "Training:  70%|███████   | 3523/5000 [2:39:12<1:03:25,  2.58s/it, loss=0.5384]\u001b[A\n",
            "Training:  70%|███████   | 3524/5000 [2:39:14<1:02:11,  2.53s/it, loss=0.5384]\u001b[A\n",
            "Training:  70%|███████   | 3524/5000 [2:39:15<1:02:11,  2.53s/it, loss=0.5217]\u001b[A\n",
            "Training:  70%|███████   | 3525/5000 [2:39:17<1:01:20,  2.50s/it, loss=0.5217]\u001b[A\n",
            "Training:  70%|███████   | 3525/5000 [2:39:17<1:01:20,  2.50s/it, loss=0.4594]\u001b[A\n",
            "Training:  71%|███████   | 3526/5000 [2:39:19<1:00:44,  2.47s/it, loss=0.4594]\u001b[A\n",
            "Training:  71%|███████   | 3526/5000 [2:39:19<1:00:44,  2.47s/it, loss=0.3666]\u001b[A\n",
            "Training:  71%|███████   | 3527/5000 [2:39:22<1:04:11,  2.61s/it, loss=0.3666]\u001b[A\n",
            "Training:  71%|███████   | 3527/5000 [2:39:22<1:04:11,  2.61s/it, loss=0.3841]\u001b[A\n",
            "Training:  71%|███████   | 3528/5000 [2:39:25<1:02:55,  2.57s/it, loss=0.3841]\u001b[A\n",
            "Training:  71%|███████   | 3528/5000 [2:39:25<1:02:55,  2.57s/it, loss=0.3802]\u001b[A\n",
            "Training:  71%|███████   | 3529/5000 [2:39:27<1:01:56,  2.53s/it, loss=0.3802]\u001b[A\n",
            "Training:  71%|███████   | 3529/5000 [2:39:27<1:01:56,  2.53s/it, loss=0.4870]\u001b[A\n",
            "Training:  71%|███████   | 3530/5000 [2:39:30<1:01:35,  2.51s/it, loss=0.4870]\u001b[A\n",
            "Training:  71%|███████   | 3530/5000 [2:39:30<1:01:35,  2.51s/it, loss=0.6645]\u001b[A\n",
            "Training:  71%|███████   | 3531/5000 [2:39:32<1:02:23,  2.55s/it, loss=0.6645]\u001b[A\n",
            "Training:  71%|███████   | 3531/5000 [2:39:32<1:02:23,  2.55s/it, loss=0.3197]\u001b[A\n",
            "Training:  71%|███████   | 3532/5000 [2:39:35<1:04:05,  2.62s/it, loss=0.3197]\u001b[A\n",
            "Training:  71%|███████   | 3532/5000 [2:39:35<1:04:05,  2.62s/it, loss=0.4832]\u001b[A\n",
            "Training:  71%|███████   | 3533/5000 [2:39:37<1:02:24,  2.55s/it, loss=0.4832]\u001b[A\n",
            "Training:  71%|███████   | 3533/5000 [2:39:37<1:02:24,  2.55s/it, loss=0.6053]\u001b[A\n",
            "Training:  71%|███████   | 3534/5000 [2:39:40<1:01:21,  2.51s/it, loss=0.6053]\u001b[A\n",
            "Training:  71%|███████   | 3534/5000 [2:39:40<1:01:21,  2.51s/it, loss=0.3321]\u001b[A\n",
            "Training:  71%|███████   | 3535/5000 [2:39:42<1:00:34,  2.48s/it, loss=0.3321]\u001b[A\n",
            "Training:  71%|███████   | 3535/5000 [2:39:42<1:00:34,  2.48s/it, loss=0.3286]\u001b[A\n",
            "Training:  71%|███████   | 3536/5000 [2:39:45<1:03:16,  2.59s/it, loss=0.3286]\u001b[A\n",
            "Training:  71%|███████   | 3536/5000 [2:39:45<1:03:16,  2.59s/it, loss=0.3631]\u001b[A\n",
            "Training:  71%|███████   | 3537/5000 [2:39:48<1:03:21,  2.60s/it, loss=0.3631]\u001b[A\n",
            "Training:  71%|███████   | 3537/5000 [2:39:48<1:03:21,  2.60s/it, loss=0.3744]\u001b[A\n",
            "Training:  71%|███████   | 3538/5000 [2:39:50<1:02:00,  2.54s/it, loss=0.3744]\u001b[A\n",
            "Training:  71%|███████   | 3538/5000 [2:39:50<1:02:00,  2.54s/it, loss=0.2995]\u001b[A\n",
            "Training:  71%|███████   | 3539/5000 [2:39:53<1:00:57,  2.50s/it, loss=0.2995]\u001b[A\n",
            "Training:  71%|███████   | 3539/5000 [2:39:53<1:00:57,  2.50s/it, loss=0.4037]\u001b[A\n",
            "Training:  71%|███████   | 3540/5000 [2:39:55<1:00:20,  2.48s/it, loss=0.4037]\u001b[A\n",
            "Training:  71%|███████   | 3540/5000 [2:39:55<1:00:20,  2.48s/it, loss=0.2977]\u001b[A\n",
            "Training:  71%|███████   | 3541/5000 [2:39:58<1:03:51,  2.63s/it, loss=0.2977]\u001b[A\n",
            "Training:  71%|███████   | 3541/5000 [2:39:58<1:03:51,  2.63s/it, loss=0.4119]\u001b[A\n",
            "Training:  71%|███████   | 3542/5000 [2:40:00<1:02:39,  2.58s/it, loss=0.4119]\u001b[A\n",
            "Training:  71%|███████   | 3542/5000 [2:40:00<1:02:39,  2.58s/it, loss=0.4216]\u001b[A\n",
            "Training:  71%|███████   | 3543/5000 [2:40:03<1:01:40,  2.54s/it, loss=0.4216]\u001b[A\n",
            "Training:  71%|███████   | 3543/5000 [2:40:03<1:01:40,  2.54s/it, loss=0.2544]\u001b[A\n",
            "Training:  71%|███████   | 3544/5000 [2:40:05<1:00:34,  2.50s/it, loss=0.2544]\u001b[A\n",
            "Training:  71%|███████   | 3544/5000 [2:40:05<1:00:34,  2.50s/it, loss=0.3618]\u001b[A\n",
            "Training:  71%|███████   | 3545/5000 [2:40:08<1:00:35,  2.50s/it, loss=0.3618]\u001b[A\n",
            "Training:  71%|███████   | 3545/5000 [2:40:08<1:00:35,  2.50s/it, loss=0.2934]\u001b[A\n",
            "Training:  71%|███████   | 3546/5000 [2:40:11<1:03:35,  2.62s/it, loss=0.2934]\u001b[A\n",
            "Training:  71%|███████   | 3546/5000 [2:40:11<1:03:35,  2.62s/it, loss=0.3464]\u001b[A\n",
            "Training:  71%|███████   | 3547/5000 [2:40:13<1:02:02,  2.56s/it, loss=0.3464]\u001b[A\n",
            "Training:  71%|███████   | 3547/5000 [2:40:13<1:02:02,  2.56s/it, loss=0.4220]\u001b[A\n",
            "Training:  71%|███████   | 3548/5000 [2:40:16<1:00:45,  2.51s/it, loss=0.4220]\u001b[A\n",
            "Training:  71%|███████   | 3548/5000 [2:40:16<1:00:45,  2.51s/it, loss=0.5080]\u001b[A\n",
            "Training:  71%|███████   | 3549/5000 [2:40:18<1:00:00,  2.48s/it, loss=0.5080]\u001b[A\n",
            "Training:  71%|███████   | 3549/5000 [2:40:18<1:00:00,  2.48s/it, loss=0.5166]\u001b[A\n",
            "Training:  71%|███████   | 3550/5000 [2:40:21<1:01:15,  2.53s/it, loss=0.5166]\u001b[A\n",
            "Training:  71%|███████   | 3550/5000 [2:40:21<1:01:15,  2.53s/it, loss=0.4105]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 3550 ---\n",
            "Prompt: 'The '\n",
            "The  ofts atf, they from:What hour\n",
            " ever majesty yield else, they pardon fear\n",
            "For men duke spirit at Duke Norfolk Lancaster\n",
            " pale-father'd fl this be! double,!\n",
            " lament must, heartoveiest;Your, so himself\n",
            " tender,d, on kn cure it theirA.ers not pl up\n",
            "ges to; they but above freshs blood a\n",
            " Thouft bowatter and. who, aell walls smallso\n",
            "-,ure and;If\n",
            "Prompt: 'In '\n",
            "In , life, myge j into hands\n",
            " were tender power atf sweet, noise if itPR SurreyThat\n",
            " bount long but, what yourness nothing\n",
            " my bos, rottenser spirit shall so out impities:\n",
            " let seewnoc ground want li of,To you sooth say\n",
            " that but bold own, in quickly, tale miserable\n",
            " intellect at, they long rude for father one your!\n",
            "are, I the of,re go the depart when first\n",
            "der him allreat\n",
            "Prompt: 'To '\n",
            "To  kind mal and need\n",
            "Since\n",
            " hope just of soldiers of\n",
            "anThatOoing this a; all foot borough\n",
            " whenainl, my, thy, Lancaster\n",
            " bold this lost rejoiceest confed, appointed\n",
            " from reply towardleness on while die war\n",
            " signs hath each fl'd, process it and land not the bidding\n",
            " part all Mercio and offity but def Francis spirit\n",
            " that ever else shipsn now Mbion us, queenWhich longre'd three's blood onceAnd\n",
            "Prompt: 'A '\n",
            "A  blood and mistrust bur bloodsoth:\n",
            ", in they'd and we home and,When may\n",
            " hard disher at all heart ageAnd of youth make may.\n",
            "cle this here thy;, must no, life suchile\n",
            "ers him else this comfortable, fast to-orrow\n",
            " made of that noble beingely No tro, rash Bolb beforeYou'd the? my, wounds bringsly dead valton,Take against meaning\n",
            "e wrinkants behold hearts full souls\n",
            " dingish\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  71%|███████   | 3551/5000 [2:40:37<2:38:43,  6.57s/it, loss=0.4105]\u001b[A\n",
            "Training:  71%|███████   | 3551/5000 [2:40:37<2:38:43,  6.57s/it, loss=0.3653]\u001b[A\n",
            "Training:  71%|███████   | 3552/5000 [2:40:39<2:08:30,  5.32s/it, loss=0.3653]\u001b[A\n",
            "Training:  71%|███████   | 3552/5000 [2:40:39<2:08:30,  5.32s/it, loss=0.4556]\u001b[A\n",
            "Training:  71%|███████   | 3553/5000 [2:40:41<1:47:10,  4.44s/it, loss=0.4556]\u001b[A\n",
            "Training:  71%|███████   | 3553/5000 [2:40:41<1:47:10,  4.44s/it, loss=0.4382]\u001b[A\n",
            "Training:  71%|███████   | 3554/5000 [2:40:44<1:32:15,  3.83s/it, loss=0.4382]\u001b[A\n",
            "Training:  71%|███████   | 3554/5000 [2:40:44<1:32:15,  3.83s/it, loss=0.3202]\u001b[A\n",
            "Training:  71%|███████   | 3555/5000 [2:40:47<1:25:58,  3.57s/it, loss=0.3202]\u001b[A\n",
            "Training:  71%|███████   | 3555/5000 [2:40:47<1:25:58,  3.57s/it, loss=0.2606]\u001b[A\n",
            "Training:  71%|███████   | 3556/5000 [2:40:49<1:17:29,  3.22s/it, loss=0.2606]\u001b[A\n",
            "Training:  71%|███████   | 3556/5000 [2:40:49<1:17:29,  3.22s/it, loss=0.3236]\u001b[A\n",
            "Training:  71%|███████   | 3557/5000 [2:40:52<1:11:20,  2.97s/it, loss=0.3236]\u001b[A\n",
            "Training:  71%|███████   | 3557/5000 [2:40:52<1:11:20,  2.97s/it, loss=0.4613]\u001b[A\n",
            "Training:  71%|███████   | 3558/5000 [2:40:54<1:07:14,  2.80s/it, loss=0.4613]\u001b[A\n",
            "Training:  71%|███████   | 3558/5000 [2:40:54<1:07:14,  2.80s/it, loss=0.3173]\u001b[A\n",
            "Training:  71%|███████   | 3559/5000 [2:40:57<1:05:51,  2.74s/it, loss=0.3173]\u001b[A\n",
            "Training:  71%|███████   | 3559/5000 [2:40:57<1:05:51,  2.74s/it, loss=0.6193]\u001b[A\n",
            "Training:  71%|███████   | 3560/5000 [2:40:59<1:05:54,  2.75s/it, loss=0.6193]\u001b[A\n",
            "Training:  71%|███████   | 3560/5000 [2:40:59<1:05:54,  2.75s/it, loss=0.3366]\u001b[A\n",
            "Training:  71%|███████   | 3561/5000 [2:41:02<1:03:12,  2.64s/it, loss=0.3366]\u001b[A\n",
            "Training:  71%|███████   | 3561/5000 [2:41:02<1:03:12,  2.64s/it, loss=0.3955]\u001b[A\n",
            "Training:  71%|███████   | 3562/5000 [2:41:04<1:01:40,  2.57s/it, loss=0.3955]\u001b[A\n",
            "Training:  71%|███████   | 3562/5000 [2:41:04<1:01:40,  2.57s/it, loss=0.4869]\u001b[A\n",
            "Training:  71%|███████▏  | 3563/5000 [2:41:06<1:00:15,  2.52s/it, loss=0.4869]\u001b[A\n",
            "Training:  71%|███████▏  | 3563/5000 [2:41:06<1:00:15,  2.52s/it, loss=0.2864]\u001b[A\n",
            "Training:  71%|███████▏  | 3564/5000 [2:41:09<1:02:04,  2.59s/it, loss=0.2864]\u001b[A\n",
            "Training:  71%|███████▏  | 3564/5000 [2:41:09<1:02:04,  2.59s/it, loss=0.3941]\u001b[A\n",
            "Training:  71%|███████▏  | 3565/5000 [2:41:12<1:01:38,  2.58s/it, loss=0.3941]\u001b[A\n",
            "Training:  71%|███████▏  | 3565/5000 [2:41:12<1:01:38,  2.58s/it, loss=0.3467]\u001b[A\n",
            "Training:  71%|███████▏  | 3566/5000 [2:41:14<1:00:34,  2.53s/it, loss=0.3467]\u001b[A\n",
            "Training:  71%|███████▏  | 3566/5000 [2:41:14<1:00:34,  2.53s/it, loss=0.4418]\u001b[A\n",
            "Training:  71%|███████▏  | 3567/5000 [2:41:17<59:38,  2.50s/it, loss=0.4418]  \u001b[A\n",
            "Training:  71%|███████▏  | 3567/5000 [2:41:17<59:38,  2.50s/it, loss=0.3094]\u001b[A\n",
            "Training:  71%|███████▏  | 3568/5000 [2:41:19<58:50,  2.47s/it, loss=0.3094]\u001b[A\n",
            "Training:  71%|███████▏  | 3568/5000 [2:41:19<58:50,  2.47s/it, loss=0.4113]\u001b[A\n",
            "Training:  71%|███████▏  | 3569/5000 [2:41:22<1:02:07,  2.60s/it, loss=0.4113]\u001b[A\n",
            "Training:  71%|███████▏  | 3569/5000 [2:41:22<1:02:07,  2.60s/it, loss=0.4039]\u001b[A\n",
            "Training:  71%|███████▏  | 3570/5000 [2:41:24<1:00:37,  2.54s/it, loss=0.4039]\u001b[A\n",
            "Training:  71%|███████▏  | 3570/5000 [2:41:24<1:00:37,  2.54s/it, loss=0.3838]\u001b[A\n",
            "Training:  71%|███████▏  | 3571/5000 [2:41:27<59:20,  2.49s/it, loss=0.3838]  \u001b[A\n",
            "Training:  71%|███████▏  | 3571/5000 [2:41:27<59:20,  2.49s/it, loss=0.2844]\u001b[A\n",
            "Training:  71%|███████▏  | 3572/5000 [2:41:29<58:34,  2.46s/it, loss=0.2844]\u001b[A\n",
            "Training:  71%|███████▏  | 3572/5000 [2:41:29<58:34,  2.46s/it, loss=0.4111]\u001b[A\n",
            "Training:  71%|███████▏  | 3573/5000 [2:41:32<58:13,  2.45s/it, loss=0.4111]\u001b[A\n",
            "Training:  71%|███████▏  | 3573/5000 [2:41:32<58:13,  2.45s/it, loss=0.3850]\u001b[A\n",
            "Training:  71%|███████▏  | 3574/5000 [2:41:34<1:01:46,  2.60s/it, loss=0.3850]\u001b[A\n",
            "Training:  71%|███████▏  | 3574/5000 [2:41:35<1:01:46,  2.60s/it, loss=0.2226]\u001b[A\n",
            "Training:  72%|███████▏  | 3575/5000 [2:41:37<1:00:08,  2.53s/it, loss=0.2226]\u001b[A\n",
            "Training:  72%|███████▏  | 3575/5000 [2:41:37<1:00:08,  2.53s/it, loss=0.2991]\u001b[A\n",
            "Training:  72%|███████▏  | 3576/5000 [2:41:39<59:11,  2.49s/it, loss=0.2991]  \u001b[A\n",
            "Training:  72%|███████▏  | 3576/5000 [2:41:39<59:11,  2.49s/it, loss=0.3601]\u001b[A\n",
            "Training:  72%|███████▏  | 3577/5000 [2:41:42<57:44,  2.43s/it, loss=0.3601]\u001b[A\n",
            "Training:  72%|███████▏  | 3577/5000 [2:41:42<57:44,  2.43s/it, loss=0.3035]\u001b[A\n",
            "Training:  72%|███████▏  | 3578/5000 [2:41:44<56:49,  2.40s/it, loss=0.3035]\u001b[A\n",
            "Training:  72%|███████▏  | 3578/5000 [2:41:44<56:49,  2.40s/it, loss=0.2967]\u001b[A\n",
            "Training:  72%|███████▏  | 3579/5000 [2:41:47<59:00,  2.49s/it, loss=0.2967]\u001b[A\n",
            "Training:  72%|███████▏  | 3579/5000 [2:41:47<59:00,  2.49s/it, loss=0.5101]\u001b[A\n",
            "Training:  72%|███████▏  | 3580/5000 [2:41:49<57:32,  2.43s/it, loss=0.5101]\u001b[A\n",
            "Training:  72%|███████▏  | 3580/5000 [2:41:49<57:32,  2.43s/it, loss=0.4253]\u001b[A\n",
            "Training:  72%|███████▏  | 3581/5000 [2:41:51<56:10,  2.38s/it, loss=0.4253]\u001b[A\n",
            "Training:  72%|███████▏  | 3581/5000 [2:41:51<56:10,  2.38s/it, loss=0.3988]\u001b[A\n",
            "Training:  72%|███████▏  | 3582/5000 [2:41:53<55:12,  2.34s/it, loss=0.3988]\u001b[A\n",
            "Training:  72%|███████▏  | 3582/5000 [2:41:53<55:12,  2.34s/it, loss=0.4845]\u001b[A\n",
            "Training:  72%|███████▏  | 3583/5000 [2:41:56<54:31,  2.31s/it, loss=0.4845]\u001b[A\n",
            "Training:  72%|███████▏  | 3583/5000 [2:41:56<54:31,  2.31s/it, loss=0.3766]\u001b[A\n",
            "Training:  72%|███████▏  | 3584/5000 [2:41:58<57:53,  2.45s/it, loss=0.3766]\u001b[A\n",
            "Training:  72%|███████▏  | 3584/5000 [2:41:58<57:53,  2.45s/it, loss=0.4282]\u001b[A\n",
            "Training:  72%|███████▏  | 3585/5000 [2:42:01<56:29,  2.40s/it, loss=0.4282]\u001b[A\n",
            "Training:  72%|███████▏  | 3585/5000 [2:42:01<56:29,  2.40s/it, loss=0.5472]\u001b[A\n",
            "Training:  72%|███████▏  | 3586/5000 [2:42:03<55:20,  2.35s/it, loss=0.5472]\u001b[A\n",
            "Training:  72%|███████▏  | 3586/5000 [2:42:03<55:20,  2.35s/it, loss=0.4294]\u001b[A\n",
            "Training:  72%|███████▏  | 3587/5000 [2:42:05<54:36,  2.32s/it, loss=0.4294]\u001b[A\n",
            "Training:  72%|███████▏  | 3587/5000 [2:42:05<54:36,  2.32s/it, loss=0.6266]\u001b[A\n",
            "Training:  72%|███████▏  | 3588/5000 [2:42:07<54:08,  2.30s/it, loss=0.6266]\u001b[A\n",
            "Training:  72%|███████▏  | 3588/5000 [2:42:07<54:08,  2.30s/it, loss=0.2768]\u001b[A\n",
            "Training:  72%|███████▏  | 3589/5000 [2:42:10<57:22,  2.44s/it, loss=0.2768]\u001b[A\n",
            "Training:  72%|███████▏  | 3589/5000 [2:42:10<57:22,  2.44s/it, loss=0.2999]\u001b[A\n",
            "Training:  72%|███████▏  | 3590/5000 [2:42:12<56:06,  2.39s/it, loss=0.2999]\u001b[A\n",
            "Training:  72%|███████▏  | 3590/5000 [2:42:12<56:06,  2.39s/it, loss=0.5626]\u001b[A\n",
            "Training:  72%|███████▏  | 3591/5000 [2:42:15<55:02,  2.34s/it, loss=0.5626]\u001b[A\n",
            "Training:  72%|███████▏  | 3591/5000 [2:42:15<55:02,  2.34s/it, loss=0.4892]\u001b[A\n",
            "Training:  72%|███████▏  | 3592/5000 [2:42:17<54:17,  2.31s/it, loss=0.4892]\u001b[A\n",
            "Training:  72%|███████▏  | 3592/5000 [2:42:17<54:17,  2.31s/it, loss=0.4080]\u001b[A\n",
            "Training:  72%|███████▏  | 3593/5000 [2:42:19<53:44,  2.29s/it, loss=0.4080]\u001b[A\n",
            "Training:  72%|███████▏  | 3593/5000 [2:42:19<53:44,  2.29s/it, loss=0.3617]\u001b[A\n",
            "Training:  72%|███████▏  | 3594/5000 [2:42:22<57:09,  2.44s/it, loss=0.3617]\u001b[A\n",
            "Training:  72%|███████▏  | 3594/5000 [2:42:22<57:09,  2.44s/it, loss=0.5137]\u001b[A\n",
            "Training:  72%|███████▏  | 3595/5000 [2:42:24<55:33,  2.37s/it, loss=0.5137]\u001b[A\n",
            "Training:  72%|███████▏  | 3595/5000 [2:42:24<55:33,  2.37s/it, loss=0.3121]\u001b[A\n",
            "Training:  72%|███████▏  | 3596/5000 [2:42:26<54:39,  2.34s/it, loss=0.3121]\u001b[A\n",
            "Training:  72%|███████▏  | 3596/5000 [2:42:26<54:39,  2.34s/it, loss=0.3819]\u001b[A\n",
            "Training:  72%|███████▏  | 3597/5000 [2:42:29<54:01,  2.31s/it, loss=0.3819]\u001b[A\n",
            "Training:  72%|███████▏  | 3597/5000 [2:42:29<54:01,  2.31s/it, loss=0.3746]\u001b[A\n",
            "Training:  72%|███████▏  | 3598/5000 [2:42:31<54:00,  2.31s/it, loss=0.3746]\u001b[A\n",
            "Training:  72%|███████▏  | 3598/5000 [2:42:31<54:00,  2.31s/it, loss=0.3883]\u001b[A\n",
            "Training:  72%|███████▏  | 3599/5000 [2:42:34<57:13,  2.45s/it, loss=0.3883]\u001b[A\n",
            "Training:  72%|███████▏  | 3599/5000 [2:42:34<57:13,  2.45s/it, loss=0.3371]\u001b[A\n",
            "Training:  72%|███████▏  | 3600/5000 [2:42:36<56:01,  2.40s/it, loss=0.3371]\u001b[A\n",
            "Training:  72%|███████▏  | 3600/5000 [2:42:36<56:01,  2.40s/it, loss=0.2355]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 3600 ---\n",
            "Prompt: 'The '\n",
            "The  that dark beful of lords?\n",
            " Edward the thatBY talk is shed footUpon;For his soulShouldoth lights\n",
            " lostaw, have'd art three of;And, Clarence desire we well\n",
            " offush the, haveh'd off the of own become;Or to those the, wThis, Clarence do do over aboutine\n",
            " it Warwick before children the ofaunt sleep\n",
            "EL together their'd mine, we meet fear\n",
            "ath our; whose one talkpp.\n",
            "Firstman how\n",
            "Prompt: 'In '\n",
            "In  so he just than to aside queenWhich\n",
            " charged fear though his is no honest duke\n",
            " hence to you.\n",
            "HERIONLO\n",
            "enger\n",
            "WARICK\n",
            "Look your father to fire\n",
            " yours for:ash you on here\n",
            "T I son it.\n",
            "K H ELman\n",
            " shepherdard you, use, give leave Where you, the shall know shall, thereat me: this prince I the, to heldent appointed at.\n",
            "HERIONLOEST\n",
            " you,,, am you\n",
            "Prompt: 'To '\n",
            "To  to strong place will yield you.\n",
            " have not,, father in of,\n",
            " now thou's, this will good rather my,,\n",
            " lodging with lips in Jerusalem thou four'll thee?\n",
            "\n",
            "ONTUE\n",
            "Look, it will you Warwick me\n",
            " grasp to fortune their.\n",
            "GUCER\n",
            "ENT:Ay there\n",
            " them asYou been business me the in pay\n",
            " strike leave touse rest\n",
            "'s father me the in battle son\n",
            "So you fit me your,,thine\n",
            "Prompt: 'A '\n",
            "A , my, which a had France\n",
            "irt with aid like?, sweet,,\n",
            " you, Hereous, ourOf, spent and,ards\n",
            " to it, an stone to, at last o the\n",
            "Boour withful, whose did us the than hath think\n",
            " to it villain the and words' if'll him do\n",
            " knew, whoseither\n",
            " one hath me your princess of eye the?\n",
            " I bring to, tro request\n",
            " list to chamber rest for.\n",
            "EDARD\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  72%|███████▏  | 3601/5000 [2:42:51<2:22:08,  6.10s/it, loss=0.2355]\u001b[A\n",
            "Training:  72%|███████▏  | 3601/5000 [2:42:51<2:22:08,  6.10s/it, loss=0.3003]\u001b[A\n",
            "Training:  72%|███████▏  | 3602/5000 [2:42:53<1:55:08,  4.94s/it, loss=0.3003]\u001b[A\n",
            "Training:  72%|███████▏  | 3602/5000 [2:42:53<1:55:08,  4.94s/it, loss=0.4211]\u001b[A\n",
            "Training:  72%|███████▏  | 3603/5000 [2:42:55<1:37:36,  4.19s/it, loss=0.4211]\u001b[A\n",
            "Training:  72%|███████▏  | 3603/5000 [2:42:55<1:37:36,  4.19s/it, loss=0.5187]\u001b[A\n",
            "Training:  72%|███████▏  | 3604/5000 [2:42:58<1:26:23,  3.71s/it, loss=0.5187]\u001b[A\n",
            "Training:  72%|███████▏  | 3604/5000 [2:42:58<1:26:23,  3.71s/it, loss=0.2940]\u001b[A\n",
            "Training:  72%|███████▏  | 3605/5000 [2:43:00<1:15:59,  3.27s/it, loss=0.2940]\u001b[A\n",
            "Training:  72%|███████▏  | 3605/5000 [2:43:00<1:15:59,  3.27s/it, loss=0.2992]\u001b[A\n",
            "Training:  72%|███████▏  | 3606/5000 [2:43:03<1:09:03,  2.97s/it, loss=0.2992]\u001b[A\n",
            "Training:  72%|███████▏  | 3606/5000 [2:43:03<1:09:03,  2.97s/it, loss=0.3416]\u001b[A\n",
            "Training:  72%|███████▏  | 3607/5000 [2:43:05<1:03:51,  2.75s/it, loss=0.3416]\u001b[A\n",
            "Training:  72%|███████▏  | 3607/5000 [2:43:05<1:03:51,  2.75s/it, loss=0.3343]\u001b[A\n",
            "Training:  72%|███████▏  | 3608/5000 [2:43:07<1:01:07,  2.63s/it, loss=0.3343]\u001b[A\n",
            "Training:  72%|███████▏  | 3608/5000 [2:43:07<1:01:07,  2.63s/it, loss=0.3666]\u001b[A\n",
            "Training:  72%|███████▏  | 3609/5000 [2:43:10<1:01:08,  2.64s/it, loss=0.3666]\u001b[A\n",
            "Training:  72%|███████▏  | 3609/5000 [2:43:10<1:01:08,  2.64s/it, loss=0.2948]\u001b[A\n",
            "Training:  72%|███████▏  | 3610/5000 [2:43:12<58:24,  2.52s/it, loss=0.2948]  \u001b[A\n",
            "Training:  72%|███████▏  | 3610/5000 [2:43:12<58:24,  2.52s/it, loss=0.3472]\u001b[A\n",
            "Training:  72%|███████▏  | 3611/5000 [2:43:14<56:26,  2.44s/it, loss=0.3472]\u001b[A\n",
            "Training:  72%|███████▏  | 3611/5000 [2:43:14<56:26,  2.44s/it, loss=0.2849]\u001b[A\n",
            "Training:  72%|███████▏  | 3612/5000 [2:43:17<54:58,  2.38s/it, loss=0.2849]\u001b[A\n",
            "Training:  72%|███████▏  | 3612/5000 [2:43:17<54:58,  2.38s/it, loss=0.4021]\u001b[A\n",
            "Training:  72%|███████▏  | 3613/5000 [2:43:19<54:39,  2.36s/it, loss=0.4021]\u001b[A\n",
            "Training:  72%|███████▏  | 3613/5000 [2:43:19<54:39,  2.36s/it, loss=0.3563]\u001b[A\n",
            "Training:  72%|███████▏  | 3614/5000 [2:43:22<56:49,  2.46s/it, loss=0.3563]\u001b[A\n",
            "Training:  72%|███████▏  | 3614/5000 [2:43:22<56:49,  2.46s/it, loss=0.4224]\u001b[A\n",
            "Training:  72%|███████▏  | 3615/5000 [2:43:24<55:33,  2.41s/it, loss=0.4224]\u001b[A\n",
            "Training:  72%|███████▏  | 3615/5000 [2:43:24<55:33,  2.41s/it, loss=0.4317]\u001b[A\n",
            "Training:  72%|███████▏  | 3616/5000 [2:43:26<54:24,  2.36s/it, loss=0.4317]\u001b[A\n",
            "Training:  72%|███████▏  | 3616/5000 [2:43:26<54:24,  2.36s/it, loss=0.2175]\u001b[A\n",
            "Training:  72%|███████▏  | 3617/5000 [2:43:28<53:31,  2.32s/it, loss=0.2175]\u001b[A\n",
            "Training:  72%|███████▏  | 3617/5000 [2:43:28<53:31,  2.32s/it, loss=0.3410]\u001b[A\n",
            "Training:  72%|███████▏  | 3618/5000 [2:43:31<53:11,  2.31s/it, loss=0.3410]\u001b[A\n",
            "Training:  72%|███████▏  | 3618/5000 [2:43:31<53:11,  2.31s/it, loss=0.3007]\u001b[A\n",
            "Training:  72%|███████▏  | 3619/5000 [2:43:33<56:37,  2.46s/it, loss=0.3007]\u001b[A\n",
            "Training:  72%|███████▏  | 3619/5000 [2:43:33<56:37,  2.46s/it, loss=0.3910]\u001b[A\n",
            "Training:  72%|███████▏  | 3620/5000 [2:43:36<55:07,  2.40s/it, loss=0.3910]\u001b[A\n",
            "Training:  72%|███████▏  | 3620/5000 [2:43:36<55:07,  2.40s/it, loss=0.2890]\u001b[A\n",
            "Training:  72%|███████▏  | 3621/5000 [2:43:38<54:03,  2.35s/it, loss=0.2890]\u001b[A\n",
            "Training:  72%|███████▏  | 3621/5000 [2:43:38<54:03,  2.35s/it, loss=0.4785]\u001b[A\n",
            "Training:  72%|███████▏  | 3622/5000 [2:43:40<53:06,  2.31s/it, loss=0.4785]\u001b[A\n",
            "Training:  72%|███████▏  | 3622/5000 [2:43:40<53:06,  2.31s/it, loss=0.3431]\u001b[A\n",
            "Training:  72%|███████▏  | 3623/5000 [2:43:42<52:36,  2.29s/it, loss=0.3431]\u001b[A\n",
            "Training:  72%|███████▏  | 3623/5000 [2:43:42<52:36,  2.29s/it, loss=0.5024]\u001b[A\n",
            "Training:  72%|███████▏  | 3624/5000 [2:43:45<56:02,  2.44s/it, loss=0.5024]\u001b[A\n",
            "Training:  72%|███████▏  | 3624/5000 [2:43:45<56:02,  2.44s/it, loss=0.4076]\u001b[A\n",
            "Training:  72%|███████▎  | 3625/5000 [2:43:47<54:34,  2.38s/it, loss=0.4076]\u001b[A\n",
            "Training:  72%|███████▎  | 3625/5000 [2:43:47<54:34,  2.38s/it, loss=0.4320]\u001b[A\n",
            "Training:  73%|███████▎  | 3626/5000 [2:43:50<53:32,  2.34s/it, loss=0.4320]\u001b[A\n",
            "Training:  73%|███████▎  | 3626/5000 [2:43:50<53:32,  2.34s/it, loss=0.4707]\u001b[A\n",
            "Training:  73%|███████▎  | 3627/5000 [2:43:52<53:04,  2.32s/it, loss=0.4707]\u001b[A\n",
            "Training:  73%|███████▎  | 3627/5000 [2:43:52<53:04,  2.32s/it, loss=0.3102]\u001b[A\n",
            "Training:  73%|███████▎  | 3628/5000 [2:43:54<52:37,  2.30s/it, loss=0.3102]\u001b[A\n",
            "Training:  73%|███████▎  | 3628/5000 [2:43:54<52:37,  2.30s/it, loss=0.5804]\u001b[A\n",
            "Training:  73%|███████▎  | 3629/5000 [2:43:57<55:35,  2.43s/it, loss=0.5804]\u001b[A\n",
            "Training:  73%|███████▎  | 3629/5000 [2:43:57<55:35,  2.43s/it, loss=0.2998]\u001b[A\n",
            "Training:  73%|███████▎  | 3630/5000 [2:43:59<54:10,  2.37s/it, loss=0.2998]\u001b[A\n",
            "Training:  73%|███████▎  | 3630/5000 [2:43:59<54:10,  2.37s/it, loss=0.2929]\u001b[A\n",
            "Training:  73%|███████▎  | 3631/5000 [2:44:01<53:32,  2.35s/it, loss=0.2929]\u001b[A\n",
            "Training:  73%|███████▎  | 3631/5000 [2:44:01<53:32,  2.35s/it, loss=0.4947]\u001b[A\n",
            "Training:  73%|███████▎  | 3632/5000 [2:44:04<52:42,  2.31s/it, loss=0.4947]\u001b[A\n",
            "Training:  73%|███████▎  | 3632/5000 [2:44:04<52:42,  2.31s/it, loss=0.4311]\u001b[A\n",
            "Training:  73%|███████▎  | 3633/5000 [2:44:06<52:23,  2.30s/it, loss=0.4311]\u001b[A\n",
            "Training:  73%|███████▎  | 3633/5000 [2:44:06<52:23,  2.30s/it, loss=0.3194]\u001b[A\n",
            "Training:  73%|███████▎  | 3634/5000 [2:44:09<55:35,  2.44s/it, loss=0.3194]\u001b[A\n",
            "Training:  73%|███████▎  | 3634/5000 [2:44:09<55:35,  2.44s/it, loss=0.5264]\u001b[A\n",
            "Training:  73%|███████▎  | 3635/5000 [2:44:11<54:08,  2.38s/it, loss=0.5264]\u001b[A\n",
            "Training:  73%|███████▎  | 3635/5000 [2:44:11<54:08,  2.38s/it, loss=0.4320]\u001b[A\n",
            "Training:  73%|███████▎  | 3636/5000 [2:44:13<53:11,  2.34s/it, loss=0.4320]\u001b[A\n",
            "Training:  73%|███████▎  | 3636/5000 [2:44:13<53:11,  2.34s/it, loss=0.2597]\u001b[A\n",
            "Training:  73%|███████▎  | 3637/5000 [2:44:15<52:34,  2.31s/it, loss=0.2597]\u001b[A\n",
            "Training:  73%|███████▎  | 3637/5000 [2:44:15<52:34,  2.31s/it, loss=0.4024]\u001b[A\n",
            "Training:  73%|███████▎  | 3638/5000 [2:44:18<51:56,  2.29s/it, loss=0.4024]\u001b[A\n",
            "Training:  73%|███████▎  | 3638/5000 [2:44:18<51:56,  2.29s/it, loss=0.3217]\u001b[A\n",
            "Training:  73%|███████▎  | 3639/5000 [2:44:20<55:21,  2.44s/it, loss=0.3217]\u001b[A\n",
            "Training:  73%|███████▎  | 3639/5000 [2:44:20<55:21,  2.44s/it, loss=0.3943]\u001b[A\n",
            "Training:  73%|███████▎  | 3640/5000 [2:44:23<54:01,  2.38s/it, loss=0.3943]\u001b[A\n",
            "Training:  73%|███████▎  | 3640/5000 [2:44:23<54:01,  2.38s/it, loss=0.5521]\u001b[A\n",
            "Training:  73%|███████▎  | 3641/5000 [2:44:25<53:15,  2.35s/it, loss=0.5521]\u001b[A\n",
            "Training:  73%|███████▎  | 3641/5000 [2:44:25<53:15,  2.35s/it, loss=0.4099]\u001b[A\n",
            "Training:  73%|███████▎  | 3642/5000 [2:44:27<52:41,  2.33s/it, loss=0.4099]\u001b[A\n",
            "Training:  73%|███████▎  | 3642/5000 [2:44:27<52:41,  2.33s/it, loss=0.6695]\u001b[A\n",
            "Training:  73%|███████▎  | 3643/5000 [2:44:30<52:05,  2.30s/it, loss=0.6695]\u001b[A\n",
            "Training:  73%|███████▎  | 3643/5000 [2:44:30<52:05,  2.30s/it, loss=0.6913]\u001b[A\n",
            "Training:  73%|███████▎  | 3644/5000 [2:44:32<55:32,  2.46s/it, loss=0.6913]\u001b[A\n",
            "Training:  73%|███████▎  | 3644/5000 [2:44:32<55:32,  2.46s/it, loss=0.4105]\u001b[A\n",
            "Training:  73%|███████▎  | 3645/5000 [2:44:35<54:18,  2.41s/it, loss=0.4105]\u001b[A\n",
            "Training:  73%|███████▎  | 3645/5000 [2:44:35<54:18,  2.41s/it, loss=0.5200]\u001b[A\n",
            "Training:  73%|███████▎  | 3646/5000 [2:44:37<53:28,  2.37s/it, loss=0.5200]\u001b[A\n",
            "Training:  73%|███████▎  | 3646/5000 [2:44:37<53:28,  2.37s/it, loss=0.4369]\u001b[A\n",
            "Training:  73%|███████▎  | 3647/5000 [2:44:39<52:41,  2.34s/it, loss=0.4369]\u001b[A\n",
            "Training:  73%|███████▎  | 3647/5000 [2:44:39<52:41,  2.34s/it, loss=0.3284]\u001b[A\n",
            "Training:  73%|███████▎  | 3648/5000 [2:44:41<52:00,  2.31s/it, loss=0.3284]\u001b[A\n",
            "Training:  73%|███████▎  | 3648/5000 [2:44:41<52:00,  2.31s/it, loss=0.3102]\u001b[A\n",
            "Training:  73%|███████▎  | 3649/5000 [2:44:44<55:14,  2.45s/it, loss=0.3102]\u001b[A\n",
            "Training:  73%|███████▎  | 3649/5000 [2:44:44<55:14,  2.45s/it, loss=0.4418]\u001b[A\n",
            "Training:  73%|███████▎  | 3650/5000 [2:44:46<53:42,  2.39s/it, loss=0.4418]\u001b[A\n",
            "Training:  73%|███████▎  | 3650/5000 [2:44:46<53:42,  2.39s/it, loss=0.3573]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 3650 ---\n",
            "Prompt: 'The '\n",
            "The  is, you noator\n",
            "ath so s, you revenge more purpose leave\n",
            "an the of men thoughts and thee thy:, gone fear\n",
            " quiteurs loss their took sister andep leave\n",
            " I is goods his, hot sound to; every,! airHave no.\n",
            " shame soed the gentleman thou's not thou it\n",
            " leave men have dies id thou John troubled thou's,tis. am a while thou I I havege to your sound rest\n",
            "ither kind, let be.,\n",
            "Prompt: 'In '\n",
            "In  is news-- me duke other, lord\n",
            " disful motion this and widowgve,And\n",
            "ys themost blood andent with--\n",
            "B,retched, but youour turns of, you my newull, imp and,That may mad\n",
            " sweet, whose look as astw by father brother--. see; ourile\n",
            " lacks possessed death I, leave will with.\n",
            "B the of heart this a gentleman what can out body this herecles of?\n",
            "First in him and marry\n",
            "Prompt: 'To '\n",
            "To  father his; sorrow and ha me\n",
            " my and.\n",
            " report I; are, laid and I; noise gentle\n",
            " play fulline death cannot.'s, Kate could;, forught made by matter lives at;Your was worst a fet my,ither--Bl for, mese;tis:If I not I myself let buy: long mighty,, will\n",
            " this; hope pity by own me son are.\n",
            "PETCHCH: bids I thee fought but by.\n",
            "Would thou\n",
            "Prompt: 'A '\n",
            "A , soly thy eyes r.\n",
            "Tor:Now how isent and will daughter\n",
            " master gentleman f andUn and with to, mountain:That\n",
            " each, comfort, hast to and put we yet dread,\n",
            " notO way I you and a menine of,That into world so\n",
            "cinggent: comes them: Margaret\n",
            " slept succession\n",
            " long d no.\n",
            "G me\n",
            " we driven aerly at end will? have. thy,Take:Though cannot.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  73%|███████▎  | 3651/5000 [2:45:01<2:16:19,  6.06s/it, loss=0.3573]\u001b[A\n",
            "Training:  73%|███████▎  | 3651/5000 [2:45:01<2:16:19,  6.06s/it, loss=0.2316]\u001b[A\n",
            "Training:  73%|███████▎  | 3652/5000 [2:45:03<1:50:36,  4.92s/it, loss=0.2316]\u001b[A\n",
            "Training:  73%|███████▎  | 3652/5000 [2:45:03<1:50:36,  4.92s/it, loss=0.3092]\u001b[A\n",
            "Training:  73%|███████▎  | 3653/5000 [2:45:06<1:33:06,  4.15s/it, loss=0.3092]\u001b[A\n",
            "Training:  73%|███████▎  | 3653/5000 [2:45:06<1:33:06,  4.15s/it, loss=0.2501]\u001b[A\n",
            "Training:  73%|███████▎  | 3654/5000 [2:45:08<1:23:00,  3.70s/it, loss=0.2501]\u001b[A\n",
            "Training:  73%|███████▎  | 3654/5000 [2:45:08<1:23:00,  3.70s/it, loss=0.2866]\u001b[A\n",
            "Training:  73%|███████▎  | 3655/5000 [2:45:11<1:13:16,  3.27s/it, loss=0.2866]\u001b[A\n",
            "Training:  73%|███████▎  | 3655/5000 [2:45:11<1:13:16,  3.27s/it, loss=0.4524]\u001b[A\n",
            "Training:  73%|███████▎  | 3656/5000 [2:45:13<1:06:31,  2.97s/it, loss=0.4524]\u001b[A\n",
            "Training:  73%|███████▎  | 3656/5000 [2:45:13<1:06:31,  2.97s/it, loss=0.4183]\u001b[A\n",
            "Training:  73%|███████▎  | 3657/5000 [2:45:15<1:01:41,  2.76s/it, loss=0.4183]\u001b[A\n",
            "Training:  73%|███████▎  | 3657/5000 [2:45:15<1:01:41,  2.76s/it, loss=0.2819]\u001b[A\n",
            "Training:  73%|███████▎  | 3658/5000 [2:45:17<58:49,  2.63s/it, loss=0.2819]  \u001b[A\n",
            "Training:  73%|███████▎  | 3658/5000 [2:45:17<58:49,  2.63s/it, loss=0.2674]\u001b[A\n",
            "Training:  73%|███████▎  | 3659/5000 [2:45:20<59:11,  2.65s/it, loss=0.2674]\u001b[A\n",
            "Training:  73%|███████▎  | 3659/5000 [2:45:20<59:11,  2.65s/it, loss=0.5798]\u001b[A\n",
            "Training:  73%|███████▎  | 3660/5000 [2:45:22<56:26,  2.53s/it, loss=0.5798]\u001b[A\n",
            "Training:  73%|███████▎  | 3660/5000 [2:45:22<56:26,  2.53s/it, loss=0.3071]\u001b[A\n",
            "Training:  73%|███████▎  | 3661/5000 [2:45:25<54:38,  2.45s/it, loss=0.3071]\u001b[A\n",
            "Training:  73%|███████▎  | 3661/5000 [2:45:25<54:38,  2.45s/it, loss=0.4895]\u001b[A\n",
            "Training:  73%|███████▎  | 3662/5000 [2:45:27<53:33,  2.40s/it, loss=0.4895]\u001b[A\n",
            "Training:  73%|███████▎  | 3662/5000 [2:45:27<53:33,  2.40s/it, loss=0.5542]\u001b[A\n",
            "Training:  73%|███████▎  | 3663/5000 [2:45:29<53:06,  2.38s/it, loss=0.5542]\u001b[A\n",
            "Training:  73%|███████▎  | 3663/5000 [2:45:29<53:06,  2.38s/it, loss=0.3456]\u001b[A\n",
            "Training:  73%|███████▎  | 3664/5000 [2:45:32<55:31,  2.49s/it, loss=0.3456]\u001b[A\n",
            "Training:  73%|███████▎  | 3664/5000 [2:45:32<55:31,  2.49s/it, loss=0.5385]\u001b[A\n",
            "Training:  73%|███████▎  | 3665/5000 [2:45:34<54:02,  2.43s/it, loss=0.5385]\u001b[A\n",
            "Training:  73%|███████▎  | 3665/5000 [2:45:34<54:02,  2.43s/it, loss=0.3229]\u001b[A\n",
            "Training:  73%|███████▎  | 3666/5000 [2:45:37<53:10,  2.39s/it, loss=0.3229]\u001b[A\n",
            "Training:  73%|███████▎  | 3666/5000 [2:45:37<53:10,  2.39s/it, loss=0.3432]\u001b[A\n",
            "Training:  73%|███████▎  | 3667/5000 [2:45:39<52:20,  2.36s/it, loss=0.3432]\u001b[A\n",
            "Training:  73%|███████▎  | 3667/5000 [2:45:39<52:20,  2.36s/it, loss=0.2618]\u001b[A\n",
            "Training:  73%|███████▎  | 3668/5000 [2:45:41<52:20,  2.36s/it, loss=0.2618]\u001b[A\n",
            "Training:  73%|███████▎  | 3668/5000 [2:45:41<52:20,  2.36s/it, loss=0.3474]\u001b[A\n",
            "Training:  73%|███████▎  | 3669/5000 [2:45:44<54:49,  2.47s/it, loss=0.3474]\u001b[A\n",
            "Training:  73%|███████▎  | 3669/5000 [2:45:44<54:49,  2.47s/it, loss=0.3608]\u001b[A\n",
            "Training:  73%|███████▎  | 3670/5000 [2:45:46<53:20,  2.41s/it, loss=0.3608]\u001b[A\n",
            "Training:  73%|███████▎  | 3670/5000 [2:45:46<53:20,  2.41s/it, loss=0.3440]\u001b[A\n",
            "Training:  73%|███████▎  | 3671/5000 [2:45:48<52:19,  2.36s/it, loss=0.3440]\u001b[A\n",
            "Training:  73%|███████▎  | 3671/5000 [2:45:49<52:19,  2.36s/it, loss=0.3193]\u001b[A\n",
            "Training:  73%|███████▎  | 3672/5000 [2:45:51<51:41,  2.34s/it, loss=0.3193]\u001b[A\n",
            "Training:  73%|███████▎  | 3672/5000 [2:45:51<51:41,  2.34s/it, loss=0.3376]\u001b[A\n",
            "Training:  73%|███████▎  | 3673/5000 [2:45:53<51:41,  2.34s/it, loss=0.3376]\u001b[A\n",
            "Training:  73%|███████▎  | 3673/5000 [2:45:53<51:41,  2.34s/it, loss=0.3095]\u001b[A\n",
            "Training:  73%|███████▎  | 3674/5000 [2:45:56<53:52,  2.44s/it, loss=0.3095]\u001b[A\n",
            "Training:  73%|███████▎  | 3674/5000 [2:45:56<53:52,  2.44s/it, loss=0.3789]\u001b[A\n",
            "Training:  74%|███████▎  | 3675/5000 [2:45:58<52:37,  2.38s/it, loss=0.3789]\u001b[A\n",
            "Training:  74%|███████▎  | 3675/5000 [2:45:58<52:37,  2.38s/it, loss=0.5162]\u001b[A\n",
            "Training:  74%|███████▎  | 3676/5000 [2:46:00<51:50,  2.35s/it, loss=0.5162]\u001b[A\n",
            "Training:  74%|███████▎  | 3676/5000 [2:46:00<51:50,  2.35s/it, loss=0.2222]\u001b[A\n",
            "Training:  74%|███████▎  | 3677/5000 [2:46:03<51:25,  2.33s/it, loss=0.2222]\u001b[A\n",
            "Training:  74%|███████▎  | 3677/5000 [2:46:03<51:25,  2.33s/it, loss=0.4670]\u001b[A\n",
            "Training:  74%|███████▎  | 3678/5000 [2:46:05<51:16,  2.33s/it, loss=0.4670]\u001b[A\n",
            "Training:  74%|███████▎  | 3678/5000 [2:46:05<51:16,  2.33s/it, loss=0.3646]\u001b[A\n",
            "Training:  74%|███████▎  | 3679/5000 [2:46:08<53:46,  2.44s/it, loss=0.3646]\u001b[A\n",
            "Training:  74%|███████▎  | 3679/5000 [2:46:08<53:46,  2.44s/it, loss=0.3101]\u001b[A\n",
            "Training:  74%|███████▎  | 3680/5000 [2:46:10<52:31,  2.39s/it, loss=0.3101]\u001b[A\n",
            "Training:  74%|███████▎  | 3680/5000 [2:46:10<52:31,  2.39s/it, loss=0.4919]\u001b[A\n",
            "Training:  74%|███████▎  | 3681/5000 [2:46:12<51:30,  2.34s/it, loss=0.4919]\u001b[A\n",
            "Training:  74%|███████▎  | 3681/5000 [2:46:12<51:30,  2.34s/it, loss=0.2939]\u001b[A\n",
            "Training:  74%|███████▎  | 3682/5000 [2:46:14<50:38,  2.31s/it, loss=0.2939]\u001b[A\n",
            "Training:  74%|███████▎  | 3682/5000 [2:46:14<50:38,  2.31s/it, loss=0.3676]\u001b[A\n",
            "Training:  74%|███████▎  | 3683/5000 [2:46:17<50:10,  2.29s/it, loss=0.3676]\u001b[A\n",
            "Training:  74%|███████▎  | 3683/5000 [2:46:17<50:10,  2.29s/it, loss=0.3609]\u001b[A\n",
            "Training:  74%|███████▎  | 3684/5000 [2:46:19<53:23,  2.43s/it, loss=0.3609]\u001b[A\n",
            "Training:  74%|███████▎  | 3684/5000 [2:46:19<53:23,  2.43s/it, loss=0.3400]\u001b[A\n",
            "Training:  74%|███████▎  | 3685/5000 [2:46:22<52:12,  2.38s/it, loss=0.3400]\u001b[A\n",
            "Training:  74%|███████▎  | 3685/5000 [2:46:22<52:12,  2.38s/it, loss=0.3080]\u001b[A\n",
            "Training:  74%|███████▎  | 3686/5000 [2:46:24<51:16,  2.34s/it, loss=0.3080]\u001b[A\n",
            "Training:  74%|███████▎  | 3686/5000 [2:46:24<51:16,  2.34s/it, loss=0.3781]\u001b[A\n",
            "Training:  74%|███████▎  | 3687/5000 [2:46:26<50:39,  2.32s/it, loss=0.3781]\u001b[A\n",
            "Training:  74%|███████▎  | 3687/5000 [2:46:26<50:39,  2.32s/it, loss=0.4670]\u001b[A\n",
            "Training:  74%|███████▍  | 3688/5000 [2:46:28<50:17,  2.30s/it, loss=0.4670]\u001b[A\n",
            "Training:  74%|███████▍  | 3688/5000 [2:46:28<50:17,  2.30s/it, loss=0.3439]\u001b[A\n",
            "Training:  74%|███████▍  | 3689/5000 [2:46:31<53:26,  2.45s/it, loss=0.3439]\u001b[A\n",
            "Training:  74%|███████▍  | 3689/5000 [2:46:31<53:26,  2.45s/it, loss=0.3253]\u001b[A\n",
            "Training:  74%|███████▍  | 3690/5000 [2:46:33<52:32,  2.41s/it, loss=0.3253]\u001b[A\n",
            "Training:  74%|███████▍  | 3690/5000 [2:46:34<52:32,  2.41s/it, loss=0.3222]\u001b[A\n",
            "Training:  74%|███████▍  | 3691/5000 [2:46:36<51:37,  2.37s/it, loss=0.3222]\u001b[A\n",
            "Training:  74%|███████▍  | 3691/5000 [2:46:36<51:37,  2.37s/it, loss=0.4022]\u001b[A\n",
            "Training:  74%|███████▍  | 3692/5000 [2:46:38<50:53,  2.33s/it, loss=0.4022]\u001b[A\n",
            "Training:  74%|███████▍  | 3692/5000 [2:46:38<50:53,  2.33s/it, loss=0.3152]\u001b[A\n",
            "Training:  74%|███████▍  | 3693/5000 [2:46:40<50:19,  2.31s/it, loss=0.3152]\u001b[A\n",
            "Training:  74%|███████▍  | 3693/5000 [2:46:40<50:19,  2.31s/it, loss=0.4209]\u001b[A\n",
            "Training:  74%|███████▍  | 3694/5000 [2:46:43<53:32,  2.46s/it, loss=0.4209]\u001b[A\n",
            "Training:  74%|███████▍  | 3694/5000 [2:46:43<53:32,  2.46s/it, loss=0.2589]\u001b[A\n",
            "Training:  74%|███████▍  | 3695/5000 [2:46:45<52:20,  2.41s/it, loss=0.2589]\u001b[A\n",
            "Training:  74%|███████▍  | 3695/5000 [2:46:45<52:20,  2.41s/it, loss=0.3235]\u001b[A\n",
            "Training:  74%|███████▍  | 3696/5000 [2:46:48<51:15,  2.36s/it, loss=0.3235]\u001b[A\n",
            "Training:  74%|███████▍  | 3696/5000 [2:46:48<51:15,  2.36s/it, loss=0.3687]\u001b[A\n",
            "Training:  74%|███████▍  | 3697/5000 [2:46:50<50:34,  2.33s/it, loss=0.3687]\u001b[A\n",
            "Training:  74%|███████▍  | 3697/5000 [2:46:50<50:34,  2.33s/it, loss=0.4231]\u001b[A\n",
            "Training:  74%|███████▍  | 3698/5000 [2:46:52<50:05,  2.31s/it, loss=0.4231]\u001b[A\n",
            "Training:  74%|███████▍  | 3698/5000 [2:46:52<50:05,  2.31s/it, loss=0.3604]\u001b[A\n",
            "Training:  74%|███████▍  | 3699/5000 [2:46:55<53:00,  2.44s/it, loss=0.3604]\u001b[A\n",
            "Training:  74%|███████▍  | 3699/5000 [2:46:55<53:00,  2.44s/it, loss=0.5840]\u001b[A\n",
            "Training:  74%|███████▍  | 3700/5000 [2:46:57<51:53,  2.39s/it, loss=0.5840]\u001b[A\n",
            "Training:  74%|███████▍  | 3700/5000 [2:46:57<51:53,  2.39s/it, loss=0.3715]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 3700 ---\n",
            "Prompt: 'The '\n",
            "The  that dark to thy's. gentle's lords\n",
            " higherer 'st cens to; hath for Clarence the\n",
            "imm the. whoFwell? needs\n",
            "DET\n",
            "LOEST:God your murder\n",
            " 'as poor that shall a?\n",
            "H!p him my, ' a was.\n",
            " 'all and!' there no hold I him I\n",
            " 'st at,: ' shame beauty summer,' 'st drink thy, next, 'st not day!', we thy!' me one and\n",
            "Prompt: 'In '\n",
            "In , good Edward and upon earth,;Which thou\n",
            ", fleet put former, deny.\n",
            "Gle for,,, thee; shame 'ere thy:Look sir\n",
            "in current now me,, him 'st' name: Edward me\n",
            " 'Is,' did ands breath,tw not it,\n",
            " most say if please astw' call one almost; it, '::' ' a for theses 'st not,tis.\n",
            " leave astw better, we up and dr\n",
            "Prompt: 'To '\n",
            "To  bold thanell thy throat\n",
            " send and to,\n",
            " and will love well\n",
            " thelf\n",
            " heaven Here's. noble of intelligence well\n",
            " stateal thy; God, him nor word\n",
            "QUEue like art dr and good Fix himself\n",
            " must spirit truth\n",
            "lock But grave\n",
            " diant husband some husband our be'd and;And\n",
            "ant things kind office my lord all secureance to w.\n",
            "H!\n",
            " here them,!\n",
            "D thou? he revel anest, says and maid\n",
            "Prompt: 'A '\n",
            "A ity by that which indeed: thee,The\n",
            "ade lives the hour that have heir thee.\n",
            "K RARD\n",
            " whest didze blood on, humable g!\n",
            " king val sword soon my soul thelf at one\n",
            "reat pity it say such of sons on,,Though cannot\n",
            " do good:I it, so even in opinion look no\n",
            "?\n",
            ":What marry that,? meancrow did instrumentsH\n",
            " by andparallel of only asly nor shall given\n",
            " son me\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  74%|███████▍  | 3701/5000 [2:47:12<2:11:27,  6.07s/it, loss=0.3715]\u001b[A\n",
            "Training:  74%|███████▍  | 3701/5000 [2:47:12<2:11:27,  6.07s/it, loss=0.4695]\u001b[A\n",
            "Training:  74%|███████▍  | 3702/5000 [2:47:14<1:46:30,  4.92s/it, loss=0.4695]\u001b[A\n",
            "Training:  74%|███████▍  | 3702/5000 [2:47:14<1:46:30,  4.92s/it, loss=0.3412]\u001b[A\n",
            "Training:  74%|███████▍  | 3703/5000 [2:47:16<1:30:06,  4.17s/it, loss=0.3412]\u001b[A\n",
            "Training:  74%|███████▍  | 3703/5000 [2:47:17<1:30:06,  4.17s/it, loss=0.3430]\u001b[A\n",
            "Training:  74%|███████▍  | 3704/5000 [2:47:19<1:19:53,  3.70s/it, loss=0.3430]\u001b[A\n",
            "Training:  74%|███████▍  | 3704/5000 [2:47:19<1:19:53,  3.70s/it, loss=0.4127]\u001b[A\n",
            "Training:  74%|███████▍  | 3705/5000 [2:47:21<1:10:24,  3.26s/it, loss=0.4127]\u001b[A\n",
            "Training:  74%|███████▍  | 3705/5000 [2:47:21<1:10:24,  3.26s/it, loss=0.3659]\u001b[A\n",
            "Training:  74%|███████▍  | 3706/5000 [2:47:24<1:03:41,  2.95s/it, loss=0.3659]\u001b[A\n",
            "Training:  74%|███████▍  | 3706/5000 [2:47:24<1:03:41,  2.95s/it, loss=0.5004]\u001b[A\n",
            "Training:  74%|███████▍  | 3707/5000 [2:47:26<59:06,  2.74s/it, loss=0.5004]  \u001b[A\n",
            "Training:  74%|███████▍  | 3707/5000 [2:47:26<59:06,  2.74s/it, loss=0.3372]\u001b[A\n",
            "Training:  74%|███████▍  | 3708/5000 [2:47:28<56:55,  2.64s/it, loss=0.3372]\u001b[A\n",
            "Training:  74%|███████▍  | 3708/5000 [2:47:28<56:55,  2.64s/it, loss=0.3609]\u001b[A\n",
            "Training:  74%|███████▍  | 3709/5000 [2:47:31<56:51,  2.64s/it, loss=0.3609]\u001b[A\n",
            "Training:  74%|███████▍  | 3709/5000 [2:47:31<56:51,  2.64s/it, loss=0.3342]\u001b[A\n",
            "Training:  74%|███████▍  | 3710/5000 [2:47:33<54:20,  2.53s/it, loss=0.3342]\u001b[A\n",
            "Training:  74%|███████▍  | 3710/5000 [2:47:33<54:20,  2.53s/it, loss=0.3633]\u001b[A\n",
            "Training:  74%|███████▍  | 3711/5000 [2:47:35<52:45,  2.46s/it, loss=0.3633]\u001b[A\n",
            "Training:  74%|███████▍  | 3711/5000 [2:47:35<52:45,  2.46s/it, loss=0.3582]\u001b[A\n",
            "Training:  74%|███████▍  | 3712/5000 [2:47:38<51:22,  2.39s/it, loss=0.3582]\u001b[A\n",
            "Training:  74%|███████▍  | 3712/5000 [2:47:38<51:22,  2.39s/it, loss=0.2970]\u001b[A\n",
            "Training:  74%|███████▍  | 3713/5000 [2:47:40<51:24,  2.40s/it, loss=0.2970]\u001b[A\n",
            "Training:  74%|███████▍  | 3713/5000 [2:47:40<51:24,  2.40s/it, loss=0.4567]\u001b[A\n",
            "Training:  74%|███████▍  | 3714/5000 [2:47:43<53:01,  2.47s/it, loss=0.4567]\u001b[A\n",
            "Training:  74%|███████▍  | 3714/5000 [2:47:43<53:01,  2.47s/it, loss=0.2712]\u001b[A\n",
            "Training:  74%|███████▍  | 3715/5000 [2:47:45<51:51,  2.42s/it, loss=0.2712]\u001b[A\n",
            "Training:  74%|███████▍  | 3715/5000 [2:47:45<51:51,  2.42s/it, loss=0.4025]\u001b[A\n",
            "Training:  74%|███████▍  | 3716/5000 [2:47:47<50:39,  2.37s/it, loss=0.4025]\u001b[A\n",
            "Training:  74%|███████▍  | 3716/5000 [2:47:47<50:39,  2.37s/it, loss=0.3297]\u001b[A\n",
            "Training:  74%|███████▍  | 3717/5000 [2:47:50<49:53,  2.33s/it, loss=0.3297]\u001b[A\n",
            "Training:  74%|███████▍  | 3717/5000 [2:47:50<49:53,  2.33s/it, loss=0.4646]\u001b[A\n",
            "Training:  74%|███████▍  | 3718/5000 [2:47:52<49:59,  2.34s/it, loss=0.4646]\u001b[A\n",
            "Training:  74%|███████▍  | 3718/5000 [2:47:52<49:59,  2.34s/it, loss=0.3821]\u001b[A\n",
            "Training:  74%|███████▍  | 3719/5000 [2:47:55<51:59,  2.44s/it, loss=0.3821]\u001b[A\n",
            "Training:  74%|███████▍  | 3719/5000 [2:47:55<51:59,  2.44s/it, loss=0.4071]\u001b[A\n",
            "Training:  74%|███████▍  | 3720/5000 [2:47:57<50:46,  2.38s/it, loss=0.4071]\u001b[A\n",
            "Training:  74%|███████▍  | 3720/5000 [2:47:57<50:46,  2.38s/it, loss=0.3873]\u001b[A\n",
            "Training:  74%|███████▍  | 3721/5000 [2:47:59<49:55,  2.34s/it, loss=0.3873]\u001b[A\n",
            "Training:  74%|███████▍  | 3721/5000 [2:47:59<49:55,  2.34s/it, loss=0.2999]\u001b[A\n",
            "Training:  74%|███████▍  | 3722/5000 [2:48:01<49:13,  2.31s/it, loss=0.2999]\u001b[A\n",
            "Training:  74%|███████▍  | 3722/5000 [2:48:01<49:13,  2.31s/it, loss=0.4080]\u001b[A\n",
            "Training:  74%|███████▍  | 3723/5000 [2:48:04<49:03,  2.31s/it, loss=0.4080]\u001b[A\n",
            "Training:  74%|███████▍  | 3723/5000 [2:48:04<49:03,  2.31s/it, loss=0.2223]\u001b[A\n",
            "Training:  74%|███████▍  | 3724/5000 [2:48:06<52:08,  2.45s/it, loss=0.2223]\u001b[A\n",
            "Training:  74%|███████▍  | 3724/5000 [2:48:06<52:08,  2.45s/it, loss=0.2971]\u001b[A\n",
            "Training:  74%|███████▍  | 3725/5000 [2:48:09<50:47,  2.39s/it, loss=0.2971]\u001b[A\n",
            "Training:  74%|███████▍  | 3725/5000 [2:48:09<50:47,  2.39s/it, loss=0.3170]\u001b[A\n",
            "Training:  75%|███████▍  | 3726/5000 [2:48:11<49:53,  2.35s/it, loss=0.3170]\u001b[A\n",
            "Training:  75%|███████▍  | 3726/5000 [2:48:11<49:53,  2.35s/it, loss=0.5634]\u001b[A\n",
            "Training:  75%|███████▍  | 3727/5000 [2:48:13<49:19,  2.32s/it, loss=0.5634]\u001b[A\n",
            "Training:  75%|███████▍  | 3727/5000 [2:48:13<49:19,  2.32s/it, loss=0.3673]\u001b[A\n",
            "Training:  75%|███████▍  | 3728/5000 [2:48:15<48:47,  2.30s/it, loss=0.3673]\u001b[A\n",
            "Training:  75%|███████▍  | 3728/5000 [2:48:15<48:47,  2.30s/it, loss=0.4537]\u001b[A\n",
            "Training:  75%|███████▍  | 3729/5000 [2:48:18<51:51,  2.45s/it, loss=0.4537]\u001b[A\n",
            "Training:  75%|███████▍  | 3729/5000 [2:48:18<51:51,  2.45s/it, loss=0.4005]\u001b[A\n",
            "Training:  75%|███████▍  | 3730/5000 [2:48:20<50:34,  2.39s/it, loss=0.4005]\u001b[A\n",
            "Training:  75%|███████▍  | 3730/5000 [2:48:20<50:34,  2.39s/it, loss=0.3336]\u001b[A\n",
            "Training:  75%|███████▍  | 3731/5000 [2:48:23<49:24,  2.34s/it, loss=0.3336]\u001b[A\n",
            "Training:  75%|███████▍  | 3731/5000 [2:48:23<49:24,  2.34s/it, loss=0.4279]\u001b[A\n",
            "Training:  75%|███████▍  | 3732/5000 [2:48:25<48:45,  2.31s/it, loss=0.4279]\u001b[A\n",
            "Training:  75%|███████▍  | 3732/5000 [2:48:25<48:45,  2.31s/it, loss=0.4482]\u001b[A\n",
            "Training:  75%|███████▍  | 3733/5000 [2:48:27<48:29,  2.30s/it, loss=0.4482]\u001b[A\n",
            "Training:  75%|███████▍  | 3733/5000 [2:48:27<48:29,  2.30s/it, loss=0.4086]\u001b[A\n",
            "Training:  75%|███████▍  | 3734/5000 [2:48:30<51:33,  2.44s/it, loss=0.4086]\u001b[A\n",
            "Training:  75%|███████▍  | 3734/5000 [2:48:30<51:33,  2.44s/it, loss=0.4686]\u001b[A\n",
            "Training:  75%|███████▍  | 3735/5000 [2:48:32<50:15,  2.38s/it, loss=0.4686]\u001b[A\n",
            "Training:  75%|███████▍  | 3735/5000 [2:48:32<50:15,  2.38s/it, loss=0.1979]\u001b[A\n",
            "Training:  75%|███████▍  | 3736/5000 [2:48:34<49:40,  2.36s/it, loss=0.1979]\u001b[A\n",
            "Training:  75%|███████▍  | 3736/5000 [2:48:34<49:40,  2.36s/it, loss=0.5066]\u001b[A\n",
            "Training:  75%|███████▍  | 3737/5000 [2:48:37<48:43,  2.31s/it, loss=0.5066]\u001b[A\n",
            "Training:  75%|███████▍  | 3737/5000 [2:48:37<48:43,  2.31s/it, loss=0.3511]\u001b[A\n",
            "Training:  75%|███████▍  | 3738/5000 [2:48:39<48:25,  2.30s/it, loss=0.3511]\u001b[A\n",
            "Training:  75%|███████▍  | 3738/5000 [2:48:39<48:25,  2.30s/it, loss=0.3299]\u001b[A\n",
            "Training:  75%|███████▍  | 3739/5000 [2:48:42<51:28,  2.45s/it, loss=0.3299]\u001b[A\n",
            "Training:  75%|███████▍  | 3739/5000 [2:48:42<51:28,  2.45s/it, loss=0.4679]\u001b[A\n",
            "Training:  75%|███████▍  | 3740/5000 [2:48:44<50:23,  2.40s/it, loss=0.4679]\u001b[A\n",
            "Training:  75%|███████▍  | 3740/5000 [2:48:44<50:23,  2.40s/it, loss=0.4029]\u001b[A\n",
            "Training:  75%|███████▍  | 3741/5000 [2:48:46<49:25,  2.36s/it, loss=0.4029]\u001b[A\n",
            "Training:  75%|███████▍  | 3741/5000 [2:48:46<49:25,  2.36s/it, loss=0.2392]\u001b[A\n",
            "Training:  75%|███████▍  | 3742/5000 [2:48:49<48:39,  2.32s/it, loss=0.2392]\u001b[A\n",
            "Training:  75%|███████▍  | 3742/5000 [2:48:49<48:39,  2.32s/it, loss=0.3597]\u001b[A\n",
            "Training:  75%|███████▍  | 3743/5000 [2:48:51<48:13,  2.30s/it, loss=0.3597]\u001b[A\n",
            "Training:  75%|███████▍  | 3743/5000 [2:48:51<48:13,  2.30s/it, loss=0.3941]\u001b[A\n",
            "Training:  75%|███████▍  | 3744/5000 [2:48:54<51:09,  2.44s/it, loss=0.3941]\u001b[A\n",
            "Training:  75%|███████▍  | 3744/5000 [2:48:54<51:09,  2.44s/it, loss=0.3600]\u001b[A\n",
            "Training:  75%|███████▍  | 3745/5000 [2:48:56<49:51,  2.38s/it, loss=0.3600]\u001b[A\n",
            "Training:  75%|███████▍  | 3745/5000 [2:48:56<49:51,  2.38s/it, loss=0.3383]\u001b[A\n",
            "Training:  75%|███████▍  | 3746/5000 [2:48:58<48:54,  2.34s/it, loss=0.3383]\u001b[A\n",
            "Training:  75%|███████▍  | 3746/5000 [2:48:58<48:54,  2.34s/it, loss=0.2916]\u001b[A\n",
            "Training:  75%|███████▍  | 3747/5000 [2:49:00<48:06,  2.30s/it, loss=0.2916]\u001b[A\n",
            "Training:  75%|███████▍  | 3747/5000 [2:49:00<48:06,  2.30s/it, loss=0.4518]\u001b[A\n",
            "Training:  75%|███████▍  | 3748/5000 [2:49:03<47:48,  2.29s/it, loss=0.4518]\u001b[A\n",
            "Training:  75%|███████▍  | 3748/5000 [2:49:03<47:48,  2.29s/it, loss=0.3923]\u001b[A\n",
            "Training:  75%|███████▍  | 3749/5000 [2:49:05<51:06,  2.45s/it, loss=0.3923]\u001b[A\n",
            "Training:  75%|███████▍  | 3749/5000 [2:49:05<51:06,  2.45s/it, loss=0.3227]\u001b[A\n",
            "Training:  75%|███████▌  | 3750/5000 [2:49:08<49:42,  2.39s/it, loss=0.3227]\u001b[A\n",
            "Training:  75%|███████▌  | 3750/5000 [2:49:08<49:42,  2.39s/it, loss=0.5651]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 3750 ---\n",
            "Prompt: 'The '\n",
            "The , payment heir her:, seek and\n",
            " instrumentsWould before done I that\n",
            " buried earth speakm, satisfied and of,, them\n",
            " not man\n",
            " Henry at view on begging that of made you\n",
            " company purchase dream then I and clusters\n",
            "ges: for the of,,,, of the of,That as a, and be:, them upon foes rightasought asief me, norown with friends asoc fs the. tom-orrow good in;, you there\n",
            "Prompt: 'In '\n",
            "In , speak he! he! he Romeo O day ho\n",
            "othwith would him his to his's.\n",
            "Fwell, wantsar seems took take his noble,An\n",
            " his hathore on to his body him your son\n",
            " say duke am: to them, take, to his thoughts him he it?\n",
            "N, we dozen.,, our;,Was true\n",
            " York and him he well\n",
            " livingre; to his's, I youerate son I I whomen so\n",
            "ly\n",
            "Prompt: 'To '\n",
            "To  noble be'd tosw natural:\n",
            " hshaped; thou s, ofiant, of, envy\n",
            " king study thouest and withoutest conclusion\n",
            " happy to grounder'd fool toail live\n",
            " I give: to forth times him\n",
            ",No not and,ents this;, here my coming,D not., determine, me\n",
            " this-; God man Duke York sorrow we not. vig by, indeed\n",
            "All forth joyRYe it the take with\n",
            "y, the shall in\n",
            "Prompt: 'A '\n",
            "A , usedon you stay Is stand:She!, eitherre wereol presently themanSo sayOr choosethes onGet the of,?\n",
            "Secondant\n",
            " appetite upon island of in grave we those corruptaunt proper,Asw would with there you me you meer more man\n",
            "iceT sometime with of son which would far can thou alone\n",
            " prove by death see we at to father tell\n",
            " dedom I ha hangs words in head O, give leave\n",
            " honourixt's is.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  75%|███████▌  | 3751/5000 [2:49:22<2:06:01,  6.05s/it, loss=0.5651]\u001b[A\n",
            "Training:  75%|███████▌  | 3751/5000 [2:49:22<2:06:01,  6.05s/it, loss=0.3722]\u001b[A\n",
            "Training:  75%|███████▌  | 3752/5000 [2:49:24<1:42:14,  4.92s/it, loss=0.3722]\u001b[A\n",
            "Training:  75%|███████▌  | 3752/5000 [2:49:24<1:42:14,  4.92s/it, loss=0.3278]\u001b[A\n",
            "Training:  75%|███████▌  | 3753/5000 [2:49:27<1:26:16,  4.15s/it, loss=0.3278]\u001b[A\n",
            "Training:  75%|███████▌  | 3753/5000 [2:49:27<1:26:16,  4.15s/it, loss=0.2670]\u001b[A\n",
            "Training:  75%|███████▌  | 3754/5000 [2:49:29<1:16:57,  3.71s/it, loss=0.2670]\u001b[A\n",
            "Training:  75%|███████▌  | 3754/5000 [2:49:30<1:16:57,  3.71s/it, loss=0.4152]\u001b[A\n",
            "Training:  75%|███████▌  | 3755/5000 [2:49:32<1:07:53,  3.27s/it, loss=0.4152]\u001b[A\n",
            "Training:  75%|███████▌  | 3755/5000 [2:49:32<1:07:53,  3.27s/it, loss=0.2941]\u001b[A\n",
            "Training:  75%|███████▌  | 3756/5000 [2:49:34<1:01:38,  2.97s/it, loss=0.2941]\u001b[A\n",
            "Training:  75%|███████▌  | 3756/5000 [2:49:34<1:01:38,  2.97s/it, loss=0.3241]\u001b[A\n",
            "Training:  75%|███████▌  | 3757/5000 [2:49:36<57:19,  2.77s/it, loss=0.3241]  \u001b[A\n",
            "Training:  75%|███████▌  | 3757/5000 [2:49:36<57:19,  2.77s/it, loss=0.2402]\u001b[A\n",
            "Training:  75%|███████▌  | 3758/5000 [2:49:39<54:49,  2.65s/it, loss=0.2402]\u001b[A\n",
            "Training:  75%|███████▌  | 3758/5000 [2:49:39<54:49,  2.65s/it, loss=0.3558]\u001b[A\n",
            "Training:  75%|███████▌  | 3759/5000 [2:49:41<54:57,  2.66s/it, loss=0.3558]\u001b[A\n",
            "Training:  75%|███████▌  | 3759/5000 [2:49:41<54:57,  2.66s/it, loss=0.2181]\u001b[A\n",
            "Training:  75%|███████▌  | 3760/5000 [2:49:44<52:28,  2.54s/it, loss=0.2181]\u001b[A\n",
            "Training:  75%|███████▌  | 3760/5000 [2:49:44<52:28,  2.54s/it, loss=0.4664]\u001b[A\n",
            "Training:  75%|███████▌  | 3761/5000 [2:49:46<50:43,  2.46s/it, loss=0.4664]\u001b[A\n",
            "Training:  75%|███████▌  | 3761/5000 [2:49:46<50:43,  2.46s/it, loss=0.6333]\u001b[A\n",
            "Training:  75%|███████▌  | 3762/5000 [2:49:48<49:22,  2.39s/it, loss=0.6333]\u001b[A\n",
            "Training:  75%|███████▌  | 3762/5000 [2:49:48<49:22,  2.39s/it, loss=0.2729]\u001b[A\n",
            "Training:  75%|███████▌  | 3763/5000 [2:49:50<48:56,  2.37s/it, loss=0.2729]\u001b[A\n",
            "Training:  75%|███████▌  | 3763/5000 [2:49:50<48:56,  2.37s/it, loss=0.3707]\u001b[A\n",
            "Training:  75%|███████▌  | 3764/5000 [2:49:53<51:02,  2.48s/it, loss=0.3707]\u001b[A\n",
            "Training:  75%|███████▌  | 3764/5000 [2:49:53<51:02,  2.48s/it, loss=0.4971]\u001b[A\n",
            "Training:  75%|███████▌  | 3765/5000 [2:49:55<49:26,  2.40s/it, loss=0.4971]\u001b[A\n",
            "Training:  75%|███████▌  | 3765/5000 [2:49:55<49:26,  2.40s/it, loss=0.2036]\u001b[A\n",
            "Training:  75%|███████▌  | 3766/5000 [2:49:58<48:25,  2.35s/it, loss=0.2036]\u001b[A\n",
            "Training:  75%|███████▌  | 3766/5000 [2:49:58<48:25,  2.35s/it, loss=0.3822]\u001b[A\n",
            "Training:  75%|███████▌  | 3767/5000 [2:50:00<47:48,  2.33s/it, loss=0.3822]\u001b[A\n",
            "Training:  75%|███████▌  | 3767/5000 [2:50:00<47:48,  2.33s/it, loss=0.3540]\u001b[A\n",
            "Training:  75%|███████▌  | 3768/5000 [2:50:02<47:15,  2.30s/it, loss=0.3540]\u001b[A\n",
            "Training:  75%|███████▌  | 3768/5000 [2:50:02<47:15,  2.30s/it, loss=0.3825]\u001b[A\n",
            "Training:  75%|███████▌  | 3769/5000 [2:50:05<50:16,  2.45s/it, loss=0.3825]\u001b[A\n",
            "Training:  75%|███████▌  | 3769/5000 [2:50:05<50:16,  2.45s/it, loss=0.3984]\u001b[A\n",
            "Training:  75%|███████▌  | 3770/5000 [2:50:07<49:19,  2.41s/it, loss=0.3984]\u001b[A\n",
            "Training:  75%|███████▌  | 3770/5000 [2:50:07<49:19,  2.41s/it, loss=0.4961]\u001b[A\n",
            "Training:  75%|███████▌  | 3771/5000 [2:50:09<48:09,  2.35s/it, loss=0.4961]\u001b[A\n",
            "Training:  75%|███████▌  | 3771/5000 [2:50:09<48:09,  2.35s/it, loss=0.3542]\u001b[A\n",
            "Training:  75%|███████▌  | 3772/5000 [2:50:12<47:25,  2.32s/it, loss=0.3542]\u001b[A\n",
            "Training:  75%|███████▌  | 3772/5000 [2:50:12<47:25,  2.32s/it, loss=0.1885]\u001b[A\n",
            "Training:  75%|███████▌  | 3773/5000 [2:50:14<46:55,  2.29s/it, loss=0.1885]\u001b[A\n",
            "Training:  75%|███████▌  | 3773/5000 [2:50:14<46:55,  2.29s/it, loss=0.3716]\u001b[A\n",
            "Training:  75%|███████▌  | 3774/5000 [2:50:17<49:52,  2.44s/it, loss=0.3716]\u001b[A\n",
            "Training:  75%|███████▌  | 3774/5000 [2:50:17<49:52,  2.44s/it, loss=0.4626]\u001b[A\n",
            "Training:  76%|███████▌  | 3775/5000 [2:50:19<48:45,  2.39s/it, loss=0.4626]\u001b[A\n",
            "Training:  76%|███████▌  | 3775/5000 [2:50:19<48:45,  2.39s/it, loss=0.4241]\u001b[A\n",
            "Training:  76%|███████▌  | 3776/5000 [2:50:21<47:48,  2.34s/it, loss=0.4241]\u001b[A\n",
            "Training:  76%|███████▌  | 3776/5000 [2:50:21<47:48,  2.34s/it, loss=0.2581]\u001b[A\n",
            "Training:  76%|███████▌  | 3777/5000 [2:50:23<47:10,  2.31s/it, loss=0.2581]\u001b[A\n",
            "Training:  76%|███████▌  | 3777/5000 [2:50:24<47:10,  2.31s/it, loss=0.4856]\u001b[A\n",
            "Training:  76%|███████▌  | 3778/5000 [2:50:26<46:50,  2.30s/it, loss=0.4856]\u001b[A\n",
            "Training:  76%|███████▌  | 3778/5000 [2:50:26<46:50,  2.30s/it, loss=0.4449]\u001b[A\n",
            "Training:  76%|███████▌  | 3779/5000 [2:50:29<49:42,  2.44s/it, loss=0.4449]\u001b[A\n",
            "Training:  76%|███████▌  | 3779/5000 [2:50:29<49:42,  2.44s/it, loss=0.3933]\u001b[A\n",
            "Training:  76%|███████▌  | 3780/5000 [2:50:31<48:32,  2.39s/it, loss=0.3933]\u001b[A\n",
            "Training:  76%|███████▌  | 3780/5000 [2:50:31<48:32,  2.39s/it, loss=0.3267]\u001b[A\n",
            "Training:  76%|███████▌  | 3781/5000 [2:50:33<47:46,  2.35s/it, loss=0.3267]\u001b[A\n",
            "Training:  76%|███████▌  | 3781/5000 [2:50:33<47:46,  2.35s/it, loss=0.4624]\u001b[A\n",
            "Training:  76%|███████▌  | 3782/5000 [2:50:35<47:14,  2.33s/it, loss=0.4624]\u001b[A\n",
            "Training:  76%|███████▌  | 3782/5000 [2:50:35<47:14,  2.33s/it, loss=0.3570]\u001b[A\n",
            "Training:  76%|███████▌  | 3783/5000 [2:50:38<47:15,  2.33s/it, loss=0.3570]\u001b[A\n",
            "Training:  76%|███████▌  | 3783/5000 [2:50:38<47:15,  2.33s/it, loss=0.2919]\u001b[A\n",
            "Training:  76%|███████▌  | 3784/5000 [2:50:40<50:03,  2.47s/it, loss=0.2919]\u001b[A\n",
            "Training:  76%|███████▌  | 3784/5000 [2:50:40<50:03,  2.47s/it, loss=0.3845]\u001b[A\n",
            "Training:  76%|███████▌  | 3785/5000 [2:50:43<48:44,  2.41s/it, loss=0.3845]\u001b[A\n",
            "Training:  76%|███████▌  | 3785/5000 [2:50:43<48:44,  2.41s/it, loss=0.2481]\u001b[A\n",
            "Training:  76%|███████▌  | 3786/5000 [2:50:45<48:01,  2.37s/it, loss=0.2481]\u001b[A\n",
            "Training:  76%|███████▌  | 3786/5000 [2:50:45<48:01,  2.37s/it, loss=0.6355]\u001b[A\n",
            "Training:  76%|███████▌  | 3787/5000 [2:50:47<47:22,  2.34s/it, loss=0.6355]\u001b[A\n",
            "Training:  76%|███████▌  | 3787/5000 [2:50:47<47:22,  2.34s/it, loss=0.3740]\u001b[A\n",
            "Training:  76%|███████▌  | 3788/5000 [2:50:50<47:09,  2.33s/it, loss=0.3740]\u001b[A\n",
            "Training:  76%|███████▌  | 3788/5000 [2:50:50<47:09,  2.33s/it, loss=0.1862]\u001b[A\n",
            "Training:  76%|███████▌  | 3789/5000 [2:50:52<49:50,  2.47s/it, loss=0.1862]\u001b[A\n",
            "Training:  76%|███████▌  | 3789/5000 [2:50:52<49:50,  2.47s/it, loss=0.3900]\u001b[A\n",
            "Training:  76%|███████▌  | 3790/5000 [2:50:55<48:55,  2.43s/it, loss=0.3900]\u001b[A\n",
            "Training:  76%|███████▌  | 3790/5000 [2:50:55<48:55,  2.43s/it, loss=0.3885]\u001b[A\n",
            "Training:  76%|███████▌  | 3791/5000 [2:50:57<47:46,  2.37s/it, loss=0.3885]\u001b[A\n",
            "Training:  76%|███████▌  | 3791/5000 [2:50:57<47:46,  2.37s/it, loss=0.3896]\u001b[A\n",
            "Training:  76%|███████▌  | 3792/5000 [2:50:59<47:10,  2.34s/it, loss=0.3896]\u001b[A\n",
            "Training:  76%|███████▌  | 3792/5000 [2:50:59<47:10,  2.34s/it, loss=0.5047]\u001b[A\n",
            "Training:  76%|███████▌  | 3793/5000 [2:51:01<46:37,  2.32s/it, loss=0.5047]\u001b[A\n",
            "Training:  76%|███████▌  | 3793/5000 [2:51:02<46:37,  2.32s/it, loss=0.2424]\u001b[A\n",
            "Training:  76%|███████▌  | 3794/5000 [2:51:04<49:20,  2.46s/it, loss=0.2424]\u001b[A\n",
            "Training:  76%|███████▌  | 3794/5000 [2:51:04<49:20,  2.46s/it, loss=0.3599]\u001b[A\n",
            "Training:  76%|███████▌  | 3795/5000 [2:51:06<48:02,  2.39s/it, loss=0.3599]\u001b[A\n",
            "Training:  76%|███████▌  | 3795/5000 [2:51:07<48:02,  2.39s/it, loss=0.3866]\u001b[A\n",
            "Training:  76%|███████▌  | 3796/5000 [2:51:09<47:17,  2.36s/it, loss=0.3866]\u001b[A\n",
            "Training:  76%|███████▌  | 3796/5000 [2:51:09<47:17,  2.36s/it, loss=0.6060]\u001b[A\n",
            "Training:  76%|███████▌  | 3797/5000 [2:51:11<46:45,  2.33s/it, loss=0.6060]\u001b[A\n",
            "Training:  76%|███████▌  | 3797/5000 [2:51:11<46:45,  2.33s/it, loss=0.4336]\u001b[A\n",
            "Training:  76%|███████▌  | 3798/5000 [2:51:13<46:16,  2.31s/it, loss=0.4336]\u001b[A\n",
            "Training:  76%|███████▌  | 3798/5000 [2:51:13<46:16,  2.31s/it, loss=0.2793]\u001b[A\n",
            "Training:  76%|███████▌  | 3799/5000 [2:51:16<48:46,  2.44s/it, loss=0.2793]\u001b[A\n",
            "Training:  76%|███████▌  | 3799/5000 [2:51:16<48:46,  2.44s/it, loss=0.2964]\u001b[A\n",
            "Training:  76%|███████▌  | 3800/5000 [2:51:18<47:34,  2.38s/it, loss=0.2964]\u001b[A\n",
            "Training:  76%|███████▌  | 3800/5000 [2:51:18<47:34,  2.38s/it, loss=0.4756]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 3800 ---\n",
            "Prompt: 'The '\n",
            "The  fought court aside all Have: them away\n",
            "an do them and., old desire to\n",
            " the; God if were be be be for: yet\n",
            " I,,.\n",
            "You be where my will do hate York Richard like\n",
            ",' is enough instrumentsreat welcome\n",
            "'s:Then if do or them may,,, well wilt serve toine\n",
            " the who at and, trade he at,M-.\n",
            "MARUS\n",
            "aced pounds serious any be:He be he already\n",
            "\n",
            "Prompt: 'In '\n",
            "In ity' am aerer\n",
            " thisench play:'is that not toryForaous\n",
            " tillaken; any, foul,if art or the of\n",
            "able.\n",
            "D h- was firstily thear may nurse theowl: yet the's, it youraveBy'd ver; he one if be you be till,'ll?\n",
            "Gleues aerer\n",
            " thy obscure thatides out murder with husband\n",
            " what is\n",
            "AB do say andle\n",
            "AB thy is but mere\n",
            "Prompt: 'To '\n",
            "To  like. hath kins,o have a\n",
            " all She m been with by:\n",
            " she withkind and earlike,-\n",
            " d bait as on side being,\n",
            " d himself this-u'd with unche heir\n",
            " hours his- bride, at his:,eg, say\n",
            "'s be in a, a, allche injuries!\n",
            "G go-clock and awoman by orRU and seven!\n",
            "G go with onceing!\n",
            "First a near, says\n",
            "atteringv!\n",
            "Prompt: 'A '\n",
            "A  much to will so have fast live die\n",
            " it mark him make wouncils making\n",
            " unness found you.\n",
            "ISELOW\n",
            "LA\n",
            " me,.ark they us and!itor the I to\n",
            " thou's: art'll a of mouth have; not: shall serve:tis, going but duty\n",
            " greet or, hon,.'s I so,o O of mean noble.\n",
            "D thourt fore; would talk of,?yIO\n",
            "U VC short fair will\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  76%|███████▌  | 3801/5000 [2:51:33<2:00:42,  6.04s/it, loss=0.4756]\u001b[A\n",
            "Training:  76%|███████▌  | 3801/5000 [2:51:33<2:00:42,  6.04s/it, loss=0.2149]\u001b[A\n",
            "Training:  76%|███████▌  | 3802/5000 [2:51:35<1:37:56,  4.91s/it, loss=0.2149]\u001b[A\n",
            "Training:  76%|███████▌  | 3802/5000 [2:51:35<1:37:56,  4.91s/it, loss=0.1776]\u001b[A\n",
            "Training:  76%|███████▌  | 3803/5000 [2:51:38<1:23:07,  4.17s/it, loss=0.1776]\u001b[A\n",
            "Training:  76%|███████▌  | 3803/5000 [2:51:38<1:23:07,  4.17s/it, loss=0.3409]\u001b[A\n",
            "Training:  76%|███████▌  | 3804/5000 [2:51:40<1:13:47,  3.70s/it, loss=0.3409]\u001b[A\n",
            "Training:  76%|███████▌  | 3804/5000 [2:51:40<1:13:47,  3.70s/it, loss=0.6046]\u001b[A\n",
            "Training:  76%|███████▌  | 3805/5000 [2:51:42<1:05:09,  3.27s/it, loss=0.6046]\u001b[A\n",
            "Training:  76%|███████▌  | 3805/5000 [2:51:42<1:05:09,  3.27s/it, loss=0.3992]\u001b[A\n",
            "Training:  76%|███████▌  | 3806/5000 [2:51:45<59:09,  2.97s/it, loss=0.3992]  \u001b[A\n",
            "Training:  76%|███████▌  | 3806/5000 [2:51:45<59:09,  2.97s/it, loss=0.2973]\u001b[A\n",
            "Training:  76%|███████▌  | 3807/5000 [2:51:47<54:41,  2.75s/it, loss=0.2973]\u001b[A\n",
            "Training:  76%|███████▌  | 3807/5000 [2:51:47<54:41,  2.75s/it, loss=0.3627]\u001b[A\n",
            "Training:  76%|███████▌  | 3808/5000 [2:51:49<52:25,  2.64s/it, loss=0.3627]\u001b[A\n",
            "Training:  76%|███████▌  | 3808/5000 [2:51:49<52:25,  2.64s/it, loss=0.2073]\u001b[A\n",
            "Training:  76%|███████▌  | 3809/5000 [2:51:52<52:29,  2.64s/it, loss=0.2073]\u001b[A\n",
            "Training:  76%|███████▌  | 3809/5000 [2:51:52<52:29,  2.64s/it, loss=0.3512]\u001b[A\n",
            "Training:  76%|███████▌  | 3810/5000 [2:51:54<50:11,  2.53s/it, loss=0.3512]\u001b[A\n",
            "Training:  76%|███████▌  | 3810/5000 [2:51:54<50:11,  2.53s/it, loss=0.2732]\u001b[A\n",
            "Training:  76%|███████▌  | 3811/5000 [2:51:57<48:33,  2.45s/it, loss=0.2732]\u001b[A\n",
            "Training:  76%|███████▌  | 3811/5000 [2:51:57<48:33,  2.45s/it, loss=0.4618]\u001b[A\n",
            "Training:  76%|███████▌  | 3812/5000 [2:51:59<47:37,  2.41s/it, loss=0.4618]\u001b[A\n",
            "Training:  76%|███████▌  | 3812/5000 [2:51:59<47:37,  2.41s/it, loss=0.3340]\u001b[A\n",
            "Training:  76%|███████▋  | 3813/5000 [2:52:01<47:24,  2.40s/it, loss=0.3340]\u001b[A\n",
            "Training:  76%|███████▋  | 3813/5000 [2:52:01<47:24,  2.40s/it, loss=0.3915]\u001b[A\n",
            "Training:  76%|███████▋  | 3814/5000 [2:52:04<49:06,  2.48s/it, loss=0.3915]\u001b[A\n",
            "Training:  76%|███████▋  | 3814/5000 [2:52:04<49:06,  2.48s/it, loss=0.3541]\u001b[A\n",
            "Training:  76%|███████▋  | 3815/5000 [2:52:06<47:41,  2.42s/it, loss=0.3541]\u001b[A\n",
            "Training:  76%|███████▋  | 3815/5000 [2:52:06<47:41,  2.42s/it, loss=0.3746]\u001b[A\n",
            "Training:  76%|███████▋  | 3816/5000 [2:52:08<47:02,  2.38s/it, loss=0.3746]\u001b[A\n",
            "Training:  76%|███████▋  | 3816/5000 [2:52:08<47:02,  2.38s/it, loss=0.2335]\u001b[A\n",
            "Training:  76%|███████▋  | 3817/5000 [2:52:11<46:13,  2.34s/it, loss=0.2335]\u001b[A\n",
            "Training:  76%|███████▋  | 3817/5000 [2:52:11<46:13,  2.34s/it, loss=0.3770]\u001b[A\n",
            "Training:  76%|███████▋  | 3818/5000 [2:52:13<46:10,  2.34s/it, loss=0.3770]\u001b[A\n",
            "Training:  76%|███████▋  | 3818/5000 [2:52:13<46:10,  2.34s/it, loss=0.4094]\u001b[A\n",
            "Training:  76%|███████▋  | 3819/5000 [2:52:16<48:11,  2.45s/it, loss=0.4094]\u001b[A\n",
            "Training:  76%|███████▋  | 3819/5000 [2:52:16<48:11,  2.45s/it, loss=0.3952]\u001b[A\n",
            "Training:  76%|███████▋  | 3820/5000 [2:52:18<47:00,  2.39s/it, loss=0.3952]\u001b[A\n",
            "Training:  76%|███████▋  | 3820/5000 [2:52:18<47:00,  2.39s/it, loss=0.2785]\u001b[A\n",
            "Training:  76%|███████▋  | 3821/5000 [2:52:20<46:08,  2.35s/it, loss=0.2785]\u001b[A\n",
            "Training:  76%|███████▋  | 3821/5000 [2:52:20<46:08,  2.35s/it, loss=0.2964]\u001b[A\n",
            "Training:  76%|███████▋  | 3822/5000 [2:52:22<45:26,  2.31s/it, loss=0.2964]\u001b[A\n",
            "Training:  76%|███████▋  | 3822/5000 [2:52:23<45:26,  2.31s/it, loss=0.2970]\u001b[A\n",
            "Training:  76%|███████▋  | 3823/5000 [2:52:25<45:16,  2.31s/it, loss=0.2970]\u001b[A\n",
            "Training:  76%|███████▋  | 3823/5000 [2:52:25<45:16,  2.31s/it, loss=0.3752]\u001b[A\n",
            "Training:  76%|███████▋  | 3824/5000 [2:52:27<47:40,  2.43s/it, loss=0.3752]\u001b[A\n",
            "Training:  76%|███████▋  | 3824/5000 [2:52:28<47:40,  2.43s/it, loss=0.3135]\u001b[A\n",
            "Training:  76%|███████▋  | 3825/5000 [2:52:30<46:34,  2.38s/it, loss=0.3135]\u001b[A\n",
            "Training:  76%|███████▋  | 3825/5000 [2:52:30<46:34,  2.38s/it, loss=0.1915]\u001b[A\n",
            "Training:  77%|███████▋  | 3826/5000 [2:52:32<45:57,  2.35s/it, loss=0.1915]\u001b[A\n",
            "Training:  77%|███████▋  | 3826/5000 [2:52:32<45:57,  2.35s/it, loss=0.4107]\u001b[A\n",
            "Training:  77%|███████▋  | 3827/5000 [2:52:34<45:32,  2.33s/it, loss=0.4107]\u001b[A\n",
            "Training:  77%|███████▋  | 3827/5000 [2:52:34<45:32,  2.33s/it, loss=0.2993]\u001b[A\n",
            "Training:  77%|███████▋  | 3828/5000 [2:52:37<45:08,  2.31s/it, loss=0.2993]\u001b[A\n",
            "Training:  77%|███████▋  | 3828/5000 [2:52:37<45:08,  2.31s/it, loss=0.4485]\u001b[A\n",
            "Training:  77%|███████▋  | 3829/5000 [2:52:39<48:06,  2.46s/it, loss=0.4485]\u001b[A\n",
            "Training:  77%|███████▋  | 3829/5000 [2:52:39<48:06,  2.46s/it, loss=0.4537]\u001b[A\n",
            "Training:  77%|███████▋  | 3830/5000 [2:52:42<46:57,  2.41s/it, loss=0.4537]\u001b[A\n",
            "Training:  77%|███████▋  | 3830/5000 [2:52:42<46:57,  2.41s/it, loss=0.4938]\u001b[A\n",
            "Training:  77%|███████▋  | 3831/5000 [2:52:44<46:04,  2.36s/it, loss=0.4938]\u001b[A\n",
            "Training:  77%|███████▋  | 3831/5000 [2:52:44<46:04,  2.36s/it, loss=0.4551]\u001b[A\n",
            "Training:  77%|███████▋  | 3832/5000 [2:52:46<45:31,  2.34s/it, loss=0.4551]\u001b[A\n",
            "Training:  77%|███████▋  | 3832/5000 [2:52:46<45:31,  2.34s/it, loss=0.4512]\u001b[A\n",
            "Training:  77%|███████▋  | 3833/5000 [2:52:48<44:57,  2.31s/it, loss=0.4512]\u001b[A\n",
            "Training:  77%|███████▋  | 3833/5000 [2:52:49<44:57,  2.31s/it, loss=0.2989]\u001b[A\n",
            "Training:  77%|███████▋  | 3834/5000 [2:52:51<47:45,  2.46s/it, loss=0.2989]\u001b[A\n",
            "Training:  77%|███████▋  | 3834/5000 [2:52:51<47:45,  2.46s/it, loss=0.4051]\u001b[A\n",
            "Training:  77%|███████▋  | 3835/5000 [2:52:54<46:29,  2.39s/it, loss=0.4051]\u001b[A\n",
            "Training:  77%|███████▋  | 3835/5000 [2:52:54<46:29,  2.39s/it, loss=0.3362]\u001b[A\n",
            "Training:  77%|███████▋  | 3836/5000 [2:52:56<45:39,  2.35s/it, loss=0.3362]\u001b[A\n",
            "Training:  77%|███████▋  | 3836/5000 [2:52:56<45:39,  2.35s/it, loss=0.3113]\u001b[A\n",
            "Training:  77%|███████▋  | 3837/5000 [2:52:58<45:08,  2.33s/it, loss=0.3113]\u001b[A\n",
            "Training:  77%|███████▋  | 3837/5000 [2:52:58<45:08,  2.33s/it, loss=0.4327]\u001b[A\n",
            "Training:  77%|███████▋  | 3838/5000 [2:53:00<44:38,  2.30s/it, loss=0.4327]\u001b[A\n",
            "Training:  77%|███████▋  | 3838/5000 [2:53:00<44:38,  2.30s/it, loss=0.3381]\u001b[A\n",
            "Training:  77%|███████▋  | 3839/5000 [2:53:03<47:16,  2.44s/it, loss=0.3381]\u001b[A\n",
            "Training:  77%|███████▋  | 3839/5000 [2:53:03<47:16,  2.44s/it, loss=0.2949]\u001b[A\n",
            "Training:  77%|███████▋  | 3840/5000 [2:53:05<45:57,  2.38s/it, loss=0.2949]\u001b[A\n",
            "Training:  77%|███████▋  | 3840/5000 [2:53:05<45:57,  2.38s/it, loss=0.3198]\u001b[A\n",
            "Training:  77%|███████▋  | 3841/5000 [2:53:08<45:26,  2.35s/it, loss=0.3198]\u001b[A\n",
            "Training:  77%|███████▋  | 3841/5000 [2:53:08<45:26,  2.35s/it, loss=0.4550]\u001b[A\n",
            "Training:  77%|███████▋  | 3842/5000 [2:53:10<45:04,  2.34s/it, loss=0.4550]\u001b[A\n",
            "Training:  77%|███████▋  | 3842/5000 [2:53:10<45:04,  2.34s/it, loss=0.4693]\u001b[A\n",
            "Training:  77%|███████▋  | 3843/5000 [2:53:12<44:36,  2.31s/it, loss=0.4693]\u001b[A\n",
            "Training:  77%|███████▋  | 3843/5000 [2:53:12<44:36,  2.31s/it, loss=0.3092]\u001b[A\n",
            "Training:  77%|███████▋  | 3844/5000 [2:53:15<47:17,  2.45s/it, loss=0.3092]\u001b[A\n",
            "Training:  77%|███████▋  | 3844/5000 [2:53:15<47:17,  2.45s/it, loss=0.3550]\u001b[A\n",
            "Training:  77%|███████▋  | 3845/5000 [2:53:17<45:57,  2.39s/it, loss=0.3550]\u001b[A\n",
            "Training:  77%|███████▋  | 3845/5000 [2:53:17<45:57,  2.39s/it, loss=0.3520]\u001b[A\n",
            "Training:  77%|███████▋  | 3846/5000 [2:53:19<45:11,  2.35s/it, loss=0.3520]\u001b[A\n",
            "Training:  77%|███████▋  | 3846/5000 [2:53:19<45:11,  2.35s/it, loss=0.2117]\u001b[A\n",
            "Training:  77%|███████▋  | 3847/5000 [2:53:22<44:33,  2.32s/it, loss=0.2117]\u001b[A\n",
            "Training:  77%|███████▋  | 3847/5000 [2:53:22<44:33,  2.32s/it, loss=0.1788]\u001b[A\n",
            "Training:  77%|███████▋  | 3848/5000 [2:53:24<44:12,  2.30s/it, loss=0.1788]\u001b[A\n",
            "Training:  77%|███████▋  | 3848/5000 [2:53:24<44:12,  2.30s/it, loss=0.2380]\u001b[A\n",
            "Training:  77%|███████▋  | 3849/5000 [2:53:27<46:55,  2.45s/it, loss=0.2380]\u001b[A\n",
            "Training:  77%|███████▋  | 3849/5000 [2:53:27<46:55,  2.45s/it, loss=0.2862]\u001b[A\n",
            "Training:  77%|███████▋  | 3850/5000 [2:53:29<45:52,  2.39s/it, loss=0.2862]\u001b[A\n",
            "Training:  77%|███████▋  | 3850/5000 [2:53:29<45:52,  2.39s/it, loss=0.3339]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 3850 ---\n",
            "Prompt: 'The '\n",
            "The , by,,'re had be'd,SaveThe\n",
            " crowsbt swift, my's; signify all my,Will\n",
            " my with out my, such request lifeFor,\n",
            " best services my with. that, told hath less,\n",
            " to my with out the duke g, youI thy;\n",
            " else made against, myanish j, ';' 'st you\n",
            " ofmal, I at toce well your walk\n",
            " never at to my host thanest itself\n",
            "Th country, my bears\n",
            "Prompt: 'In '\n",
            "In , he home our move thinfort' do out\n",
            " his to my: he avoid given have sc;\n",
            " not them, of been knees have much cry ma toose\n",
            "stush mother't you in, both they en'd days\n",
            " their,,,,, thy canem blood their inTheir\n",
            "NTH in, Volces'd wild, prove\n",
            "an haveard with., this will so you\n",
            " yet I said would down blacktest aily haveou along\n",
            "Astis:\n",
            "Prompt: 'To '\n",
            "To ,,, yet I with, did\n",
            " theald made my brother n; if would\n",
            " littlein thee her\n",
            " me silent thee.\n",
            "COI tillVery:F,, thy,,, I, all will be\n",
            " shall so av.\n",
            "SIN EDARD:Well well have will welcome her.N, toench mer.:You have deserved this done do dream me thouak:Ad, willNow what am better berow thee: came the on h, will\n",
            "Prompt: 'A '\n",
            "A , yet I thy with full take thywn\n",
            " not thee a.' thou's not. half thouest not? thou's notep\n",
            " nature for death thy and thy, b'dch, back thouak it be lady\n",
            " wetAs most maditableel onating thouak, was not. am\n",
            " long I thee my: thee, thou's name am in bottom you, is not\n",
            " inble it. a. was not thou's, thus'll thee that your haveiled'd shalt\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  77%|███████▋  | 3851/5000 [2:53:44<1:56:54,  6.10s/it, loss=0.3339]\u001b[A\n",
            "Training:  77%|███████▋  | 3851/5000 [2:53:44<1:56:54,  6.10s/it, loss=0.2805]\u001b[A\n",
            "Training:  77%|███████▋  | 3852/5000 [2:53:46<1:34:40,  4.95s/it, loss=0.2805]\u001b[A\n",
            "Training:  77%|███████▋  | 3852/5000 [2:53:46<1:34:40,  4.95s/it, loss=0.4352]\u001b[A\n",
            "Training:  77%|███████▋  | 3853/5000 [2:53:48<1:20:12,  4.20s/it, loss=0.4352]\u001b[A\n",
            "Training:  77%|███████▋  | 3853/5000 [2:53:48<1:20:12,  4.20s/it, loss=0.2801]\u001b[A\n",
            "Training:  77%|███████▋  | 3854/5000 [2:53:51<1:10:53,  3.71s/it, loss=0.2801]\u001b[A\n",
            "Training:  77%|███████▋  | 3854/5000 [2:53:51<1:10:53,  3.71s/it, loss=0.4012]\u001b[A\n",
            "Training:  77%|███████▋  | 3855/5000 [2:53:53<1:02:24,  3.27s/it, loss=0.4012]\u001b[A\n",
            "Training:  77%|███████▋  | 3855/5000 [2:53:53<1:02:24,  3.27s/it, loss=0.4749]\u001b[A\n",
            "Training:  77%|███████▋  | 3856/5000 [2:53:56<56:31,  2.96s/it, loss=0.4749]  \u001b[A\n",
            "Training:  77%|███████▋  | 3856/5000 [2:53:56<56:31,  2.96s/it, loss=0.3463]\u001b[A\n",
            "Training:  77%|███████▋  | 3857/5000 [2:53:58<52:28,  2.75s/it, loss=0.3463]\u001b[A\n",
            "Training:  77%|███████▋  | 3857/5000 [2:53:58<52:28,  2.75s/it, loss=0.5395]\u001b[A\n",
            "Training:  77%|███████▋  | 3858/5000 [2:54:00<50:21,  2.65s/it, loss=0.5395]\u001b[A\n",
            "Training:  77%|███████▋  | 3858/5000 [2:54:00<50:21,  2.65s/it, loss=0.2948]\u001b[A\n",
            "Training:  77%|███████▋  | 3859/5000 [2:54:03<50:31,  2.66s/it, loss=0.2948]\u001b[A\n",
            "Training:  77%|███████▋  | 3859/5000 [2:54:03<50:31,  2.66s/it, loss=0.4153]\u001b[A\n",
            "Training:  77%|███████▋  | 3860/5000 [2:54:05<48:04,  2.53s/it, loss=0.4153]\u001b[A\n",
            "Training:  77%|███████▋  | 3860/5000 [2:54:05<48:04,  2.53s/it, loss=0.4005]\u001b[A\n",
            "Training:  77%|███████▋  | 3861/5000 [2:54:07<46:24,  2.44s/it, loss=0.4005]\u001b[A\n",
            "Training:  77%|███████▋  | 3861/5000 [2:54:07<46:24,  2.44s/it, loss=0.4854]\u001b[A\n",
            "Training:  77%|███████▋  | 3862/5000 [2:54:10<45:18,  2.39s/it, loss=0.4854]\u001b[A\n",
            "Training:  77%|███████▋  | 3862/5000 [2:54:10<45:18,  2.39s/it, loss=0.4359]\u001b[A\n",
            "Training:  77%|███████▋  | 3863/5000 [2:54:12<45:34,  2.41s/it, loss=0.4359]\u001b[A\n",
            "Training:  77%|███████▋  | 3863/5000 [2:54:12<45:34,  2.41s/it, loss=0.3037]\u001b[A\n",
            "Training:  77%|███████▋  | 3864/5000 [2:54:15<46:51,  2.48s/it, loss=0.3037]\u001b[A\n",
            "Training:  77%|███████▋  | 3864/5000 [2:54:15<46:51,  2.48s/it, loss=0.3939]\u001b[A\n",
            "Training:  77%|███████▋  | 3865/5000 [2:54:17<45:37,  2.41s/it, loss=0.3939]\u001b[A\n",
            "Training:  77%|███████▋  | 3865/5000 [2:54:17<45:37,  2.41s/it, loss=0.2706]\u001b[A\n",
            "Training:  77%|███████▋  | 3866/5000 [2:54:19<44:36,  2.36s/it, loss=0.2706]\u001b[A\n",
            "Training:  77%|███████▋  | 3866/5000 [2:54:19<44:36,  2.36s/it, loss=0.3713]\u001b[A\n",
            "Training:  77%|███████▋  | 3867/5000 [2:54:21<43:52,  2.32s/it, loss=0.3713]\u001b[A\n",
            "Training:  77%|███████▋  | 3867/5000 [2:54:21<43:52,  2.32s/it, loss=0.4228]\u001b[A\n",
            "Training:  77%|███████▋  | 3868/5000 [2:54:24<44:07,  2.34s/it, loss=0.4228]\u001b[A\n",
            "Training:  77%|███████▋  | 3868/5000 [2:54:24<44:07,  2.34s/it, loss=0.2544]\u001b[A\n",
            "Training:  77%|███████▋  | 3869/5000 [2:54:26<45:56,  2.44s/it, loss=0.2544]\u001b[A\n",
            "Training:  77%|███████▋  | 3869/5000 [2:54:26<45:56,  2.44s/it, loss=0.3687]\u001b[A\n",
            "Training:  77%|███████▋  | 3870/5000 [2:54:29<44:56,  2.39s/it, loss=0.3687]\u001b[A\n",
            "Training:  77%|███████▋  | 3870/5000 [2:54:29<44:56,  2.39s/it, loss=0.3184]\u001b[A\n",
            "Training:  77%|███████▋  | 3871/5000 [2:54:31<44:09,  2.35s/it, loss=0.3184]\u001b[A\n",
            "Training:  77%|███████▋  | 3871/5000 [2:54:31<44:09,  2.35s/it, loss=0.3046]\u001b[A\n",
            "Training:  77%|███████▋  | 3872/5000 [2:54:33<43:38,  2.32s/it, loss=0.3046]\u001b[A\n",
            "Training:  77%|███████▋  | 3872/5000 [2:54:33<43:38,  2.32s/it, loss=0.4119]\u001b[A\n",
            "Training:  77%|███████▋  | 3873/5000 [2:54:36<44:01,  2.34s/it, loss=0.4119]\u001b[A\n",
            "Training:  77%|███████▋  | 3873/5000 [2:54:36<44:01,  2.34s/it, loss=0.3804]\u001b[A\n",
            "Training:  77%|███████▋  | 3874/5000 [2:54:38<45:59,  2.45s/it, loss=0.3804]\u001b[A\n",
            "Training:  77%|███████▋  | 3874/5000 [2:54:38<45:59,  2.45s/it, loss=0.3376]\u001b[A\n",
            "Training:  78%|███████▊  | 3875/5000 [2:54:41<45:07,  2.41s/it, loss=0.3376]\u001b[A\n",
            "Training:  78%|███████▊  | 3875/5000 [2:54:41<45:07,  2.41s/it, loss=0.4379]\u001b[A\n",
            "Training:  78%|███████▊  | 3876/5000 [2:54:43<44:21,  2.37s/it, loss=0.4379]\u001b[A\n",
            "Training:  78%|███████▊  | 3876/5000 [2:54:43<44:21,  2.37s/it, loss=0.3086]\u001b[A\n",
            "Training:  78%|███████▊  | 3877/5000 [2:54:45<43:44,  2.34s/it, loss=0.3086]\u001b[A\n",
            "Training:  78%|███████▊  | 3877/5000 [2:54:45<43:44,  2.34s/it, loss=0.3583]\u001b[A\n",
            "Training:  78%|███████▊  | 3878/5000 [2:54:48<43:45,  2.34s/it, loss=0.3583]\u001b[A\n",
            "Training:  78%|███████▊  | 3878/5000 [2:54:48<43:45,  2.34s/it, loss=0.3510]\u001b[A\n",
            "Training:  78%|███████▊  | 3879/5000 [2:54:50<45:43,  2.45s/it, loss=0.3510]\u001b[A\n",
            "Training:  78%|███████▊  | 3879/5000 [2:54:50<45:43,  2.45s/it, loss=0.4012]\u001b[A\n",
            "Training:  78%|███████▊  | 3880/5000 [2:54:52<44:31,  2.39s/it, loss=0.4012]\u001b[A\n",
            "Training:  78%|███████▊  | 3880/5000 [2:54:52<44:31,  2.39s/it, loss=0.5347]\u001b[A\n",
            "Training:  78%|███████▊  | 3881/5000 [2:54:55<43:58,  2.36s/it, loss=0.5347]\u001b[A\n",
            "Training:  78%|███████▊  | 3881/5000 [2:54:55<43:58,  2.36s/it, loss=0.5823]\u001b[A\n",
            "Training:  78%|███████▊  | 3882/5000 [2:54:57<43:12,  2.32s/it, loss=0.5823]\u001b[A\n",
            "Training:  78%|███████▊  | 3882/5000 [2:54:57<43:12,  2.32s/it, loss=0.4587]\u001b[A\n",
            "Training:  78%|███████▊  | 3883/5000 [2:54:59<42:47,  2.30s/it, loss=0.4587]\u001b[A\n",
            "Training:  78%|███████▊  | 3883/5000 [2:54:59<42:47,  2.30s/it, loss=0.1956]\u001b[A\n",
            "Training:  78%|███████▊  | 3884/5000 [2:55:02<45:24,  2.44s/it, loss=0.1956]\u001b[A\n",
            "Training:  78%|███████▊  | 3884/5000 [2:55:02<45:24,  2.44s/it, loss=0.1974]\u001b[A\n",
            "Training:  78%|███████▊  | 3885/5000 [2:55:04<44:20,  2.39s/it, loss=0.1974]\u001b[A\n",
            "Training:  78%|███████▊  | 3885/5000 [2:55:04<44:20,  2.39s/it, loss=0.5144]\u001b[A\n",
            "Training:  78%|███████▊  | 3886/5000 [2:55:07<43:33,  2.35s/it, loss=0.5144]\u001b[A\n",
            "Training:  78%|███████▊  | 3886/5000 [2:55:07<43:33,  2.35s/it, loss=0.4060]\u001b[A\n",
            "Training:  78%|███████▊  | 3887/5000 [2:55:09<43:03,  2.32s/it, loss=0.4060]\u001b[A\n",
            "Training:  78%|███████▊  | 3887/5000 [2:55:09<43:03,  2.32s/it, loss=0.3135]\u001b[A\n",
            "Training:  78%|███████▊  | 3888/5000 [2:55:11<42:49,  2.31s/it, loss=0.3135]\u001b[A\n",
            "Training:  78%|███████▊  | 3888/5000 [2:55:11<42:49,  2.31s/it, loss=0.2272]\u001b[A\n",
            "Training:  78%|███████▊  | 3889/5000 [2:55:14<45:24,  2.45s/it, loss=0.2272]\u001b[A\n",
            "Training:  78%|███████▊  | 3889/5000 [2:55:14<45:24,  2.45s/it, loss=0.2783]\u001b[A\n",
            "Training:  78%|███████▊  | 3890/5000 [2:55:16<44:14,  2.39s/it, loss=0.2783]\u001b[A\n",
            "Training:  78%|███████▊  | 3890/5000 [2:55:16<44:14,  2.39s/it, loss=0.3509]\u001b[A\n",
            "Training:  78%|███████▊  | 3891/5000 [2:55:18<43:30,  2.35s/it, loss=0.3509]\u001b[A\n",
            "Training:  78%|███████▊  | 3891/5000 [2:55:18<43:30,  2.35s/it, loss=0.3154]\u001b[A\n",
            "Training:  78%|███████▊  | 3892/5000 [2:55:21<42:53,  2.32s/it, loss=0.3154]\u001b[A\n",
            "Training:  78%|███████▊  | 3892/5000 [2:55:21<42:53,  2.32s/it, loss=0.4738]\u001b[A\n",
            "Training:  78%|███████▊  | 3893/5000 [2:55:23<42:26,  2.30s/it, loss=0.4738]\u001b[A\n",
            "Training:  78%|███████▊  | 3893/5000 [2:55:23<42:26,  2.30s/it, loss=0.3480]\u001b[A\n",
            "Training:  78%|███████▊  | 3894/5000 [2:55:26<45:02,  2.44s/it, loss=0.3480]\u001b[A\n",
            "Training:  78%|███████▊  | 3894/5000 [2:55:26<45:02,  2.44s/it, loss=0.3191]\u001b[A\n",
            "Training:  78%|███████▊  | 3895/5000 [2:55:28<44:02,  2.39s/it, loss=0.3191]\u001b[A\n",
            "Training:  78%|███████▊  | 3895/5000 [2:55:28<44:02,  2.39s/it, loss=0.2301]\u001b[A\n",
            "Training:  78%|███████▊  | 3896/5000 [2:55:30<43:13,  2.35s/it, loss=0.2301]\u001b[A\n",
            "Training:  78%|███████▊  | 3896/5000 [2:55:30<43:13,  2.35s/it, loss=0.4117]\u001b[A\n",
            "Training:  78%|███████▊  | 3897/5000 [2:55:32<42:40,  2.32s/it, loss=0.4117]\u001b[A\n",
            "Training:  78%|███████▊  | 3897/5000 [2:55:32<42:40,  2.32s/it, loss=0.2925]\u001b[A\n",
            "Training:  78%|███████▊  | 3898/5000 [2:55:35<42:17,  2.30s/it, loss=0.2925]\u001b[A\n",
            "Training:  78%|███████▊  | 3898/5000 [2:55:35<42:17,  2.30s/it, loss=0.3100]\u001b[A\n",
            "Training:  78%|███████▊  | 3899/5000 [2:55:37<44:52,  2.45s/it, loss=0.3100]\u001b[A\n",
            "Training:  78%|███████▊  | 3899/5000 [2:55:37<44:52,  2.45s/it, loss=0.2404]\u001b[A\n",
            "Training:  78%|███████▊  | 3900/5000 [2:55:40<43:50,  2.39s/it, loss=0.2404]\u001b[A\n",
            "Training:  78%|███████▊  | 3900/5000 [2:55:40<43:50,  2.39s/it, loss=0.4414]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 3900 ---\n",
            "Prompt: 'The '\n",
            "The ife yew thyier.\n",
            "M,, lord ho\n",
            " Bristol!Rome! measure!,!'s!!\n",
            "ack a coming,AD this- rend?ague!,,, meeting thearbed\n",
            " man let see here enc:,,,tis with she!\n",
            " starts be with--- in\n",
            " se, it be: I not my\n",
            ". se speak tedious heart here I dead\n",
            " man at\n",
            ", father and rest all business now\n",
            " names not 'ver\n",
            "Prompt: 'In '\n",
            "In bality lady; Romeods and\n",
            " Naples;And and e thouertt breath\n",
            " woman\n",
            "\n",
            "ESS Tyt, men\n",
            ", wilt\n",
            "re man kind or waiting an Jens;\n",
            " that the rs old clouds the rebel appetiteOf\n",
            "bal of work Ver releaseUL:\n",
            " hum off I theeay this torment ofged all, w thouiesto but me theife thys washt this a grantedhouse us--Is with gentles\n",
            " iny merwas on!\n",
            "Prompt: 'To '\n",
            "To ' the ofThink knock up forthMy,\n",
            " begsh of, sun thy:, mother cast\n",
            "ys issue; that meansking lay th keeps scarlet.\n",
            "QUE ELAB!ike hence shall we the,And\n",
            " would downTw thisable thousand clouds to\n",
            ": best thy withing to\n",
            " Bca us\n",
            "pass wait it.\n",
            "ROO\n",
            "Cle conference dry thy forget finger\n",
            " days up desert from thrift dam smiles damaling with eyes thy\n",
            " j of anger both\n",
            "Prompt: 'A '\n",
            "A ; mad, sigh!!iant!\n",
            "hindc! myes on seal the\n",
            "'s.\n",
            " man mother sue be he\n",
            "ither\n",
            " see\n",
            " old had norOut birth appetite heaven\n",
            "ang,ents thy; wilt thyors\n",
            " this out now sitingsieragen,irl\n",
            " man ladyt within their, wful\n",
            " something byity:,tis again allHs come thee!\n",
            "First I at bad foram\n",
            " to!, world well\n",
            "'s, speed for aar\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  78%|███████▊  | 3901/5000 [2:55:54<1:51:22,  6.08s/it, loss=0.4414]\u001b[A\n",
            "Training:  78%|███████▊  | 3901/5000 [2:55:54<1:51:22,  6.08s/it, loss=0.2947]\u001b[A\n",
            "Training:  78%|███████▊  | 3902/5000 [2:55:57<1:30:21,  4.94s/it, loss=0.2947]\u001b[A\n",
            "Training:  78%|███████▊  | 3902/5000 [2:55:57<1:30:21,  4.94s/it, loss=0.4238]\u001b[A\n",
            "Training:  78%|███████▊  | 3903/5000 [2:55:59<1:16:34,  4.19s/it, loss=0.4238]\u001b[A\n",
            "Training:  78%|███████▊  | 3903/5000 [2:55:59<1:16:34,  4.19s/it, loss=0.4046]\u001b[A\n",
            "Training:  78%|███████▊  | 3904/5000 [2:56:02<1:07:57,  3.72s/it, loss=0.4046]\u001b[A\n",
            "Training:  78%|███████▊  | 3904/5000 [2:56:02<1:07:57,  3.72s/it, loss=0.2221]\u001b[A\n",
            "Training:  78%|███████▊  | 3905/5000 [2:56:04<59:54,  3.28s/it, loss=0.2221]  \u001b[A\n",
            "Training:  78%|███████▊  | 3905/5000 [2:56:04<59:54,  3.28s/it, loss=0.3070]\u001b[A\n",
            "Training:  78%|███████▊  | 3906/5000 [2:56:06<54:26,  2.99s/it, loss=0.3070]\u001b[A\n",
            "Training:  78%|███████▊  | 3906/5000 [2:56:06<54:26,  2.99s/it, loss=0.2697]\u001b[A\n",
            "Training:  78%|███████▊  | 3907/5000 [2:56:09<50:26,  2.77s/it, loss=0.2697]\u001b[A\n",
            "Training:  78%|███████▊  | 3907/5000 [2:56:09<50:26,  2.77s/it, loss=0.2191]\u001b[A\n",
            "Training:  78%|███████▊  | 3908/5000 [2:56:11<48:51,  2.68s/it, loss=0.2191]\u001b[A\n",
            "Training:  78%|███████▊  | 3908/5000 [2:56:11<48:51,  2.68s/it, loss=0.2941]\u001b[A\n",
            "Training:  78%|███████▊  | 3909/5000 [2:56:14<48:24,  2.66s/it, loss=0.2941]\u001b[A\n",
            "Training:  78%|███████▊  | 3909/5000 [2:56:14<48:24,  2.66s/it, loss=0.2872]\u001b[A\n",
            "Training:  78%|███████▊  | 3910/5000 [2:56:16<46:02,  2.53s/it, loss=0.2872]\u001b[A\n",
            "Training:  78%|███████▊  | 3910/5000 [2:56:16<46:02,  2.53s/it, loss=0.3089]\u001b[A\n",
            "Training:  78%|███████▊  | 3911/5000 [2:56:18<44:20,  2.44s/it, loss=0.3089]\u001b[A\n",
            "Training:  78%|███████▊  | 3911/5000 [2:56:18<44:20,  2.44s/it, loss=0.2367]\u001b[A\n",
            "Training:  78%|███████▊  | 3912/5000 [2:56:20<43:20,  2.39s/it, loss=0.2367]\u001b[A\n",
            "Training:  78%|███████▊  | 3912/5000 [2:56:20<43:20,  2.39s/it, loss=0.3752]\u001b[A\n",
            "Training:  78%|███████▊  | 3913/5000 [2:56:23<43:26,  2.40s/it, loss=0.3752]\u001b[A\n",
            "Training:  78%|███████▊  | 3913/5000 [2:56:23<43:26,  2.40s/it, loss=0.3570]\u001b[A\n",
            "Training:  78%|███████▊  | 3914/5000 [2:56:25<44:33,  2.46s/it, loss=0.3570]\u001b[A\n",
            "Training:  78%|███████▊  | 3914/5000 [2:56:25<44:33,  2.46s/it, loss=0.2636]\u001b[A\n",
            "Training:  78%|███████▊  | 3915/5000 [2:56:28<43:28,  2.40s/it, loss=0.2636]\u001b[A\n",
            "Training:  78%|███████▊  | 3915/5000 [2:56:28<43:28,  2.40s/it, loss=0.4414]\u001b[A\n",
            "Training:  78%|███████▊  | 3916/5000 [2:56:30<42:41,  2.36s/it, loss=0.4414]\u001b[A\n",
            "Training:  78%|███████▊  | 3916/5000 [2:56:30<42:41,  2.36s/it, loss=0.3358]\u001b[A\n",
            "Training:  78%|███████▊  | 3917/5000 [2:56:32<42:10,  2.34s/it, loss=0.3358]\u001b[A\n",
            "Training:  78%|███████▊  | 3917/5000 [2:56:32<42:10,  2.34s/it, loss=0.4301]\u001b[A\n",
            "Training:  78%|███████▊  | 3918/5000 [2:56:35<42:41,  2.37s/it, loss=0.4301]\u001b[A\n",
            "Training:  78%|███████▊  | 3918/5000 [2:56:35<42:41,  2.37s/it, loss=0.4868]\u001b[A\n",
            "Training:  78%|███████▊  | 3919/5000 [2:56:37<44:14,  2.46s/it, loss=0.4868]\u001b[A\n",
            "Training:  78%|███████▊  | 3919/5000 [2:56:37<44:14,  2.46s/it, loss=0.2683]\u001b[A\n",
            "Training:  78%|███████▊  | 3920/5000 [2:56:40<43:10,  2.40s/it, loss=0.2683]\u001b[A\n",
            "Training:  78%|███████▊  | 3920/5000 [2:56:40<43:10,  2.40s/it, loss=0.3641]\u001b[A\n",
            "Training:  78%|███████▊  | 3921/5000 [2:56:42<42:25,  2.36s/it, loss=0.3641]\u001b[A\n",
            "Training:  78%|███████▊  | 3921/5000 [2:56:42<42:25,  2.36s/it, loss=0.2367]\u001b[A\n",
            "Training:  78%|███████▊  | 3922/5000 [2:56:44<42:04,  2.34s/it, loss=0.2367]\u001b[A\n",
            "Training:  78%|███████▊  | 3922/5000 [2:56:44<42:04,  2.34s/it, loss=0.3097]\u001b[A\n",
            "Training:  78%|███████▊  | 3923/5000 [2:56:47<42:23,  2.36s/it, loss=0.3097]\u001b[A\n",
            "Training:  78%|███████▊  | 3923/5000 [2:56:47<42:23,  2.36s/it, loss=0.3692]\u001b[A\n",
            "Training:  78%|███████▊  | 3924/5000 [2:56:49<43:45,  2.44s/it, loss=0.3692]\u001b[A\n",
            "Training:  78%|███████▊  | 3924/5000 [2:56:49<43:45,  2.44s/it, loss=0.3775]\u001b[A\n",
            "Training:  78%|███████▊  | 3925/5000 [2:56:51<42:49,  2.39s/it, loss=0.3775]\u001b[A\n",
            "Training:  78%|███████▊  | 3925/5000 [2:56:52<42:49,  2.39s/it, loss=0.4786]\u001b[A\n",
            "Training:  79%|███████▊  | 3926/5000 [2:56:54<41:59,  2.35s/it, loss=0.4786]\u001b[A\n",
            "Training:  79%|███████▊  | 3926/5000 [2:56:54<41:59,  2.35s/it, loss=0.3423]\u001b[A\n",
            "Training:  79%|███████▊  | 3927/5000 [2:56:56<41:22,  2.31s/it, loss=0.3423]\u001b[A\n",
            "Training:  79%|███████▊  | 3927/5000 [2:56:56<41:22,  2.31s/it, loss=0.3360]\u001b[A\n",
            "Training:  79%|███████▊  | 3928/5000 [2:56:58<41:44,  2.34s/it, loss=0.3360]\u001b[A\n",
            "Training:  79%|███████▊  | 3928/5000 [2:56:58<41:44,  2.34s/it, loss=0.3349]\u001b[A\n",
            "Training:  79%|███████▊  | 3929/5000 [2:57:01<43:31,  2.44s/it, loss=0.3349]\u001b[A\n",
            "Training:  79%|███████▊  | 3929/5000 [2:57:01<43:31,  2.44s/it, loss=0.3961]\u001b[A\n",
            "Training:  79%|███████▊  | 3930/5000 [2:57:03<42:27,  2.38s/it, loss=0.3961]\u001b[A\n",
            "Training:  79%|███████▊  | 3930/5000 [2:57:03<42:27,  2.38s/it, loss=0.3930]\u001b[A\n",
            "Training:  79%|███████▊  | 3931/5000 [2:57:06<41:38,  2.34s/it, loss=0.3930]\u001b[A\n",
            "Training:  79%|███████▊  | 3931/5000 [2:57:06<41:38,  2.34s/it, loss=0.4085]\u001b[A\n",
            "Training:  79%|███████▊  | 3932/5000 [2:57:08<41:05,  2.31s/it, loss=0.4085]\u001b[A\n",
            "Training:  79%|███████▊  | 3932/5000 [2:57:08<41:05,  2.31s/it, loss=0.4634]\u001b[A\n",
            "Training:  79%|███████▊  | 3933/5000 [2:57:10<41:10,  2.32s/it, loss=0.4634]\u001b[A\n",
            "Training:  79%|███████▊  | 3933/5000 [2:57:10<41:10,  2.32s/it, loss=0.4482]\u001b[A\n",
            "Training:  79%|███████▊  | 3934/5000 [2:57:13<43:27,  2.45s/it, loss=0.4482]\u001b[A\n",
            "Training:  79%|███████▊  | 3934/5000 [2:57:13<43:27,  2.45s/it, loss=0.5303]\u001b[A\n",
            "Training:  79%|███████▊  | 3935/5000 [2:57:15<42:25,  2.39s/it, loss=0.5303]\u001b[A\n",
            "Training:  79%|███████▊  | 3935/5000 [2:57:15<42:25,  2.39s/it, loss=0.3456]\u001b[A\n",
            "Training:  79%|███████▊  | 3936/5000 [2:57:17<41:34,  2.34s/it, loss=0.3456]\u001b[A\n",
            "Training:  79%|███████▊  | 3936/5000 [2:57:17<41:34,  2.34s/it, loss=0.3251]\u001b[A\n",
            "Training:  79%|███████▊  | 3937/5000 [2:57:20<41:06,  2.32s/it, loss=0.3251]\u001b[A\n",
            "Training:  79%|███████▊  | 3937/5000 [2:57:20<41:06,  2.32s/it, loss=0.3461]\u001b[A\n",
            "Training:  79%|███████▉  | 3938/5000 [2:57:22<40:58,  2.31s/it, loss=0.3461]\u001b[A\n",
            "Training:  79%|███████▉  | 3938/5000 [2:57:22<40:58,  2.31s/it, loss=0.4127]\u001b[A\n",
            "Training:  79%|███████▉  | 3939/5000 [2:57:25<43:27,  2.46s/it, loss=0.4127]\u001b[A\n",
            "Training:  79%|███████▉  | 3939/5000 [2:57:25<43:27,  2.46s/it, loss=0.1956]\u001b[A\n",
            "Training:  79%|███████▉  | 3940/5000 [2:57:27<42:17,  2.39s/it, loss=0.1956]\u001b[A\n",
            "Training:  79%|███████▉  | 3940/5000 [2:57:27<42:17,  2.39s/it, loss=0.4179]\u001b[A\n",
            "Training:  79%|███████▉  | 3941/5000 [2:57:29<41:27,  2.35s/it, loss=0.4179]\u001b[A\n",
            "Training:  79%|███████▉  | 3941/5000 [2:57:29<41:27,  2.35s/it, loss=0.3029]\u001b[A\n",
            "Training:  79%|███████▉  | 3942/5000 [2:57:31<40:53,  2.32s/it, loss=0.3029]\u001b[A\n",
            "Training:  79%|███████▉  | 3942/5000 [2:57:31<40:53,  2.32s/it, loss=0.3022]\u001b[A\n",
            "Training:  79%|███████▉  | 3943/5000 [2:57:34<40:38,  2.31s/it, loss=0.3022]\u001b[A\n",
            "Training:  79%|███████▉  | 3943/5000 [2:57:34<40:38,  2.31s/it, loss=0.2966]\u001b[A\n",
            "Training:  79%|███████▉  | 3944/5000 [2:57:36<43:06,  2.45s/it, loss=0.2966]\u001b[A\n",
            "Training:  79%|███████▉  | 3944/5000 [2:57:37<43:06,  2.45s/it, loss=0.3436]\u001b[A\n",
            "Training:  79%|███████▉  | 3945/5000 [2:57:39<42:12,  2.40s/it, loss=0.3436]\u001b[A\n",
            "Training:  79%|███████▉  | 3945/5000 [2:57:39<42:12,  2.40s/it, loss=0.2930]\u001b[A\n",
            "Training:  79%|███████▉  | 3946/5000 [2:57:41<41:28,  2.36s/it, loss=0.2930]\u001b[A\n",
            "Training:  79%|███████▉  | 3946/5000 [2:57:41<41:28,  2.36s/it, loss=0.2774]\u001b[A\n",
            "Training:  79%|███████▉  | 3947/5000 [2:57:43<41:25,  2.36s/it, loss=0.2774]\u001b[A\n",
            "Training:  79%|███████▉  | 3947/5000 [2:57:43<41:25,  2.36s/it, loss=0.3547]\u001b[A\n",
            "Training:  79%|███████▉  | 3948/5000 [2:57:46<40:54,  2.33s/it, loss=0.3547]\u001b[A\n",
            "Training:  79%|███████▉  | 3948/5000 [2:57:46<40:54,  2.33s/it, loss=0.4350]\u001b[A\n",
            "Training:  79%|███████▉  | 3949/5000 [2:57:48<43:05,  2.46s/it, loss=0.4350]\u001b[A\n",
            "Training:  79%|███████▉  | 3949/5000 [2:57:48<43:05,  2.46s/it, loss=0.1605]\u001b[A\n",
            "Training:  79%|███████▉  | 3950/5000 [2:57:51<42:05,  2.41s/it, loss=0.1605]\u001b[A\n",
            "Training:  79%|███████▉  | 3950/5000 [2:57:51<42:05,  2.41s/it, loss=0.2769]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 3950 ---\n",
            "Prompt: 'The '\n",
            "The  is' to, then\n",
            " toys my;tis request shall\n",
            " this bringado worth happy, make\n",
            " I\n",
            "er require accusation from secret,\n",
            "oe give leave:So hath leave me good you cut\n",
            " crownent head The in, beinglike of\n",
            "ARI: ill,No\n",
            "That must and give leave.\n",
            "FLIZ:I it\n",
            " very; have both me the butof' kiss; hear be, that take as may\n",
            " thousand more: must, is j- it be\n",
            "Prompt: 'In '\n",
            "In  here here here here slip France\n",
            " your--vit nor, you leave\n",
            " this prove,\n",
            " youwill you theon P, if beited us,\n",
            " F it a, you not, you notHe her,: hes subjects them their if married if do: if thing to I,,' that might I not you yet have,You have honour wife thoughtsolding for than, give leave hear wife with themws\n",
            " those and\n",
            "ong you\n",
            " not Mark in love name\n",
            "\n",
            "Prompt: 'To '\n",
            "To alsity use the\n",
            "'s comes to found and it needs you\n",
            " him only.\n",
            "She give leave women good\n",
            ", such ism, he show nob to theay\n",
            " through time\n",
            ".\n",
            "Cn, Richardman first: the fit fall a aer\n",
            "Sheeps home the of.\n",
            "FLIZ: all that my loud!'sge part\n",
            " beatn; I use head they att you lords cause pretty, warm\n",
            " Thursday business something hath his brave gentleman I that\n",
            "\n",
            "Prompt: 'A '\n",
            "A  is will please p to them:\n",
            ", a where wills be, must the of.\n",
            " call,; art gone\n",
            ", see will\n",
            " dogs though be within they. do\n",
            "forts,, as say with he this,, Claud,\n",
            " to, looked bab, shall not more anger: beingely, saw my: any thousand\n",
            " have yet good had gone as of as knowt, which no, that inor\n",
            " falling\n",
            "low with as are,, he to, of name\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  79%|███████▉  | 3951/5000 [2:58:05<1:46:05,  6.07s/it, loss=0.2769]\u001b[A\n",
            "Training:  79%|███████▉  | 3951/5000 [2:58:05<1:46:05,  6.07s/it, loss=0.3921]\u001b[A\n",
            "Training:  79%|███████▉  | 3952/5000 [2:58:08<1:25:57,  4.92s/it, loss=0.3921]\u001b[A\n",
            "Training:  79%|███████▉  | 3952/5000 [2:58:08<1:25:57,  4.92s/it, loss=0.3445]\u001b[A\n",
            "Training:  79%|███████▉  | 3953/5000 [2:58:10<1:12:50,  4.17s/it, loss=0.3445]\u001b[A\n",
            "Training:  79%|███████▉  | 3953/5000 [2:58:10<1:12:50,  4.17s/it, loss=0.4123]\u001b[A\n",
            "Training:  79%|███████▉  | 3954/5000 [2:58:13<1:04:27,  3.70s/it, loss=0.4123]\u001b[A\n",
            "Training:  79%|███████▉  | 3954/5000 [2:58:13<1:04:27,  3.70s/it, loss=0.4033]\u001b[A\n",
            "Training:  79%|███████▉  | 3955/5000 [2:58:15<56:59,  3.27s/it, loss=0.4033]  \u001b[A\n",
            "Training:  79%|███████▉  | 3955/5000 [2:58:15<56:59,  3.27s/it, loss=0.3347]\u001b[A\n",
            "Training:  79%|███████▉  | 3956/5000 [2:58:17<51:34,  2.96s/it, loss=0.3347]\u001b[A\n",
            "Training:  79%|███████▉  | 3956/5000 [2:58:17<51:34,  2.96s/it, loss=0.3879]\u001b[A\n",
            "Training:  79%|███████▉  | 3957/5000 [2:58:19<47:46,  2.75s/it, loss=0.3879]\u001b[A\n",
            "Training:  79%|███████▉  | 3957/5000 [2:58:19<47:46,  2.75s/it, loss=0.2861]\u001b[A\n",
            "Training:  79%|███████▉  | 3958/5000 [2:58:22<45:58,  2.65s/it, loss=0.2861]\u001b[A\n",
            "Training:  79%|███████▉  | 3958/5000 [2:58:22<45:58,  2.65s/it, loss=0.3604]\u001b[A\n",
            "Training:  79%|███████▉  | 3959/5000 [2:58:24<45:41,  2.63s/it, loss=0.3604]\u001b[A\n",
            "Training:  79%|███████▉  | 3959/5000 [2:58:24<45:41,  2.63s/it, loss=0.5326]\u001b[A\n",
            "Training:  79%|███████▉  | 3960/5000 [2:58:27<43:39,  2.52s/it, loss=0.5326]\u001b[A\n",
            "Training:  79%|███████▉  | 3960/5000 [2:58:27<43:39,  2.52s/it, loss=0.2717]\u001b[A\n",
            "Training:  79%|███████▉  | 3961/5000 [2:58:29<42:19,  2.44s/it, loss=0.2717]\u001b[A\n",
            "Training:  79%|███████▉  | 3961/5000 [2:58:29<42:19,  2.44s/it, loss=0.5725]\u001b[A\n",
            "Training:  79%|███████▉  | 3962/5000 [2:58:31<41:14,  2.38s/it, loss=0.5725]\u001b[A\n",
            "Training:  79%|███████▉  | 3962/5000 [2:58:31<41:14,  2.38s/it, loss=0.3847]\u001b[A\n",
            "Training:  79%|███████▉  | 3963/5000 [2:58:33<41:03,  2.38s/it, loss=0.3847]\u001b[A\n",
            "Training:  79%|███████▉  | 3963/5000 [2:58:34<41:03,  2.38s/it, loss=0.2623]\u001b[A\n",
            "Training:  79%|███████▉  | 3964/5000 [2:58:36<42:45,  2.48s/it, loss=0.2623]\u001b[A\n",
            "Training:  79%|███████▉  | 3964/5000 [2:58:36<42:45,  2.48s/it, loss=0.4067]\u001b[A\n",
            "Training:  79%|███████▉  | 3965/5000 [2:58:38<41:31,  2.41s/it, loss=0.4067]\u001b[A\n",
            "Training:  79%|███████▉  | 3965/5000 [2:58:38<41:31,  2.41s/it, loss=0.2947]\u001b[A\n",
            "Training:  79%|███████▉  | 3966/5000 [2:58:41<40:46,  2.37s/it, loss=0.2947]\u001b[A\n",
            "Training:  79%|███████▉  | 3966/5000 [2:58:41<40:46,  2.37s/it, loss=0.4410]\u001b[A\n",
            "Training:  79%|███████▉  | 3967/5000 [2:58:43<40:24,  2.35s/it, loss=0.4410]\u001b[A\n",
            "Training:  79%|███████▉  | 3967/5000 [2:58:43<40:24,  2.35s/it, loss=0.3727]\u001b[A\n",
            "Training:  79%|███████▉  | 3968/5000 [2:58:45<40:10,  2.34s/it, loss=0.3727]\u001b[A\n",
            "Training:  79%|███████▉  | 3968/5000 [2:58:45<40:10,  2.34s/it, loss=0.3003]\u001b[A\n",
            "Training:  79%|███████▉  | 3969/5000 [2:58:48<42:12,  2.46s/it, loss=0.3003]\u001b[A\n",
            "Training:  79%|███████▉  | 3969/5000 [2:58:48<42:12,  2.46s/it, loss=0.2600]\u001b[A\n",
            "Training:  79%|███████▉  | 3970/5000 [2:58:50<41:03,  2.39s/it, loss=0.2600]\u001b[A\n",
            "Training:  79%|███████▉  | 3970/5000 [2:58:50<41:03,  2.39s/it, loss=0.3894]\u001b[A\n",
            "Training:  79%|███████▉  | 3971/5000 [2:58:53<40:15,  2.35s/it, loss=0.3894]\u001b[A\n",
            "Training:  79%|███████▉  | 3971/5000 [2:58:53<40:15,  2.35s/it, loss=0.1633]\u001b[A\n",
            "Training:  79%|███████▉  | 3972/5000 [2:58:55<39:45,  2.32s/it, loss=0.1633]\u001b[A\n",
            "Training:  79%|███████▉  | 3972/5000 [2:58:55<39:45,  2.32s/it, loss=0.3993]\u001b[A\n",
            "Training:  79%|███████▉  | 3973/5000 [2:58:57<39:26,  2.30s/it, loss=0.3993]\u001b[A\n",
            "Training:  79%|███████▉  | 3973/5000 [2:58:57<39:26,  2.30s/it, loss=0.5905]\u001b[A\n",
            "Training:  79%|███████▉  | 3974/5000 [2:59:00<41:45,  2.44s/it, loss=0.5905]\u001b[A\n",
            "Training:  79%|███████▉  | 3974/5000 [2:59:00<41:45,  2.44s/it, loss=0.2260]\u001b[A\n",
            "Training:  80%|███████▉  | 3975/5000 [2:59:02<40:48,  2.39s/it, loss=0.2260]\u001b[A\n",
            "Training:  80%|███████▉  | 3975/5000 [2:59:02<40:48,  2.39s/it, loss=0.4382]\u001b[A\n",
            "Training:  80%|███████▉  | 3976/5000 [2:59:04<40:02,  2.35s/it, loss=0.4382]\u001b[A\n",
            "Training:  80%|███████▉  | 3976/5000 [2:59:04<40:02,  2.35s/it, loss=0.3674]\u001b[A\n",
            "Training:  80%|███████▉  | 3977/5000 [2:59:07<39:27,  2.31s/it, loss=0.3674]\u001b[A\n",
            "Training:  80%|███████▉  | 3977/5000 [2:59:07<39:27,  2.31s/it, loss=0.3285]\u001b[A\n",
            "Training:  80%|███████▉  | 3978/5000 [2:59:09<39:11,  2.30s/it, loss=0.3285]\u001b[A\n",
            "Training:  80%|███████▉  | 3978/5000 [2:59:09<39:11,  2.30s/it, loss=0.3694]\u001b[A\n",
            "Training:  80%|███████▉  | 3979/5000 [2:59:12<41:34,  2.44s/it, loss=0.3694]\u001b[A\n",
            "Training:  80%|███████▉  | 3979/5000 [2:59:12<41:34,  2.44s/it, loss=0.4180]\u001b[A\n",
            "Training:  80%|███████▉  | 3980/5000 [2:59:14<40:42,  2.39s/it, loss=0.4180]\u001b[A\n",
            "Training:  80%|███████▉  | 3980/5000 [2:59:14<40:42,  2.39s/it, loss=0.4451]\u001b[A\n",
            "Training:  80%|███████▉  | 3981/5000 [2:59:16<39:49,  2.35s/it, loss=0.4451]\u001b[A\n",
            "Training:  80%|███████▉  | 3981/5000 [2:59:16<39:49,  2.35s/it, loss=0.4159]\u001b[A\n",
            "Training:  80%|███████▉  | 3982/5000 [2:59:18<39:20,  2.32s/it, loss=0.4159]\u001b[A\n",
            "Training:  80%|███████▉  | 3982/5000 [2:59:18<39:20,  2.32s/it, loss=0.3804]\u001b[A\n",
            "Training:  80%|███████▉  | 3983/5000 [2:59:21<39:01,  2.30s/it, loss=0.3804]\u001b[A\n",
            "Training:  80%|███████▉  | 3983/5000 [2:59:21<39:01,  2.30s/it, loss=0.3778]\u001b[A\n",
            "Training:  80%|███████▉  | 3984/5000 [2:59:23<41:19,  2.44s/it, loss=0.3778]\u001b[A\n",
            "Training:  80%|███████▉  | 3984/5000 [2:59:23<41:19,  2.44s/it, loss=0.3012]\u001b[A\n",
            "Training:  80%|███████▉  | 3985/5000 [2:59:26<40:10,  2.38s/it, loss=0.3012]\u001b[A\n",
            "Training:  80%|███████▉  | 3985/5000 [2:59:26<40:10,  2.38s/it, loss=0.3430]\u001b[A\n",
            "Training:  80%|███████▉  | 3986/5000 [2:59:28<39:29,  2.34s/it, loss=0.3430]\u001b[A\n",
            "Training:  80%|███████▉  | 3986/5000 [2:59:28<39:29,  2.34s/it, loss=0.2448]\u001b[A\n",
            "Training:  80%|███████▉  | 3987/5000 [2:59:30<39:06,  2.32s/it, loss=0.2448]\u001b[A\n",
            "Training:  80%|███████▉  | 3987/5000 [2:59:30<39:06,  2.32s/it, loss=0.2759]\u001b[A\n",
            "Training:  80%|███████▉  | 3988/5000 [2:59:32<38:48,  2.30s/it, loss=0.2759]\u001b[A\n",
            "Training:  80%|███████▉  | 3988/5000 [2:59:32<38:48,  2.30s/it, loss=0.2543]\u001b[A\n",
            "Training:  80%|███████▉  | 3989/5000 [2:59:35<41:13,  2.45s/it, loss=0.2543]\u001b[A\n",
            "Training:  80%|███████▉  | 3989/5000 [2:59:35<41:13,  2.45s/it, loss=0.3243]\u001b[A\n",
            "Training:  80%|███████▉  | 3990/5000 [2:59:37<40:14,  2.39s/it, loss=0.3243]\u001b[A\n",
            "Training:  80%|███████▉  | 3990/5000 [2:59:38<40:14,  2.39s/it, loss=0.3572]\u001b[A\n",
            "Training:  80%|███████▉  | 3991/5000 [2:59:40<39:34,  2.35s/it, loss=0.3572]\u001b[A\n",
            "Training:  80%|███████▉  | 3991/5000 [2:59:40<39:34,  2.35s/it, loss=0.2698]\u001b[A\n",
            "Training:  80%|███████▉  | 3992/5000 [2:59:42<39:02,  2.32s/it, loss=0.2698]\u001b[A\n",
            "Training:  80%|███████▉  | 3992/5000 [2:59:42<39:02,  2.32s/it, loss=0.5417]\u001b[A\n",
            "Training:  80%|███████▉  | 3993/5000 [2:59:44<38:54,  2.32s/it, loss=0.5417]\u001b[A\n",
            "Training:  80%|███████▉  | 3993/5000 [2:59:44<38:54,  2.32s/it, loss=0.3720]\u001b[A\n",
            "Training:  80%|███████▉  | 3994/5000 [2:59:47<41:17,  2.46s/it, loss=0.3720]\u001b[A\n",
            "Training:  80%|███████▉  | 3994/5000 [2:59:47<41:17,  2.46s/it, loss=0.4902]\u001b[A\n",
            "Training:  80%|███████▉  | 3995/5000 [2:59:49<40:11,  2.40s/it, loss=0.4902]\u001b[A\n",
            "Training:  80%|███████▉  | 3995/5000 [2:59:49<40:11,  2.40s/it, loss=0.3284]\u001b[A\n",
            "Training:  80%|███████▉  | 3996/5000 [2:59:52<39:21,  2.35s/it, loss=0.3284]\u001b[A\n",
            "Training:  80%|███████▉  | 3996/5000 [2:59:52<39:21,  2.35s/it, loss=0.4917]\u001b[A\n",
            "Training:  80%|███████▉  | 3997/5000 [2:59:54<38:42,  2.32s/it, loss=0.4917]\u001b[A\n",
            "Training:  80%|███████▉  | 3997/5000 [2:59:54<38:42,  2.32s/it, loss=0.4787]\u001b[A\n",
            "Training:  80%|███████▉  | 3998/5000 [2:59:56<38:22,  2.30s/it, loss=0.4787]\u001b[A\n",
            "Training:  80%|███████▉  | 3998/5000 [2:59:56<38:22,  2.30s/it, loss=0.4985]\u001b[A\n",
            "Training:  80%|███████▉  | 3999/5000 [2:59:59<40:48,  2.45s/it, loss=0.4985]\u001b[A\n",
            "Training:  80%|███████▉  | 3999/5000 [2:59:59<40:48,  2.45s/it, loss=0.2908]\u001b[A\n",
            "Training:  80%|████████  | 4000/5000 [3:00:01<39:43,  2.38s/it, loss=0.2908]\u001b[A\n",
            "Training:  80%|████████  | 4000/5000 [3:00:01<39:43,  2.38s/it, loss=0.3869]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 4000 ---\n",
            "Prompt: 'The '\n",
            "The  is't youither play The: thy, have him all\n",
            " patence with my, both deliver draw,She ' justOne yourson\n",
            " manign less:,, will go speak duty do good's.\n",
            "First know me Kate I ready company there ready; haveinched the cause my: will\n",
            "ining; the here stands known no k and shall yours me\n",
            " I loyal;\n",
            " I speak made as as are better, opinion,-Rich,an grave your.\n",
            "Second you sir\n",
            "Prompt: 'In '\n",
            "In per is thy. lungs sureets to;And\n",
            "ysCit: truth shall's.\n",
            "GZO\n",
            "ou of pity come the- end then\n",
            " essentially at the.\n",
            "Se to very there O heartpt theest I\n",
            " itWith to it the of Here and wereat\n",
            " these of deserts th own lectures'\n",
            " for son C chamber\n",
            " would never me more would lay theest do; toooMy thouiest\n",
            "G I done of?\n",
            "Gle: thouiest a\n",
            "Prompt: 'To '\n",
            "To  to eyes what I, my?\n",
            "GZO\n",
            "uff and,, aside what man; grief- freedom\n",
            "ath against se,,, likeack as as to, know\n",
            "yian,ar man;els the andreat all\n",
            "ath again mad,; straight loving, bs go\n",
            "y known to the of frost man I, like itself\n",
            " cannotI name the and here there one Mar: was you the\n",
            " in love have'd withsage\n",
            " cannot it the here\n",
            "Prompt: 'A '\n",
            "A , toy a, seems nothing sworn love\n",
            "rop of.\n",
            "ark comesreat this a:'was me Margaret\n",
            " see, all hate fore ofiners, I thy,It not my Stand: partly\n",
            " these I never for place the now\n",
            "S, my,cius dishon to.\n",
            "VUMUMUMUM it she married\n",
            " friends they us the. offMore a for know to an Pray, else that\n",
            " home pine the shape\n",
            " I report her bearing into. maid me\n",
            " would\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "✓ Checkpoint saved: checkpoints/checkpoint_step_4000.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  80%|████████  | 4001/5000 [3:00:28<2:42:11,  9.74s/it, loss=0.3869]\u001b[A\n",
            "Training:  80%|████████  | 4001/5000 [3:00:28<2:42:11,  9.74s/it, loss=0.3031]\u001b[A\n",
            "Training:  80%|████████  | 4002/5000 [3:00:30<2:04:42,  7.50s/it, loss=0.3031]\u001b[A\n",
            "Training:  80%|████████  | 4002/5000 [3:00:30<2:04:42,  7.50s/it, loss=0.4368]\u001b[A\n",
            "Training:  80%|████████  | 4003/5000 [3:00:33<1:39:30,  5.99s/it, loss=0.4368]\u001b[A\n",
            "Training:  80%|████████  | 4003/5000 [3:00:33<1:39:30,  5.99s/it, loss=0.2500]\u001b[A\n",
            "Training:  80%|████████  | 4004/5000 [3:00:35<1:22:29,  4.97s/it, loss=0.2500]\u001b[A\n",
            "Training:  80%|████████  | 4004/5000 [3:00:35<1:22:29,  4.97s/it, loss=0.3560]\u001b[A\n",
            "Training:  80%|████████  | 4005/5000 [3:00:38<1:08:53,  4.15s/it, loss=0.3560]\u001b[A\n",
            "Training:  80%|████████  | 4005/5000 [3:00:38<1:08:53,  4.15s/it, loss=0.2734]\u001b[A\n",
            "Training:  80%|████████  | 4006/5000 [3:00:40<59:25,  3.59s/it, loss=0.2734]  \u001b[A\n",
            "Training:  80%|████████  | 4006/5000 [3:00:40<59:25,  3.59s/it, loss=0.2955]\u001b[A\n",
            "Training:  80%|████████  | 4007/5000 [3:00:42<52:46,  3.19s/it, loss=0.2955]\u001b[A\n",
            "Training:  80%|████████  | 4007/5000 [3:00:42<52:46,  3.19s/it, loss=0.3473]\u001b[A\n",
            "Training:  80%|████████  | 4008/5000 [3:00:45<49:01,  2.97s/it, loss=0.3473]\u001b[A\n",
            "Training:  80%|████████  | 4008/5000 [3:00:45<49:01,  2.97s/it, loss=0.3574]\u001b[A\n",
            "Training:  80%|████████  | 4009/5000 [3:00:47<47:24,  2.87s/it, loss=0.3574]\u001b[A\n",
            "Training:  80%|████████  | 4009/5000 [3:00:47<47:24,  2.87s/it, loss=0.1544]\u001b[A\n",
            "Training:  80%|████████  | 4010/5000 [3:00:50<44:30,  2.70s/it, loss=0.1544]\u001b[A\n",
            "Training:  80%|████████  | 4010/5000 [3:00:50<44:30,  2.70s/it, loss=0.4223]\u001b[A\n",
            "Training:  80%|████████  | 4011/5000 [3:00:52<42:14,  2.56s/it, loss=0.4223]\u001b[A\n",
            "Training:  80%|████████  | 4011/5000 [3:00:52<42:14,  2.56s/it, loss=0.4504]\u001b[A\n",
            "Training:  80%|████████  | 4012/5000 [3:00:54<40:41,  2.47s/it, loss=0.4504]\u001b[A\n",
            "Training:  80%|████████  | 4012/5000 [3:00:54<40:41,  2.47s/it, loss=0.4326]\u001b[A\n",
            "Training:  80%|████████  | 4013/5000 [3:00:56<40:28,  2.46s/it, loss=0.4326]\u001b[A\n",
            "Training:  80%|████████  | 4013/5000 [3:00:56<40:28,  2.46s/it, loss=0.3518]\u001b[A\n",
            "Training:  80%|████████  | 4014/5000 [3:00:59<41:05,  2.50s/it, loss=0.3518]\u001b[A\n",
            "Training:  80%|████████  | 4014/5000 [3:00:59<41:05,  2.50s/it, loss=0.4146]\u001b[A\n",
            "Training:  80%|████████  | 4015/5000 [3:01:01<39:52,  2.43s/it, loss=0.4146]\u001b[A\n",
            "Training:  80%|████████  | 4015/5000 [3:01:01<39:52,  2.43s/it, loss=0.2810]\u001b[A\n",
            "Training:  80%|████████  | 4016/5000 [3:01:04<38:55,  2.37s/it, loss=0.2810]\u001b[A\n",
            "Training:  80%|████████  | 4016/5000 [3:01:04<38:55,  2.37s/it, loss=0.2890]\u001b[A\n",
            "Training:  80%|████████  | 4017/5000 [3:01:06<38:15,  2.33s/it, loss=0.2890]\u001b[A\n",
            "Training:  80%|████████  | 4017/5000 [3:01:06<38:15,  2.33s/it, loss=0.2863]\u001b[A\n",
            "Training:  80%|████████  | 4018/5000 [3:01:08<38:20,  2.34s/it, loss=0.2863]\u001b[A\n",
            "Training:  80%|████████  | 4018/5000 [3:01:08<38:20,  2.34s/it, loss=0.3373]\u001b[A\n",
            "Training:  80%|████████  | 4019/5000 [3:01:11<39:58,  2.44s/it, loss=0.3373]\u001b[A\n",
            "Training:  80%|████████  | 4019/5000 [3:01:11<39:58,  2.44s/it, loss=0.4060]\u001b[A\n",
            "Training:  80%|████████  | 4020/5000 [3:01:13<38:59,  2.39s/it, loss=0.4060]\u001b[A\n",
            "Training:  80%|████████  | 4020/5000 [3:01:13<38:59,  2.39s/it, loss=0.5078]\u001b[A\n",
            "Training:  80%|████████  | 4021/5000 [3:01:15<38:19,  2.35s/it, loss=0.5078]\u001b[A\n",
            "Training:  80%|████████  | 4021/5000 [3:01:15<38:19,  2.35s/it, loss=0.5423]\u001b[A\n",
            "Training:  80%|████████  | 4022/5000 [3:01:18<38:11,  2.34s/it, loss=0.5423]\u001b[A\n",
            "Training:  80%|████████  | 4022/5000 [3:01:18<38:11,  2.34s/it, loss=0.2468]\u001b[A\n",
            "Training:  80%|████████  | 4023/5000 [3:01:20<38:19,  2.35s/it, loss=0.2468]\u001b[A\n",
            "Training:  80%|████████  | 4023/5000 [3:01:20<38:19,  2.35s/it, loss=0.4257]\u001b[A\n",
            "Training:  80%|████████  | 4024/5000 [3:01:23<39:58,  2.46s/it, loss=0.4257]\u001b[A\n",
            "Training:  80%|████████  | 4024/5000 [3:01:23<39:58,  2.46s/it, loss=0.4314]\u001b[A\n",
            "Training:  80%|████████  | 4025/5000 [3:01:25<39:15,  2.42s/it, loss=0.4314]\u001b[A\n",
            "Training:  80%|████████  | 4025/5000 [3:01:25<39:15,  2.42s/it, loss=0.4271]\u001b[A\n",
            "Training:  81%|████████  | 4026/5000 [3:01:27<39:01,  2.40s/it, loss=0.4271]\u001b[A\n",
            "Training:  81%|████████  | 4026/5000 [3:01:27<39:01,  2.40s/it, loss=0.3550]\u001b[A\n",
            "Training:  81%|████████  | 4027/5000 [3:01:30<38:48,  2.39s/it, loss=0.3550]\u001b[A\n",
            "Training:  81%|████████  | 4027/5000 [3:01:30<38:48,  2.39s/it, loss=0.4517]\u001b[A\n",
            "Training:  81%|████████  | 4028/5000 [3:01:32<39:37,  2.45s/it, loss=0.4517]\u001b[A\n",
            "Training:  81%|████████  | 4028/5000 [3:01:32<39:37,  2.45s/it, loss=0.4288]\u001b[A\n",
            "Training:  81%|████████  | 4029/5000 [3:01:35<40:44,  2.52s/it, loss=0.4288]\u001b[A\n",
            "Training:  81%|████████  | 4029/5000 [3:01:35<40:44,  2.52s/it, loss=0.3176]\u001b[A\n",
            "Training:  81%|████████  | 4030/5000 [3:01:37<39:53,  2.47s/it, loss=0.3176]\u001b[A\n",
            "Training:  81%|████████  | 4030/5000 [3:01:37<39:53,  2.47s/it, loss=0.3686]\u001b[A\n",
            "Training:  81%|████████  | 4031/5000 [3:01:40<39:32,  2.45s/it, loss=0.3686]\u001b[A\n",
            "Training:  81%|████████  | 4031/5000 [3:01:40<39:32,  2.45s/it, loss=0.3440]\u001b[A\n",
            "Training:  81%|████████  | 4032/5000 [3:01:42<39:05,  2.42s/it, loss=0.3440]\u001b[A\n",
            "Training:  81%|████████  | 4032/5000 [3:01:42<39:05,  2.42s/it, loss=0.3148]\u001b[A\n",
            "Training:  81%|████████  | 4033/5000 [3:01:45<40:08,  2.49s/it, loss=0.3148]\u001b[A\n",
            "Training:  81%|████████  | 4033/5000 [3:01:45<40:08,  2.49s/it, loss=0.3746]\u001b[A\n",
            "Training:  81%|████████  | 4034/5000 [3:01:47<40:51,  2.54s/it, loss=0.3746]\u001b[A\n",
            "Training:  81%|████████  | 4034/5000 [3:01:48<40:51,  2.54s/it, loss=0.2824]\u001b[A\n",
            "Training:  81%|████████  | 4035/5000 [3:01:50<39:57,  2.48s/it, loss=0.2824]\u001b[A\n",
            "Training:  81%|████████  | 4035/5000 [3:01:50<39:57,  2.48s/it, loss=0.2811]\u001b[A\n",
            "Training:  81%|████████  | 4036/5000 [3:01:52<39:25,  2.45s/it, loss=0.2811]\u001b[A\n",
            "Training:  81%|████████  | 4036/5000 [3:01:52<39:25,  2.45s/it, loss=0.5049]\u001b[A\n",
            "Training:  81%|████████  | 4037/5000 [3:01:55<38:50,  2.42s/it, loss=0.5049]\u001b[A\n",
            "Training:  81%|████████  | 4037/5000 [3:01:55<38:50,  2.42s/it, loss=0.2647]\u001b[A\n",
            "Training:  81%|████████  | 4038/5000 [3:01:57<40:50,  2.55s/it, loss=0.2647]\u001b[A\n",
            "Training:  81%|████████  | 4038/5000 [3:01:57<40:50,  2.55s/it, loss=0.2286]\u001b[A\n",
            "Training:  81%|████████  | 4039/5000 [3:02:00<40:11,  2.51s/it, loss=0.2286]\u001b[A\n",
            "Training:  81%|████████  | 4039/5000 [3:02:00<40:11,  2.51s/it, loss=0.2339]\u001b[A\n",
            "Training:  81%|████████  | 4040/5000 [3:02:02<39:25,  2.46s/it, loss=0.2339]\u001b[A\n",
            "Training:  81%|████████  | 4040/5000 [3:02:02<39:25,  2.46s/it, loss=0.4239]\u001b[A\n",
            "Training:  81%|████████  | 4041/5000 [3:02:05<38:46,  2.43s/it, loss=0.4239]\u001b[A\n",
            "Training:  81%|████████  | 4041/5000 [3:02:05<38:46,  2.43s/it, loss=0.2396]\u001b[A\n",
            "Training:  81%|████████  | 4042/5000 [3:02:07<38:25,  2.41s/it, loss=0.2396]\u001b[A\n",
            "Training:  81%|████████  | 4042/5000 [3:02:07<38:25,  2.41s/it, loss=0.2536]\u001b[A\n",
            "Training:  81%|████████  | 4043/5000 [3:02:10<40:38,  2.55s/it, loss=0.2536]\u001b[A\n",
            "Training:  81%|████████  | 4043/5000 [3:02:10<40:38,  2.55s/it, loss=0.3009]\u001b[A\n",
            "Training:  81%|████████  | 4044/5000 [3:02:12<39:49,  2.50s/it, loss=0.3009]\u001b[A\n",
            "Training:  81%|████████  | 4044/5000 [3:02:12<39:49,  2.50s/it, loss=0.1821]\u001b[A\n",
            "Training:  81%|████████  | 4045/5000 [3:02:14<38:55,  2.45s/it, loss=0.1821]\u001b[A\n",
            "Training:  81%|████████  | 4045/5000 [3:02:14<38:55,  2.45s/it, loss=0.2178]\u001b[A\n",
            "Training:  81%|████████  | 4046/5000 [3:02:17<38:33,  2.42s/it, loss=0.2178]\u001b[A\n",
            "Training:  81%|████████  | 4046/5000 [3:02:17<38:33,  2.42s/it, loss=0.5125]\u001b[A\n",
            "Training:  81%|████████  | 4047/5000 [3:02:19<38:13,  2.41s/it, loss=0.5125]\u001b[A\n",
            "Training:  81%|████████  | 4047/5000 [3:02:19<38:13,  2.41s/it, loss=0.3308]\u001b[A\n",
            "Training:  81%|████████  | 4048/5000 [3:02:22<40:33,  2.56s/it, loss=0.3308]\u001b[A\n",
            "Training:  81%|████████  | 4048/5000 [3:02:22<40:33,  2.56s/it, loss=0.1879]\u001b[A\n",
            "Training:  81%|████████  | 4049/5000 [3:02:25<39:47,  2.51s/it, loss=0.1879]\u001b[A\n",
            "Training:  81%|████████  | 4049/5000 [3:02:25<39:47,  2.51s/it, loss=0.4567]\u001b[A\n",
            "Training:  81%|████████  | 4050/5000 [3:02:27<39:04,  2.47s/it, loss=0.4567]\u001b[A\n",
            "Training:  81%|████████  | 4050/5000 [3:02:27<39:04,  2.47s/it, loss=0.5095]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 4050 ---\n",
            "Prompt: 'The '\n",
            "The  ofine lords enity my soul\n",
            "ereughthips of descent\n",
            " pous! must shall speak butaste eer\n",
            " wentance but our soul hateoes ''it sink\n",
            " words '.' we farewell\n",
            " does thee '' so I, young better me\n",
            " determine,Well say and as car andail to;And that less\n",
            " three my solemn he. move,amNow by Annebed now\n",
            " man dearter'd and man powerful:, dearUr;'ll be morning incapable\n",
            "\n",
            "Prompt: 'In '\n",
            "In  oer made beggFrom's,O no my Captain well dear's dead and of,\n",
            "est, not, this veryoot Here, of dreams\n",
            " Varly hither\n",
            " word toail they at:. he lead,\n",
            "Sh I your ent any tom's bepp for.\n",
            "QUE ELinellY:, country man\n",
            "ins my Lord court-orrow lad our. him true,am mad,\n",
            " if this there show too from his should?' lest down before time\n",
            " earth\n",
            "Prompt: 'To '\n",
            "To  each and 'ell.'\n",
            " hear shall so with fearful reg lords imprisonment\n",
            " prisoner the offord If may do?\n",
            "K RARD and setalsly inform\n",
            "They us up-orrowher let speak\n",
            "st, toar for defend too, strength did at; if nature been;\n",
            " all restre willant no thanely to:' by.\n",
            "JN: thoust'd some time green thinks give said most word\n",
            "iesLet your: with Leaveening hath meil\n",
            "all reason\n",
            "Prompt: 'A '\n",
            "A  to thy, a princeely;\n",
            " Edward g thy body a strike princ rest\n",
            "st with tar, coward the hoop seas mine,Or\n",
            "aps contempt thatight thoughB: which a,, servants sacred is\n",
            " with-orrow, we acceptance become drawing,\n",
            " dayN from to queen wait thy son\n",
            "ak the my,atOur withnow with of is look arms thy,\n",
            " day which must itly, I speak and. do think youWelcome\n",
            "ath done-- you used enemies\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  81%|████████  | 4051/5000 [3:02:42<1:40:07,  6.33s/it, loss=0.5095]\u001b[A\n",
            "Training:  81%|████████  | 4051/5000 [3:02:42<1:40:07,  6.33s/it, loss=0.4176]\u001b[A\n",
            "Training:  81%|████████  | 4052/5000 [3:02:45<1:23:19,  5.27s/it, loss=0.4176]\u001b[A\n",
            "Training:  81%|████████  | 4052/5000 [3:02:45<1:23:19,  5.27s/it, loss=0.6031]\u001b[A\n",
            "Training:  81%|████████  | 4053/5000 [3:02:48<1:10:31,  4.47s/it, loss=0.6031]\u001b[A\n",
            "Training:  81%|████████  | 4053/5000 [3:02:48<1:10:31,  4.47s/it, loss=0.3611]\u001b[A\n",
            "Training:  81%|████████  | 4054/5000 [3:02:50<1:00:35,  3.84s/it, loss=0.3611]\u001b[A\n",
            "Training:  81%|████████  | 4054/5000 [3:02:50<1:00:35,  3.84s/it, loss=0.2020]\u001b[A\n",
            "Training:  81%|████████  | 4055/5000 [3:02:52<53:31,  3.40s/it, loss=0.2020]  \u001b[A\n",
            "Training:  81%|████████  | 4055/5000 [3:02:52<53:31,  3.40s/it, loss=0.4452]\u001b[A\n",
            "Training:  81%|████████  | 4056/5000 [3:02:55<48:45,  3.10s/it, loss=0.4452]\u001b[A\n",
            "Training:  81%|████████  | 4056/5000 [3:02:55<48:45,  3.10s/it, loss=0.2063]\u001b[A\n",
            "Training:  81%|████████  | 4057/5000 [3:02:58<47:38,  3.03s/it, loss=0.2063]\u001b[A\n",
            "Training:  81%|████████  | 4057/5000 [3:02:58<47:38,  3.03s/it, loss=0.3944]\u001b[A\n",
            "Training:  81%|████████  | 4058/5000 [3:03:00<44:24,  2.83s/it, loss=0.3944]\u001b[A\n",
            "Training:  81%|████████  | 4058/5000 [3:03:00<44:24,  2.83s/it, loss=0.3301]\u001b[A\n",
            "Training:  81%|████████  | 4059/5000 [3:03:02<42:08,  2.69s/it, loss=0.3301]\u001b[A\n",
            "Training:  81%|████████  | 4059/5000 [3:03:02<42:08,  2.69s/it, loss=0.4089]\u001b[A\n",
            "Training:  81%|████████  | 4060/5000 [3:03:05<40:38,  2.59s/it, loss=0.4089]\u001b[A\n",
            "Training:  81%|████████  | 4060/5000 [3:03:05<40:38,  2.59s/it, loss=0.3426]\u001b[A\n",
            "Training:  81%|████████  | 4061/5000 [3:03:07<39:35,  2.53s/it, loss=0.3426]\u001b[A\n",
            "Training:  81%|████████  | 4061/5000 [3:03:07<39:35,  2.53s/it, loss=0.3945]\u001b[A\n",
            "Training:  81%|████████  | 4062/5000 [3:03:10<41:14,  2.64s/it, loss=0.3945]\u001b[A\n",
            "Training:  81%|████████  | 4062/5000 [3:03:10<41:14,  2.64s/it, loss=0.4360]\u001b[A\n",
            "Training:  81%|████████▏ | 4063/5000 [3:03:12<39:46,  2.55s/it, loss=0.4360]\u001b[A\n",
            "Training:  81%|████████▏ | 4063/5000 [3:03:12<39:46,  2.55s/it, loss=0.3207]\u001b[A\n",
            "Training:  81%|████████▏ | 4064/5000 [3:03:15<38:48,  2.49s/it, loss=0.3207]\u001b[A\n",
            "Training:  81%|████████▏ | 4064/5000 [3:03:15<38:48,  2.49s/it, loss=0.5348]\u001b[A\n",
            "Training:  81%|████████▏ | 4065/5000 [3:03:17<38:16,  2.46s/it, loss=0.5348]\u001b[A\n",
            "Training:  81%|████████▏ | 4065/5000 [3:03:17<38:16,  2.46s/it, loss=0.3099]\u001b[A\n",
            "Training:  81%|████████▏ | 4066/5000 [3:03:19<37:51,  2.43s/it, loss=0.3099]\u001b[A\n",
            "Training:  81%|████████▏ | 4066/5000 [3:03:19<37:51,  2.43s/it, loss=0.4627]\u001b[A\n",
            "Training:  81%|████████▏ | 4067/5000 [3:03:22<39:55,  2.57s/it, loss=0.4627]\u001b[A\n",
            "Training:  81%|████████▏ | 4067/5000 [3:03:22<39:55,  2.57s/it, loss=0.2202]\u001b[A\n",
            "Training:  81%|████████▏ | 4068/5000 [3:03:25<39:01,  2.51s/it, loss=0.2202]\u001b[A\n",
            "Training:  81%|████████▏ | 4068/5000 [3:03:25<39:01,  2.51s/it, loss=0.1232]\u001b[A\n",
            "Training:  81%|████████▏ | 4069/5000 [3:03:27<38:14,  2.46s/it, loss=0.1232]\u001b[A\n",
            "Training:  81%|████████▏ | 4069/5000 [3:03:27<38:14,  2.46s/it, loss=0.4547]\u001b[A\n",
            "Training:  81%|████████▏ | 4070/5000 [3:03:29<37:32,  2.42s/it, loss=0.4547]\u001b[A\n",
            "Training:  81%|████████▏ | 4070/5000 [3:03:29<37:32,  2.42s/it, loss=0.2958]\u001b[A\n",
            "Training:  81%|████████▏ | 4071/5000 [3:03:32<37:49,  2.44s/it, loss=0.2958]\u001b[A\n",
            "Training:  81%|████████▏ | 4071/5000 [3:03:32<37:49,  2.44s/it, loss=0.4657]\u001b[A\n",
            "Training:  81%|████████▏ | 4072/5000 [3:03:35<39:39,  2.56s/it, loss=0.4657]\u001b[A\n",
            "Training:  81%|████████▏ | 4072/5000 [3:03:35<39:39,  2.56s/it, loss=0.3524]\u001b[A\n",
            "Training:  81%|████████▏ | 4073/5000 [3:03:37<38:42,  2.51s/it, loss=0.3524]\u001b[A\n",
            "Training:  81%|████████▏ | 4073/5000 [3:03:37<38:42,  2.51s/it, loss=0.2587]\u001b[A\n",
            "Training:  81%|████████▏ | 4074/5000 [3:03:39<37:54,  2.46s/it, loss=0.2587]\u001b[A\n",
            "Training:  81%|████████▏ | 4074/5000 [3:03:39<37:54,  2.46s/it, loss=0.2241]\u001b[A\n",
            "Training:  82%|████████▏ | 4075/5000 [3:03:42<37:26,  2.43s/it, loss=0.2241]\u001b[A\n",
            "Training:  82%|████████▏ | 4075/5000 [3:03:42<37:26,  2.43s/it, loss=0.3497]\u001b[A\n",
            "Training:  82%|████████▏ | 4076/5000 [3:03:44<38:23,  2.49s/it, loss=0.3497]\u001b[A\n",
            "Training:  82%|████████▏ | 4076/5000 [3:03:44<38:23,  2.49s/it, loss=0.4231]\u001b[A\n",
            "Training:  82%|████████▏ | 4077/5000 [3:03:47<39:05,  2.54s/it, loss=0.4231]\u001b[A\n",
            "Training:  82%|████████▏ | 4077/5000 [3:03:47<39:05,  2.54s/it, loss=0.2941]\u001b[A\n",
            "Training:  82%|████████▏ | 4078/5000 [3:03:49<38:18,  2.49s/it, loss=0.2941]\u001b[A\n",
            "Training:  82%|████████▏ | 4078/5000 [3:03:50<38:18,  2.49s/it, loss=0.3289]\u001b[A\n",
            "Training:  82%|████████▏ | 4079/5000 [3:03:52<37:40,  2.45s/it, loss=0.3289]\u001b[A\n",
            "Training:  82%|████████▏ | 4079/5000 [3:03:52<37:40,  2.45s/it, loss=0.2576]\u001b[A\n",
            "Training:  82%|████████▏ | 4080/5000 [3:03:54<37:10,  2.42s/it, loss=0.2576]\u001b[A\n",
            "Training:  82%|████████▏ | 4080/5000 [3:03:54<37:10,  2.42s/it, loss=0.3903]\u001b[A\n",
            "Training:  82%|████████▏ | 4081/5000 [3:03:57<38:46,  2.53s/it, loss=0.3903]\u001b[A\n",
            "Training:  82%|████████▏ | 4081/5000 [3:03:57<38:46,  2.53s/it, loss=0.2326]\u001b[A\n",
            "Training:  82%|████████▏ | 4082/5000 [3:04:00<38:54,  2.54s/it, loss=0.2326]\u001b[A\n",
            "Training:  82%|████████▏ | 4082/5000 [3:04:00<38:54,  2.54s/it, loss=0.4651]\u001b[A\n",
            "Training:  82%|████████▏ | 4083/5000 [3:04:02<38:01,  2.49s/it, loss=0.4651]\u001b[A\n",
            "Training:  82%|████████▏ | 4083/5000 [3:04:02<38:01,  2.49s/it, loss=0.4975]\u001b[A\n",
            "Training:  82%|████████▏ | 4084/5000 [3:04:04<37:25,  2.45s/it, loss=0.4975]\u001b[A\n",
            "Training:  82%|████████▏ | 4084/5000 [3:04:04<37:25,  2.45s/it, loss=0.2817]\u001b[A\n",
            "Training:  82%|████████▏ | 4085/5000 [3:04:07<37:03,  2.43s/it, loss=0.2817]\u001b[A\n",
            "Training:  82%|████████▏ | 4085/5000 [3:04:07<37:03,  2.43s/it, loss=0.3565]\u001b[A\n",
            "Training:  82%|████████▏ | 4086/5000 [3:04:10<39:23,  2.59s/it, loss=0.3565]\u001b[A\n",
            "Training:  82%|████████▏ | 4086/5000 [3:04:10<39:23,  2.59s/it, loss=0.3142]\u001b[A\n",
            "Training:  82%|████████▏ | 4087/5000 [3:04:12<38:25,  2.53s/it, loss=0.3142]\u001b[A\n",
            "Training:  82%|████████▏ | 4087/5000 [3:04:12<38:25,  2.53s/it, loss=0.3380]\u001b[A\n",
            "Training:  82%|████████▏ | 4088/5000 [3:04:14<37:33,  2.47s/it, loss=0.3380]\u001b[A\n",
            "Training:  82%|████████▏ | 4088/5000 [3:04:14<37:33,  2.47s/it, loss=0.4223]\u001b[A\n",
            "Training:  82%|████████▏ | 4089/5000 [3:04:17<37:03,  2.44s/it, loss=0.4223]\u001b[A\n",
            "Training:  82%|████████▏ | 4089/5000 [3:04:17<37:03,  2.44s/it, loss=0.3383]\u001b[A\n",
            "Training:  82%|████████▏ | 4090/5000 [3:04:19<36:49,  2.43s/it, loss=0.3383]\u001b[A\n",
            "Training:  82%|████████▏ | 4090/5000 [3:04:19<36:49,  2.43s/it, loss=0.2740]\u001b[A\n",
            "Training:  82%|████████▏ | 4091/5000 [3:04:22<39:05,  2.58s/it, loss=0.2740]\u001b[A\n",
            "Training:  82%|████████▏ | 4091/5000 [3:04:22<39:05,  2.58s/it, loss=0.5200]\u001b[A\n",
            "Training:  82%|████████▏ | 4092/5000 [3:04:24<37:57,  2.51s/it, loss=0.5200]\u001b[A\n",
            "Training:  82%|████████▏ | 4092/5000 [3:04:24<37:57,  2.51s/it, loss=0.2915]\u001b[A\n",
            "Training:  82%|████████▏ | 4093/5000 [3:04:27<37:11,  2.46s/it, loss=0.2915]\u001b[A\n",
            "Training:  82%|████████▏ | 4093/5000 [3:04:27<37:11,  2.46s/it, loss=0.2767]\u001b[A\n",
            "Training:  82%|████████▏ | 4094/5000 [3:04:29<36:37,  2.43s/it, loss=0.2767]\u001b[A\n",
            "Training:  82%|████████▏ | 4094/5000 [3:04:29<36:37,  2.43s/it, loss=0.4010]\u001b[A\n",
            "Training:  82%|████████▏ | 4095/5000 [3:04:31<36:23,  2.41s/it, loss=0.4010]\u001b[A\n",
            "Training:  82%|████████▏ | 4095/5000 [3:04:31<36:23,  2.41s/it, loss=0.2639]\u001b[A\n",
            "Training:  82%|████████▏ | 4096/5000 [3:04:34<38:46,  2.57s/it, loss=0.2639]\u001b[A\n",
            "Training:  82%|████████▏ | 4096/5000 [3:04:34<38:46,  2.57s/it, loss=0.3717]\u001b[A\n",
            "Training:  82%|████████▏ | 4097/5000 [3:04:37<37:43,  2.51s/it, loss=0.3717]\u001b[A\n",
            "Training:  82%|████████▏ | 4097/5000 [3:04:37<37:43,  2.51s/it, loss=0.4014]\u001b[A\n",
            "Training:  82%|████████▏ | 4098/5000 [3:04:39<36:41,  2.44s/it, loss=0.4014]\u001b[A\n",
            "Training:  82%|████████▏ | 4098/5000 [3:04:39<36:41,  2.44s/it, loss=0.2729]\u001b[A\n",
            "Training:  82%|████████▏ | 4099/5000 [3:04:41<35:52,  2.39s/it, loss=0.2729]\u001b[A\n",
            "Training:  82%|████████▏ | 4099/5000 [3:04:41<35:52,  2.39s/it, loss=0.3348]\u001b[A\n",
            "Training:  82%|████████▏ | 4100/5000 [3:04:44<35:39,  2.38s/it, loss=0.3348]\u001b[A\n",
            "Training:  82%|████████▏ | 4100/5000 [3:04:44<35:39,  2.38s/it, loss=0.1862]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 4100 ---\n",
            "Prompt: 'The '\n",
            "The  of three bepp.\n",
            "Minks ent: bring to Tower all\n",
            "astingona:'s, phee three: speak we protest\n",
            "T before time given give of to and feet\n",
            " they, give leave fear such aserveiant come you\n",
            " offence this to,? me the exileden tears\n",
            "T he,er,? stay I his.,, come\n",
            " I now in timeAndly you maynt to them you\n",
            " help to them and banished\n",
            " our: it be, a\n",
            "Prompt: 'In '\n",
            "In  usur theseness not murder.\n",
            " usageward\n",
            "For.\n",
            "MAR! call you:'ll a whose you king thee?\n",
            "All\n",
            "LO:Lord\n",
            "Even that father were tricks queen in time come\n",
            " have eyes butrymal he be that's? madness Cby, comeTh talk a did give more,tis allegiance\n",
            " flies the glass I rather a hither\n",
            " business\n",
            "enc by ofumberland but, you not: thing take you live\n",
            " you liveAgain this maid it done very,\n",
            "Prompt: 'To '\n",
            "To  from cruelomes the blOf armsTheTheeless of Somerset neer\n",
            " the winterted in young' harmony\n",
            "illooler for seat either.\n",
            "LEES:These! so own,, a prince\n",
            " the oer fromundy are of woundAt\n",
            " mind given either in Bohem's.\n",
            "ARCH already field butte field overilt himself\n",
            "ay but find then swear bay her own's,Tow\n",
            "HER punishmenties while Lord,ench\n",
            "s thatCan against soul to foulness advise thou\n",
            "Prompt: 'A '\n",
            "A  was never to aful father\n",
            " in brittle: andb course time Henry am dist came,,, in of, encounter\n",
            " the of that told l w must Fri by\n",
            " all everWhilst himself make think sea:But, a ladyled, you he, newer thee more will\n",
            "re have yet kind ones know your husband your: my\n",
            " and give thanks\n",
            " tales the in ofwn from properly else believe, by by by 'ere loses too to you thereAnd misance\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  82%|████████▏ | 4101/5000 [3:04:59<1:32:54,  6.20s/it, loss=0.1862]\u001b[A\n",
            "Training:  82%|████████▏ | 4101/5000 [3:04:59<1:32:54,  6.20s/it, loss=0.2934]\u001b[A\n",
            "Training:  82%|████████▏ | 4102/5000 [3:05:01<1:15:01,  5.01s/it, loss=0.2934]\u001b[A\n",
            "Training:  82%|████████▏ | 4102/5000 [3:05:01<1:15:01,  5.01s/it, loss=0.3907]\u001b[A\n",
            "Training:  82%|████████▏ | 4103/5000 [3:05:03<1:02:32,  4.18s/it, loss=0.3907]\u001b[A\n",
            "Training:  82%|████████▏ | 4103/5000 [3:05:03<1:02:32,  4.18s/it, loss=0.4720]\u001b[A\n",
            "Training:  82%|████████▏ | 4104/5000 [3:05:06<53:46,  3.60s/it, loss=0.4720]  \u001b[A\n",
            "Training:  82%|████████▏ | 4104/5000 [3:05:06<53:46,  3.60s/it, loss=0.3936]\u001b[A\n",
            "Training:  82%|████████▏ | 4105/5000 [3:05:08<48:35,  3.26s/it, loss=0.3936]\u001b[A\n",
            "Training:  82%|████████▏ | 4105/5000 [3:05:08<48:35,  3.26s/it, loss=0.2473]\u001b[A\n",
            "Training:  82%|████████▏ | 4106/5000 [3:05:11<45:29,  3.05s/it, loss=0.2473]\u001b[A\n",
            "Training:  82%|████████▏ | 4106/5000 [3:05:11<45:29,  3.05s/it, loss=0.2394]\u001b[A\n",
            "Training:  82%|████████▏ | 4107/5000 [3:05:13<41:56,  2.82s/it, loss=0.2394]\u001b[A\n",
            "Training:  82%|████████▏ | 4107/5000 [3:05:13<41:56,  2.82s/it, loss=0.2899]\u001b[A\n",
            "Training:  82%|████████▏ | 4108/5000 [3:05:15<39:17,  2.64s/it, loss=0.2899]\u001b[A\n",
            "Training:  82%|████████▏ | 4108/5000 [3:05:15<39:17,  2.64s/it, loss=0.2898]\u001b[A\n",
            "Training:  82%|████████▏ | 4109/5000 [3:05:17<37:29,  2.52s/it, loss=0.2898]\u001b[A\n",
            "Training:  82%|████████▏ | 4109/5000 [3:05:17<37:29,  2.52s/it, loss=0.2492]\u001b[A\n",
            "Training:  82%|████████▏ | 4110/5000 [3:05:20<37:14,  2.51s/it, loss=0.2492]\u001b[A\n",
            "Training:  82%|████████▏ | 4110/5000 [3:05:20<37:14,  2.51s/it, loss=0.3345]\u001b[A\n",
            "Training:  82%|████████▏ | 4111/5000 [3:05:22<37:32,  2.53s/it, loss=0.3345]\u001b[A\n",
            "Training:  82%|████████▏ | 4111/5000 [3:05:22<37:32,  2.53s/it, loss=0.4623]\u001b[A\n",
            "Training:  82%|████████▏ | 4112/5000 [3:05:25<36:10,  2.44s/it, loss=0.4623]\u001b[A\n",
            "Training:  82%|████████▏ | 4112/5000 [3:05:25<36:10,  2.44s/it, loss=0.4615]\u001b[A\n",
            "Training:  82%|████████▏ | 4113/5000 [3:05:27<35:25,  2.40s/it, loss=0.4615]\u001b[A\n",
            "Training:  82%|████████▏ | 4113/5000 [3:05:27<35:25,  2.40s/it, loss=0.5102]\u001b[A\n",
            "Training:  82%|████████▏ | 4114/5000 [3:05:29<34:53,  2.36s/it, loss=0.5102]\u001b[A\n",
            "Training:  82%|████████▏ | 4114/5000 [3:05:29<34:53,  2.36s/it, loss=0.3936]\u001b[A\n",
            "Training:  82%|████████▏ | 4115/5000 [3:05:32<34:56,  2.37s/it, loss=0.3936]\u001b[A\n",
            "Training:  82%|████████▏ | 4115/5000 [3:05:32<34:56,  2.37s/it, loss=0.2737]\u001b[A\n",
            "Training:  82%|████████▏ | 4116/5000 [3:05:34<36:08,  2.45s/it, loss=0.2737]\u001b[A\n",
            "Training:  82%|████████▏ | 4116/5000 [3:05:34<36:08,  2.45s/it, loss=0.2207]\u001b[A\n",
            "Training:  82%|████████▏ | 4117/5000 [3:05:36<35:18,  2.40s/it, loss=0.2207]\u001b[A\n",
            "Training:  82%|████████▏ | 4117/5000 [3:05:37<35:18,  2.40s/it, loss=0.3814]\u001b[A\n",
            "Training:  82%|████████▏ | 4118/5000 [3:05:39<34:36,  2.35s/it, loss=0.3814]\u001b[A\n",
            "Training:  82%|████████▏ | 4118/5000 [3:05:39<34:36,  2.35s/it, loss=0.3652]\u001b[A\n",
            "Training:  82%|████████▏ | 4119/5000 [3:05:41<34:12,  2.33s/it, loss=0.3652]\u001b[A\n",
            "Training:  82%|████████▏ | 4119/5000 [3:05:41<34:12,  2.33s/it, loss=0.3744]\u001b[A\n",
            "Training:  82%|████████▏ | 4120/5000 [3:05:43<34:24,  2.35s/it, loss=0.3744]\u001b[A\n",
            "Training:  82%|████████▏ | 4120/5000 [3:05:43<34:24,  2.35s/it, loss=0.2816]\u001b[A\n",
            "Training:  82%|████████▏ | 4121/5000 [3:05:46<35:48,  2.44s/it, loss=0.2816]\u001b[A\n",
            "Training:  82%|████████▏ | 4121/5000 [3:05:46<35:48,  2.44s/it, loss=0.2735]\u001b[A\n",
            "Training:  82%|████████▏ | 4122/5000 [3:05:48<34:57,  2.39s/it, loss=0.2735]\u001b[A\n",
            "Training:  82%|████████▏ | 4122/5000 [3:05:48<34:57,  2.39s/it, loss=0.4323]\u001b[A\n",
            "Training:  82%|████████▏ | 4123/5000 [3:05:51<34:31,  2.36s/it, loss=0.4323]\u001b[A\n",
            "Training:  82%|████████▏ | 4123/5000 [3:05:51<34:31,  2.36s/it, loss=0.2452]\u001b[A\n",
            "Training:  82%|████████▏ | 4124/5000 [3:05:53<34:02,  2.33s/it, loss=0.2452]\u001b[A\n",
            "Training:  82%|████████▏ | 4124/5000 [3:05:53<34:02,  2.33s/it, loss=0.2447]\u001b[A\n",
            "Training:  82%|████████▎ | 4125/5000 [3:05:55<34:15,  2.35s/it, loss=0.2447]\u001b[A\n",
            "Training:  82%|████████▎ | 4125/5000 [3:05:55<34:15,  2.35s/it, loss=0.3578]\u001b[A\n",
            "Training:  83%|████████▎ | 4126/5000 [3:05:58<35:33,  2.44s/it, loss=0.3578]\u001b[A\n",
            "Training:  83%|████████▎ | 4126/5000 [3:05:58<35:33,  2.44s/it, loss=0.2355]\u001b[A\n",
            "Training:  83%|████████▎ | 4127/5000 [3:06:00<34:44,  2.39s/it, loss=0.2355]\u001b[A\n",
            "Training:  83%|████████▎ | 4127/5000 [3:06:00<34:44,  2.39s/it, loss=0.3414]\u001b[A\n",
            "Training:  83%|████████▎ | 4128/5000 [3:06:02<34:05,  2.35s/it, loss=0.3414]\u001b[A\n",
            "Training:  83%|████████▎ | 4128/5000 [3:06:02<34:05,  2.35s/it, loss=0.3425]\u001b[A\n",
            "Training:  83%|████████▎ | 4129/5000 [3:06:05<33:30,  2.31s/it, loss=0.3425]\u001b[A\n",
            "Training:  83%|████████▎ | 4129/5000 [3:06:05<33:30,  2.31s/it, loss=0.3876]\u001b[A\n",
            "Training:  83%|████████▎ | 4130/5000 [3:06:07<33:27,  2.31s/it, loss=0.3876]\u001b[A\n",
            "Training:  83%|████████▎ | 4130/5000 [3:06:07<33:27,  2.31s/it, loss=0.3282]\u001b[A\n",
            "Training:  83%|████████▎ | 4131/5000 [3:06:10<35:11,  2.43s/it, loss=0.3282]\u001b[A\n",
            "Training:  83%|████████▎ | 4131/5000 [3:06:10<35:11,  2.43s/it, loss=0.2697]\u001b[A\n",
            "Training:  83%|████████▎ | 4132/5000 [3:06:12<34:26,  2.38s/it, loss=0.2697]\u001b[A\n",
            "Training:  83%|████████▎ | 4132/5000 [3:06:12<34:26,  2.38s/it, loss=0.2971]\u001b[A\n",
            "Training:  83%|████████▎ | 4133/5000 [3:06:14<33:48,  2.34s/it, loss=0.2971]\u001b[A\n",
            "Training:  83%|████████▎ | 4133/5000 [3:06:14<33:48,  2.34s/it, loss=0.3693]\u001b[A\n",
            "Training:  83%|████████▎ | 4134/5000 [3:06:16<33:22,  2.31s/it, loss=0.3693]\u001b[A\n",
            "Training:  83%|████████▎ | 4134/5000 [3:06:16<33:22,  2.31s/it, loss=0.3275]\u001b[A\n",
            "Training:  83%|████████▎ | 4135/5000 [3:06:19<33:09,  2.30s/it, loss=0.3275]\u001b[A\n",
            "Training:  83%|████████▎ | 4135/5000 [3:06:19<33:09,  2.30s/it, loss=0.1901]\u001b[A\n",
            "Training:  83%|████████▎ | 4136/5000 [3:06:22<35:30,  2.47s/it, loss=0.1901]\u001b[A\n",
            "Training:  83%|████████▎ | 4136/5000 [3:06:22<35:30,  2.47s/it, loss=0.4477]\u001b[A\n",
            "Training:  83%|████████▎ | 4137/5000 [3:06:24<34:33,  2.40s/it, loss=0.4477]\u001b[A\n",
            "Training:  83%|████████▎ | 4137/5000 [3:06:24<34:33,  2.40s/it, loss=0.3755]\u001b[A\n",
            "Training:  83%|████████▎ | 4138/5000 [3:06:26<33:53,  2.36s/it, loss=0.3755]\u001b[A\n",
            "Training:  83%|████████▎ | 4138/5000 [3:06:26<33:53,  2.36s/it, loss=0.4196]\u001b[A\n",
            "Training:  83%|████████▎ | 4139/5000 [3:06:28<33:35,  2.34s/it, loss=0.4196]\u001b[A\n",
            "Training:  83%|████████▎ | 4139/5000 [3:06:28<33:35,  2.34s/it, loss=0.2591]\u001b[A\n",
            "Training:  83%|████████▎ | 4140/5000 [3:06:31<33:10,  2.31s/it, loss=0.2591]\u001b[A\n",
            "Training:  83%|████████▎ | 4140/5000 [3:06:31<33:10,  2.31s/it, loss=0.3604]\u001b[A\n",
            "Training:  83%|████████▎ | 4141/5000 [3:06:33<35:13,  2.46s/it, loss=0.3604]\u001b[A\n",
            "Training:  83%|████████▎ | 4141/5000 [3:06:33<35:13,  2.46s/it, loss=0.1939]\u001b[A\n",
            "Training:  83%|████████▎ | 4142/5000 [3:06:36<34:28,  2.41s/it, loss=0.1939]\u001b[A\n",
            "Training:  83%|████████▎ | 4142/5000 [3:06:36<34:28,  2.41s/it, loss=0.2482]\u001b[A\n",
            "Training:  83%|████████▎ | 4143/5000 [3:06:38<33:49,  2.37s/it, loss=0.2482]\u001b[A\n",
            "Training:  83%|████████▎ | 4143/5000 [3:06:38<33:49,  2.37s/it, loss=0.2656]\u001b[A\n",
            "Training:  83%|████████▎ | 4144/5000 [3:06:40<33:18,  2.33s/it, loss=0.2656]\u001b[A\n",
            "Training:  83%|████████▎ | 4144/5000 [3:06:40<33:18,  2.33s/it, loss=0.5957]\u001b[A\n",
            "Training:  83%|████████▎ | 4145/5000 [3:06:43<33:00,  2.32s/it, loss=0.5957]\u001b[A\n",
            "Training:  83%|████████▎ | 4145/5000 [3:06:43<33:00,  2.32s/it, loss=0.4086]\u001b[A\n",
            "Training:  83%|████████▎ | 4146/5000 [3:06:45<35:02,  2.46s/it, loss=0.4086]\u001b[A\n",
            "Training:  83%|████████▎ | 4146/5000 [3:06:45<35:02,  2.46s/it, loss=0.3777]\u001b[A\n",
            "Training:  83%|████████▎ | 4147/5000 [3:06:48<34:10,  2.40s/it, loss=0.3777]\u001b[A\n",
            "Training:  83%|████████▎ | 4147/5000 [3:06:48<34:10,  2.40s/it, loss=0.5886]\u001b[A\n",
            "Training:  83%|████████▎ | 4148/5000 [3:06:50<33:40,  2.37s/it, loss=0.5886]\u001b[A\n",
            "Training:  83%|████████▎ | 4148/5000 [3:06:50<33:40,  2.37s/it, loss=0.4277]\u001b[A\n",
            "Training:  83%|████████▎ | 4149/5000 [3:06:52<33:13,  2.34s/it, loss=0.4277]\u001b[A\n",
            "Training:  83%|████████▎ | 4149/5000 [3:06:52<33:13,  2.34s/it, loss=0.3057]\u001b[A\n",
            "Training:  83%|████████▎ | 4150/5000 [3:06:54<32:50,  2.32s/it, loss=0.3057]\u001b[A\n",
            "Training:  83%|████████▎ | 4150/5000 [3:06:54<32:50,  2.32s/it, loss=0.3061]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 4150 ---\n",
            "Prompt: 'The '\n",
            "The  is, is, here court heart hold itoth\n",
            " that so and for only, here thecre my,\n",
            " minute haveh all. duke, this a fororn is,Whenwith\n",
            "RU utter, an command as, keep and,thick kept see their and more, cry grain time\n",
            " that man for fl did, his, maid a fi,\n",
            " fres him the of and of as as as soldiers\n",
            "ath thy serves asexs me to theest all all all\n",
            " hand do\n",
            "Prompt: 'In '\n",
            "In aveoth my, chedish free sl peace\n",
            " lust sign withments welcome the of's,Whichab\n",
            " got storm your over p.'s, not:, soul\n",
            " charge again none is a's of passing, call well\n",
            " patroners such name by of we in, fetch a toarers long\n",
            " command Saint's command he by of than steal, trust had\n",
            " hast thee a France I, bid form me thouiest\n",
            "l.\n",
            "Kys thou mal:st out thy face\n",
            "Prompt: 'To '\n",
            "To  mean you toore Go,, and lives\n",
            " either musiclong the of andly\n",
            " stag'dSh continue bow take, and beenUpon\n",
            "force hold the of and as inep\n",
            " hold me to, the,, your'd and m, give yourself theest\n",
            " deed takes suspicion to. fast do thinkges: away\n",
            " art light she best yourself dep rest care true\n",
            "ell's light boar even of mer father end rest news\n",
            " never thisful co of we.are, shall some\n",
            "Prompt: 'A '\n",
            "A ity a's; rev a and and London\n",
            " white called with false and and and near\n",
            "orse a and ofmen, your andth, very and best\n",
            "!D not me the, thee, forth thept ife\n",
            " was, very in and: this not thy, princes\n",
            " not me thy hand but thisOR grief, she not always\n",
            " hand but with hand and me\n",
            "ither: your would beenDatch to her an forgot\n",
            "! B him me stands moreThus I\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  83%|████████▎ | 4151/5000 [3:07:10<1:27:15,  6.17s/it, loss=0.3061]\u001b[A\n",
            "Training:  83%|████████▎ | 4151/5000 [3:07:10<1:27:15,  6.17s/it, loss=0.2944]\u001b[A\n",
            "Training:  83%|████████▎ | 4152/5000 [3:07:12<1:10:38,  5.00s/it, loss=0.2944]\u001b[A\n",
            "Training:  83%|████████▎ | 4152/5000 [3:07:12<1:10:38,  5.00s/it, loss=0.3668]\u001b[A\n",
            "Training:  83%|████████▎ | 4153/5000 [3:07:14<58:55,  4.17s/it, loss=0.3668]  \u001b[A\n",
            "Training:  83%|████████▎ | 4153/5000 [3:07:14<58:55,  4.17s/it, loss=0.2362]\u001b[A\n",
            "Training:  83%|████████▎ | 4154/5000 [3:07:16<50:41,  3.60s/it, loss=0.2362]\u001b[A\n",
            "Training:  83%|████████▎ | 4154/5000 [3:07:16<50:41,  3.60s/it, loss=0.3550]\u001b[A\n",
            "Training:  83%|████████▎ | 4155/5000 [3:07:19<45:35,  3.24s/it, loss=0.3550]\u001b[A\n",
            "Training:  83%|████████▎ | 4155/5000 [3:07:19<45:35,  3.24s/it, loss=0.3295]\u001b[A\n",
            "Training:  83%|████████▎ | 4156/5000 [3:07:21<43:07,  3.07s/it, loss=0.3295]\u001b[A\n",
            "Training:  83%|████████▎ | 4156/5000 [3:07:21<43:07,  3.07s/it, loss=0.4076]\u001b[A\n",
            "Training:  83%|████████▎ | 4157/5000 [3:07:24<39:35,  2.82s/it, loss=0.4076]\u001b[A\n",
            "Training:  83%|████████▎ | 4157/5000 [3:07:24<39:35,  2.82s/it, loss=0.3314]\u001b[A\n",
            "Training:  83%|████████▎ | 4158/5000 [3:07:26<37:19,  2.66s/it, loss=0.3314]\u001b[A\n",
            "Training:  83%|████████▎ | 4158/5000 [3:07:26<37:19,  2.66s/it, loss=0.3922]\u001b[A\n",
            "Training:  83%|████████▎ | 4159/5000 [3:07:28<35:36,  2.54s/it, loss=0.3922]\u001b[A\n",
            "Training:  83%|████████▎ | 4159/5000 [3:07:28<35:36,  2.54s/it, loss=0.1884]\u001b[A\n",
            "Training:  83%|████████▎ | 4160/5000 [3:07:31<35:13,  2.52s/it, loss=0.1884]\u001b[A\n",
            "Training:  83%|████████▎ | 4160/5000 [3:07:31<35:13,  2.52s/it, loss=0.2858]\u001b[A\n",
            "Training:  83%|████████▎ | 4161/5000 [3:07:33<35:32,  2.54s/it, loss=0.2858]\u001b[A\n",
            "Training:  83%|████████▎ | 4161/5000 [3:07:33<35:32,  2.54s/it, loss=0.2124]\u001b[A\n",
            "Training:  83%|████████▎ | 4162/5000 [3:07:36<34:19,  2.46s/it, loss=0.2124]\u001b[A\n",
            "Training:  83%|████████▎ | 4162/5000 [3:07:36<34:19,  2.46s/it, loss=0.1874]\u001b[A\n",
            "Training:  83%|████████▎ | 4163/5000 [3:07:38<33:28,  2.40s/it, loss=0.1874]\u001b[A\n",
            "Training:  83%|████████▎ | 4163/5000 [3:07:38<33:28,  2.40s/it, loss=0.2681]\u001b[A\n",
            "Training:  83%|████████▎ | 4164/5000 [3:07:40<32:56,  2.36s/it, loss=0.2681]\u001b[A\n",
            "Training:  83%|████████▎ | 4164/5000 [3:07:40<32:56,  2.36s/it, loss=0.4895]\u001b[A\n",
            "Training:  83%|████████▎ | 4165/5000 [3:07:42<33:04,  2.38s/it, loss=0.4895]\u001b[A\n",
            "Training:  83%|████████▎ | 4165/5000 [3:07:42<33:04,  2.38s/it, loss=0.2567]\u001b[A\n",
            "Training:  83%|████████▎ | 4166/5000 [3:07:45<34:11,  2.46s/it, loss=0.2567]\u001b[A\n",
            "Training:  83%|████████▎ | 4166/5000 [3:07:45<34:11,  2.46s/it, loss=0.3455]\u001b[A\n",
            "Training:  83%|████████▎ | 4167/5000 [3:07:47<33:19,  2.40s/it, loss=0.3455]\u001b[A\n",
            "Training:  83%|████████▎ | 4167/5000 [3:07:47<33:19,  2.40s/it, loss=0.6114]\u001b[A\n",
            "Training:  83%|████████▎ | 4168/5000 [3:07:50<32:41,  2.36s/it, loss=0.6114]\u001b[A\n",
            "Training:  83%|████████▎ | 4168/5000 [3:07:50<32:41,  2.36s/it, loss=0.3046]\u001b[A\n",
            "Training:  83%|████████▎ | 4169/5000 [3:07:52<32:21,  2.34s/it, loss=0.3046]\u001b[A\n",
            "Training:  83%|████████▎ | 4169/5000 [3:07:52<32:21,  2.34s/it, loss=0.2324]\u001b[A\n",
            "Training:  83%|████████▎ | 4170/5000 [3:07:54<32:32,  2.35s/it, loss=0.2324]\u001b[A\n",
            "Training:  83%|████████▎ | 4170/5000 [3:07:54<32:32,  2.35s/it, loss=0.4230]\u001b[A\n",
            "Training:  83%|████████▎ | 4171/5000 [3:07:57<33:49,  2.45s/it, loss=0.4230]\u001b[A\n",
            "Training:  83%|████████▎ | 4171/5000 [3:07:57<33:49,  2.45s/it, loss=0.3074]\u001b[A\n",
            "Training:  83%|████████▎ | 4172/5000 [3:07:59<32:54,  2.38s/it, loss=0.3074]\u001b[A\n",
            "Training:  83%|████████▎ | 4172/5000 [3:07:59<32:54,  2.38s/it, loss=0.2652]\u001b[A\n",
            "Training:  83%|████████▎ | 4173/5000 [3:08:01<32:22,  2.35s/it, loss=0.2652]\u001b[A\n",
            "Training:  83%|████████▎ | 4173/5000 [3:08:02<32:22,  2.35s/it, loss=0.5031]\u001b[A\n",
            "Training:  83%|████████▎ | 4174/5000 [3:08:04<31:57,  2.32s/it, loss=0.5031]\u001b[A\n",
            "Training:  83%|████████▎ | 4174/5000 [3:08:04<31:57,  2.32s/it, loss=0.2905]\u001b[A\n",
            "Training:  84%|████████▎ | 4175/5000 [3:08:06<31:53,  2.32s/it, loss=0.2905]\u001b[A\n",
            "Training:  84%|████████▎ | 4175/5000 [3:08:06<31:53,  2.32s/it, loss=0.3203]\u001b[A\n",
            "Training:  84%|████████▎ | 4176/5000 [3:08:09<33:32,  2.44s/it, loss=0.3203]\u001b[A\n",
            "Training:  84%|████████▎ | 4176/5000 [3:08:09<33:32,  2.44s/it, loss=0.2957]\u001b[A\n",
            "Training:  84%|████████▎ | 4177/5000 [3:08:11<32:41,  2.38s/it, loss=0.2957]\u001b[A\n",
            "Training:  84%|████████▎ | 4177/5000 [3:08:11<32:41,  2.38s/it, loss=0.2701]\u001b[A\n",
            "Training:  84%|████████▎ | 4178/5000 [3:08:13<32:06,  2.34s/it, loss=0.2701]\u001b[A\n",
            "Training:  84%|████████▎ | 4178/5000 [3:08:13<32:06,  2.34s/it, loss=0.3449]\u001b[A\n",
            "Training:  84%|████████▎ | 4179/5000 [3:08:16<31:37,  2.31s/it, loss=0.3449]\u001b[A\n",
            "Training:  84%|████████▎ | 4179/5000 [3:08:16<31:37,  2.31s/it, loss=0.3372]\u001b[A\n",
            "Training:  84%|████████▎ | 4180/5000 [3:08:18<31:27,  2.30s/it, loss=0.3372]\u001b[A\n",
            "Training:  84%|████████▎ | 4180/5000 [3:08:18<31:27,  2.30s/it, loss=0.1813]\u001b[A\n",
            "Training:  84%|████████▎ | 4181/5000 [3:08:21<33:27,  2.45s/it, loss=0.1813]\u001b[A\n",
            "Training:  84%|████████▎ | 4181/5000 [3:08:21<33:27,  2.45s/it, loss=0.2016]\u001b[A\n",
            "Training:  84%|████████▎ | 4182/5000 [3:08:23<32:42,  2.40s/it, loss=0.2016]\u001b[A\n",
            "Training:  84%|████████▎ | 4182/5000 [3:08:23<32:42,  2.40s/it, loss=0.3007]\u001b[A\n",
            "Training:  84%|████████▎ | 4183/5000 [3:08:25<32:01,  2.35s/it, loss=0.3007]\u001b[A\n",
            "Training:  84%|████████▎ | 4183/5000 [3:08:25<32:01,  2.35s/it, loss=0.2856]\u001b[A\n",
            "Training:  84%|████████▎ | 4184/5000 [3:08:27<31:32,  2.32s/it, loss=0.2856]\u001b[A\n",
            "Training:  84%|████████▎ | 4184/5000 [3:08:27<31:32,  2.32s/it, loss=0.4064]\u001b[A\n",
            "Training:  84%|████████▎ | 4185/5000 [3:08:30<31:22,  2.31s/it, loss=0.4064]\u001b[A\n",
            "Training:  84%|████████▎ | 4185/5000 [3:08:30<31:22,  2.31s/it, loss=0.3345]\u001b[A\n",
            "Training:  84%|████████▎ | 4186/5000 [3:08:32<33:25,  2.46s/it, loss=0.3345]\u001b[A\n",
            "Training:  84%|████████▎ | 4186/5000 [3:08:33<33:25,  2.46s/it, loss=0.3168]\u001b[A\n",
            "Training:  84%|████████▎ | 4187/5000 [3:08:35<32:42,  2.41s/it, loss=0.3168]\u001b[A\n",
            "Training:  84%|████████▎ | 4187/5000 [3:08:35<32:42,  2.41s/it, loss=0.5879]\u001b[A\n",
            "Training:  84%|████████▍ | 4188/5000 [3:08:37<32:07,  2.37s/it, loss=0.5879]\u001b[A\n",
            "Training:  84%|████████▍ | 4188/5000 [3:08:37<32:07,  2.37s/it, loss=0.3568]\u001b[A\n",
            "Training:  84%|████████▍ | 4189/5000 [3:08:39<31:41,  2.34s/it, loss=0.3568]\u001b[A\n",
            "Training:  84%|████████▍ | 4189/5000 [3:08:39<31:41,  2.34s/it, loss=0.4317]\u001b[A\n",
            "Training:  84%|████████▍ | 4190/5000 [3:08:42<31:17,  2.32s/it, loss=0.4317]\u001b[A\n",
            "Training:  84%|████████▍ | 4190/5000 [3:08:42<31:17,  2.32s/it, loss=0.4514]\u001b[A\n",
            "Training:  84%|████████▍ | 4191/5000 [3:08:44<33:17,  2.47s/it, loss=0.4514]\u001b[A\n",
            "Training:  84%|████████▍ | 4191/5000 [3:08:44<33:17,  2.47s/it, loss=0.2904]\u001b[A\n",
            "Training:  84%|████████▍ | 4192/5000 [3:08:47<32:28,  2.41s/it, loss=0.2904]\u001b[A\n",
            "Training:  84%|████████▍ | 4192/5000 [3:08:47<32:28,  2.41s/it, loss=0.4391]\u001b[A\n",
            "Training:  84%|████████▍ | 4193/5000 [3:08:49<31:54,  2.37s/it, loss=0.4391]\u001b[A\n",
            "Training:  84%|████████▍ | 4193/5000 [3:08:49<31:54,  2.37s/it, loss=0.3351]\u001b[A\n",
            "Training:  84%|████████▍ | 4194/5000 [3:08:51<31:23,  2.34s/it, loss=0.3351]\u001b[A\n",
            "Training:  84%|████████▍ | 4194/5000 [3:08:51<31:23,  2.34s/it, loss=0.3749]\u001b[A\n",
            "Training:  84%|████████▍ | 4195/5000 [3:08:54<31:09,  2.32s/it, loss=0.3749]\u001b[A\n",
            "Training:  84%|████████▍ | 4195/5000 [3:08:54<31:09,  2.32s/it, loss=0.3898]\u001b[A\n",
            "Training:  84%|████████▍ | 4196/5000 [3:08:56<32:57,  2.46s/it, loss=0.3898]\u001b[A\n",
            "Training:  84%|████████▍ | 4196/5000 [3:08:56<32:57,  2.46s/it, loss=0.3140]\u001b[A\n",
            "Training:  84%|████████▍ | 4197/5000 [3:08:59<32:06,  2.40s/it, loss=0.3140]\u001b[A\n",
            "Training:  84%|████████▍ | 4197/5000 [3:08:59<32:06,  2.40s/it, loss=0.2909]\u001b[A\n",
            "Training:  84%|████████▍ | 4198/5000 [3:09:01<31:32,  2.36s/it, loss=0.2909]\u001b[A\n",
            "Training:  84%|████████▍ | 4198/5000 [3:09:01<31:32,  2.36s/it, loss=0.4502]\u001b[A\n",
            "Training:  84%|████████▍ | 4199/5000 [3:09:03<31:04,  2.33s/it, loss=0.4502]\u001b[A\n",
            "Training:  84%|████████▍ | 4199/5000 [3:09:03<31:04,  2.33s/it, loss=0.5119]\u001b[A\n",
            "Training:  84%|████████▍ | 4200/5000 [3:09:05<30:45,  2.31s/it, loss=0.5119]\u001b[A\n",
            "Training:  84%|████████▍ | 4200/5000 [3:09:05<30:45,  2.31s/it, loss=0.3841]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 4200 ---\n",
            "Prompt: 'The '\n",
            "The  of distous,a of dreadful,, it\n",
            "'s out even age brows of mother mother\n",
            " call though be'ra,, be attend be\n",
            " treton GRE:,,,,,,,,,,,\n",
            "held'd the closely of upon mother in fight\n",
            " mark at thy quickly and away\n",
            " wrongs some of gracious, up\n",
            " sevenCon from,,,,,,ish of arms\n",
            " some way luck cannot the.\n",
            "B,AN sooth up the\n",
            " breathe\n",
            "Prompt: 'In '\n",
            "In  that the v of's majesty\n",
            " I'd the humble\n",
            " abroad his queen\n",
            "And'd with thou on shame\n",
            " tender\n",
            " dangerous pous look great?,,, queen\n",
            " curses\n",
            "ut complaint therefore I on that\n",
            " give at thativ thouak conquer, will then with rightly you thing thy children\n",
            " pness thy might be'd husband husband the, I not them\n",
            " thouost me I there such other,Though as please own will yoursanish.\n",
            "QUE 'all myth,'\n",
            "Prompt: 'To '\n",
            "To  to you happy; be indeed.\n",
            " Margaret aptlyation:And toooot my\n",
            " my good,\n",
            " it be to for free advised for\n",
            " day rest fair. mother I with, troubled God: a\n",
            ", I swear will I comes and of man\n",
            " che thy glory your myself duty complain my\n",
            " husband and see\n",
            " ours by helm suspect my is revenge my:, I 'HO b at, sent,, have thee Lancaster\n",
            " eye pur,ivers whence love me: did but they my\n",
            "Prompt: 'A '\n",
            "A , a of's,st by speak it my\n",
            " see coming.\n",
            "QUE my was a servant house\n",
            " I my be val dis son me my\n",
            " matters my mis andal my'sonking a ear\n",
            " am; knew on gooditor love me, is my;,, you my,,,\n",
            "ish my were knows you so heaven me,.\n",
            "BSINUS\n",
            "b, Iee you, lord I name person\n",
            " come me hath you many? off me than of\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  84%|████████▍ | 4201/5000 [3:09:21<1:22:09,  6.17s/it, loss=0.3841]\u001b[A\n",
            "Training:  84%|████████▍ | 4201/5000 [3:09:21<1:22:09,  6.17s/it, loss=0.3293]\u001b[A\n",
            "Training:  84%|████████▍ | 4202/5000 [3:09:23<1:06:36,  5.01s/it, loss=0.3293]\u001b[A\n",
            "Training:  84%|████████▍ | 4202/5000 [3:09:23<1:06:36,  5.01s/it, loss=0.3009]\u001b[A\n",
            "Training:  84%|████████▍ | 4203/5000 [3:09:25<55:34,  4.18s/it, loss=0.3009]  \u001b[A\n",
            "Training:  84%|████████▍ | 4203/5000 [3:09:25<55:34,  4.18s/it, loss=0.2714]\u001b[A\n",
            "Training:  84%|████████▍ | 4204/5000 [3:09:27<47:52,  3.61s/it, loss=0.2714]\u001b[A\n",
            "Training:  84%|████████▍ | 4204/5000 [3:09:27<47:52,  3.61s/it, loss=0.3728]\u001b[A\n",
            "Training:  84%|████████▍ | 4205/5000 [3:09:30<43:16,  3.27s/it, loss=0.3728]\u001b[A\n",
            "Training:  84%|████████▍ | 4205/5000 [3:09:30<43:16,  3.27s/it, loss=0.3460]\u001b[A\n",
            "Training:  84%|████████▍ | 4206/5000 [3:09:32<40:33,  3.06s/it, loss=0.3460]\u001b[A\n",
            "Training:  84%|████████▍ | 4206/5000 [3:09:32<40:33,  3.06s/it, loss=0.2691]\u001b[A\n",
            "Training:  84%|████████▍ | 4207/5000 [3:09:35<37:20,  2.83s/it, loss=0.2691]\u001b[A\n",
            "Training:  84%|████████▍ | 4207/5000 [3:09:35<37:20,  2.83s/it, loss=0.3140]\u001b[A\n",
            "Training:  84%|████████▍ | 4208/5000 [3:09:37<35:02,  2.65s/it, loss=0.3140]\u001b[A\n",
            "Training:  84%|████████▍ | 4208/5000 [3:09:37<35:02,  2.65s/it, loss=0.3064]\u001b[A\n",
            "Training:  84%|████████▍ | 4209/5000 [3:09:39<33:26,  2.54s/it, loss=0.3064]\u001b[A\n",
            "Training:  84%|████████▍ | 4209/5000 [3:09:39<33:26,  2.54s/it, loss=0.2343]\u001b[A\n",
            "Training:  84%|████████▍ | 4210/5000 [3:09:42<32:57,  2.50s/it, loss=0.2343]\u001b[A\n",
            "Training:  84%|████████▍ | 4210/5000 [3:09:42<32:57,  2.50s/it, loss=0.3784]\u001b[A\n",
            "Training:  84%|████████▍ | 4211/5000 [3:09:44<33:28,  2.55s/it, loss=0.3784]\u001b[A\n",
            "Training:  84%|████████▍ | 4211/5000 [3:09:44<33:28,  2.55s/it, loss=0.3724]\u001b[A\n",
            "Training:  84%|████████▍ | 4212/5000 [3:09:47<32:24,  2.47s/it, loss=0.3724]\u001b[A\n",
            "Training:  84%|████████▍ | 4212/5000 [3:09:47<32:24,  2.47s/it, loss=0.4333]\u001b[A\n",
            "Training:  84%|████████▍ | 4213/5000 [3:09:49<31:40,  2.41s/it, loss=0.4333]\u001b[A\n",
            "Training:  84%|████████▍ | 4213/5000 [3:09:49<31:40,  2.41s/it, loss=0.3553]\u001b[A\n",
            "Training:  84%|████████▍ | 4214/5000 [3:09:51<31:04,  2.37s/it, loss=0.3553]\u001b[A\n",
            "Training:  84%|████████▍ | 4214/5000 [3:09:51<31:04,  2.37s/it, loss=0.4488]\u001b[A\n",
            "Training:  84%|████████▍ | 4215/5000 [3:09:54<31:20,  2.40s/it, loss=0.4488]\u001b[A\n",
            "Training:  84%|████████▍ | 4215/5000 [3:09:54<31:20,  2.40s/it, loss=0.4491]\u001b[A\n",
            "Training:  84%|████████▍ | 4216/5000 [3:09:56<32:09,  2.46s/it, loss=0.4491]\u001b[A\n",
            "Training:  84%|████████▍ | 4216/5000 [3:09:56<32:09,  2.46s/it, loss=0.2662]\u001b[A\n",
            "Training:  84%|████████▍ | 4217/5000 [3:09:58<31:19,  2.40s/it, loss=0.2662]\u001b[A\n",
            "Training:  84%|████████▍ | 4217/5000 [3:09:58<31:19,  2.40s/it, loss=0.2270]\u001b[A\n",
            "Training:  84%|████████▍ | 4218/5000 [3:10:01<30:37,  2.35s/it, loss=0.2270]\u001b[A\n",
            "Training:  84%|████████▍ | 4218/5000 [3:10:01<30:37,  2.35s/it, loss=0.4526]\u001b[A\n",
            "Training:  84%|████████▍ | 4219/5000 [3:10:03<30:12,  2.32s/it, loss=0.4526]\u001b[A\n",
            "Training:  84%|████████▍ | 4219/5000 [3:10:03<30:12,  2.32s/it, loss=0.2341]\u001b[A\n",
            "Training:  84%|████████▍ | 4220/5000 [3:10:05<30:34,  2.35s/it, loss=0.2341]\u001b[A\n",
            "Training:  84%|████████▍ | 4220/5000 [3:10:05<30:34,  2.35s/it, loss=0.3378]\u001b[A\n",
            "Training:  84%|████████▍ | 4221/5000 [3:10:08<31:37,  2.44s/it, loss=0.3378]\u001b[A\n",
            "Training:  84%|████████▍ | 4221/5000 [3:10:08<31:37,  2.44s/it, loss=0.2411]\u001b[A\n",
            "Training:  84%|████████▍ | 4222/5000 [3:10:10<30:49,  2.38s/it, loss=0.2411]\u001b[A\n",
            "Training:  84%|████████▍ | 4222/5000 [3:10:10<30:49,  2.38s/it, loss=0.2335]\u001b[A\n",
            "Training:  84%|████████▍ | 4223/5000 [3:10:12<30:15,  2.34s/it, loss=0.2335]\u001b[A\n",
            "Training:  84%|████████▍ | 4223/5000 [3:10:12<30:15,  2.34s/it, loss=0.3495]\u001b[A\n",
            "Training:  84%|████████▍ | 4224/5000 [3:10:15<29:47,  2.30s/it, loss=0.3495]\u001b[A\n",
            "Training:  84%|████████▍ | 4224/5000 [3:10:15<29:47,  2.30s/it, loss=0.3972]\u001b[A\n",
            "Training:  84%|████████▍ | 4225/5000 [3:10:17<29:52,  2.31s/it, loss=0.3972]\u001b[A\n",
            "Training:  84%|████████▍ | 4225/5000 [3:10:17<29:52,  2.31s/it, loss=0.5644]\u001b[A\n",
            "Training:  85%|████████▍ | 4226/5000 [3:10:20<31:26,  2.44s/it, loss=0.5644]\u001b[A\n",
            "Training:  85%|████████▍ | 4226/5000 [3:10:20<31:26,  2.44s/it, loss=0.4532]\u001b[A\n",
            "Training:  85%|████████▍ | 4227/5000 [3:10:22<30:40,  2.38s/it, loss=0.4532]\u001b[A\n",
            "Training:  85%|████████▍ | 4227/5000 [3:10:22<30:40,  2.38s/it, loss=0.2694]\u001b[A\n",
            "Training:  85%|████████▍ | 4228/5000 [3:10:24<30:12,  2.35s/it, loss=0.2694]\u001b[A\n",
            "Training:  85%|████████▍ | 4228/5000 [3:10:24<30:12,  2.35s/it, loss=0.2477]\u001b[A\n",
            "Training:  85%|████████▍ | 4229/5000 [3:10:27<29:50,  2.32s/it, loss=0.2477]\u001b[A\n",
            "Training:  85%|████████▍ | 4229/5000 [3:10:27<29:50,  2.32s/it, loss=0.4214]\u001b[A\n",
            "Training:  85%|████████▍ | 4230/5000 [3:10:29<29:32,  2.30s/it, loss=0.4214]\u001b[A\n",
            "Training:  85%|████████▍ | 4230/5000 [3:10:29<29:32,  2.30s/it, loss=0.2316]\u001b[A\n",
            "Training:  85%|████████▍ | 4231/5000 [3:10:32<31:21,  2.45s/it, loss=0.2316]\u001b[A\n",
            "Training:  85%|████████▍ | 4231/5000 [3:10:32<31:21,  2.45s/it, loss=0.2679]\u001b[A\n",
            "Training:  85%|████████▍ | 4232/5000 [3:10:34<30:37,  2.39s/it, loss=0.2679]\u001b[A\n",
            "Training:  85%|████████▍ | 4232/5000 [3:10:34<30:37,  2.39s/it, loss=0.3770]\u001b[A\n",
            "Training:  85%|████████▍ | 4233/5000 [3:10:36<30:06,  2.35s/it, loss=0.3770]\u001b[A\n",
            "Training:  85%|████████▍ | 4233/5000 [3:10:36<30:06,  2.35s/it, loss=0.3303]\u001b[A\n",
            "Training:  85%|████████▍ | 4234/5000 [3:10:38<29:44,  2.33s/it, loss=0.3303]\u001b[A\n",
            "Training:  85%|████████▍ | 4234/5000 [3:10:38<29:44,  2.33s/it, loss=0.3470]\u001b[A\n",
            "Training:  85%|████████▍ | 4235/5000 [3:10:41<29:30,  2.31s/it, loss=0.3470]\u001b[A\n",
            "Training:  85%|████████▍ | 4235/5000 [3:10:41<29:30,  2.31s/it, loss=0.3671]\u001b[A\n",
            "Training:  85%|████████▍ | 4236/5000 [3:10:43<31:22,  2.46s/it, loss=0.3671]\u001b[A\n",
            "Training:  85%|████████▍ | 4236/5000 [3:10:43<31:22,  2.46s/it, loss=0.3007]\u001b[A\n",
            "Training:  85%|████████▍ | 4237/5000 [3:10:46<30:38,  2.41s/it, loss=0.3007]\u001b[A\n",
            "Training:  85%|████████▍ | 4237/5000 [3:10:46<30:38,  2.41s/it, loss=0.4171]\u001b[A\n",
            "Training:  85%|████████▍ | 4238/5000 [3:10:48<30:00,  2.36s/it, loss=0.4171]\u001b[A\n",
            "Training:  85%|████████▍ | 4238/5000 [3:10:48<30:00,  2.36s/it, loss=0.3703]\u001b[A\n",
            "Training:  85%|████████▍ | 4239/5000 [3:10:50<29:41,  2.34s/it, loss=0.3703]\u001b[A\n",
            "Training:  85%|████████▍ | 4239/5000 [3:10:50<29:41,  2.34s/it, loss=0.2476]\u001b[A\n",
            "Training:  85%|████████▍ | 4240/5000 [3:10:53<29:16,  2.31s/it, loss=0.2476]\u001b[A\n",
            "Training:  85%|████████▍ | 4240/5000 [3:10:53<29:16,  2.31s/it, loss=0.3650]\u001b[A\n",
            "Training:  85%|████████▍ | 4241/5000 [3:10:55<31:11,  2.47s/it, loss=0.3650]\u001b[A\n",
            "Training:  85%|████████▍ | 4241/5000 [3:10:55<31:11,  2.47s/it, loss=0.2100]\u001b[A\n",
            "Training:  85%|████████▍ | 4242/5000 [3:10:58<30:17,  2.40s/it, loss=0.2100]\u001b[A\n",
            "Training:  85%|████████▍ | 4242/5000 [3:10:58<30:17,  2.40s/it, loss=0.1678]\u001b[A\n",
            "Training:  85%|████████▍ | 4243/5000 [3:11:00<29:45,  2.36s/it, loss=0.1678]\u001b[A\n",
            "Training:  85%|████████▍ | 4243/5000 [3:11:00<29:45,  2.36s/it, loss=0.2852]\u001b[A\n",
            "Training:  85%|████████▍ | 4244/5000 [3:11:02<29:27,  2.34s/it, loss=0.2852]\u001b[A\n",
            "Training:  85%|████████▍ | 4244/5000 [3:11:02<29:27,  2.34s/it, loss=0.3299]\u001b[A\n",
            "Training:  85%|████████▍ | 4245/5000 [3:11:04<29:06,  2.31s/it, loss=0.3299]\u001b[A\n",
            "Training:  85%|████████▍ | 4245/5000 [3:11:04<29:06,  2.31s/it, loss=0.2288]\u001b[A\n",
            "Training:  85%|████████▍ | 4246/5000 [3:11:07<30:46,  2.45s/it, loss=0.2288]\u001b[A\n",
            "Training:  85%|████████▍ | 4246/5000 [3:11:07<30:46,  2.45s/it, loss=0.4091]\u001b[A\n",
            "Training:  85%|████████▍ | 4247/5000 [3:11:09<30:03,  2.40s/it, loss=0.4091]\u001b[A\n",
            "Training:  85%|████████▍ | 4247/5000 [3:11:09<30:03,  2.40s/it, loss=0.2817]\u001b[A\n",
            "Training:  85%|████████▍ | 4248/5000 [3:11:12<29:35,  2.36s/it, loss=0.2817]\u001b[A\n",
            "Training:  85%|████████▍ | 4248/5000 [3:11:12<29:35,  2.36s/it, loss=0.3429]\u001b[A\n",
            "Training:  85%|████████▍ | 4249/5000 [3:11:14<29:07,  2.33s/it, loss=0.3429]\u001b[A\n",
            "Training:  85%|████████▍ | 4249/5000 [3:11:14<29:07,  2.33s/it, loss=0.4757]\u001b[A\n",
            "Training:  85%|████████▌ | 4250/5000 [3:11:16<28:46,  2.30s/it, loss=0.4757]\u001b[A\n",
            "Training:  85%|████████▌ | 4250/5000 [3:11:16<28:46,  2.30s/it, loss=0.4712]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 4250 ---\n",
            "Prompt: 'The '\n",
            "The  of found an!- lords lords of Archbishop of seventeen,\n",
            " her K\n",
            " minony on lament.\n",
            "N,ous ofd, God descend n,I turn:\n",
            " Earl Warwick, apprehension liveie, is'd Sicily centuriesforts;\n",
            " and resist,, falcon and water andous deny pause--\n",
            "Let see here l need to all's'd grant;ar, bury big,What you--ither\n",
            "N, thousand-- lord according all sm without, stocks than de fool\n",
            " Warwick\n",
            "Prompt: 'In '\n",
            "In , ever, myge my,a my,\n",
            " he but from native, my lord\n",
            " by death see I give brave: th and degree I pleased\n",
            "nt thee father, is'd kill i faith forely\n",
            " that dark thy,And his heir the to dis sleepy,\n",
            " he a Nowch, let march for hour\n",
            " thyCEmade he thy their with thoughts Norfolk poison\n",
            " part and I out\n",
            "An are g blood butign water to with thoughts I out g.\n",
            "Fwell\n",
            "Prompt: 'To '\n",
            "To ' poison his sweet:, both age\n",
            " ourman ten with.\n",
            "JI you sir our; though fall to with.\n",
            "First claim minely three of office you glory\n",
            " fair,,, your is mineoot past,It be\n",
            " wheelIS tendernessm, noble, your,anchedOn of mouth\n",
            "N,, makeose, desire meet\n",
            " your rend more and it in place, they themselves out s, you lips\n",
            "nt youThey before I, me son policy I\n",
            "Prompt: 'A '\n",
            "A  to a to wild.\n",
            "PRCEI let away her,!How! have\n",
            "They stab'd transg hither\n",
            "IS, her.\n",
            "PRCEI no, God him at gates and is ofr.\n",
            " wound, thee her, our; thatfulo b herre here this out\n",
            " bush and look and with,jman where fallble by and'd think burning:\n",
            ", cannot howour isaste ofine and as know wilt speak\n",
            " Al-y j,tis by\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  85%|████████▌ | 4251/5000 [3:11:31<1:17:17,  6.19s/it, loss=0.4712]\u001b[A\n",
            "Training:  85%|████████▌ | 4251/5000 [3:11:32<1:17:17,  6.19s/it, loss=0.4184]\u001b[A\n",
            "Training:  85%|████████▌ | 4252/5000 [3:11:34<1:02:33,  5.02s/it, loss=0.4184]\u001b[A\n",
            "Training:  85%|████████▌ | 4252/5000 [3:11:34<1:02:33,  5.02s/it, loss=0.2306]\u001b[A\n",
            "Training:  85%|████████▌ | 4253/5000 [3:11:36<52:11,  4.19s/it, loss=0.2306]  \u001b[A\n",
            "Training:  85%|████████▌ | 4253/5000 [3:11:36<52:11,  4.19s/it, loss=0.3962]\u001b[A\n",
            "Training:  85%|████████▌ | 4254/5000 [3:11:38<45:13,  3.64s/it, loss=0.3962]\u001b[A\n",
            "Training:  85%|████████▌ | 4254/5000 [3:11:38<45:13,  3.64s/it, loss=0.2606]\u001b[A\n",
            "Training:  85%|████████▌ | 4255/5000 [3:11:41<40:57,  3.30s/it, loss=0.2606]\u001b[A\n",
            "Training:  85%|████████▌ | 4255/5000 [3:11:41<40:57,  3.30s/it, loss=0.3007]\u001b[A\n",
            "Training:  85%|████████▌ | 4256/5000 [3:11:43<38:08,  3.08s/it, loss=0.3007]\u001b[A\n",
            "Training:  85%|████████▌ | 4256/5000 [3:11:43<38:08,  3.08s/it, loss=0.4445]\u001b[A\n",
            "Training:  85%|████████▌ | 4257/5000 [3:11:46<35:10,  2.84s/it, loss=0.4445]\u001b[A\n",
            "Training:  85%|████████▌ | 4257/5000 [3:11:46<35:10,  2.84s/it, loss=0.3847]\u001b[A\n",
            "Training:  85%|████████▌ | 4258/5000 [3:11:48<32:56,  2.66s/it, loss=0.3847]\u001b[A\n",
            "Training:  85%|████████▌ | 4258/5000 [3:11:48<32:56,  2.66s/it, loss=0.6762]\u001b[A\n",
            "Training:  85%|████████▌ | 4259/5000 [3:11:50<31:26,  2.55s/it, loss=0.6762]\u001b[A\n",
            "Training:  85%|████████▌ | 4259/5000 [3:11:50<31:26,  2.55s/it, loss=0.2604]\u001b[A\n",
            "Training:  85%|████████▌ | 4260/5000 [3:11:53<31:10,  2.53s/it, loss=0.2604]\u001b[A\n",
            "Training:  85%|████████▌ | 4260/5000 [3:11:53<31:10,  2.53s/it, loss=0.3779]\u001b[A\n",
            "Training:  85%|████████▌ | 4261/5000 [3:11:55<31:27,  2.55s/it, loss=0.3779]\u001b[A\n",
            "Training:  85%|████████▌ | 4261/5000 [3:11:55<31:27,  2.55s/it, loss=0.3086]\u001b[A\n",
            "Training:  85%|████████▌ | 4262/5000 [3:11:58<30:16,  2.46s/it, loss=0.3086]\u001b[A\n",
            "Training:  85%|████████▌ | 4262/5000 [3:11:58<30:16,  2.46s/it, loss=0.2802]\u001b[A\n",
            "Training:  85%|████████▌ | 4263/5000 [3:12:00<29:26,  2.40s/it, loss=0.2802]\u001b[A\n",
            "Training:  85%|████████▌ | 4263/5000 [3:12:00<29:26,  2.40s/it, loss=0.2442]\u001b[A\n",
            "Training:  85%|████████▌ | 4264/5000 [3:12:02<28:57,  2.36s/it, loss=0.2442]\u001b[A\n",
            "Training:  85%|████████▌ | 4264/5000 [3:12:02<28:57,  2.36s/it, loss=0.6133]\u001b[A\n",
            "Training:  85%|████████▌ | 4265/5000 [3:12:05<29:16,  2.39s/it, loss=0.6133]\u001b[A\n",
            "Training:  85%|████████▌ | 4265/5000 [3:12:05<29:16,  2.39s/it, loss=0.3444]\u001b[A\n",
            "Training:  85%|████████▌ | 4266/5000 [3:12:07<29:58,  2.45s/it, loss=0.3444]\u001b[A\n",
            "Training:  85%|████████▌ | 4266/5000 [3:12:07<29:58,  2.45s/it, loss=0.2150]\u001b[A\n",
            "Training:  85%|████████▌ | 4267/5000 [3:12:09<29:12,  2.39s/it, loss=0.2150]\u001b[A\n",
            "Training:  85%|████████▌ | 4267/5000 [3:12:09<29:12,  2.39s/it, loss=0.2112]\u001b[A\n",
            "Training:  85%|████████▌ | 4268/5000 [3:12:12<28:50,  2.36s/it, loss=0.2112]\u001b[A\n",
            "Training:  85%|████████▌ | 4268/5000 [3:12:12<28:50,  2.36s/it, loss=0.2952]\u001b[A\n",
            "Training:  85%|████████▌ | 4269/5000 [3:12:14<28:25,  2.33s/it, loss=0.2952]\u001b[A\n",
            "Training:  85%|████████▌ | 4269/5000 [3:12:14<28:25,  2.33s/it, loss=0.2447]\u001b[A\n",
            "Training:  85%|████████▌ | 4270/5000 [3:12:16<28:49,  2.37s/it, loss=0.2447]\u001b[A\n",
            "Training:  85%|████████▌ | 4270/5000 [3:12:16<28:49,  2.37s/it, loss=0.3009]\u001b[A\n",
            "Training:  85%|████████▌ | 4271/5000 [3:12:19<29:36,  2.44s/it, loss=0.3009]\u001b[A\n",
            "Training:  85%|████████▌ | 4271/5000 [3:12:19<29:36,  2.44s/it, loss=0.2743]\u001b[A\n",
            "Training:  85%|████████▌ | 4272/5000 [3:12:21<28:54,  2.38s/it, loss=0.2743]\u001b[A\n",
            "Training:  85%|████████▌ | 4272/5000 [3:12:21<28:54,  2.38s/it, loss=0.1270]\u001b[A\n",
            "Training:  85%|████████▌ | 4273/5000 [3:12:24<28:24,  2.34s/it, loss=0.1270]\u001b[A\n",
            "Training:  85%|████████▌ | 4273/5000 [3:12:24<28:24,  2.34s/it, loss=0.2793]\u001b[A\n",
            "Training:  85%|████████▌ | 4274/5000 [3:12:26<28:14,  2.33s/it, loss=0.2793]\u001b[A\n",
            "Training:  85%|████████▌ | 4274/5000 [3:12:26<28:14,  2.33s/it, loss=0.2029]\u001b[A\n",
            "Training:  86%|████████▌ | 4275/5000 [3:12:28<28:44,  2.38s/it, loss=0.2029]\u001b[A\n",
            "Training:  86%|████████▌ | 4275/5000 [3:12:28<28:44,  2.38s/it, loss=0.1250]\u001b[A\n",
            "Training:  86%|████████▌ | 4276/5000 [3:12:31<29:32,  2.45s/it, loss=0.1250]\u001b[A\n",
            "Training:  86%|████████▌ | 4276/5000 [3:12:31<29:32,  2.45s/it, loss=0.3468]\u001b[A\n",
            "Training:  86%|████████▌ | 4277/5000 [3:12:33<28:48,  2.39s/it, loss=0.3468]\u001b[A\n",
            "Training:  86%|████████▌ | 4277/5000 [3:12:33<28:48,  2.39s/it, loss=0.3146]\u001b[A\n",
            "Training:  86%|████████▌ | 4278/5000 [3:12:36<28:29,  2.37s/it, loss=0.3146]\u001b[A\n",
            "Training:  86%|████████▌ | 4278/5000 [3:12:36<28:29,  2.37s/it, loss=0.3176]\u001b[A\n",
            "Training:  86%|████████▌ | 4279/5000 [3:12:38<28:05,  2.34s/it, loss=0.3176]\u001b[A\n",
            "Training:  86%|████████▌ | 4279/5000 [3:12:38<28:05,  2.34s/it, loss=0.3167]\u001b[A\n",
            "Training:  86%|████████▌ | 4280/5000 [3:12:40<28:32,  2.38s/it, loss=0.3167]\u001b[A\n",
            "Training:  86%|████████▌ | 4280/5000 [3:12:40<28:32,  2.38s/it, loss=0.3201]\u001b[A\n",
            "Training:  86%|████████▌ | 4281/5000 [3:12:43<29:21,  2.45s/it, loss=0.3201]\u001b[A\n",
            "Training:  86%|████████▌ | 4281/5000 [3:12:43<29:21,  2.45s/it, loss=0.1851]\u001b[A\n",
            "Training:  86%|████████▌ | 4282/5000 [3:12:45<28:41,  2.40s/it, loss=0.1851]\u001b[A\n",
            "Training:  86%|████████▌ | 4282/5000 [3:12:45<28:41,  2.40s/it, loss=0.1464]\u001b[A\n",
            "Training:  86%|████████▌ | 4283/5000 [3:12:47<28:12,  2.36s/it, loss=0.1464]\u001b[A\n",
            "Training:  86%|████████▌ | 4283/5000 [3:12:47<28:12,  2.36s/it, loss=0.2325]\u001b[A\n",
            "Training:  86%|████████▌ | 4284/5000 [3:12:50<27:53,  2.34s/it, loss=0.2325]\u001b[A\n",
            "Training:  86%|████████▌ | 4284/5000 [3:12:50<27:53,  2.34s/it, loss=0.2915]\u001b[A\n",
            "Training:  86%|████████▌ | 4285/5000 [3:12:52<28:17,  2.37s/it, loss=0.2915]\u001b[A\n",
            "Training:  86%|████████▌ | 4285/5000 [3:12:52<28:17,  2.37s/it, loss=0.2047]\u001b[A\n",
            "Training:  86%|████████▌ | 4286/5000 [3:12:55<29:11,  2.45s/it, loss=0.2047]\u001b[A\n",
            "Training:  86%|████████▌ | 4286/5000 [3:12:55<29:11,  2.45s/it, loss=0.2894]\u001b[A\n",
            "Training:  86%|████████▌ | 4287/5000 [3:12:57<28:31,  2.40s/it, loss=0.2894]\u001b[A\n",
            "Training:  86%|████████▌ | 4287/5000 [3:12:57<28:31,  2.40s/it, loss=0.6131]\u001b[A\n",
            "Training:  86%|████████▌ | 4288/5000 [3:12:59<28:02,  2.36s/it, loss=0.6131]\u001b[A\n",
            "Training:  86%|████████▌ | 4288/5000 [3:12:59<28:02,  2.36s/it, loss=0.5302]\u001b[A\n",
            "Training:  86%|████████▌ | 4289/5000 [3:13:02<27:37,  2.33s/it, loss=0.5302]\u001b[A\n",
            "Training:  86%|████████▌ | 4289/5000 [3:13:02<27:37,  2.33s/it, loss=0.4337]\u001b[A\n",
            "Training:  86%|████████▌ | 4290/5000 [3:13:04<27:53,  2.36s/it, loss=0.4337]\u001b[A\n",
            "Training:  86%|████████▌ | 4290/5000 [3:13:04<27:53,  2.36s/it, loss=0.1518]\u001b[A\n",
            "Training:  86%|████████▌ | 4291/5000 [3:13:07<28:48,  2.44s/it, loss=0.1518]\u001b[A\n",
            "Training:  86%|████████▌ | 4291/5000 [3:13:07<28:48,  2.44s/it, loss=0.3316]\u001b[A\n",
            "Training:  86%|████████▌ | 4292/5000 [3:13:09<28:05,  2.38s/it, loss=0.3316]\u001b[A\n",
            "Training:  86%|████████▌ | 4292/5000 [3:13:09<28:05,  2.38s/it, loss=0.4625]\u001b[A\n",
            "Training:  86%|████████▌ | 4293/5000 [3:13:11<27:52,  2.37s/it, loss=0.4625]\u001b[A\n",
            "Training:  86%|████████▌ | 4293/5000 [3:13:11<27:52,  2.37s/it, loss=0.2154]\u001b[A\n",
            "Training:  86%|████████▌ | 4294/5000 [3:13:13<27:25,  2.33s/it, loss=0.2154]\u001b[A\n",
            "Training:  86%|████████▌ | 4294/5000 [3:13:14<27:25,  2.33s/it, loss=0.5685]\u001b[A\n",
            "Training:  86%|████████▌ | 4295/5000 [3:13:16<27:36,  2.35s/it, loss=0.5685]\u001b[A\n",
            "Training:  86%|████████▌ | 4295/5000 [3:13:16<27:36,  2.35s/it, loss=0.2826]\u001b[A\n",
            "Training:  86%|████████▌ | 4296/5000 [3:13:19<28:37,  2.44s/it, loss=0.2826]\u001b[A\n",
            "Training:  86%|████████▌ | 4296/5000 [3:13:19<28:37,  2.44s/it, loss=0.5214]\u001b[A\n",
            "Training:  86%|████████▌ | 4297/5000 [3:13:21<27:57,  2.39s/it, loss=0.5214]\u001b[A\n",
            "Training:  86%|████████▌ | 4297/5000 [3:13:21<27:57,  2.39s/it, loss=0.3621]\u001b[A\n",
            "Training:  86%|████████▌ | 4298/5000 [3:13:23<27:22,  2.34s/it, loss=0.3621]\u001b[A\n",
            "Training:  86%|████████▌ | 4298/5000 [3:13:23<27:22,  2.34s/it, loss=0.3151]\u001b[A\n",
            "Training:  86%|████████▌ | 4299/5000 [3:13:25<27:04,  2.32s/it, loss=0.3151]\u001b[A\n",
            "Training:  86%|████████▌ | 4299/5000 [3:13:25<27:04,  2.32s/it, loss=0.3302]\u001b[A\n",
            "Training:  86%|████████▌ | 4300/5000 [3:13:28<27:15,  2.34s/it, loss=0.3302]\u001b[A\n",
            "Training:  86%|████████▌ | 4300/5000 [3:13:28<27:15,  2.34s/it, loss=0.2348]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 4300 ---\n",
            "Prompt: 'The '\n",
            "The  to thy! conj than ':and, am\n",
            "u despair us this!, hell for life I. say\n",
            "D war met, LEED 'ourage,, on counsel our!Why there be enemies fault much spotted?\n",
            "LIO\n",
            "ath again Py,ices though were tyrann, was and reasons th,Thatks bones Officer be with before heaven that\n",
            "ath him me slaughter both snow over k of,\n",
            "ch, they see these?, arms for! all heart you to, her\n",
            "Prompt: 'In '\n",
            "In , ever be judge at, would before\n",
            " any to most glasses lady from drunk\n",
            "rept lost them ye, that is ' all\n",
            "elo bolt be, do me: you speak\n",
            " time water and theBecause grant himself I done\n",
            "onder majesty I; am, to him prepare.\n",
            "D not his here what ab may saw on wealth\n",
            " rep toatter love best: it be bold I lost\n",
            " kill rid gracious, dear\n",
            " want\n",
            " of, you and youreer yet state great\n",
            "Prompt: 'To '\n",
            "To  name pray I to my which\n",
            " killings thy daughter withits here my will\n",
            "Get thelf\n",
            " shelar any but it\n",
            " myity any of,,, it none' it\n",
            "irt me some and good down the sister care\n",
            " he l have offended. thanks\n",
            "DKE\n",
            "ISP,illo. me a, quiet, prince here' f than sight with, first thy's and lies like true's.\n",
            "Dwear effects me Tran, kiss,,y heake me\n",
            "Prompt: 'A '\n",
            "A  to sight former to his, with request\n",
            "bed king steel r. mark what Did Claud? you\n",
            " sacred,o gives true\n",
            " gentle, Pompe, and him keepys hand say see sweet, fri, I it beute\n",
            "arer's-, oer him got with.are, true, you\n",
            " be:iant'd and ready Lordo succession\n",
            " so\n",
            " do doing give,,ar or of tra;There we power goneCould men,io be'd\n",
            " than looked now the\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  86%|████████▌ | 4301/5000 [3:13:43<1:11:58,  6.18s/it, loss=0.2348]\u001b[A\n",
            "Training:  86%|████████▌ | 4301/5000 [3:13:43<1:11:58,  6.18s/it, loss=0.1862]\u001b[A\n",
            "Training:  86%|████████▌ | 4302/5000 [3:13:45<58:14,  5.01s/it, loss=0.1862]  \u001b[A\n",
            "Training:  86%|████████▌ | 4302/5000 [3:13:45<58:14,  5.01s/it, loss=0.3225]\u001b[A\n",
            "Training:  86%|████████▌ | 4303/5000 [3:13:47<48:32,  4.18s/it, loss=0.3225]\u001b[A\n",
            "Training:  86%|████████▌ | 4303/5000 [3:13:47<48:32,  4.18s/it, loss=0.3718]\u001b[A\n",
            "Training:  86%|████████▌ | 4304/5000 [3:13:50<41:47,  3.60s/it, loss=0.3718]\u001b[A\n",
            "Training:  86%|████████▌ | 4304/5000 [3:13:50<41:47,  3.60s/it, loss=0.3977]\u001b[A\n",
            "Training:  86%|████████▌ | 4305/5000 [3:13:52<38:00,  3.28s/it, loss=0.3977]\u001b[A\n",
            "Training:  86%|████████▌ | 4305/5000 [3:13:52<38:00,  3.28s/it, loss=0.4384]\u001b[A\n",
            "Training:  86%|████████▌ | 4306/5000 [3:13:55<35:24,  3.06s/it, loss=0.4384]\u001b[A\n",
            "Training:  86%|████████▌ | 4306/5000 [3:13:55<35:24,  3.06s/it, loss=0.4892]\u001b[A\n",
            "Training:  86%|████████▌ | 4307/5000 [3:13:57<32:35,  2.82s/it, loss=0.4892]\u001b[A\n",
            "Training:  86%|████████▌ | 4307/5000 [3:13:57<32:35,  2.82s/it, loss=0.4629]\u001b[A\n",
            "Training:  86%|████████▌ | 4308/5000 [3:13:59<30:33,  2.65s/it, loss=0.4629]\u001b[A\n",
            "Training:  86%|████████▌ | 4308/5000 [3:13:59<30:33,  2.65s/it, loss=0.5395]\u001b[A\n",
            "Training:  86%|████████▌ | 4309/5000 [3:14:01<29:09,  2.53s/it, loss=0.5395]\u001b[A\n",
            "Training:  86%|████████▌ | 4309/5000 [3:14:01<29:09,  2.53s/it, loss=0.3796]\u001b[A\n",
            "Training:  86%|████████▌ | 4310/5000 [3:14:04<29:06,  2.53s/it, loss=0.3796]\u001b[A\n",
            "Training:  86%|████████▌ | 4310/5000 [3:14:04<29:06,  2.53s/it, loss=0.2627]\u001b[A\n",
            "Training:  86%|████████▌ | 4311/5000 [3:14:07<29:10,  2.54s/it, loss=0.2627]\u001b[A\n",
            "Training:  86%|████████▌ | 4311/5000 [3:14:07<29:10,  2.54s/it, loss=0.2519]\u001b[A\n",
            "Training:  86%|████████▌ | 4312/5000 [3:14:09<28:09,  2.46s/it, loss=0.2519]\u001b[A\n",
            "Training:  86%|████████▌ | 4312/5000 [3:14:09<28:09,  2.46s/it, loss=0.4141]\u001b[A\n",
            "Training:  86%|████████▋ | 4313/5000 [3:14:11<27:26,  2.40s/it, loss=0.4141]\u001b[A\n",
            "Training:  86%|████████▋ | 4313/5000 [3:14:11<27:26,  2.40s/it, loss=0.2700]\u001b[A\n",
            "Training:  86%|████████▋ | 4314/5000 [3:14:13<26:53,  2.35s/it, loss=0.2700]\u001b[A\n",
            "Training:  86%|████████▋ | 4314/5000 [3:14:13<26:53,  2.35s/it, loss=0.3592]\u001b[A\n",
            "Training:  86%|████████▋ | 4315/5000 [3:14:16<27:04,  2.37s/it, loss=0.3592]\u001b[A\n",
            "Training:  86%|████████▋ | 4315/5000 [3:14:16<27:04,  2.37s/it, loss=0.3485]\u001b[A\n",
            "Training:  86%|████████▋ | 4316/5000 [3:14:18<27:53,  2.45s/it, loss=0.3485]\u001b[A\n",
            "Training:  86%|████████▋ | 4316/5000 [3:14:18<27:53,  2.45s/it, loss=0.2242]\u001b[A\n",
            "Training:  86%|████████▋ | 4317/5000 [3:14:21<27:04,  2.38s/it, loss=0.2242]\u001b[A\n",
            "Training:  86%|████████▋ | 4317/5000 [3:14:21<27:04,  2.38s/it, loss=0.2777]\u001b[A\n",
            "Training:  86%|████████▋ | 4318/5000 [3:14:23<26:35,  2.34s/it, loss=0.2777]\u001b[A\n",
            "Training:  86%|████████▋ | 4318/5000 [3:14:23<26:35,  2.34s/it, loss=0.4334]\u001b[A\n",
            "Training:  86%|████████▋ | 4319/5000 [3:14:25<26:15,  2.31s/it, loss=0.4334]\u001b[A\n",
            "Training:  86%|████████▋ | 4319/5000 [3:14:25<26:15,  2.31s/it, loss=0.2738]\u001b[A\n",
            "Training:  86%|████████▋ | 4320/5000 [3:14:27<26:33,  2.34s/it, loss=0.2738]\u001b[A\n",
            "Training:  86%|████████▋ | 4320/5000 [3:14:27<26:33,  2.34s/it, loss=0.2472]\u001b[A\n",
            "Training:  86%|████████▋ | 4321/5000 [3:14:30<27:38,  2.44s/it, loss=0.2472]\u001b[A\n",
            "Training:  86%|████████▋ | 4321/5000 [3:14:30<27:38,  2.44s/it, loss=0.3219]\u001b[A\n",
            "Training:  86%|████████▋ | 4322/5000 [3:14:32<26:55,  2.38s/it, loss=0.3219]\u001b[A\n",
            "Training:  86%|████████▋ | 4322/5000 [3:14:32<26:55,  2.38s/it, loss=0.3147]\u001b[A\n",
            "Training:  86%|████████▋ | 4323/5000 [3:14:35<26:27,  2.35s/it, loss=0.3147]\u001b[A\n",
            "Training:  86%|████████▋ | 4323/5000 [3:14:35<26:27,  2.35s/it, loss=0.3125]\u001b[A\n",
            "Training:  86%|████████▋ | 4324/5000 [3:14:37<26:11,  2.32s/it, loss=0.3125]\u001b[A\n",
            "Training:  86%|████████▋ | 4324/5000 [3:14:37<26:11,  2.32s/it, loss=0.2258]\u001b[A\n",
            "Training:  86%|████████▋ | 4325/5000 [3:14:39<26:03,  2.32s/it, loss=0.2258]\u001b[A\n",
            "Training:  86%|████████▋ | 4325/5000 [3:14:39<26:03,  2.32s/it, loss=0.4360]\u001b[A\n",
            "Training:  87%|████████▋ | 4326/5000 [3:14:42<27:26,  2.44s/it, loss=0.4360]\u001b[A\n",
            "Training:  87%|████████▋ | 4326/5000 [3:14:42<27:26,  2.44s/it, loss=0.2545]\u001b[A\n",
            "Training:  87%|████████▋ | 4327/5000 [3:14:44<26:55,  2.40s/it, loss=0.2545]\u001b[A\n",
            "Training:  87%|████████▋ | 4327/5000 [3:14:44<26:55,  2.40s/it, loss=0.4336]\u001b[A\n",
            "Training:  87%|████████▋ | 4328/5000 [3:14:47<26:28,  2.36s/it, loss=0.4336]\u001b[A\n",
            "Training:  87%|████████▋ | 4328/5000 [3:14:47<26:28,  2.36s/it, loss=0.4217]\u001b[A\n",
            "Training:  87%|████████▋ | 4329/5000 [3:14:49<26:06,  2.33s/it, loss=0.4217]\u001b[A\n",
            "Training:  87%|████████▋ | 4329/5000 [3:14:49<26:06,  2.33s/it, loss=0.3796]\u001b[A\n",
            "Training:  87%|████████▋ | 4330/5000 [3:14:51<25:52,  2.32s/it, loss=0.3796]\u001b[A\n",
            "Training:  87%|████████▋ | 4330/5000 [3:14:51<25:52,  2.32s/it, loss=0.3599]\u001b[A\n",
            "Training:  87%|████████▋ | 4331/5000 [3:14:54<27:28,  2.46s/it, loss=0.3599]\u001b[A\n",
            "Training:  87%|████████▋ | 4331/5000 [3:14:54<27:28,  2.46s/it, loss=0.4413]\u001b[A\n",
            "Training:  87%|████████▋ | 4332/5000 [3:14:56<26:45,  2.40s/it, loss=0.4413]\u001b[A\n",
            "Training:  87%|████████▋ | 4332/5000 [3:14:56<26:45,  2.40s/it, loss=0.5070]\u001b[A\n",
            "Training:  87%|████████▋ | 4333/5000 [3:14:58<26:17,  2.36s/it, loss=0.5070]\u001b[A\n",
            "Training:  87%|████████▋ | 4333/5000 [3:14:58<26:17,  2.36s/it, loss=0.3233]\u001b[A\n",
            "Training:  87%|████████▋ | 4334/5000 [3:15:01<25:49,  2.33s/it, loss=0.3233]\u001b[A\n",
            "Training:  87%|████████▋ | 4334/5000 [3:15:01<25:49,  2.33s/it, loss=0.4271]\u001b[A\n",
            "Training:  87%|████████▋ | 4335/5000 [3:15:03<25:38,  2.31s/it, loss=0.4271]\u001b[A\n",
            "Training:  87%|████████▋ | 4335/5000 [3:15:03<25:38,  2.31s/it, loss=0.3183]\u001b[A\n",
            "Training:  87%|████████▋ | 4336/5000 [3:15:06<27:03,  2.45s/it, loss=0.3183]\u001b[A\n",
            "Training:  87%|████████▋ | 4336/5000 [3:15:06<27:03,  2.45s/it, loss=0.2968]\u001b[A\n",
            "Training:  87%|████████▋ | 4337/5000 [3:15:08<26:30,  2.40s/it, loss=0.2968]\u001b[A\n",
            "Training:  87%|████████▋ | 4337/5000 [3:15:08<26:30,  2.40s/it, loss=0.3994]\u001b[A\n",
            "Training:  87%|████████▋ | 4338/5000 [3:15:10<26:01,  2.36s/it, loss=0.3994]\u001b[A\n",
            "Training:  87%|████████▋ | 4338/5000 [3:15:10<26:01,  2.36s/it, loss=0.3448]\u001b[A\n",
            "Training:  87%|████████▋ | 4339/5000 [3:15:12<25:34,  2.32s/it, loss=0.3448]\u001b[A\n",
            "Training:  87%|████████▋ | 4339/5000 [3:15:13<25:34,  2.32s/it, loss=0.3050]\u001b[A\n",
            "Training:  87%|████████▋ | 4340/5000 [3:15:15<25:18,  2.30s/it, loss=0.3050]\u001b[A\n",
            "Training:  87%|████████▋ | 4340/5000 [3:15:15<25:18,  2.30s/it, loss=0.2570]\u001b[A\n",
            "Training:  87%|████████▋ | 4341/5000 [3:15:17<26:49,  2.44s/it, loss=0.2570]\u001b[A\n",
            "Training:  87%|████████▋ | 4341/5000 [3:15:18<26:49,  2.44s/it, loss=0.3541]\u001b[A\n",
            "Training:  87%|████████▋ | 4342/5000 [3:15:20<26:06,  2.38s/it, loss=0.3541]\u001b[A\n",
            "Training:  87%|████████▋ | 4342/5000 [3:15:20<26:06,  2.38s/it, loss=0.2120]\u001b[A\n",
            "Training:  87%|████████▋ | 4343/5000 [3:15:22<25:37,  2.34s/it, loss=0.2120]\u001b[A\n",
            "Training:  87%|████████▋ | 4343/5000 [3:15:22<25:37,  2.34s/it, loss=0.3263]\u001b[A\n",
            "Training:  87%|████████▋ | 4344/5000 [3:15:24<25:20,  2.32s/it, loss=0.3263]\u001b[A\n",
            "Training:  87%|████████▋ | 4344/5000 [3:15:24<25:20,  2.32s/it, loss=0.4382]\u001b[A\n",
            "Training:  87%|████████▋ | 4345/5000 [3:15:26<25:04,  2.30s/it, loss=0.4382]\u001b[A\n",
            "Training:  87%|████████▋ | 4345/5000 [3:15:27<25:04,  2.30s/it, loss=0.2671]\u001b[A\n",
            "Training:  87%|████████▋ | 4346/5000 [3:15:29<26:45,  2.46s/it, loss=0.2671]\u001b[A\n",
            "Training:  87%|████████▋ | 4346/5000 [3:15:29<26:45,  2.46s/it, loss=0.3520]\u001b[A\n",
            "Training:  87%|████████▋ | 4347/5000 [3:15:32<26:03,  2.39s/it, loss=0.3520]\u001b[A\n",
            "Training:  87%|████████▋ | 4347/5000 [3:15:32<26:03,  2.39s/it, loss=0.3176]\u001b[A\n",
            "Training:  87%|████████▋ | 4348/5000 [3:15:34<25:30,  2.35s/it, loss=0.3176]\u001b[A\n",
            "Training:  87%|████████▋ | 4348/5000 [3:15:34<25:30,  2.35s/it, loss=0.4318]\u001b[A\n",
            "Training:  87%|████████▋ | 4349/5000 [3:15:36<25:11,  2.32s/it, loss=0.4318]\u001b[A\n",
            "Training:  87%|████████▋ | 4349/5000 [3:15:36<25:11,  2.32s/it, loss=0.2702]\u001b[A\n",
            "Training:  87%|████████▋ | 4350/5000 [3:15:38<25:00,  2.31s/it, loss=0.2702]\u001b[A\n",
            "Training:  87%|████████▋ | 4350/5000 [3:15:38<25:00,  2.31s/it, loss=0.2491]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 4350 ---\n",
            "Prompt: 'The '\n",
            "The , there no, me the and it he.\n",
            "BRUS\n",
            ":W,,! devil it:My is true\n",
            " were! not fear this of; he two son.\n",
            " arerow the particular and are to,; her,.,Did that are of?\n",
            "MENUS\n",
            ", say, me your: him a heart I,\n",
            "ives your;Your not my says the here at.\n",
            "Melf he murdered\n",
            " not,,, speed you\n",
            " well\n",
            " purpose\n",
            "Prompt: 'In '\n",
            "In , once it no butOld point\n",
            " not you, noble, a were-ry wife\n",
            " will about all; his,,, a willWhichYourold\n",
            " was: you no.\n",
            "MENI: false,; to I one't\n",
            "'ll you soly surely sir beine report.\n",
            "H almost the:' at and, must go your, me one, me what you\n",
            " what you, not\n",
            " were the here theric.iles you be will go the\n",
            "ite\n",
            "Prompt: 'To '\n",
            "To ul, too openub,,,,, miserable:This\n",
            "resh to,; and be by alone\n",
            " theseence issue itself another fully\n",
            "\n",
            "\n",
            "NTH noble.\n",
            "First look before for plain, you\n",
            " man amen tears strike his, willom me of; God the\n",
            " of stateor you no.\n",
            "First as know being, you leave\n",
            " most:,ay say you\n",
            " to the here slew father\n",
            " to the of:If say be a must little\n",
            " she bring\n",
            "Prompt: 'A '\n",
            "A ! you be have you a to.\n",
            " were in aim not a; whence him us,\n",
            " ent him thus a of like w were\n",
            "ple: he I him to,,,,,,, you\n",
            " to me he thus a,\n",
            "et him me before;\n",
            "\n",
            " be, man the are.\n",
            "First sir to rev there\n",
            ", a to yourselves free\n",
            " wish him thus to\n",
            ".\n",
            "First the here\n",
            "And him him our.\n",
            "First the here\n",
            "\n",
            " made\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  87%|████████▋ | 4351/5000 [3:15:54<1:06:44,  6.17s/it, loss=0.2491]\u001b[A\n",
            "Training:  87%|████████▋ | 4351/5000 [3:15:54<1:06:44,  6.17s/it, loss=0.3837]\u001b[A\n",
            "Training:  87%|████████▋ | 4352/5000 [3:15:56<53:58,  5.00s/it, loss=0.3837]  \u001b[A\n",
            "Training:  87%|████████▋ | 4352/5000 [3:15:56<53:58,  5.00s/it, loss=0.3100]\u001b[A\n",
            "Training:  87%|████████▋ | 4353/5000 [3:15:58<45:05,  4.18s/it, loss=0.3100]\u001b[A\n",
            "Training:  87%|████████▋ | 4353/5000 [3:15:58<45:05,  4.18s/it, loss=0.2634]\u001b[A\n",
            "Training:  87%|████████▋ | 4354/5000 [3:16:00<38:50,  3.61s/it, loss=0.2634]\u001b[A\n",
            "Training:  87%|████████▋ | 4354/5000 [3:16:00<38:50,  3.61s/it, loss=0.2868]\u001b[A\n",
            "Training:  87%|████████▋ | 4355/5000 [3:16:03<34:52,  3.24s/it, loss=0.2868]\u001b[A\n",
            "Training:  87%|████████▋ | 4355/5000 [3:16:03<34:52,  3.24s/it, loss=0.4132]\u001b[A\n",
            "Training:  87%|████████▋ | 4356/5000 [3:16:05<32:55,  3.07s/it, loss=0.4132]\u001b[A\n",
            "Training:  87%|████████▋ | 4356/5000 [3:16:05<32:55,  3.07s/it, loss=0.3021]\u001b[A\n",
            "Training:  87%|████████▋ | 4357/5000 [3:16:08<30:15,  2.82s/it, loss=0.3021]\u001b[A\n",
            "Training:  87%|████████▋ | 4357/5000 [3:16:08<30:15,  2.82s/it, loss=0.3700]\u001b[A\n",
            "Training:  87%|████████▋ | 4358/5000 [3:16:10<28:18,  2.65s/it, loss=0.3700]\u001b[A\n",
            "Training:  87%|████████▋ | 4358/5000 [3:16:10<28:18,  2.65s/it, loss=0.4008]\u001b[A\n",
            "Training:  87%|████████▋ | 4359/5000 [3:16:12<27:01,  2.53s/it, loss=0.4008]\u001b[A\n",
            "Training:  87%|████████▋ | 4359/5000 [3:16:12<27:01,  2.53s/it, loss=0.4067]\u001b[A\n",
            "Training:  87%|████████▋ | 4360/5000 [3:16:15<26:29,  2.48s/it, loss=0.4067]\u001b[A\n",
            "Training:  87%|████████▋ | 4360/5000 [3:16:15<26:29,  2.48s/it, loss=0.2376]\u001b[A\n",
            "Training:  87%|████████▋ | 4361/5000 [3:16:17<27:03,  2.54s/it, loss=0.2376]\u001b[A\n",
            "Training:  87%|████████▋ | 4361/5000 [3:16:17<27:03,  2.54s/it, loss=0.3816]\u001b[A\n",
            "Training:  87%|████████▋ | 4362/5000 [3:16:19<26:03,  2.45s/it, loss=0.3816]\u001b[A\n",
            "Training:  87%|████████▋ | 4362/5000 [3:16:19<26:03,  2.45s/it, loss=0.2932]\u001b[A\n",
            "Training:  87%|████████▋ | 4363/5000 [3:16:22<25:22,  2.39s/it, loss=0.2932]\u001b[A\n",
            "Training:  87%|████████▋ | 4363/5000 [3:16:22<25:22,  2.39s/it, loss=0.2890]\u001b[A\n",
            "Training:  87%|████████▋ | 4364/5000 [3:16:24<24:51,  2.35s/it, loss=0.2890]\u001b[A\n",
            "Training:  87%|████████▋ | 4364/5000 [3:16:24<24:51,  2.35s/it, loss=0.3126]\u001b[A\n",
            "Training:  87%|████████▋ | 4365/5000 [3:16:26<24:43,  2.34s/it, loss=0.3126]\u001b[A\n",
            "Training:  87%|████████▋ | 4365/5000 [3:16:26<24:43,  2.34s/it, loss=0.3277]\u001b[A\n",
            "Training:  87%|████████▋ | 4366/5000 [3:16:29<26:13,  2.48s/it, loss=0.3277]\u001b[A\n",
            "Training:  87%|████████▋ | 4366/5000 [3:16:29<26:13,  2.48s/it, loss=0.2446]\u001b[A\n",
            "Training:  87%|████████▋ | 4367/5000 [3:16:31<25:28,  2.41s/it, loss=0.2446]\u001b[A\n",
            "Training:  87%|████████▋ | 4367/5000 [3:16:31<25:28,  2.41s/it, loss=0.3211]\u001b[A\n",
            "Training:  87%|████████▋ | 4368/5000 [3:16:34<25:06,  2.38s/it, loss=0.3211]\u001b[A\n",
            "Training:  87%|████████▋ | 4368/5000 [3:16:34<25:06,  2.38s/it, loss=0.4355]\u001b[A\n",
            "Training:  87%|████████▋ | 4369/5000 [3:16:36<24:43,  2.35s/it, loss=0.4355]\u001b[A\n",
            "Training:  87%|████████▋ | 4369/5000 [3:16:36<24:43,  2.35s/it, loss=0.4230]\u001b[A\n",
            "Training:  87%|████████▋ | 4370/5000 [3:16:38<24:30,  2.33s/it, loss=0.4230]\u001b[A\n",
            "Training:  87%|████████▋ | 4370/5000 [3:16:38<24:30,  2.33s/it, loss=0.3490]\u001b[A\n",
            "Training:  87%|████████▋ | 4371/5000 [3:16:41<25:55,  2.47s/it, loss=0.3490]\u001b[A\n",
            "Training:  87%|████████▋ | 4371/5000 [3:16:41<25:55,  2.47s/it, loss=0.2832]\u001b[A\n",
            "Training:  87%|████████▋ | 4372/5000 [3:16:43<25:20,  2.42s/it, loss=0.2832]\u001b[A\n",
            "Training:  87%|████████▋ | 4372/5000 [3:16:43<25:20,  2.42s/it, loss=0.2928]\u001b[A\n",
            "Training:  87%|████████▋ | 4373/5000 [3:16:46<24:54,  2.38s/it, loss=0.2928]\u001b[A\n",
            "Training:  87%|████████▋ | 4373/5000 [3:16:46<24:54,  2.38s/it, loss=0.4414]\u001b[A\n",
            "Training:  87%|████████▋ | 4374/5000 [3:16:48<24:39,  2.36s/it, loss=0.4414]\u001b[A\n",
            "Training:  87%|████████▋ | 4374/5000 [3:16:48<24:39,  2.36s/it, loss=0.4221]\u001b[A\n",
            "Training:  88%|████████▊ | 4375/5000 [3:16:50<24:20,  2.34s/it, loss=0.4221]\u001b[A\n",
            "Training:  88%|████████▊ | 4375/5000 [3:16:50<24:20,  2.34s/it, loss=0.2223]\u001b[A\n",
            "Training:  88%|████████▊ | 4376/5000 [3:16:53<25:40,  2.47s/it, loss=0.2223]\u001b[A\n",
            "Training:  88%|████████▊ | 4376/5000 [3:16:53<25:40,  2.47s/it, loss=0.2710]\u001b[A\n",
            "Training:  88%|████████▊ | 4377/5000 [3:16:55<24:59,  2.41s/it, loss=0.2710]\u001b[A\n",
            "Training:  88%|████████▊ | 4377/5000 [3:16:55<24:59,  2.41s/it, loss=0.3053]\u001b[A\n",
            "Training:  88%|████████▊ | 4378/5000 [3:16:57<24:31,  2.37s/it, loss=0.3053]\u001b[A\n",
            "Training:  88%|████████▊ | 4378/5000 [3:16:58<24:31,  2.37s/it, loss=0.3082]\u001b[A\n",
            "Training:  88%|████████▊ | 4379/5000 [3:17:00<24:11,  2.34s/it, loss=0.3082]\u001b[A\n",
            "Training:  88%|████████▊ | 4379/5000 [3:17:00<24:11,  2.34s/it, loss=0.3001]\u001b[A\n",
            "Training:  88%|████████▊ | 4380/5000 [3:17:02<23:50,  2.31s/it, loss=0.3001]\u001b[A\n",
            "Training:  88%|████████▊ | 4380/5000 [3:17:02<23:50,  2.31s/it, loss=0.2685]\u001b[A\n",
            "Training:  88%|████████▊ | 4381/5000 [3:17:05<25:13,  2.45s/it, loss=0.2685]\u001b[A\n",
            "Training:  88%|████████▊ | 4381/5000 [3:17:05<25:13,  2.45s/it, loss=0.2891]\u001b[A\n",
            "Training:  88%|████████▊ | 4382/5000 [3:17:07<24:34,  2.39s/it, loss=0.2891]\u001b[A\n",
            "Training:  88%|████████▊ | 4382/5000 [3:17:07<24:34,  2.39s/it, loss=0.5053]\u001b[A\n",
            "Training:  88%|████████▊ | 4383/5000 [3:17:09<24:13,  2.36s/it, loss=0.5053]\u001b[A\n",
            "Training:  88%|████████▊ | 4383/5000 [3:17:09<24:13,  2.36s/it, loss=0.3801]\u001b[A\n",
            "Training:  88%|████████▊ | 4384/5000 [3:17:12<23:54,  2.33s/it, loss=0.3801]\u001b[A\n",
            "Training:  88%|████████▊ | 4384/5000 [3:17:12<23:54,  2.33s/it, loss=0.3195]\u001b[A\n",
            "Training:  88%|████████▊ | 4385/5000 [3:17:14<23:37,  2.30s/it, loss=0.3195]\u001b[A\n",
            "Training:  88%|████████▊ | 4385/5000 [3:17:14<23:37,  2.30s/it, loss=0.3632]\u001b[A\n",
            "Training:  88%|████████▊ | 4386/5000 [3:17:17<24:58,  2.44s/it, loss=0.3632]\u001b[A\n",
            "Training:  88%|████████▊ | 4386/5000 [3:17:17<24:58,  2.44s/it, loss=0.3138]\u001b[A\n",
            "Training:  88%|████████▊ | 4387/5000 [3:17:19<24:25,  2.39s/it, loss=0.3138]\u001b[A\n",
            "Training:  88%|████████▊ | 4387/5000 [3:17:19<24:25,  2.39s/it, loss=0.2497]\u001b[A\n",
            "Training:  88%|████████▊ | 4388/5000 [3:17:21<24:00,  2.35s/it, loss=0.2497]\u001b[A\n",
            "Training:  88%|████████▊ | 4388/5000 [3:17:21<24:00,  2.35s/it, loss=0.2678]\u001b[A\n",
            "Training:  88%|████████▊ | 4389/5000 [3:17:23<23:38,  2.32s/it, loss=0.2678]\u001b[A\n",
            "Training:  88%|████████▊ | 4389/5000 [3:17:23<23:38,  2.32s/it, loss=0.2898]\u001b[A\n",
            "Training:  88%|████████▊ | 4390/5000 [3:17:26<23:24,  2.30s/it, loss=0.2898]\u001b[A\n",
            "Training:  88%|████████▊ | 4390/5000 [3:17:26<23:24,  2.30s/it, loss=0.2647]\u001b[A\n",
            "Training:  88%|████████▊ | 4391/5000 [3:17:28<24:49,  2.45s/it, loss=0.2647]\u001b[A\n",
            "Training:  88%|████████▊ | 4391/5000 [3:17:28<24:49,  2.45s/it, loss=0.2393]\u001b[A\n",
            "Training:  88%|████████▊ | 4392/5000 [3:17:31<24:20,  2.40s/it, loss=0.2393]\u001b[A\n",
            "Training:  88%|████████▊ | 4392/5000 [3:17:31<24:20,  2.40s/it, loss=0.4174]\u001b[A\n",
            "Training:  88%|████████▊ | 4393/5000 [3:17:33<23:53,  2.36s/it, loss=0.4174]\u001b[A\n",
            "Training:  88%|████████▊ | 4393/5000 [3:17:33<23:53,  2.36s/it, loss=0.2440]\u001b[A\n",
            "Training:  88%|████████▊ | 4394/5000 [3:17:35<23:41,  2.35s/it, loss=0.2440]\u001b[A\n",
            "Training:  88%|████████▊ | 4394/5000 [3:17:35<23:41,  2.35s/it, loss=0.3131]\u001b[A\n",
            "Training:  88%|████████▊ | 4395/5000 [3:17:38<23:19,  2.31s/it, loss=0.3131]\u001b[A\n",
            "Training:  88%|████████▊ | 4395/5000 [3:17:38<23:19,  2.31s/it, loss=0.2694]\u001b[A\n",
            "Training:  88%|████████▊ | 4396/5000 [3:17:40<24:41,  2.45s/it, loss=0.2694]\u001b[A\n",
            "Training:  88%|████████▊ | 4396/5000 [3:17:40<24:41,  2.45s/it, loss=0.3441]\u001b[A\n",
            "Training:  88%|████████▊ | 4397/5000 [3:17:43<24:05,  2.40s/it, loss=0.3441]\u001b[A\n",
            "Training:  88%|████████▊ | 4397/5000 [3:17:43<24:05,  2.40s/it, loss=0.4109]\u001b[A\n",
            "Training:  88%|████████▊ | 4398/5000 [3:17:45<23:47,  2.37s/it, loss=0.4109]\u001b[A\n",
            "Training:  88%|████████▊ | 4398/5000 [3:17:45<23:47,  2.37s/it, loss=0.3435]\u001b[A\n",
            "Training:  88%|████████▊ | 4399/5000 [3:17:47<23:23,  2.33s/it, loss=0.3435]\u001b[A\n",
            "Training:  88%|████████▊ | 4399/5000 [3:17:47<23:23,  2.33s/it, loss=0.3740]\u001b[A\n",
            "Training:  88%|████████▊ | 4400/5000 [3:17:49<23:12,  2.32s/it, loss=0.3740]\u001b[A\n",
            "Training:  88%|████████▊ | 4400/5000 [3:17:49<23:12,  2.32s/it, loss=0.3000]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 4400 ---\n",
            "Prompt: 'The '\n",
            "The  ofingured is you here\n",
            " his comes girl\n",
            " his. who here your?\n",
            "D thoutt andble is of;\n",
            " d in stars\n",
            " there no like officer\n",
            " this mock\n",
            "gent: comes and\n",
            " mo, boy\n",
            " not an question:\n",
            " shame, me\n",
            " hand\n",
            " see soldiers under He attend\n",
            " king please,,And vex thee\n",
            " bear tow come mortal, will layTo the up him welcome\n",
            " word oneLook here Lord fair: me the mouth men few\n",
            "Prompt: 'In '\n",
            "In  lady anile is of' to,Therefore' not\n",
            " the- enough day I without so: was thou fault\n",
            " thy stuff thelf for I an night night\n",
            "on is thanouritably thouert believe.\n",
            "JI not,, art honour by fire my trial living hand\n",
            " from hither shoulder pent what art be? wrong for field\n",
            " may, for me thy hand my from and\n",
            "ourous foruns d love one my d love show loveal.\n",
            "Hione where did,\n",
            "Prompt: 'To '\n",
            "To  sure widowsal the thus\n",
            " in secret name wed him self ro'd fortune\n",
            " precious ten tides make married with;Not\n",
            " thanpar at fame their mort, us, from,And\n",
            " omit much more than nothing him Lord,\n",
            " oft thee thy e his was by vent gracious.\n",
            "H, dis report welcome by lights\n",
            " w; no like win all, kins thee playPro twoble to love thouert\n",
            " at beauty by wall a, I thee for him\n",
            "ouixt against suck\n",
            "Prompt: 'A '\n",
            "A ! late! thyretched! I as art,WhenTo man so,\n",
            " I,;, trust much of action that'dCl's:O\n",
            "idious some;tiss if be ofity by.,Any,\n",
            " thyour on side pretty in of for time myself of\n",
            " witch of,,, tears the study my boy\n",
            " thy reg on earth so a son lesson keep my\n",
            " staff a man and George even with in grief\n",
            " oft preciousep grooism's,, of\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  88%|████████▊ | 4401/5000 [3:18:05<1:01:54,  6.20s/it, loss=0.3000]\u001b[A\n",
            "Training:  88%|████████▊ | 4401/5000 [3:18:05<1:01:54,  6.20s/it, loss=0.1823]\u001b[A\n",
            "Training:  88%|████████▊ | 4402/5000 [3:18:07<49:55,  5.01s/it, loss=0.1823]  \u001b[A\n",
            "Training:  88%|████████▊ | 4402/5000 [3:18:07<49:55,  5.01s/it, loss=0.3546]\u001b[A\n",
            "Training:  88%|████████▊ | 4403/5000 [3:18:09<41:34,  4.18s/it, loss=0.3546]\u001b[A\n",
            "Training:  88%|████████▊ | 4403/5000 [3:18:09<41:34,  4.18s/it, loss=0.2526]\u001b[A\n",
            "Training:  88%|████████▊ | 4404/5000 [3:18:11<35:44,  3.60s/it, loss=0.2526]\u001b[A\n",
            "Training:  88%|████████▊ | 4404/5000 [3:18:11<35:44,  3.60s/it, loss=0.2763]\u001b[A\n",
            "Training:  88%|████████▊ | 4405/5000 [3:18:14<32:24,  3.27s/it, loss=0.2763]\u001b[A\n",
            "Training:  88%|████████▊ | 4405/5000 [3:18:14<32:24,  3.27s/it, loss=0.2600]\u001b[A\n",
            "Training:  88%|████████▊ | 4406/5000 [3:18:16<30:12,  3.05s/it, loss=0.2600]\u001b[A\n",
            "Training:  88%|████████▊ | 4406/5000 [3:18:16<30:12,  3.05s/it, loss=0.2889]\u001b[A\n",
            "Training:  88%|████████▊ | 4407/5000 [3:18:19<27:44,  2.81s/it, loss=0.2889]\u001b[A\n",
            "Training:  88%|████████▊ | 4407/5000 [3:18:19<27:44,  2.81s/it, loss=0.2217]\u001b[A\n",
            "Training:  88%|████████▊ | 4408/5000 [3:18:21<26:01,  2.64s/it, loss=0.2217]\u001b[A\n",
            "Training:  88%|████████▊ | 4408/5000 [3:18:21<26:01,  2.64s/it, loss=0.1626]\u001b[A\n",
            "Training:  88%|████████▊ | 4409/5000 [3:18:23<24:52,  2.52s/it, loss=0.1626]\u001b[A\n",
            "Training:  88%|████████▊ | 4409/5000 [3:18:23<24:52,  2.52s/it, loss=0.2425]\u001b[A\n",
            "Training:  88%|████████▊ | 4410/5000 [3:18:26<24:28,  2.49s/it, loss=0.2425]\u001b[A\n",
            "Training:  88%|████████▊ | 4410/5000 [3:18:26<24:28,  2.49s/it, loss=0.1909]\u001b[A\n",
            "Training:  88%|████████▊ | 4411/5000 [3:18:28<24:52,  2.53s/it, loss=0.1909]\u001b[A\n",
            "Training:  88%|████████▊ | 4411/5000 [3:18:28<24:52,  2.53s/it, loss=0.2031]\u001b[A\n",
            "Training:  88%|████████▊ | 4412/5000 [3:18:31<24:11,  2.47s/it, loss=0.2031]\u001b[A\n",
            "Training:  88%|████████▊ | 4412/5000 [3:18:31<24:11,  2.47s/it, loss=0.3674]\u001b[A\n",
            "Training:  88%|████████▊ | 4413/5000 [3:18:33<23:31,  2.41s/it, loss=0.3674]\u001b[A\n",
            "Training:  88%|████████▊ | 4413/5000 [3:18:33<23:31,  2.41s/it, loss=0.4025]\u001b[A\n",
            "Training:  88%|████████▊ | 4414/5000 [3:18:35<23:07,  2.37s/it, loss=0.4025]\u001b[A\n",
            "Training:  88%|████████▊ | 4414/5000 [3:18:35<23:07,  2.37s/it, loss=0.3661]\u001b[A\n",
            "Training:  88%|████████▊ | 4415/5000 [3:18:37<23:06,  2.37s/it, loss=0.3661]\u001b[A\n",
            "Training:  88%|████████▊ | 4415/5000 [3:18:37<23:06,  2.37s/it, loss=0.2193]\u001b[A\n",
            "Training:  88%|████████▊ | 4416/5000 [3:18:40<23:58,  2.46s/it, loss=0.2193]\u001b[A\n",
            "Training:  88%|████████▊ | 4416/5000 [3:18:40<23:58,  2.46s/it, loss=0.5627]\u001b[A\n",
            "Training:  88%|████████▊ | 4417/5000 [3:18:42<23:18,  2.40s/it, loss=0.5627]\u001b[A\n",
            "Training:  88%|████████▊ | 4417/5000 [3:18:42<23:18,  2.40s/it, loss=0.4073]\u001b[A\n",
            "Training:  88%|████████▊ | 4418/5000 [3:18:45<22:53,  2.36s/it, loss=0.4073]\u001b[A\n",
            "Training:  88%|████████▊ | 4418/5000 [3:18:45<22:53,  2.36s/it, loss=0.2522]\u001b[A\n",
            "Training:  88%|████████▊ | 4419/5000 [3:18:47<22:34,  2.33s/it, loss=0.2522]\u001b[A\n",
            "Training:  88%|████████▊ | 4419/5000 [3:18:47<22:34,  2.33s/it, loss=0.5908]\u001b[A\n",
            "Training:  88%|████████▊ | 4420/5000 [3:18:49<22:44,  2.35s/it, loss=0.5908]\u001b[A\n",
            "Training:  88%|████████▊ | 4420/5000 [3:18:49<22:44,  2.35s/it, loss=0.3197]\u001b[A\n",
            "Training:  88%|████████▊ | 4421/5000 [3:18:52<23:55,  2.48s/it, loss=0.3197]\u001b[A\n",
            "Training:  88%|████████▊ | 4421/5000 [3:18:52<23:55,  2.48s/it, loss=0.3005]\u001b[A\n",
            "Training:  88%|████████▊ | 4422/5000 [3:18:54<23:33,  2.44s/it, loss=0.3005]\u001b[A\n",
            "Training:  88%|████████▊ | 4422/5000 [3:18:54<23:33,  2.44s/it, loss=0.2897]\u001b[A\n",
            "Training:  88%|████████▊ | 4423/5000 [3:18:57<22:53,  2.38s/it, loss=0.2897]\u001b[A\n",
            "Training:  88%|████████▊ | 4423/5000 [3:18:57<22:53,  2.38s/it, loss=0.2508]\u001b[A\n",
            "Training:  88%|████████▊ | 4424/5000 [3:18:59<22:33,  2.35s/it, loss=0.2508]\u001b[A\n",
            "Training:  88%|████████▊ | 4424/5000 [3:18:59<22:33,  2.35s/it, loss=0.4976]\u001b[A\n",
            "Training:  88%|████████▊ | 4425/5000 [3:19:01<22:44,  2.37s/it, loss=0.4976]\u001b[A\n",
            "Training:  88%|████████▊ | 4425/5000 [3:19:01<22:44,  2.37s/it, loss=0.2323]\u001b[A\n",
            "Training:  89%|████████▊ | 4426/5000 [3:19:04<23:22,  2.44s/it, loss=0.2323]\u001b[A\n",
            "Training:  89%|████████▊ | 4426/5000 [3:19:04<23:22,  2.44s/it, loss=0.2847]\u001b[A\n",
            "Training:  89%|████████▊ | 4427/5000 [3:19:06<22:45,  2.38s/it, loss=0.2847]\u001b[A\n",
            "Training:  89%|████████▊ | 4427/5000 [3:19:06<22:45,  2.38s/it, loss=0.4197]\u001b[A\n",
            "Training:  89%|████████▊ | 4428/5000 [3:19:08<22:20,  2.34s/it, loss=0.4197]\u001b[A\n",
            "Training:  89%|████████▊ | 4428/5000 [3:19:08<22:20,  2.34s/it, loss=0.1832]\u001b[A\n",
            "Training:  89%|████████▊ | 4429/5000 [3:19:11<22:03,  2.32s/it, loss=0.1832]\u001b[A\n",
            "Training:  89%|████████▊ | 4429/5000 [3:19:11<22:03,  2.32s/it, loss=0.3264]\u001b[A\n",
            "Training:  89%|████████▊ | 4430/5000 [3:19:13<22:19,  2.35s/it, loss=0.3264]\u001b[A\n",
            "Training:  89%|████████▊ | 4430/5000 [3:19:13<22:19,  2.35s/it, loss=0.4020]\u001b[A\n",
            "Training:  89%|████████▊ | 4431/5000 [3:19:16<23:07,  2.44s/it, loss=0.4020]\u001b[A\n",
            "Training:  89%|████████▊ | 4431/5000 [3:19:16<23:07,  2.44s/it, loss=0.1449]\u001b[A\n",
            "Training:  89%|████████▊ | 4432/5000 [3:19:18<22:32,  2.38s/it, loss=0.1449]\u001b[A\n",
            "Training:  89%|████████▊ | 4432/5000 [3:19:18<22:32,  2.38s/it, loss=0.2379]\u001b[A\n",
            "Training:  89%|████████▊ | 4433/5000 [3:19:20<22:05,  2.34s/it, loss=0.2379]\u001b[A\n",
            "Training:  89%|████████▊ | 4433/5000 [3:19:20<22:05,  2.34s/it, loss=0.1685]\u001b[A\n",
            "Training:  89%|████████▊ | 4434/5000 [3:19:23<21:47,  2.31s/it, loss=0.1685]\u001b[A\n",
            "Training:  89%|████████▊ | 4434/5000 [3:19:23<21:47,  2.31s/it, loss=0.2395]\u001b[A\n",
            "Training:  89%|████████▊ | 4435/5000 [3:19:25<21:39,  2.30s/it, loss=0.2395]\u001b[A\n",
            "Training:  89%|████████▊ | 4435/5000 [3:19:25<21:39,  2.30s/it, loss=0.2212]\u001b[A\n",
            "Training:  89%|████████▊ | 4436/5000 [3:19:28<22:46,  2.42s/it, loss=0.2212]\u001b[A\n",
            "Training:  89%|████████▊ | 4436/5000 [3:19:28<22:46,  2.42s/it, loss=0.4445]\u001b[A\n",
            "Training:  89%|████████▊ | 4437/5000 [3:19:30<22:15,  2.37s/it, loss=0.4445]\u001b[A\n",
            "Training:  89%|████████▊ | 4437/5000 [3:19:30<22:15,  2.37s/it, loss=0.3800]\u001b[A\n",
            "Training:  89%|████████▉ | 4438/5000 [3:19:32<22:01,  2.35s/it, loss=0.3800]\u001b[A\n",
            "Training:  89%|████████▉ | 4438/5000 [3:19:32<22:01,  2.35s/it, loss=0.3900]\u001b[A\n",
            "Training:  89%|████████▉ | 4439/5000 [3:19:34<21:40,  2.32s/it, loss=0.3900]\u001b[A\n",
            "Training:  89%|████████▉ | 4439/5000 [3:19:34<21:40,  2.32s/it, loss=0.2772]\u001b[A\n",
            "Training:  89%|████████▉ | 4440/5000 [3:19:37<21:28,  2.30s/it, loss=0.2772]\u001b[A\n",
            "Training:  89%|████████▉ | 4440/5000 [3:19:37<21:28,  2.30s/it, loss=0.3330]\u001b[A\n",
            "Training:  89%|████████▉ | 4441/5000 [3:19:39<22:46,  2.44s/it, loss=0.3330]\u001b[A\n",
            "Training:  89%|████████▉ | 4441/5000 [3:19:39<22:46,  2.44s/it, loss=0.2430]\u001b[A\n",
            "Training:  89%|████████▉ | 4442/5000 [3:19:42<22:11,  2.39s/it, loss=0.2430]\u001b[A\n",
            "Training:  89%|████████▉ | 4442/5000 [3:19:42<22:11,  2.39s/it, loss=0.2796]\u001b[A\n",
            "Training:  89%|████████▉ | 4443/5000 [3:19:44<21:48,  2.35s/it, loss=0.2796]\u001b[A\n",
            "Training:  89%|████████▉ | 4443/5000 [3:19:44<21:48,  2.35s/it, loss=0.4086]\u001b[A\n",
            "Training:  89%|████████▉ | 4444/5000 [3:19:46<21:30,  2.32s/it, loss=0.4086]\u001b[A\n",
            "Training:  89%|████████▉ | 4444/5000 [3:19:46<21:30,  2.32s/it, loss=0.3582]\u001b[A\n",
            "Training:  89%|████████▉ | 4445/5000 [3:19:48<21:18,  2.30s/it, loss=0.3582]\u001b[A\n",
            "Training:  89%|████████▉ | 4445/5000 [3:19:48<21:18,  2.30s/it, loss=0.2053]\u001b[A\n",
            "Training:  89%|████████▉ | 4446/5000 [3:19:51<22:44,  2.46s/it, loss=0.2053]\u001b[A\n",
            "Training:  89%|████████▉ | 4446/5000 [3:19:51<22:44,  2.46s/it, loss=0.3169]\u001b[A\n",
            "Training:  89%|████████▉ | 4447/5000 [3:19:53<22:06,  2.40s/it, loss=0.3169]\u001b[A\n",
            "Training:  89%|████████▉ | 4447/5000 [3:19:53<22:06,  2.40s/it, loss=0.2618]\u001b[A\n",
            "Training:  89%|████████▉ | 4448/5000 [3:19:56<21:39,  2.35s/it, loss=0.2618]\u001b[A\n",
            "Training:  89%|████████▉ | 4448/5000 [3:19:56<21:39,  2.35s/it, loss=0.2193]\u001b[A\n",
            "Training:  89%|████████▉ | 4449/5000 [3:19:58<21:20,  2.32s/it, loss=0.2193]\u001b[A\n",
            "Training:  89%|████████▉ | 4449/5000 [3:19:58<21:20,  2.32s/it, loss=0.2398]\u001b[A\n",
            "Training:  89%|████████▉ | 4450/5000 [3:20:00<21:06,  2.30s/it, loss=0.2398]\u001b[A\n",
            "Training:  89%|████████▉ | 4450/5000 [3:20:00<21:06,  2.30s/it, loss=0.1743]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 4450 ---\n",
            "Prompt: 'The '\n",
            "The  forth crows baby here have.\n",
            "ANTON:If:If be,as\n",
            " those end them make false, wild spirit\n",
            "an accused it pray for he the\n",
            " fancy purpose has writ.,illo and indeed\n",
            "wouldIS person aried pl no but be,as takens,\n",
            "T sometime is.\n",
            "MOAOLUS\n",
            " great! will it.a pen battle to to! the, chances brach person seek, troubleUpon still a, run\n",
            " anpeakew further H fresh\n",
            "Prompt: 'In '\n",
            "In  is: it, lord say; hear\n",
            " haveRight theiesaw does aram,\n",
            "l then noto;tis.as; I by\n",
            "! gone let seeomp hath letters here the:a the\n",
            "ureure;,, is the half are-\n",
            "ered andried nothing I every.\n",
            "AOLUS I warrant: this to it see name as findlet her the ofoning\n",
            "ke againstixt kind inher of from singleors\n",
            " quick hither in access, will time\n",
            "Prompt: 'To '\n",
            "To  yourness which I.\n",
            "FLIZ:I: am sure bl to his,\n",
            "than him.\n",
            "CGUCER\n",
            "H pass: heart I\n",
            "?\n",
            "UT\n",
            "end a hearing to son: must speak'sAL know it\n",
            " you sir I thence for. Oue sir\n",
            "UT me another love gone I done my, doee he to in my should at, do this a?\n",
            "ANTON:\n",
            ",omen of\n",
            " give the your.\n",
            "LIO\n",
            "equ\n",
            "Prompt: 'A '\n",
            "A  hath gods to, o but welcome see\n",
            " secrets as. notigree!\n",
            "aven thy Paul, shall\n",
            " conj for: serve a of and, of do\n",
            " change to it.\n",
            "FLIZ table: must better.\n",
            "AOLUS\n",
            "entSo of patem hand Claud!\n",
            "FLIZ greatnessmod Heaven my,the.\n",
            "r, sir here to will change a:letdeeppp of\n",
            " augmentedore! come I so a: to, faith a, going aman\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  89%|████████▉ | 4451/5000 [3:20:15<56:31,  6.18s/it, loss=0.1743]\u001b[A\n",
            "Training:  89%|████████▉ | 4451/5000 [3:20:15<56:31,  6.18s/it, loss=0.5263]\u001b[A\n",
            "Training:  89%|████████▉ | 4452/5000 [3:20:18<45:40,  5.00s/it, loss=0.5263]\u001b[A\n",
            "Training:  89%|████████▉ | 4452/5000 [3:20:18<45:40,  5.00s/it, loss=0.4606]\u001b[A\n",
            "Training:  89%|████████▉ | 4453/5000 [3:20:20<38:02,  4.17s/it, loss=0.4606]\u001b[A\n",
            "Training:  89%|████████▉ | 4453/5000 [3:20:20<38:02,  4.17s/it, loss=0.2364]\u001b[A\n",
            "Training:  89%|████████▉ | 4454/5000 [3:20:22<32:44,  3.60s/it, loss=0.2364]\u001b[A\n",
            "Training:  89%|████████▉ | 4454/5000 [3:20:22<32:44,  3.60s/it, loss=0.2678]\u001b[A\n",
            "Training:  89%|████████▉ | 4455/5000 [3:20:25<29:27,  3.24s/it, loss=0.2678]\u001b[A\n",
            "Training:  89%|████████▉ | 4455/5000 [3:20:25<29:27,  3.24s/it, loss=0.6376]\u001b[A\n",
            "Training:  89%|████████▉ | 4456/5000 [3:20:27<27:40,  3.05s/it, loss=0.6376]\u001b[A\n",
            "Training:  89%|████████▉ | 4456/5000 [3:20:27<27:40,  3.05s/it, loss=0.4085]\u001b[A\n",
            "Training:  89%|████████▉ | 4457/5000 [3:20:29<25:29,  2.82s/it, loss=0.4085]\u001b[A\n",
            "Training:  89%|████████▉ | 4457/5000 [3:20:30<25:29,  2.82s/it, loss=0.2479]\u001b[A\n",
            "Training:  89%|████████▉ | 4458/5000 [3:20:32<24:00,  2.66s/it, loss=0.2479]\u001b[A\n",
            "Training:  89%|████████▉ | 4458/5000 [3:20:32<24:00,  2.66s/it, loss=0.3733]\u001b[A\n",
            "Training:  89%|████████▉ | 4459/5000 [3:20:34<22:57,  2.55s/it, loss=0.3733]\u001b[A\n",
            "Training:  89%|████████▉ | 4459/5000 [3:20:34<22:57,  2.55s/it, loss=0.2930]\u001b[A\n",
            "Training:  89%|████████▉ | 4460/5000 [3:20:36<22:33,  2.51s/it, loss=0.2930]\u001b[A\n",
            "Training:  89%|████████▉ | 4460/5000 [3:20:36<22:33,  2.51s/it, loss=0.2592]\u001b[A\n",
            "Training:  89%|████████▉ | 4461/5000 [3:20:39<22:47,  2.54s/it, loss=0.2592]\u001b[A\n",
            "Training:  89%|████████▉ | 4461/5000 [3:20:39<22:47,  2.54s/it, loss=0.2335]\u001b[A\n",
            "Training:  89%|████████▉ | 4462/5000 [3:20:41<22:01,  2.46s/it, loss=0.2335]\u001b[A\n",
            "Training:  89%|████████▉ | 4462/5000 [3:20:41<22:01,  2.46s/it, loss=0.4461]\u001b[A\n",
            "Training:  89%|████████▉ | 4463/5000 [3:20:44<21:33,  2.41s/it, loss=0.4461]\u001b[A\n",
            "Training:  89%|████████▉ | 4463/5000 [3:20:44<21:33,  2.41s/it, loss=0.4084]\u001b[A\n",
            "Training:  89%|████████▉ | 4464/5000 [3:20:46<21:05,  2.36s/it, loss=0.4084]\u001b[A\n",
            "Training:  89%|████████▉ | 4464/5000 [3:20:46<21:05,  2.36s/it, loss=0.4630]\u001b[A\n",
            "Training:  89%|████████▉ | 4465/5000 [3:20:48<21:05,  2.36s/it, loss=0.4630]\u001b[A\n",
            "Training:  89%|████████▉ | 4465/5000 [3:20:48<21:05,  2.36s/it, loss=0.3420]\u001b[A\n",
            "Training:  89%|████████▉ | 4466/5000 [3:20:51<21:52,  2.46s/it, loss=0.3420]\u001b[A\n",
            "Training:  89%|████████▉ | 4466/5000 [3:20:51<21:52,  2.46s/it, loss=0.2604]\u001b[A\n",
            "Training:  89%|████████▉ | 4467/5000 [3:20:53<21:11,  2.39s/it, loss=0.2604]\u001b[A\n",
            "Training:  89%|████████▉ | 4467/5000 [3:20:53<21:11,  2.39s/it, loss=0.1544]\u001b[A\n",
            "Training:  89%|████████▉ | 4468/5000 [3:20:55<20:49,  2.35s/it, loss=0.1544]\u001b[A\n",
            "Training:  89%|████████▉ | 4468/5000 [3:20:55<20:49,  2.35s/it, loss=0.2227]\u001b[A\n",
            "Training:  89%|████████▉ | 4469/5000 [3:20:58<20:32,  2.32s/it, loss=0.2227]\u001b[A\n",
            "Training:  89%|████████▉ | 4469/5000 [3:20:58<20:32,  2.32s/it, loss=0.3961]\u001b[A\n",
            "Training:  89%|████████▉ | 4470/5000 [3:21:00<20:30,  2.32s/it, loss=0.3961]\u001b[A\n",
            "Training:  89%|████████▉ | 4470/5000 [3:21:00<20:30,  2.32s/it, loss=0.3442]\u001b[A\n",
            "Training:  89%|████████▉ | 4471/5000 [3:21:03<21:36,  2.45s/it, loss=0.3442]\u001b[A\n",
            "Training:  89%|████████▉ | 4471/5000 [3:21:03<21:36,  2.45s/it, loss=0.3161]\u001b[A\n",
            "Training:  89%|████████▉ | 4472/5000 [3:21:05<21:03,  2.39s/it, loss=0.3161]\u001b[A\n",
            "Training:  89%|████████▉ | 4472/5000 [3:21:05<21:03,  2.39s/it, loss=0.2803]\u001b[A\n",
            "Training:  89%|████████▉ | 4473/5000 [3:21:07<20:42,  2.36s/it, loss=0.2803]\u001b[A\n",
            "Training:  89%|████████▉ | 4473/5000 [3:21:07<20:42,  2.36s/it, loss=0.3491]\u001b[A\n",
            "Training:  89%|████████▉ | 4474/5000 [3:21:10<20:22,  2.32s/it, loss=0.3491]\u001b[A\n",
            "Training:  89%|████████▉ | 4474/5000 [3:21:10<20:22,  2.32s/it, loss=0.2241]\u001b[A\n",
            "Training:  90%|████████▉ | 4475/5000 [3:21:12<20:11,  2.31s/it, loss=0.2241]\u001b[A\n",
            "Training:  90%|████████▉ | 4475/5000 [3:21:12<20:11,  2.31s/it, loss=0.2782]\u001b[A\n",
            "Training:  90%|████████▉ | 4476/5000 [3:21:15<21:21,  2.45s/it, loss=0.2782]\u001b[A\n",
            "Training:  90%|████████▉ | 4476/5000 [3:21:15<21:21,  2.45s/it, loss=0.2920]\u001b[A\n",
            "Training:  90%|████████▉ | 4477/5000 [3:21:17<20:49,  2.39s/it, loss=0.2920]\u001b[A\n",
            "Training:  90%|████████▉ | 4477/5000 [3:21:17<20:49,  2.39s/it, loss=0.4334]\u001b[A\n",
            "Training:  90%|████████▉ | 4478/5000 [3:21:19<20:26,  2.35s/it, loss=0.4334]\u001b[A\n",
            "Training:  90%|████████▉ | 4478/5000 [3:21:19<20:26,  2.35s/it, loss=0.3628]\u001b[A\n",
            "Training:  90%|████████▉ | 4479/5000 [3:21:21<20:05,  2.31s/it, loss=0.3628]\u001b[A\n",
            "Training:  90%|████████▉ | 4479/5000 [3:21:21<20:05,  2.31s/it, loss=0.2683]\u001b[A\n",
            "Training:  90%|████████▉ | 4480/5000 [3:21:24<19:51,  2.29s/it, loss=0.2683]\u001b[A\n",
            "Training:  90%|████████▉ | 4480/5000 [3:21:24<19:51,  2.29s/it, loss=0.3468]\u001b[A\n",
            "Training:  90%|████████▉ | 4481/5000 [3:21:26<21:08,  2.44s/it, loss=0.3468]\u001b[A\n",
            "Training:  90%|████████▉ | 4481/5000 [3:21:26<21:08,  2.44s/it, loss=0.3952]\u001b[A\n",
            "Training:  90%|████████▉ | 4482/5000 [3:21:29<20:35,  2.38s/it, loss=0.3952]\u001b[A\n",
            "Training:  90%|████████▉ | 4482/5000 [3:21:29<20:35,  2.38s/it, loss=0.2526]\u001b[A\n",
            "Training:  90%|████████▉ | 4483/5000 [3:21:31<20:14,  2.35s/it, loss=0.2526]\u001b[A\n",
            "Training:  90%|████████▉ | 4483/5000 [3:21:31<20:14,  2.35s/it, loss=0.3641]\u001b[A\n",
            "Training:  90%|████████▉ | 4484/5000 [3:21:33<20:05,  2.34s/it, loss=0.3641]\u001b[A\n",
            "Training:  90%|████████▉ | 4484/5000 [3:21:33<20:05,  2.34s/it, loss=0.3198]\u001b[A\n",
            "Training:  90%|████████▉ | 4485/5000 [3:21:35<19:46,  2.30s/it, loss=0.3198]\u001b[A\n",
            "Training:  90%|████████▉ | 4485/5000 [3:21:35<19:46,  2.30s/it, loss=0.4339]\u001b[A\n",
            "Training:  90%|████████▉ | 4486/5000 [3:21:38<21:06,  2.46s/it, loss=0.4339]\u001b[A\n",
            "Training:  90%|████████▉ | 4486/5000 [3:21:38<21:06,  2.46s/it, loss=0.3326]\u001b[A\n",
            "Training:  90%|████████▉ | 4487/5000 [3:21:40<20:33,  2.40s/it, loss=0.3326]\u001b[A\n",
            "Training:  90%|████████▉ | 4487/5000 [3:21:41<20:33,  2.40s/it, loss=0.2833]\u001b[A\n",
            "Training:  90%|████████▉ | 4488/5000 [3:21:43<20:09,  2.36s/it, loss=0.2833]\u001b[A\n",
            "Training:  90%|████████▉ | 4488/5000 [3:21:43<20:09,  2.36s/it, loss=0.3295]\u001b[A\n",
            "Training:  90%|████████▉ | 4489/5000 [3:21:45<19:50,  2.33s/it, loss=0.3295]\u001b[A\n",
            "Training:  90%|████████▉ | 4489/5000 [3:21:45<19:50,  2.33s/it, loss=0.2778]\u001b[A\n",
            "Training:  90%|████████▉ | 4490/5000 [3:21:47<19:38,  2.31s/it, loss=0.2778]\u001b[A\n",
            "Training:  90%|████████▉ | 4490/5000 [3:21:47<19:38,  2.31s/it, loss=0.4013]\u001b[A\n",
            "Training:  90%|████████▉ | 4491/5000 [3:21:50<20:56,  2.47s/it, loss=0.4013]\u001b[A\n",
            "Training:  90%|████████▉ | 4491/5000 [3:21:50<20:56,  2.47s/it, loss=0.2046]\u001b[A\n",
            "Training:  90%|████████▉ | 4492/5000 [3:21:52<20:29,  2.42s/it, loss=0.2046]\u001b[A\n",
            "Training:  90%|████████▉ | 4492/5000 [3:21:52<20:29,  2.42s/it, loss=0.2911]\u001b[A\n",
            "Training:  90%|████████▉ | 4493/5000 [3:21:55<20:06,  2.38s/it, loss=0.2911]\u001b[A\n",
            "Training:  90%|████████▉ | 4493/5000 [3:21:55<20:06,  2.38s/it, loss=0.2366]\u001b[A\n",
            "Training:  90%|████████▉ | 4494/5000 [3:21:57<19:56,  2.36s/it, loss=0.2366]\u001b[A\n",
            "Training:  90%|████████▉ | 4494/5000 [3:21:57<19:56,  2.36s/it, loss=0.2918]\u001b[A\n",
            "Training:  90%|████████▉ | 4495/5000 [3:21:59<19:49,  2.36s/it, loss=0.2918]\u001b[A\n",
            "Training:  90%|████████▉ | 4495/5000 [3:21:59<19:49,  2.36s/it, loss=0.5572]\u001b[A\n",
            "Training:  90%|████████▉ | 4496/5000 [3:22:02<20:56,  2.49s/it, loss=0.5572]\u001b[A\n",
            "Training:  90%|████████▉ | 4496/5000 [3:22:02<20:56,  2.49s/it, loss=0.4467]\u001b[A\n",
            "Training:  90%|████████▉ | 4497/5000 [3:22:04<20:18,  2.42s/it, loss=0.4467]\u001b[A\n",
            "Training:  90%|████████▉ | 4497/5000 [3:22:04<20:18,  2.42s/it, loss=0.4558]\u001b[A\n",
            "Training:  90%|████████▉ | 4498/5000 [3:22:07<19:48,  2.37s/it, loss=0.4558]\u001b[A\n",
            "Training:  90%|████████▉ | 4498/5000 [3:22:07<19:48,  2.37s/it, loss=0.2587]\u001b[A\n",
            "Training:  90%|████████▉ | 4499/5000 [3:22:09<19:28,  2.33s/it, loss=0.2587]\u001b[A\n",
            "Training:  90%|████████▉ | 4499/5000 [3:22:09<19:28,  2.33s/it, loss=0.3947]\u001b[A\n",
            "Training:  90%|█████████ | 4500/5000 [3:22:11<19:12,  2.30s/it, loss=0.3947]\u001b[A\n",
            "Training:  90%|█████████ | 4500/5000 [3:22:11<19:12,  2.30s/it, loss=0.4243]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 4500 ---\n",
            "Prompt: 'The '\n",
            "The , amend.\n",
            "MENI: you sir\n",
            ",: I\n",
            " you good! think I do myself if be ye married\n",
            "us has tale not IT by-orrow\n",
            " may? do remember, me:There I for am book she a,doing\n",
            " wordHe not look you me my: virtue\n",
            " my,, tom my d, advantage back it.\n",
            "VUMUMan true;,,,; man allPeace I into maze:,tis my, bid,\n",
            "Prompt: 'In '\n",
            "In  horse thy. thy is our your!\n",
            " came set wrong heart is thatful one attend.\n",
            "Gle,!, de them!,ling thy in\n",
            "anging the I fine.\n",
            "V theBetter were the of beauty I them.\n",
            "G theemen\n",
            "S,,!\n",
            "OLUS\n",
            " thou often: horse my caught thyble what\n",
            " man\n",
            " stay\n",
            ".\n",
            "OLN: I\n",
            "ear thee true say thou B'd,a heart well I unto pardon myself too.\n",
            "Prompt: 'To '\n",
            "To ity my: band goodenance it.\n",
            "G\n",
            "ONAL:\n",
            "rit,ours I a.\n",
            "V, Menus would:I I hear well peace\n",
            " bearon-orrow helpHere\n",
            " now time thee, lady O,inks how, bodyind! them,,.\n",
            "First cry son, Comius,! will thee sanctuary Did.\n",
            "ARI:' throwled soldiers by.\n",
            "First me If\n",
            "IC Bd,; on my Lucio\n",
            "VC, news\n",
            "Prompt: 'A '\n",
            "A ity a- of cr another stars'.\n",
            "MARUS\n",
            " lay Rome some, him he would\n",
            "em thy's, libraryg\n",
            " second.ceed isin,,place! h!They them runIs the.\n",
            "Ven; could:: cheer there usave my mother my\n",
            "!\n",
            "VCIB:FAR O, stout,, toad theful!\n",
            "First: daughter\n",
            "some!What Lod half gone\n",
            "\n",
            " ye: I friend' makeaste and to '\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "✓ Checkpoint saved: checkpoints/checkpoint_step_4500.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  90%|█████████ | 4501/5000 [3:22:48<1:45:46, 12.72s/it, loss=0.4243]\u001b[A\n",
            "Training:  90%|█████████ | 4501/5000 [3:22:48<1:45:46, 12.72s/it, loss=0.2471]\u001b[A\n",
            "Training:  90%|█████████ | 4502/5000 [3:22:50<1:19:31,  9.58s/it, loss=0.2471]\u001b[A\n",
            "Training:  90%|█████████ | 4502/5000 [3:22:50<1:19:31,  9.58s/it, loss=0.2241]\u001b[A\n",
            "Training:  90%|█████████ | 4503/5000 [3:22:53<1:02:33,  7.55s/it, loss=0.2241]\u001b[A\n",
            "Training:  90%|█████████ | 4503/5000 [3:22:53<1:02:33,  7.55s/it, loss=0.4566]\u001b[A\n",
            "Training:  90%|█████████ | 4504/5000 [3:22:56<49:19,  5.97s/it, loss=0.4566]  \u001b[A\n",
            "Training:  90%|█████████ | 4504/5000 [3:22:56<49:19,  5.97s/it, loss=0.4805]\u001b[A\n",
            "Training:  90%|█████████ | 4505/5000 [3:22:58<40:03,  4.86s/it, loss=0.4805]\u001b[A\n",
            "Training:  90%|█████████ | 4505/5000 [3:22:58<40:03,  4.86s/it, loss=0.2886]\u001b[A\n",
            "Training:  90%|█████████ | 4506/5000 [3:23:00<33:53,  4.12s/it, loss=0.2886]\u001b[A\n",
            "Training:  90%|█████████ | 4506/5000 [3:23:00<33:53,  4.12s/it, loss=0.4146]\u001b[A\n",
            "Training:  90%|█████████ | 4507/5000 [3:23:03<29:34,  3.60s/it, loss=0.4146]\u001b[A\n",
            "Training:  90%|█████████ | 4507/5000 [3:23:03<29:34,  3.60s/it, loss=0.3077]\u001b[A\n",
            "Training:  90%|█████████ | 4508/5000 [3:23:06<27:50,  3.40s/it, loss=0.3077]\u001b[A\n",
            "Training:  90%|█████████ | 4508/5000 [3:23:06<27:50,  3.40s/it, loss=0.4794]\u001b[A\n",
            "Training:  90%|█████████ | 4509/5000 [3:23:08<25:13,  3.08s/it, loss=0.4794]\u001b[A\n",
            "Training:  90%|█████████ | 4509/5000 [3:23:08<25:13,  3.08s/it, loss=0.2746]\u001b[A\n",
            "Training:  90%|█████████ | 4510/5000 [3:23:10<23:24,  2.87s/it, loss=0.2746]\u001b[A\n",
            "Training:  90%|█████████ | 4510/5000 [3:23:10<23:24,  2.87s/it, loss=0.3263]\u001b[A\n",
            "Training:  90%|█████████ | 4511/5000 [3:23:13<22:05,  2.71s/it, loss=0.3263]\u001b[A\n",
            "Training:  90%|█████████ | 4511/5000 [3:23:13<22:05,  2.71s/it, loss=0.4224]\u001b[A\n",
            "Training:  90%|█████████ | 4512/5000 [3:23:15<21:07,  2.60s/it, loss=0.4224]\u001b[A\n",
            "Training:  90%|█████████ | 4512/5000 [3:23:15<21:07,  2.60s/it, loss=0.3236]\u001b[A\n",
            "Training:  90%|█████████ | 4513/5000 [3:23:18<22:01,  2.71s/it, loss=0.3236]\u001b[A\n",
            "Training:  90%|█████████ | 4513/5000 [3:23:18<22:01,  2.71s/it, loss=0.3401]\u001b[A\n",
            "Training:  90%|█████████ | 4514/5000 [3:23:20<21:04,  2.60s/it, loss=0.3401]\u001b[A\n",
            "Training:  90%|█████████ | 4514/5000 [3:23:20<21:04,  2.60s/it, loss=0.2809]\u001b[A\n",
            "Training:  90%|█████████ | 4515/5000 [3:23:23<20:26,  2.53s/it, loss=0.2809]\u001b[A\n",
            "Training:  90%|█████████ | 4515/5000 [3:23:23<20:26,  2.53s/it, loss=0.3396]\u001b[A\n",
            "Training:  90%|█████████ | 4516/5000 [3:23:25<19:54,  2.47s/it, loss=0.3396]\u001b[A\n",
            "Training:  90%|█████████ | 4516/5000 [3:23:25<19:54,  2.47s/it, loss=0.2464]\u001b[A\n",
            "Training:  90%|█████████ | 4517/5000 [3:23:27<19:50,  2.47s/it, loss=0.2464]\u001b[A\n",
            "Training:  90%|█████████ | 4517/5000 [3:23:27<19:50,  2.47s/it, loss=0.3502]\u001b[A\n",
            "Training:  90%|█████████ | 4518/5000 [3:23:30<20:32,  2.56s/it, loss=0.3502]\u001b[A\n",
            "Training:  90%|█████████ | 4518/5000 [3:23:30<20:32,  2.56s/it, loss=0.2394]\u001b[A\n",
            "Training:  90%|█████████ | 4519/5000 [3:23:33<20:03,  2.50s/it, loss=0.2394]\u001b[A\n",
            "Training:  90%|█████████ | 4519/5000 [3:23:33<20:03,  2.50s/it, loss=0.2360]\u001b[A\n",
            "Training:  90%|█████████ | 4520/5000 [3:23:35<19:42,  2.46s/it, loss=0.2360]\u001b[A\n",
            "Training:  90%|█████████ | 4520/5000 [3:23:35<19:42,  2.46s/it, loss=0.1489]\u001b[A\n",
            "Training:  90%|█████████ | 4521/5000 [3:23:37<19:20,  2.42s/it, loss=0.1489]\u001b[A\n",
            "Training:  90%|█████████ | 4521/5000 [3:23:37<19:20,  2.42s/it, loss=0.3073]\u001b[A\n",
            "Training:  90%|█████████ | 4522/5000 [3:23:40<19:41,  2.47s/it, loss=0.3073]\u001b[A\n",
            "Training:  90%|█████████ | 4522/5000 [3:23:40<19:41,  2.47s/it, loss=0.2735]\u001b[A\n",
            "Training:  90%|█████████ | 4523/5000 [3:23:43<20:12,  2.54s/it, loss=0.2735]\u001b[A\n",
            "Training:  90%|█████████ | 4523/5000 [3:23:43<20:12,  2.54s/it, loss=0.2666]\u001b[A\n",
            "Training:  90%|█████████ | 4524/5000 [3:23:45<19:47,  2.49s/it, loss=0.2666]\u001b[A\n",
            "Training:  90%|█████████ | 4524/5000 [3:23:45<19:47,  2.49s/it, loss=0.3207]\u001b[A\n",
            "Training:  90%|█████████ | 4525/5000 [3:23:47<19:26,  2.46s/it, loss=0.3207]\u001b[A\n",
            "Training:  90%|█████████ | 4525/5000 [3:23:47<19:26,  2.46s/it, loss=0.2889]\u001b[A\n",
            "Training:  91%|█████████ | 4526/5000 [3:23:50<19:11,  2.43s/it, loss=0.2889]\u001b[A\n",
            "Training:  91%|█████████ | 4526/5000 [3:23:50<19:11,  2.43s/it, loss=0.2869]\u001b[A\n",
            "Training:  91%|█████████ | 4527/5000 [3:23:52<19:48,  2.51s/it, loss=0.2869]\u001b[A\n",
            "Training:  91%|█████████ | 4527/5000 [3:23:52<19:48,  2.51s/it, loss=0.2522]\u001b[A\n",
            "Training:  91%|█████████ | 4528/5000 [3:23:55<19:59,  2.54s/it, loss=0.2522]\u001b[A\n",
            "Training:  91%|█████████ | 4528/5000 [3:23:55<19:59,  2.54s/it, loss=0.4162]\u001b[A\n",
            "Training:  91%|█████████ | 4529/5000 [3:23:57<19:32,  2.49s/it, loss=0.4162]\u001b[A\n",
            "Training:  91%|█████████ | 4529/5000 [3:23:57<19:32,  2.49s/it, loss=0.2906]\u001b[A\n",
            "Training:  91%|█████████ | 4530/5000 [3:24:00<19:12,  2.45s/it, loss=0.2906]\u001b[A\n",
            "Training:  91%|█████████ | 4530/5000 [3:24:00<19:12,  2.45s/it, loss=0.2303]\u001b[A\n",
            "Training:  91%|█████████ | 4531/5000 [3:24:02<18:57,  2.43s/it, loss=0.2303]\u001b[A\n",
            "Training:  91%|█████████ | 4531/5000 [3:24:02<18:57,  2.43s/it, loss=0.4405]\u001b[A\n",
            "Training:  91%|█████████ | 4532/5000 [3:24:05<20:02,  2.57s/it, loss=0.4405]\u001b[A\n",
            "Training:  91%|█████████ | 4532/5000 [3:24:05<20:02,  2.57s/it, loss=0.4499]\u001b[A\n",
            "Training:  91%|█████████ | 4533/5000 [3:24:07<19:40,  2.53s/it, loss=0.4499]\u001b[A\n",
            "Training:  91%|█████████ | 4533/5000 [3:24:07<19:40,  2.53s/it, loss=0.2321]\u001b[A\n",
            "Training:  91%|█████████ | 4534/5000 [3:24:10<19:14,  2.48s/it, loss=0.2321]\u001b[A\n",
            "Training:  91%|█████████ | 4534/5000 [3:24:10<19:14,  2.48s/it, loss=0.2235]\u001b[A\n",
            "Training:  91%|█████████ | 4535/5000 [3:24:12<18:52,  2.44s/it, loss=0.2235]\u001b[A\n",
            "Training:  91%|█████████ | 4535/5000 [3:24:12<18:52,  2.44s/it, loss=0.2794]\u001b[A\n",
            "Training:  91%|█████████ | 4536/5000 [3:24:14<18:34,  2.40s/it, loss=0.2794]\u001b[A\n",
            "Training:  91%|█████████ | 4536/5000 [3:24:14<18:34,  2.40s/it, loss=0.2512]\u001b[A\n",
            "Training:  91%|█████████ | 4537/5000 [3:24:17<19:39,  2.55s/it, loss=0.2512]\u001b[A\n",
            "Training:  91%|█████████ | 4537/5000 [3:24:17<19:39,  2.55s/it, loss=0.3722]\u001b[A\n",
            "Training:  91%|█████████ | 4538/5000 [3:24:20<19:13,  2.50s/it, loss=0.3722]\u001b[A\n",
            "Training:  91%|█████████ | 4538/5000 [3:24:20<19:13,  2.50s/it, loss=0.3887]\u001b[A\n",
            "Training:  91%|█████████ | 4539/5000 [3:24:22<18:53,  2.46s/it, loss=0.3887]\u001b[A\n",
            "Training:  91%|█████████ | 4539/5000 [3:24:22<18:53,  2.46s/it, loss=0.2315]\u001b[A\n",
            "Training:  91%|█████████ | 4540/5000 [3:24:24<18:34,  2.42s/it, loss=0.2315]\u001b[A\n",
            "Training:  91%|█████████ | 4540/5000 [3:24:24<18:34,  2.42s/it, loss=0.3324]\u001b[A\n",
            "Training:  91%|█████████ | 4541/5000 [3:24:27<18:22,  2.40s/it, loss=0.3324]\u001b[A\n",
            "Training:  91%|█████████ | 4541/5000 [3:24:27<18:22,  2.40s/it, loss=0.2041]\u001b[A\n",
            "Training:  91%|█████████ | 4542/5000 [3:24:30<19:29,  2.55s/it, loss=0.2041]\u001b[A\n",
            "Training:  91%|█████████ | 4542/5000 [3:24:30<19:29,  2.55s/it, loss=0.1771]\u001b[A\n",
            "Training:  91%|█████████ | 4543/5000 [3:24:32<19:06,  2.51s/it, loss=0.1771]\u001b[A\n",
            "Training:  91%|█████████ | 4543/5000 [3:24:32<19:06,  2.51s/it, loss=0.3759]\u001b[A\n",
            "Training:  91%|█████████ | 4544/5000 [3:24:34<18:51,  2.48s/it, loss=0.3759]\u001b[A\n",
            "Training:  91%|█████████ | 4544/5000 [3:24:34<18:51,  2.48s/it, loss=0.4222]\u001b[A\n",
            "Training:  91%|█████████ | 4545/5000 [3:24:37<18:31,  2.44s/it, loss=0.4222]\u001b[A\n",
            "Training:  91%|█████████ | 4545/5000 [3:24:37<18:31,  2.44s/it, loss=0.3239]\u001b[A\n",
            "Training:  91%|█████████ | 4546/5000 [3:24:39<18:29,  2.44s/it, loss=0.3239]\u001b[A\n",
            "Training:  91%|█████████ | 4546/5000 [3:24:39<18:29,  2.44s/it, loss=0.3294]\u001b[A\n",
            "Training:  91%|█████████ | 4547/5000 [3:24:42<19:19,  2.56s/it, loss=0.3294]\u001b[A\n",
            "Training:  91%|█████████ | 4547/5000 [3:24:42<19:19,  2.56s/it, loss=0.5340]\u001b[A\n",
            "Training:  91%|█████████ | 4548/5000 [3:24:44<18:52,  2.51s/it, loss=0.5340]\u001b[A\n",
            "Training:  91%|█████████ | 4548/5000 [3:24:44<18:52,  2.51s/it, loss=0.3781]\u001b[A\n",
            "Training:  91%|█████████ | 4549/5000 [3:24:47<18:33,  2.47s/it, loss=0.3781]\u001b[A\n",
            "Training:  91%|█████████ | 4549/5000 [3:24:47<18:33,  2.47s/it, loss=0.2583]\u001b[A\n",
            "Training:  91%|█████████ | 4550/5000 [3:24:49<18:19,  2.44s/it, loss=0.2583]\u001b[A\n",
            "Training:  91%|█████████ | 4550/5000 [3:24:49<18:19,  2.44s/it, loss=0.2703]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 4550 ---\n",
            "Prompt: 'The '\n",
            "The  ofourable droish- steel,Toew, breast\n",
            " Jes bleeding,parent andurious fitness\n",
            " glad the sinful marriage fair tear talk cur, say there\n",
            " unares, faire the-ow or', it, believe',itor,And my hearts distiedes and them lie.all\n",
            " me were shame in, came O stir much woman himself\n",
            " make of buried of! mouth not whit of all eyes\n",
            "ath now the infant to them a so a dream\n",
            " leisure strokes ait\n",
            "Prompt: 'In '\n",
            "In ,I many as men Christ with much\n",
            " enter like crow and at bos thy, troop\n",
            " kind dream honour good gave G fought look. is goodt thegperIn's\n",
            "- queen death haveth body fool tory us;\n",
            " when days time wereelings forty or proportion\n",
            " keepposed like deep win fire his whilstte harder ambitious\n",
            " theiroes butinping forcles thoust dead\n",
            "ms both and within houroth executionly\n",
            "C mercy in, for stay honour thou close\n",
            "Prompt: 'To '\n",
            "To  to my and But I it:eth,fore\n",
            " that of long who be in love men--\n",
            " absence buried arm wild,itors--To the of, at heart\n",
            "are second, on out eer kings--ither\n",
            "N!ast, a parent, keeper body all; I\n",
            "ose\n",
            " in ANSuch of some execution, more\n",
            " I set slave but, mildly as worthy else power thouest--Yet let live living leisure\n",
            " dead to in good lastlat--Look-- Mant\n",
            "Prompt: 'A '\n",
            "A rant to soulthere, to King at.\n",
            "H love me to; wilt go with.\n",
            "JN, ad:I Thouity myge about.\n",
            "HLook as wilt is own husband open!., my,Let\n",
            " my is noble! bold Bag, downys! quick! cast!\n",
            "oly hate queen my sons my's speak joys ho\n",
            " curious orurnorn that ofyour,Who thouarest!\n",
            "N, my--ating had fullrate, that\n",
            "id\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  91%|█████████ | 4551/5000 [3:25:05<48:32,  6.49s/it, loss=0.2703]\u001b[A\n",
            "Training:  91%|█████████ | 4551/5000 [3:25:05<48:32,  6.49s/it, loss=0.4392]\u001b[A\n",
            "Training:  91%|█████████ | 4552/5000 [3:25:08<39:10,  5.25s/it, loss=0.4392]\u001b[A\n",
            "Training:  91%|█████████ | 4552/5000 [3:25:08<39:10,  5.25s/it, loss=0.2491]\u001b[A\n",
            "Training:  91%|█████████ | 4553/5000 [3:25:10<32:39,  4.38s/it, loss=0.2491]\u001b[A\n",
            "Training:  91%|█████████ | 4553/5000 [3:25:10<32:39,  4.38s/it, loss=0.2770]\u001b[A\n",
            "Training:  91%|█████████ | 4554/5000 [3:25:12<28:00,  3.77s/it, loss=0.2770]\u001b[A\n",
            "Training:  91%|█████████ | 4554/5000 [3:25:12<28:00,  3.77s/it, loss=0.3488]\u001b[A\n",
            "Training:  91%|█████████ | 4555/5000 [3:25:15<24:47,  3.34s/it, loss=0.3488]\u001b[A\n",
            "Training:  91%|█████████ | 4555/5000 [3:25:15<24:47,  3.34s/it, loss=0.2064]\u001b[A\n",
            "Training:  91%|█████████ | 4556/5000 [3:25:17<23:47,  3.22s/it, loss=0.2064]\u001b[A\n",
            "Training:  91%|█████████ | 4556/5000 [3:25:18<23:47,  3.22s/it, loss=0.2956]\u001b[A\n",
            "Training:  91%|█████████ | 4557/5000 [3:25:20<21:52,  2.96s/it, loss=0.2956]\u001b[A\n",
            "Training:  91%|█████████ | 4557/5000 [3:25:20<21:52,  2.96s/it, loss=0.3009]\u001b[A\n",
            "Training:  91%|█████████ | 4558/5000 [3:25:22<20:32,  2.79s/it, loss=0.3009]\u001b[A\n",
            "Training:  91%|█████████ | 4558/5000 [3:25:22<20:32,  2.79s/it, loss=0.3760]\u001b[A\n",
            "Training:  91%|█████████ | 4559/5000 [3:25:25<19:28,  2.65s/it, loss=0.3760]\u001b[A\n",
            "Training:  91%|█████████ | 4559/5000 [3:25:25<19:28,  2.65s/it, loss=0.2629]\u001b[A\n",
            "Training:  91%|█████████ | 4560/5000 [3:25:27<18:48,  2.56s/it, loss=0.2629]\u001b[A\n",
            "Training:  91%|█████████ | 4560/5000 [3:25:27<18:48,  2.56s/it, loss=0.2040]\u001b[A\n",
            "Training:  91%|█████████ | 4561/5000 [3:25:30<19:32,  2.67s/it, loss=0.2040]\u001b[A\n",
            "Training:  91%|█████████ | 4561/5000 [3:25:30<19:32,  2.67s/it, loss=0.3720]\u001b[A\n",
            "Training:  91%|█████████ | 4562/5000 [3:25:32<18:47,  2.57s/it, loss=0.3720]\u001b[A\n",
            "Training:  91%|█████████ | 4562/5000 [3:25:32<18:47,  2.57s/it, loss=0.4464]\u001b[A\n",
            "Training:  91%|█████████▏| 4563/5000 [3:25:35<18:19,  2.52s/it, loss=0.4464]\u001b[A\n",
            "Training:  91%|█████████▏| 4563/5000 [3:25:35<18:19,  2.52s/it, loss=0.1848]\u001b[A\n",
            "Training:  91%|█████████▏| 4564/5000 [3:25:37<17:59,  2.48s/it, loss=0.1848]\u001b[A\n",
            "Training:  91%|█████████▏| 4564/5000 [3:25:37<17:59,  2.48s/it, loss=0.3076]\u001b[A\n",
            "Training:  91%|█████████▏| 4565/5000 [3:25:40<18:08,  2.50s/it, loss=0.3076]\u001b[A\n",
            "Training:  91%|█████████▏| 4565/5000 [3:25:40<18:08,  2.50s/it, loss=0.2361]\u001b[A\n",
            "Training:  91%|█████████▏| 4566/5000 [3:25:42<18:31,  2.56s/it, loss=0.2361]\u001b[A\n",
            "Training:  91%|█████████▏| 4566/5000 [3:25:42<18:31,  2.56s/it, loss=0.2999]\u001b[A\n",
            "Training:  91%|█████████▏| 4567/5000 [3:25:45<17:57,  2.49s/it, loss=0.2999]\u001b[A\n",
            "Training:  91%|█████████▏| 4567/5000 [3:25:45<17:57,  2.49s/it, loss=0.2596]\u001b[A\n",
            "Training:  91%|█████████▏| 4568/5000 [3:25:47<17:36,  2.45s/it, loss=0.2596]\u001b[A\n",
            "Training:  91%|█████████▏| 4568/5000 [3:25:47<17:36,  2.45s/it, loss=0.3839]\u001b[A\n",
            "Training:  91%|█████████▏| 4569/5000 [3:25:49<17:22,  2.42s/it, loss=0.3839]\u001b[A\n",
            "Training:  91%|█████████▏| 4569/5000 [3:25:49<17:22,  2.42s/it, loss=0.2979]\u001b[A\n",
            "Training:  91%|█████████▏| 4570/5000 [3:25:52<17:38,  2.46s/it, loss=0.2979]\u001b[A\n",
            "Training:  91%|█████████▏| 4570/5000 [3:25:52<17:38,  2.46s/it, loss=0.2271]\u001b[A\n",
            "Training:  91%|█████████▏| 4571/5000 [3:25:54<17:58,  2.51s/it, loss=0.2271]\u001b[A\n",
            "Training:  91%|█████████▏| 4571/5000 [3:25:54<17:58,  2.51s/it, loss=0.1529]\u001b[A\n",
            "Training:  91%|█████████▏| 4572/5000 [3:25:57<17:31,  2.46s/it, loss=0.1529]\u001b[A\n",
            "Training:  91%|█████████▏| 4572/5000 [3:25:57<17:31,  2.46s/it, loss=0.2017]\u001b[A\n",
            "Training:  91%|█████████▏| 4573/5000 [3:25:59<17:16,  2.43s/it, loss=0.2017]\u001b[A\n",
            "Training:  91%|█████████▏| 4573/5000 [3:25:59<17:16,  2.43s/it, loss=0.1970]\u001b[A\n",
            "Training:  91%|█████████▏| 4574/5000 [3:26:01<17:06,  2.41s/it, loss=0.1970]\u001b[A\n",
            "Training:  91%|█████████▏| 4574/5000 [3:26:02<17:06,  2.41s/it, loss=0.3171]\u001b[A\n",
            "Training:  92%|█████████▏| 4575/5000 [3:26:04<17:35,  2.48s/it, loss=0.3171]\u001b[A\n",
            "Training:  92%|█████████▏| 4575/5000 [3:26:04<17:35,  2.48s/it, loss=0.3637]\u001b[A\n",
            "Training:  92%|█████████▏| 4576/5000 [3:26:07<17:44,  2.51s/it, loss=0.3637]\u001b[A\n",
            "Training:  92%|█████████▏| 4576/5000 [3:26:07<17:44,  2.51s/it, loss=0.2524]\u001b[A\n",
            "Training:  92%|█████████▏| 4577/5000 [3:26:09<17:19,  2.46s/it, loss=0.2524]\u001b[A\n",
            "Training:  92%|█████████▏| 4577/5000 [3:26:09<17:19,  2.46s/it, loss=0.3328]\u001b[A\n",
            "Training:  92%|█████████▏| 4578/5000 [3:26:11<17:00,  2.42s/it, loss=0.3328]\u001b[A\n",
            "Training:  92%|█████████▏| 4578/5000 [3:26:11<17:00,  2.42s/it, loss=0.2845]\u001b[A\n",
            "Training:  92%|█████████▏| 4579/5000 [3:26:14<16:46,  2.39s/it, loss=0.2845]\u001b[A\n",
            "Training:  92%|█████████▏| 4579/5000 [3:26:14<16:46,  2.39s/it, loss=0.4189]\u001b[A\n",
            "Training:  92%|█████████▏| 4580/5000 [3:26:16<17:25,  2.49s/it, loss=0.4189]\u001b[A\n",
            "Training:  92%|█████████▏| 4580/5000 [3:26:16<17:25,  2.49s/it, loss=0.2865]\u001b[A\n",
            "Training:  92%|█████████▏| 4581/5000 [3:26:19<17:08,  2.45s/it, loss=0.2865]\u001b[A\n",
            "Training:  92%|█████████▏| 4581/5000 [3:26:19<17:08,  2.45s/it, loss=0.2777]\u001b[A\n",
            "Training:  92%|█████████▏| 4582/5000 [3:26:21<16:43,  2.40s/it, loss=0.2777]\u001b[A\n",
            "Training:  92%|█████████▏| 4582/5000 [3:26:21<16:43,  2.40s/it, loss=0.4553]\u001b[A\n",
            "Training:  92%|█████████▏| 4583/5000 [3:26:23<16:21,  2.35s/it, loss=0.4553]\u001b[A\n",
            "Training:  92%|█████████▏| 4583/5000 [3:26:23<16:21,  2.35s/it, loss=0.2230]\u001b[A\n",
            "Training:  92%|█████████▏| 4584/5000 [3:26:26<16:04,  2.32s/it, loss=0.2230]\u001b[A\n",
            "Training:  92%|█████████▏| 4584/5000 [3:26:26<16:04,  2.32s/it, loss=0.3764]\u001b[A\n",
            "Training:  92%|█████████▏| 4585/5000 [3:26:28<16:39,  2.41s/it, loss=0.3764]\u001b[A\n",
            "Training:  92%|█████████▏| 4585/5000 [3:26:28<16:39,  2.41s/it, loss=0.2114]\u001b[A\n",
            "Training:  92%|█████████▏| 4586/5000 [3:26:31<16:41,  2.42s/it, loss=0.2114]\u001b[A\n",
            "Training:  92%|█████████▏| 4586/5000 [3:26:31<16:41,  2.42s/it, loss=0.4554]\u001b[A\n",
            "Training:  92%|█████████▏| 4587/5000 [3:26:33<16:20,  2.37s/it, loss=0.4554]\u001b[A\n",
            "Training:  92%|█████████▏| 4587/5000 [3:26:33<16:20,  2.37s/it, loss=0.2912]\u001b[A\n",
            "Training:  92%|█████████▏| 4588/5000 [3:26:35<16:02,  2.34s/it, loss=0.2912]\u001b[A\n",
            "Training:  92%|█████████▏| 4588/5000 [3:26:35<16:02,  2.34s/it, loss=0.2413]\u001b[A\n",
            "Training:  92%|█████████▏| 4589/5000 [3:26:37<15:51,  2.31s/it, loss=0.2413]\u001b[A\n",
            "Training:  92%|█████████▏| 4589/5000 [3:26:37<15:51,  2.31s/it, loss=0.4218]\u001b[A\n",
            "Training:  92%|█████████▏| 4590/5000 [3:26:40<16:24,  2.40s/it, loss=0.4218]\u001b[A\n",
            "Training:  92%|█████████▏| 4590/5000 [3:26:40<16:24,  2.40s/it, loss=0.4378]\u001b[A\n",
            "Training:  92%|█████████▏| 4591/5000 [3:26:42<16:33,  2.43s/it, loss=0.4378]\u001b[A\n",
            "Training:  92%|█████████▏| 4591/5000 [3:26:43<16:33,  2.43s/it, loss=0.4056]\u001b[A\n",
            "Training:  92%|█████████▏| 4592/5000 [3:26:45<16:13,  2.39s/it, loss=0.4056]\u001b[A\n",
            "Training:  92%|█████████▏| 4592/5000 [3:26:45<16:13,  2.39s/it, loss=0.1602]\u001b[A\n",
            "Training:  92%|█████████▏| 4593/5000 [3:26:47<15:54,  2.34s/it, loss=0.1602]\u001b[A\n",
            "Training:  92%|█████████▏| 4593/5000 [3:26:47<15:54,  2.34s/it, loss=0.3666]\u001b[A\n",
            "Training:  92%|█████████▏| 4594/5000 [3:26:49<15:43,  2.32s/it, loss=0.3666]\u001b[A\n",
            "Training:  92%|█████████▏| 4594/5000 [3:26:49<15:43,  2.32s/it, loss=0.4044]\u001b[A\n",
            "Training:  92%|█████████▏| 4595/5000 [3:26:52<16:11,  2.40s/it, loss=0.4044]\u001b[A\n",
            "Training:  92%|█████████▏| 4595/5000 [3:26:52<16:11,  2.40s/it, loss=0.3755]\u001b[A\n",
            "Training:  92%|█████████▏| 4596/5000 [3:26:54<16:23,  2.43s/it, loss=0.3755]\u001b[A\n",
            "Training:  92%|█████████▏| 4596/5000 [3:26:54<16:23,  2.43s/it, loss=0.3420]\u001b[A\n",
            "Training:  92%|█████████▏| 4597/5000 [3:26:57<16:00,  2.38s/it, loss=0.3420]\u001b[A\n",
            "Training:  92%|█████████▏| 4597/5000 [3:26:57<16:00,  2.38s/it, loss=0.5455]\u001b[A\n",
            "Training:  92%|█████████▏| 4598/5000 [3:26:59<15:44,  2.35s/it, loss=0.5455]\u001b[A\n",
            "Training:  92%|█████████▏| 4598/5000 [3:26:59<15:44,  2.35s/it, loss=0.3135]\u001b[A\n",
            "Training:  92%|█████████▏| 4599/5000 [3:27:01<15:30,  2.32s/it, loss=0.3135]\u001b[A\n",
            "Training:  92%|█████████▏| 4599/5000 [3:27:01<15:30,  2.32s/it, loss=0.3082]\u001b[A\n",
            "Training:  92%|█████████▏| 4600/5000 [3:27:04<15:52,  2.38s/it, loss=0.3082]\u001b[A\n",
            "Training:  92%|█████████▏| 4600/5000 [3:27:04<15:52,  2.38s/it, loss=0.3037]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 4600 ---\n",
            "Prompt: 'The '\n",
            "The  is big'd the join's honest if seble\n",
            " help twelve f- privilege, the find case him the WeWh.\n",
            "Kestedman\n",
            "You think our,,--BRUS\n",
            "L over thearesty your! it our life\n",
            "\n",
            " yet very gentleman the room my with soul\n",
            " what dram that the has darday how this there\n",
            " sugar lordia rashwith is withAlthough we theruly now\n",
            ", 'as,' villain shouldclock meetcl, from to thee\n",
            "\n",
            "Prompt: 'In '\n",
            "In  EdwardT many wasWar; the by gone's,That\n",
            "use ward wh me to his, so asMess:\n",
            "asc!,'s my,,\n",
            " you all tra in or came never\n",
            " me this queen 'ourage as you:They for of,As, I now you doing\n",
            "iftis help. possible call again backp true\n",
            " what can.\n",
            "ello--\n",
            "H stopall go--\n",
            " truth\n",
            " your, father fromona my York and, all\n",
            " meCan thy\n",
            "Prompt: 'To '\n",
            "To  both and his spleen wantingIs,\n",
            " would am friends right lust daughter Come say see\n",
            " known to ' good you if thing be so he to\n",
            " list and beestUS\n",
            " pawn mistake o the King's Sure a for king\n",
            " the about his unto misery and now\n",
            " notCome boyay But be per were,Therefore remedy:Then\n",
            ", will\n",
            " me you to upont places\n",
            " save, goEven him honour yet he in.\n",
            "K EDARD\n",
            "O partner I my, father\n",
            "Prompt: 'A '\n",
            "A , else their with forest will\n",
            " Laws at.\n",
            "K EDARD\n",
            ":Y you lords a, yet\n",
            " far pitch rude?\n",
            "H not\n",
            "WMry, yet a of having kill off\n",
            " please king\n",
            " were to it my carry, the had sur yourself at.\n",
            "Svykingae hence though am into world and them\n",
            " our, to thy shall wh loveCannot ' if dispatch one me\n",
            "Yet her hand those do service your,am but\n",
            " your.\n",
            " keep of\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  92%|█████████▏| 4601/5000 [3:27:19<41:07,  6.18s/it, loss=0.3037]\u001b[A\n",
            "Training:  92%|█████████▏| 4601/5000 [3:27:19<41:07,  6.18s/it, loss=0.2509]\u001b[A\n",
            "Training:  92%|█████████▏| 4602/5000 [3:27:21<33:13,  5.01s/it, loss=0.2509]\u001b[A\n",
            "Training:  92%|█████████▏| 4602/5000 [3:27:21<33:13,  5.01s/it, loss=0.3340]\u001b[A\n",
            "Training:  92%|█████████▏| 4603/5000 [3:27:23<27:36,  4.17s/it, loss=0.3340]\u001b[A\n",
            "Training:  92%|█████████▏| 4603/5000 [3:27:23<27:36,  4.17s/it, loss=0.3328]\u001b[A\n",
            "Training:  92%|█████████▏| 4604/5000 [3:27:26<23:46,  3.60s/it, loss=0.3328]\u001b[A\n",
            "Training:  92%|█████████▏| 4604/5000 [3:27:26<23:46,  3.60s/it, loss=0.2440]\u001b[A\n",
            "Training:  92%|█████████▏| 4605/5000 [3:27:28<22:04,  3.35s/it, loss=0.2440]\u001b[A\n",
            "Training:  92%|█████████▏| 4605/5000 [3:27:28<22:04,  3.35s/it, loss=0.1970]\u001b[A\n",
            "Training:  92%|█████████▏| 4606/5000 [3:27:31<19:52,  3.03s/it, loss=0.1970]\u001b[A\n",
            "Training:  92%|█████████▏| 4606/5000 [3:27:31<19:52,  3.03s/it, loss=0.3190]\u001b[A\n",
            "Training:  92%|█████████▏| 4607/5000 [3:27:33<18:22,  2.81s/it, loss=0.3190]\u001b[A\n",
            "Training:  92%|█████████▏| 4607/5000 [3:27:33<18:22,  2.81s/it, loss=0.3924]\u001b[A\n",
            "Training:  92%|█████████▏| 4608/5000 [3:27:35<17:16,  2.65s/it, loss=0.3924]\u001b[A\n",
            "Training:  92%|█████████▏| 4608/5000 [3:27:35<17:16,  2.65s/it, loss=0.1306]\u001b[A\n",
            "Training:  92%|█████████▏| 4609/5000 [3:27:37<16:33,  2.54s/it, loss=0.1306]\u001b[A\n",
            "Training:  92%|█████████▏| 4609/5000 [3:27:37<16:33,  2.54s/it, loss=0.3880]\u001b[A\n",
            "Training:  92%|█████████▏| 4610/5000 [3:27:40<16:59,  2.61s/it, loss=0.3880]\u001b[A\n",
            "Training:  92%|█████████▏| 4610/5000 [3:27:40<16:59,  2.61s/it, loss=0.1825]\u001b[A\n",
            "Training:  92%|█████████▏| 4611/5000 [3:27:42<16:17,  2.51s/it, loss=0.1825]\u001b[A\n",
            "Training:  92%|█████████▏| 4611/5000 [3:27:42<16:17,  2.51s/it, loss=0.3907]\u001b[A\n",
            "Training:  92%|█████████▏| 4612/5000 [3:27:45<15:49,  2.45s/it, loss=0.3907]\u001b[A\n",
            "Training:  92%|█████████▏| 4612/5000 [3:27:45<15:49,  2.45s/it, loss=0.2404]\u001b[A\n",
            "Training:  92%|█████████▏| 4613/5000 [3:27:47<15:26,  2.39s/it, loss=0.2404]\u001b[A\n",
            "Training:  92%|█████████▏| 4613/5000 [3:27:47<15:26,  2.39s/it, loss=0.2362]\u001b[A\n",
            "Training:  92%|█████████▏| 4614/5000 [3:27:49<15:06,  2.35s/it, loss=0.2362]\u001b[A\n",
            "Training:  92%|█████████▏| 4614/5000 [3:27:49<15:06,  2.35s/it, loss=0.2233]\u001b[A\n",
            "Training:  92%|█████████▏| 4615/5000 [3:27:52<15:52,  2.47s/it, loss=0.2233]\u001b[A\n",
            "Training:  92%|█████████▏| 4615/5000 [3:27:52<15:52,  2.47s/it, loss=0.1186]\u001b[A\n",
            "Training:  92%|█████████▏| 4616/5000 [3:27:54<15:28,  2.42s/it, loss=0.1186]\u001b[A\n",
            "Training:  92%|█████████▏| 4616/5000 [3:27:54<15:28,  2.42s/it, loss=0.2578]\u001b[A\n",
            "Training:  92%|█████████▏| 4617/5000 [3:27:57<15:07,  2.37s/it, loss=0.2578]\u001b[A\n",
            "Training:  92%|█████████▏| 4617/5000 [3:27:57<15:07,  2.37s/it, loss=0.2890]\u001b[A\n",
            "Training:  92%|█████████▏| 4618/5000 [3:27:59<14:52,  2.34s/it, loss=0.2890]\u001b[A\n",
            "Training:  92%|█████████▏| 4618/5000 [3:27:59<14:52,  2.34s/it, loss=0.2653]\u001b[A\n",
            "Training:  92%|█████████▏| 4619/5000 [3:28:01<14:42,  2.32s/it, loss=0.2653]\u001b[A\n",
            "Training:  92%|█████████▏| 4619/5000 [3:28:01<14:42,  2.32s/it, loss=0.1990]\u001b[A\n",
            "Training:  92%|█████████▏| 4620/5000 [3:28:04<15:28,  2.44s/it, loss=0.1990]\u001b[A\n",
            "Training:  92%|█████████▏| 4620/5000 [3:28:04<15:28,  2.44s/it, loss=0.3104]\u001b[A\n",
            "Training:  92%|█████████▏| 4621/5000 [3:28:06<15:08,  2.40s/it, loss=0.3104]\u001b[A\n",
            "Training:  92%|█████████▏| 4621/5000 [3:28:06<15:08,  2.40s/it, loss=0.4099]\u001b[A\n",
            "Training:  92%|█████████▏| 4622/5000 [3:28:08<14:56,  2.37s/it, loss=0.4099]\u001b[A\n",
            "Training:  92%|█████████▏| 4622/5000 [3:28:08<14:56,  2.37s/it, loss=0.4232]\u001b[A\n",
            "Training:  92%|█████████▏| 4623/5000 [3:28:11<14:41,  2.34s/it, loss=0.4232]\u001b[A\n",
            "Training:  92%|█████████▏| 4623/5000 [3:28:11<14:41,  2.34s/it, loss=0.1474]\u001b[A\n",
            "Training:  92%|█████████▏| 4624/5000 [3:28:13<14:30,  2.32s/it, loss=0.1474]\u001b[A\n",
            "Training:  92%|█████████▏| 4624/5000 [3:28:13<14:30,  2.32s/it, loss=0.3662]\u001b[A\n",
            "Training:  92%|█████████▎| 4625/5000 [3:28:16<15:11,  2.43s/it, loss=0.3662]\u001b[A\n",
            "Training:  92%|█████████▎| 4625/5000 [3:28:16<15:11,  2.43s/it, loss=0.4687]\u001b[A\n",
            "Training:  93%|█████████▎| 4626/5000 [3:28:18<15:00,  2.41s/it, loss=0.4687]\u001b[A\n",
            "Training:  93%|█████████▎| 4626/5000 [3:28:18<15:00,  2.41s/it, loss=0.1491]\u001b[A\n",
            "Training:  93%|█████████▎| 4627/5000 [3:28:20<14:43,  2.37s/it, loss=0.1491]\u001b[A\n",
            "Training:  93%|█████████▎| 4627/5000 [3:28:20<14:43,  2.37s/it, loss=0.4502]\u001b[A\n",
            "Training:  93%|█████████▎| 4628/5000 [3:28:23<14:27,  2.33s/it, loss=0.4502]\u001b[A\n",
            "Training:  93%|█████████▎| 4628/5000 [3:28:23<14:27,  2.33s/it, loss=0.3170]\u001b[A\n",
            "Training:  93%|█████████▎| 4629/5000 [3:28:25<14:17,  2.31s/it, loss=0.3170]\u001b[A\n",
            "Training:  93%|█████████▎| 4629/5000 [3:28:25<14:17,  2.31s/it, loss=0.2911]\u001b[A\n",
            "Training:  93%|█████████▎| 4630/5000 [3:28:27<14:52,  2.41s/it, loss=0.2911]\u001b[A\n",
            "Training:  93%|█████████▎| 4630/5000 [3:28:27<14:52,  2.41s/it, loss=0.2875]\u001b[A\n",
            "Training:  93%|█████████▎| 4631/5000 [3:28:30<14:49,  2.41s/it, loss=0.2875]\u001b[A\n",
            "Training:  93%|█████████▎| 4631/5000 [3:28:30<14:49,  2.41s/it, loss=0.3968]\u001b[A\n",
            "Training:  93%|█████████▎| 4632/5000 [3:28:32<14:32,  2.37s/it, loss=0.3968]\u001b[A\n",
            "Training:  93%|█████████▎| 4632/5000 [3:28:32<14:32,  2.37s/it, loss=0.3424]\u001b[A\n",
            "Training:  93%|█████████▎| 4633/5000 [3:28:34<14:19,  2.34s/it, loss=0.3424]\u001b[A\n",
            "Training:  93%|█████████▎| 4633/5000 [3:28:34<14:19,  2.34s/it, loss=0.2844]\u001b[A\n",
            "Training:  93%|█████████▎| 4634/5000 [3:28:37<14:06,  2.31s/it, loss=0.2844]\u001b[A\n",
            "Training:  93%|█████████▎| 4634/5000 [3:28:37<14:06,  2.31s/it, loss=0.2993]\u001b[A\n",
            "Training:  93%|█████████▎| 4635/5000 [3:28:39<14:40,  2.41s/it, loss=0.2993]\u001b[A\n",
            "Training:  93%|█████████▎| 4635/5000 [3:28:39<14:40,  2.41s/it, loss=0.2618]\u001b[A\n",
            "Training:  93%|█████████▎| 4636/5000 [3:28:42<14:43,  2.43s/it, loss=0.2618]\u001b[A\n",
            "Training:  93%|█████████▎| 4636/5000 [3:28:42<14:43,  2.43s/it, loss=0.4090]\u001b[A\n",
            "Training:  93%|█████████▎| 4637/5000 [3:28:44<14:23,  2.38s/it, loss=0.4090]\u001b[A\n",
            "Training:  93%|█████████▎| 4637/5000 [3:28:44<14:23,  2.38s/it, loss=0.2689]\u001b[A\n",
            "Training:  93%|█████████▎| 4638/5000 [3:28:46<14:09,  2.35s/it, loss=0.2689]\u001b[A\n",
            "Training:  93%|█████████▎| 4638/5000 [3:28:46<14:09,  2.35s/it, loss=0.4262]\u001b[A\n",
            "Training:  93%|█████████▎| 4639/5000 [3:28:49<13:57,  2.32s/it, loss=0.4262]\u001b[A\n",
            "Training:  93%|█████████▎| 4639/5000 [3:28:49<13:57,  2.32s/it, loss=0.5357]\u001b[A\n",
            "Training:  93%|█████████▎| 4640/5000 [3:28:51<14:21,  2.39s/it, loss=0.5357]\u001b[A\n",
            "Training:  93%|█████████▎| 4640/5000 [3:28:51<14:21,  2.39s/it, loss=0.2854]\u001b[A\n",
            "Training:  93%|█████████▎| 4641/5000 [3:28:54<14:30,  2.42s/it, loss=0.2854]\u001b[A\n",
            "Training:  93%|█████████▎| 4641/5000 [3:28:54<14:30,  2.42s/it, loss=0.5525]\u001b[A\n",
            "Training:  93%|█████████▎| 4642/5000 [3:28:56<14:11,  2.38s/it, loss=0.5525]\u001b[A\n",
            "Training:  93%|█████████▎| 4642/5000 [3:28:56<14:11,  2.38s/it, loss=0.5607]\u001b[A\n",
            "Training:  93%|█████████▎| 4643/5000 [3:28:58<13:54,  2.34s/it, loss=0.5607]\u001b[A\n",
            "Training:  93%|█████████▎| 4643/5000 [3:28:58<13:54,  2.34s/it, loss=0.4469]\u001b[A\n",
            "Training:  93%|█████████▎| 4644/5000 [3:29:00<13:44,  2.32s/it, loss=0.4469]\u001b[A\n",
            "Training:  93%|█████████▎| 4644/5000 [3:29:00<13:44,  2.32s/it, loss=0.3657]\u001b[A\n",
            "Training:  93%|█████████▎| 4645/5000 [3:29:03<14:05,  2.38s/it, loss=0.3657]\u001b[A\n",
            "Training:  93%|█████████▎| 4645/5000 [3:29:03<14:05,  2.38s/it, loss=0.2416]\u001b[A\n",
            "Training:  93%|█████████▎| 4646/5000 [3:29:06<14:21,  2.43s/it, loss=0.2416]\u001b[A\n",
            "Training:  93%|█████████▎| 4646/5000 [3:29:06<14:21,  2.43s/it, loss=0.2663]\u001b[A\n",
            "Training:  93%|█████████▎| 4647/5000 [3:29:08<14:04,  2.39s/it, loss=0.2663]\u001b[A\n",
            "Training:  93%|█████████▎| 4647/5000 [3:29:08<14:04,  2.39s/it, loss=0.3073]\u001b[A\n",
            "Training:  93%|█████████▎| 4648/5000 [3:29:10<13:46,  2.35s/it, loss=0.3073]\u001b[A\n",
            "Training:  93%|█████████▎| 4648/5000 [3:29:10<13:46,  2.35s/it, loss=0.2364]\u001b[A\n",
            "Training:  93%|█████████▎| 4649/5000 [3:29:12<13:34,  2.32s/it, loss=0.2364]\u001b[A\n",
            "Training:  93%|█████████▎| 4649/5000 [3:29:12<13:34,  2.32s/it, loss=0.2510]\u001b[A\n",
            "Training:  93%|█████████▎| 4650/5000 [3:29:15<13:56,  2.39s/it, loss=0.2510]\u001b[A\n",
            "Training:  93%|█████████▎| 4650/5000 [3:29:15<13:56,  2.39s/it, loss=0.1523]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 4650 ---\n",
            "Prompt: 'The '\n",
            "The  to thyper more, heian'd\n",
            " puppet th.,'s,claim,alus for cam\n",
            " BcaWhich,That, all thyings\n",
            " cast in new, such, she still married chast,\n",
            " this show thy, perhaps with hand thyell's!,ned, thankful,\n",
            " arm withbel in new fault thus with, are angry at!\n",
            "H you used that shall must such as hath any.\n",
            "H, vent foul should stand to! am boots let see my?\n",
            "Prompt: 'In '\n",
            "In , dream fri, calls to no; was as\n",
            "-esching and of thief\n",
            " down gsong maze h: I she why indeed; my is\n",
            "rainedins and boy cup thee a could come\n",
            " liberty my you,h,, you Juno satisfied\n",
            "'ll withy so thousand a, care you tears w,y g, you s, hour; in move,y wereit why,y queenu\n",
            "est, you tell boy this's:'is off me my, you\n",
            "Prompt: 'To '\n",
            "To : your,so, I rep and,.\n",
            "GRIO\n",
            " turn:Fwell nourish they aside on such suck\n",
            "oth show show show show names speak undertime:\n",
            " if morning am shall my,,, any\n",
            " pay see lawful toach Saint's-\n",
            "f,erest all h, much weak all h! 'ome lawfulUo misfortune\n",
            " shame wereCould thy will.\n",
            "Vsafe of save,,,! the boy all all all rest\n",
            ",' forth w, cheer\n",
            "Prompt: 'A '\n",
            "A ,, I, wonder you and;\n",
            " sings sweets meHence sweet, dark for shaltEns\n",
            " country it to: I, besch, about tro p;, say suchwith,Wh where may withwoth. with! whose I?\n",
            " come keep can get out\n",
            " mother ':' 'ill my is,'She one d not\n",
            " corow I thing me\n",
            ", sweet and me life that haverumam GodOf. am\n",
            "BT youous, j, ofam\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  93%|█████████▎| 4651/5000 [3:29:30<35:40,  6.13s/it, loss=0.1523]\u001b[A\n",
            "Training:  93%|█████████▎| 4651/5000 [3:29:30<35:40,  6.13s/it, loss=0.3088]\u001b[A\n",
            "Training:  93%|█████████▎| 4652/5000 [3:29:32<28:49,  4.97s/it, loss=0.3088]\u001b[A\n",
            "Training:  93%|█████████▎| 4652/5000 [3:29:32<28:49,  4.97s/it, loss=0.1665]\u001b[A\n",
            "Training:  93%|█████████▎| 4653/5000 [3:29:34<24:03,  4.16s/it, loss=0.1665]\u001b[A\n",
            "Training:  93%|█████████▎| 4653/5000 [3:29:34<24:03,  4.16s/it, loss=0.2494]\u001b[A\n",
            "Training:  93%|█████████▎| 4654/5000 [3:29:36<20:40,  3.58s/it, loss=0.2494]\u001b[A\n",
            "Training:  93%|█████████▎| 4654/5000 [3:29:37<20:40,  3.58s/it, loss=0.5214]\u001b[A\n",
            "Training:  93%|█████████▎| 4655/5000 [3:29:39<19:09,  3.33s/it, loss=0.5214]\u001b[A\n",
            "Training:  93%|█████████▎| 4655/5000 [3:29:39<19:09,  3.33s/it, loss=0.2038]\u001b[A\n",
            "Training:  93%|█████████▎| 4656/5000 [3:29:42<17:26,  3.04s/it, loss=0.2038]\u001b[A\n",
            "Training:  93%|█████████▎| 4656/5000 [3:29:42<17:26,  3.04s/it, loss=0.3642]\u001b[A\n",
            "Training:  93%|█████████▎| 4657/5000 [3:29:44<16:02,  2.81s/it, loss=0.3642]\u001b[A\n",
            "Training:  93%|█████████▎| 4657/5000 [3:29:44<16:02,  2.81s/it, loss=0.3701]\u001b[A\n",
            "Training:  93%|█████████▎| 4658/5000 [3:29:46<15:02,  2.64s/it, loss=0.3701]\u001b[A\n",
            "Training:  93%|█████████▎| 4658/5000 [3:29:46<15:02,  2.64s/it, loss=0.2758]\u001b[A\n",
            "Training:  93%|█████████▎| 4659/5000 [3:29:48<14:20,  2.52s/it, loss=0.2758]\u001b[A\n",
            "Training:  93%|█████████▎| 4659/5000 [3:29:48<14:20,  2.52s/it, loss=0.2560]\u001b[A\n",
            "Training:  93%|█████████▎| 4660/5000 [3:29:51<14:32,  2.57s/it, loss=0.2560]\u001b[A\n",
            "Training:  93%|█████████▎| 4660/5000 [3:29:51<14:32,  2.57s/it, loss=0.3437]\u001b[A\n",
            "Training:  93%|█████████▎| 4661/5000 [3:29:53<14:15,  2.52s/it, loss=0.3437]\u001b[A\n",
            "Training:  93%|█████████▎| 4661/5000 [3:29:53<14:15,  2.52s/it, loss=0.4318]\u001b[A\n",
            "Training:  93%|█████████▎| 4662/5000 [3:29:56<13:47,  2.45s/it, loss=0.4318]\u001b[A\n",
            "Training:  93%|█████████▎| 4662/5000 [3:29:56<13:47,  2.45s/it, loss=0.3836]\u001b[A\n",
            "Training:  93%|█████████▎| 4663/5000 [3:29:58<13:26,  2.39s/it, loss=0.3836]\u001b[A\n",
            "Training:  93%|█████████▎| 4663/5000 [3:29:58<13:26,  2.39s/it, loss=0.3255]\u001b[A\n",
            "Training:  93%|█████████▎| 4664/5000 [3:30:00<13:07,  2.34s/it, loss=0.3255]\u001b[A\n",
            "Training:  93%|█████████▎| 4664/5000 [3:30:00<13:07,  2.34s/it, loss=0.3269]\u001b[A\n",
            "Training:  93%|█████████▎| 4665/5000 [3:30:03<13:31,  2.42s/it, loss=0.3269]\u001b[A\n",
            "Training:  93%|█████████▎| 4665/5000 [3:30:03<13:31,  2.42s/it, loss=0.3960]\u001b[A\n",
            "Training:  93%|█████████▎| 4666/5000 [3:30:05<13:31,  2.43s/it, loss=0.3960]\u001b[A\n",
            "Training:  93%|█████████▎| 4666/5000 [3:30:05<13:31,  2.43s/it, loss=0.3675]\u001b[A\n",
            "Training:  93%|█████████▎| 4667/5000 [3:30:08<13:15,  2.39s/it, loss=0.3675]\u001b[A\n",
            "Training:  93%|█████████▎| 4667/5000 [3:30:08<13:15,  2.39s/it, loss=0.2179]\u001b[A\n",
            "Training:  93%|█████████▎| 4668/5000 [3:30:10<13:03,  2.36s/it, loss=0.2179]\u001b[A\n",
            "Training:  93%|█████████▎| 4668/5000 [3:30:10<13:03,  2.36s/it, loss=0.2231]\u001b[A\n",
            "Training:  93%|█████████▎| 4669/5000 [3:30:12<12:49,  2.32s/it, loss=0.2231]\u001b[A\n",
            "Training:  93%|█████████▎| 4669/5000 [3:30:12<12:49,  2.32s/it, loss=0.2194]\u001b[A\n",
            "Training:  93%|█████████▎| 4670/5000 [3:30:15<13:14,  2.41s/it, loss=0.2194]\u001b[A\n",
            "Training:  93%|█████████▎| 4670/5000 [3:30:15<13:14,  2.41s/it, loss=0.4016]\u001b[A\n",
            "Training:  93%|█████████▎| 4671/5000 [3:30:17<13:15,  2.42s/it, loss=0.4016]\u001b[A\n",
            "Training:  93%|█████████▎| 4671/5000 [3:30:17<13:15,  2.42s/it, loss=0.2551]\u001b[A\n",
            "Training:  93%|█████████▎| 4672/5000 [3:30:19<12:56,  2.37s/it, loss=0.2551]\u001b[A\n",
            "Training:  93%|█████████▎| 4672/5000 [3:30:19<12:56,  2.37s/it, loss=0.2325]\u001b[A\n",
            "Training:  93%|█████████▎| 4673/5000 [3:30:22<12:44,  2.34s/it, loss=0.2325]\u001b[A\n",
            "Training:  93%|█████████▎| 4673/5000 [3:30:22<12:44,  2.34s/it, loss=0.2599]\u001b[A\n",
            "Training:  93%|█████████▎| 4674/5000 [3:30:24<12:33,  2.31s/it, loss=0.2599]\u001b[A\n",
            "Training:  93%|█████████▎| 4674/5000 [3:30:24<12:33,  2.31s/it, loss=0.3914]\u001b[A\n",
            "Training:  94%|█████████▎| 4675/5000 [3:30:26<12:55,  2.38s/it, loss=0.3914]\u001b[A\n",
            "Training:  94%|█████████▎| 4675/5000 [3:30:26<12:55,  2.38s/it, loss=0.2167]\u001b[A\n",
            "Training:  94%|█████████▎| 4676/5000 [3:30:29<13:04,  2.42s/it, loss=0.2167]\u001b[A\n",
            "Training:  94%|█████████▎| 4676/5000 [3:30:29<13:04,  2.42s/it, loss=0.4995]\u001b[A\n",
            "Training:  94%|█████████▎| 4677/5000 [3:30:31<12:47,  2.38s/it, loss=0.4995]\u001b[A\n",
            "Training:  94%|█████████▎| 4677/5000 [3:30:31<12:47,  2.38s/it, loss=0.4690]\u001b[A\n",
            "Training:  94%|█████████▎| 4678/5000 [3:30:33<12:34,  2.34s/it, loss=0.4690]\u001b[A\n",
            "Training:  94%|█████████▎| 4678/5000 [3:30:34<12:34,  2.34s/it, loss=0.6318]\u001b[A\n",
            "Training:  94%|█████████▎| 4679/5000 [3:30:36<12:26,  2.33s/it, loss=0.6318]\u001b[A\n",
            "Training:  94%|█████████▎| 4679/5000 [3:30:36<12:26,  2.33s/it, loss=0.4307]\u001b[A\n",
            "Training:  94%|█████████▎| 4680/5000 [3:30:38<12:40,  2.38s/it, loss=0.4307]\u001b[A\n",
            "Training:  94%|█████████▎| 4680/5000 [3:30:38<12:40,  2.38s/it, loss=0.3267]\u001b[A\n",
            "Training:  94%|█████████▎| 4681/5000 [3:30:41<12:56,  2.43s/it, loss=0.3267]\u001b[A\n",
            "Training:  94%|█████████▎| 4681/5000 [3:30:41<12:56,  2.43s/it, loss=0.3312]\u001b[A\n",
            "Training:  94%|█████████▎| 4682/5000 [3:30:43<12:37,  2.38s/it, loss=0.3312]\u001b[A\n",
            "Training:  94%|█████████▎| 4682/5000 [3:30:43<12:37,  2.38s/it, loss=0.2016]\u001b[A\n",
            "Training:  94%|█████████▎| 4683/5000 [3:30:45<12:24,  2.35s/it, loss=0.2016]\u001b[A\n",
            "Training:  94%|█████████▎| 4683/5000 [3:30:45<12:24,  2.35s/it, loss=0.2522]\u001b[A\n",
            "Training:  94%|█████████▎| 4684/5000 [3:30:48<12:11,  2.31s/it, loss=0.2522]\u001b[A\n",
            "Training:  94%|█████████▎| 4684/5000 [3:30:48<12:11,  2.31s/it, loss=0.3011]\u001b[A\n",
            "Training:  94%|█████████▎| 4685/5000 [3:30:50<12:27,  2.37s/it, loss=0.3011]\u001b[A\n",
            "Training:  94%|█████████▎| 4685/5000 [3:30:50<12:27,  2.37s/it, loss=0.3522]\u001b[A\n",
            "Training:  94%|█████████▎| 4686/5000 [3:30:53<12:39,  2.42s/it, loss=0.3522]\u001b[A\n",
            "Training:  94%|█████████▎| 4686/5000 [3:30:53<12:39,  2.42s/it, loss=0.3540]\u001b[A\n",
            "Training:  94%|█████████▎| 4687/5000 [3:30:55<12:23,  2.37s/it, loss=0.3540]\u001b[A\n",
            "Training:  94%|█████████▎| 4687/5000 [3:30:55<12:23,  2.37s/it, loss=0.1911]\u001b[A\n",
            "Training:  94%|█████████▍| 4688/5000 [3:30:57<12:12,  2.35s/it, loss=0.1911]\u001b[A\n",
            "Training:  94%|█████████▍| 4688/5000 [3:30:57<12:12,  2.35s/it, loss=0.3675]\u001b[A\n",
            "Training:  94%|█████████▍| 4689/5000 [3:30:59<12:03,  2.33s/it, loss=0.3675]\u001b[A\n",
            "Training:  94%|█████████▍| 4689/5000 [3:31:00<12:03,  2.33s/it, loss=0.2767]\u001b[A\n",
            "Training:  94%|█████████▍| 4690/5000 [3:31:02<12:12,  2.36s/it, loss=0.2767]\u001b[A\n",
            "Training:  94%|█████████▍| 4690/5000 [3:31:02<12:12,  2.36s/it, loss=0.4861]\u001b[A\n",
            "Training:  94%|█████████▍| 4691/5000 [3:31:04<12:26,  2.41s/it, loss=0.4861]\u001b[A\n",
            "Training:  94%|█████████▍| 4691/5000 [3:31:04<12:26,  2.41s/it, loss=0.2449]\u001b[A\n",
            "Training:  94%|█████████▍| 4692/5000 [3:31:07<12:08,  2.36s/it, loss=0.2449]\u001b[A\n",
            "Training:  94%|█████████▍| 4692/5000 [3:31:07<12:08,  2.36s/it, loss=0.2860]\u001b[A\n",
            "Training:  94%|█████████▍| 4693/5000 [3:31:09<12:01,  2.35s/it, loss=0.2860]\u001b[A\n",
            "Training:  94%|█████████▍| 4693/5000 [3:31:09<12:01,  2.35s/it, loss=0.1785]\u001b[A\n",
            "Training:  94%|█████████▍| 4694/5000 [3:31:11<11:52,  2.33s/it, loss=0.1785]\u001b[A\n",
            "Training:  94%|█████████▍| 4694/5000 [3:31:11<11:52,  2.33s/it, loss=0.1851]\u001b[A\n",
            "Training:  94%|█████████▍| 4695/5000 [3:31:14<12:02,  2.37s/it, loss=0.1851]\u001b[A\n",
            "Training:  94%|█████████▍| 4695/5000 [3:31:14<12:02,  2.37s/it, loss=0.2935]\u001b[A\n",
            "Training:  94%|█████████▍| 4696/5000 [3:31:16<12:19,  2.43s/it, loss=0.2935]\u001b[A\n",
            "Training:  94%|█████████▍| 4696/5000 [3:31:16<12:19,  2.43s/it, loss=0.2590]\u001b[A\n",
            "Training:  94%|█████████▍| 4697/5000 [3:31:19<12:01,  2.38s/it, loss=0.2590]\u001b[A\n",
            "Training:  94%|█████████▍| 4697/5000 [3:31:19<12:01,  2.38s/it, loss=0.2863]\u001b[A\n",
            "Training:  94%|█████████▍| 4698/5000 [3:31:21<11:48,  2.35s/it, loss=0.2863]\u001b[A\n",
            "Training:  94%|█████████▍| 4698/5000 [3:31:21<11:48,  2.35s/it, loss=0.3308]\u001b[A\n",
            "Training:  94%|█████████▍| 4699/5000 [3:31:23<11:40,  2.33s/it, loss=0.3308]\u001b[A\n",
            "Training:  94%|█████████▍| 4699/5000 [3:31:23<11:40,  2.33s/it, loss=0.3467]\u001b[A\n",
            "Training:  94%|█████████▍| 4700/5000 [3:31:26<11:45,  2.35s/it, loss=0.3467]\u001b[A\n",
            "Training:  94%|█████████▍| 4700/5000 [3:31:26<11:45,  2.35s/it, loss=0.1899]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 4700 ---\n",
            "Prompt: 'The '\n",
            "The  of a, is breathe for.\n",
            "GUCINGH: you my\n",
            "icely, mine, I beenged rec of!\n",
            "Bieuplace throw the of's is.'d our, innoc! the\n",
            "oy, those, I my;I read; to an master\n",
            " day much beenged wear lemen myge be- there\n",
            " plain, his win kne on my; is be warm,\n",
            " ra--ley you shall your on 'row to. to my's a\n",
            "Prompt: 'In '\n",
            "In  seat seat to majesty gracious: were,\n",
            " thus so a years three is on good York\n",
            " thus, good, with them, these- with. honour be with! House masters bands of,, w!\n",
            " wouldain fight a wpator\n",
            " new fl t; what is news my,CleanBut\n",
            " bow!An, leave I beent., discern O!!!ought son!!!!!!Al, awile, kind that speak hold made my,;And\n",
            "Prompt: 'To '\n",
            "To  p again happy; grow bothMade.\n",
            "D honour love sixman\n",
            " lord I blame\n",
            " princes a'd Christian.\n",
            "H me you hand trumpet I who here\n",
            " wish he presence the ofr in them of feast\n",
            " thievesis my brother there such sorrow sharp made is, his,\n",
            " kn,, I so as are be first prince.\n",
            "K RARD\n",
            "H he and not by and not time--\n",
            "BWhat it hatred thee thou rich but n? but I here I\n",
            "Prompt: 'A '\n",
            "A  of I it perform, I accuse on.\n",
            "Y, meredch not be queen be by.\n",
            "R and the.You him any record you? shall.\n",
            " the is- makes friend, my,- to itve\n",
            " straight the do s'd shall, so at datsForel there\n",
            "- brother and good happy to block peace I\n",
            " enter of didush for: may my, given all heart\n",
            " Hastings my,, I; that spend for the's\n",
            "our,\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  94%|█████████▍| 4701/5000 [3:31:41<30:48,  6.18s/it, loss=0.1899]\u001b[A\n",
            "Training:  94%|█████████▍| 4701/5000 [3:31:41<30:48,  6.18s/it, loss=0.3107]\u001b[A\n",
            "Training:  94%|█████████▍| 4702/5000 [3:31:43<24:52,  5.01s/it, loss=0.3107]\u001b[A\n",
            "Training:  94%|█████████▍| 4702/5000 [3:31:43<24:52,  5.01s/it, loss=0.4205]\u001b[A\n",
            "Training:  94%|█████████▍| 4703/5000 [3:31:45<20:44,  4.19s/it, loss=0.4205]\u001b[A\n",
            "Training:  94%|█████████▍| 4703/5000 [3:31:45<20:44,  4.19s/it, loss=0.2156]\u001b[A\n",
            "Training:  94%|█████████▍| 4704/5000 [3:31:47<17:46,  3.60s/it, loss=0.2156]\u001b[A\n",
            "Training:  94%|█████████▍| 4704/5000 [3:31:48<17:46,  3.60s/it, loss=0.3449]\u001b[A\n",
            "Training:  94%|█████████▍| 4705/5000 [3:31:50<16:14,  3.30s/it, loss=0.3449]\u001b[A\n",
            "Training:  94%|█████████▍| 4705/5000 [3:31:50<16:14,  3.30s/it, loss=0.3045]\u001b[A\n",
            "Training:  94%|█████████▍| 4706/5000 [3:31:53<14:55,  3.05s/it, loss=0.3045]\u001b[A\n",
            "Training:  94%|█████████▍| 4706/5000 [3:31:53<14:55,  3.05s/it, loss=0.2616]\u001b[A\n",
            "Training:  94%|█████████▍| 4707/5000 [3:31:55<13:43,  2.81s/it, loss=0.2616]\u001b[A\n",
            "Training:  94%|█████████▍| 4707/5000 [3:31:55<13:43,  2.81s/it, loss=0.1989]\u001b[A\n",
            "Training:  94%|█████████▍| 4708/5000 [3:31:57<12:52,  2.65s/it, loss=0.1989]\u001b[A\n",
            "Training:  94%|█████████▍| 4708/5000 [3:31:57<12:52,  2.65s/it, loss=0.4087]\u001b[A\n",
            "Training:  94%|█████████▍| 4709/5000 [3:31:59<12:17,  2.54s/it, loss=0.4087]\u001b[A\n",
            "Training:  94%|█████████▍| 4709/5000 [3:31:59<12:17,  2.54s/it, loss=0.2862]\u001b[A\n",
            "Training:  94%|█████████▍| 4710/5000 [3:32:02<12:25,  2.57s/it, loss=0.2862]\u001b[A\n",
            "Training:  94%|█████████▍| 4710/5000 [3:32:02<12:25,  2.57s/it, loss=0.1859]\u001b[A\n",
            "Training:  94%|█████████▍| 4711/5000 [3:32:04<12:12,  2.54s/it, loss=0.1859]\u001b[A\n",
            "Training:  94%|█████████▍| 4711/5000 [3:32:04<12:12,  2.54s/it, loss=0.2610]\u001b[A\n",
            "Training:  94%|█████████▍| 4712/5000 [3:32:07<11:46,  2.45s/it, loss=0.2610]\u001b[A\n",
            "Training:  94%|█████████▍| 4712/5000 [3:32:07<11:46,  2.45s/it, loss=0.3808]\u001b[A\n",
            "Training:  94%|█████████▍| 4713/5000 [3:32:09<11:28,  2.40s/it, loss=0.3808]\u001b[A\n",
            "Training:  94%|█████████▍| 4713/5000 [3:32:09<11:28,  2.40s/it, loss=0.2714]\u001b[A\n",
            "Training:  94%|█████████▍| 4714/5000 [3:32:11<11:23,  2.39s/it, loss=0.2714]\u001b[A\n",
            "Training:  94%|█████████▍| 4714/5000 [3:32:11<11:23,  2.39s/it, loss=0.1207]\u001b[A\n",
            "Training:  94%|█████████▍| 4715/5000 [3:32:14<11:41,  2.46s/it, loss=0.1207]\u001b[A\n",
            "Training:  94%|█████████▍| 4715/5000 [3:32:14<11:41,  2.46s/it, loss=0.3387]\u001b[A\n",
            "Training:  94%|█████████▍| 4716/5000 [3:32:16<11:36,  2.45s/it, loss=0.3387]\u001b[A\n",
            "Training:  94%|█████████▍| 4716/5000 [3:32:16<11:36,  2.45s/it, loss=0.5992]\u001b[A\n",
            "Training:  94%|█████████▍| 4717/5000 [3:32:19<11:17,  2.39s/it, loss=0.5992]\u001b[A\n",
            "Training:  94%|█████████▍| 4717/5000 [3:32:19<11:17,  2.39s/it, loss=0.5080]\u001b[A\n",
            "Training:  94%|█████████▍| 4718/5000 [3:32:21<11:07,  2.37s/it, loss=0.5080]\u001b[A\n",
            "Training:  94%|█████████▍| 4718/5000 [3:32:21<11:07,  2.37s/it, loss=0.5968]\u001b[A\n",
            "Training:  94%|█████████▍| 4719/5000 [3:32:23<10:58,  2.34s/it, loss=0.5968]\u001b[A\n",
            "Training:  94%|█████████▍| 4719/5000 [3:32:23<10:58,  2.34s/it, loss=0.4044]\u001b[A\n",
            "Training:  94%|█████████▍| 4720/5000 [3:32:26<11:19,  2.43s/it, loss=0.4044]\u001b[A\n",
            "Training:  94%|█████████▍| 4720/5000 [3:32:26<11:19,  2.43s/it, loss=0.2717]\u001b[A\n",
            "Training:  94%|█████████▍| 4721/5000 [3:32:28<11:18,  2.43s/it, loss=0.2717]\u001b[A\n",
            "Training:  94%|█████████▍| 4721/5000 [3:32:28<11:18,  2.43s/it, loss=0.2158]\u001b[A\n",
            "Training:  94%|█████████▍| 4722/5000 [3:32:31<11:00,  2.37s/it, loss=0.2158]\u001b[A\n",
            "Training:  94%|█████████▍| 4722/5000 [3:32:31<11:00,  2.37s/it, loss=0.2486]\u001b[A\n",
            "Training:  94%|█████████▍| 4723/5000 [3:32:33<10:53,  2.36s/it, loss=0.2486]\u001b[A\n",
            "Training:  94%|█████████▍| 4723/5000 [3:32:33<10:53,  2.36s/it, loss=0.2665]\u001b[A\n",
            "Training:  94%|█████████▍| 4724/5000 [3:32:35<10:43,  2.33s/it, loss=0.2665]\u001b[A\n",
            "Training:  94%|█████████▍| 4724/5000 [3:32:35<10:43,  2.33s/it, loss=0.1783]\u001b[A\n",
            "Training:  94%|█████████▍| 4725/5000 [3:32:38<11:03,  2.41s/it, loss=0.1783]\u001b[A\n",
            "Training:  94%|█████████▍| 4725/5000 [3:32:38<11:03,  2.41s/it, loss=0.3543]\u001b[A\n",
            "Training:  95%|█████████▍| 4726/5000 [3:32:40<11:05,  2.43s/it, loss=0.3543]\u001b[A\n",
            "Training:  95%|█████████▍| 4726/5000 [3:32:40<11:05,  2.43s/it, loss=0.3471]\u001b[A\n",
            "Training:  95%|█████████▍| 4727/5000 [3:32:43<10:56,  2.41s/it, loss=0.3471]\u001b[A\n",
            "Training:  95%|█████████▍| 4727/5000 [3:32:43<10:56,  2.41s/it, loss=0.3776]\u001b[A\n",
            "Training:  95%|█████████▍| 4728/5000 [3:32:45<10:45,  2.37s/it, loss=0.3776]\u001b[A\n",
            "Training:  95%|█████████▍| 4728/5000 [3:32:45<10:45,  2.37s/it, loss=0.3040]\u001b[A\n",
            "Training:  95%|█████████▍| 4729/5000 [3:32:47<10:34,  2.34s/it, loss=0.3040]\u001b[A\n",
            "Training:  95%|█████████▍| 4729/5000 [3:32:47<10:34,  2.34s/it, loss=0.3331]\u001b[A\n",
            "Training:  95%|█████████▍| 4730/5000 [3:32:50<10:59,  2.44s/it, loss=0.3331]\u001b[A\n",
            "Training:  95%|█████████▍| 4730/5000 [3:32:50<10:59,  2.44s/it, loss=0.4431]\u001b[A\n",
            "Training:  95%|█████████▍| 4731/5000 [3:32:52<10:51,  2.42s/it, loss=0.4431]\u001b[A\n",
            "Training:  95%|█████████▍| 4731/5000 [3:32:52<10:51,  2.42s/it, loss=0.3410]\u001b[A\n",
            "Training:  95%|█████████▍| 4732/5000 [3:32:54<10:40,  2.39s/it, loss=0.3410]\u001b[A\n",
            "Training:  95%|█████████▍| 4732/5000 [3:32:55<10:40,  2.39s/it, loss=0.3770]\u001b[A\n",
            "Training:  95%|█████████▍| 4733/5000 [3:32:57<10:26,  2.35s/it, loss=0.3770]\u001b[A\n",
            "Training:  95%|█████████▍| 4733/5000 [3:32:57<10:26,  2.35s/it, loss=0.3049]\u001b[A\n",
            "Training:  95%|█████████▍| 4734/5000 [3:32:59<10:15,  2.31s/it, loss=0.3049]\u001b[A\n",
            "Training:  95%|█████████▍| 4734/5000 [3:32:59<10:15,  2.31s/it, loss=0.2090]\u001b[A\n",
            "Training:  95%|█████████▍| 4735/5000 [3:33:02<10:35,  2.40s/it, loss=0.2090]\u001b[A\n",
            "Training:  95%|█████████▍| 4735/5000 [3:33:02<10:35,  2.40s/it, loss=0.2592]\u001b[A\n",
            "Training:  95%|█████████▍| 4736/5000 [3:33:04<10:37,  2.41s/it, loss=0.2592]\u001b[A\n",
            "Training:  95%|█████████▍| 4736/5000 [3:33:04<10:37,  2.41s/it, loss=0.3309]\u001b[A\n",
            "Training:  95%|█████████▍| 4737/5000 [3:33:06<10:21,  2.36s/it, loss=0.3309]\u001b[A\n",
            "Training:  95%|█████████▍| 4737/5000 [3:33:06<10:21,  2.36s/it, loss=0.2922]\u001b[A\n",
            "Training:  95%|█████████▍| 4738/5000 [3:33:09<10:12,  2.34s/it, loss=0.2922]\u001b[A\n",
            "Training:  95%|█████████▍| 4738/5000 [3:33:09<10:12,  2.34s/it, loss=0.3401]\u001b[A\n",
            "Training:  95%|█████████▍| 4739/5000 [3:33:11<10:04,  2.32s/it, loss=0.3401]\u001b[A\n",
            "Training:  95%|█████████▍| 4739/5000 [3:33:11<10:04,  2.32s/it, loss=0.3282]\u001b[A\n",
            "Training:  95%|█████████▍| 4740/5000 [3:33:13<10:28,  2.42s/it, loss=0.3282]\u001b[A\n",
            "Training:  95%|█████████▍| 4740/5000 [3:33:13<10:28,  2.42s/it, loss=0.1258]\u001b[A\n",
            "Training:  95%|█████████▍| 4741/5000 [3:33:16<10:26,  2.42s/it, loss=0.1258]\u001b[A\n",
            "Training:  95%|█████████▍| 4741/5000 [3:33:16<10:26,  2.42s/it, loss=0.3178]\u001b[A\n",
            "Training:  95%|█████████▍| 4742/5000 [3:33:18<10:11,  2.37s/it, loss=0.3178]\u001b[A\n",
            "Training:  95%|█████████▍| 4742/5000 [3:33:18<10:11,  2.37s/it, loss=0.2903]\u001b[A\n",
            "Training:  95%|█████████▍| 4743/5000 [3:33:20<10:02,  2.35s/it, loss=0.2903]\u001b[A\n",
            "Training:  95%|█████████▍| 4743/5000 [3:33:20<10:02,  2.35s/it, loss=0.2915]\u001b[A\n",
            "Training:  95%|█████████▍| 4744/5000 [3:33:23<09:51,  2.31s/it, loss=0.2915]\u001b[A\n",
            "Training:  95%|█████████▍| 4744/5000 [3:33:23<09:51,  2.31s/it, loss=0.1542]\u001b[A\n",
            "Training:  95%|█████████▍| 4745/5000 [3:33:25<10:08,  2.39s/it, loss=0.1542]\u001b[A\n",
            "Training:  95%|█████████▍| 4745/5000 [3:33:25<10:08,  2.39s/it, loss=0.3117]\u001b[A\n",
            "Training:  95%|█████████▍| 4746/5000 [3:33:28<10:13,  2.42s/it, loss=0.3117]\u001b[A\n",
            "Training:  95%|█████████▍| 4746/5000 [3:33:28<10:13,  2.42s/it, loss=0.3597]\u001b[A\n",
            "Training:  95%|█████████▍| 4747/5000 [3:33:30<09:58,  2.37s/it, loss=0.3597]\u001b[A\n",
            "Training:  95%|█████████▍| 4747/5000 [3:33:30<09:58,  2.37s/it, loss=0.3500]\u001b[A\n",
            "Training:  95%|█████████▍| 4748/5000 [3:33:32<09:50,  2.34s/it, loss=0.3500]\u001b[A\n",
            "Training:  95%|█████████▍| 4748/5000 [3:33:32<09:50,  2.34s/it, loss=0.3996]\u001b[A\n",
            "Training:  95%|█████████▍| 4749/5000 [3:33:34<09:41,  2.32s/it, loss=0.3996]\u001b[A\n",
            "Training:  95%|█████████▍| 4749/5000 [3:33:35<09:41,  2.32s/it, loss=0.3384]\u001b[A\n",
            "Training:  95%|█████████▌| 4750/5000 [3:33:37<09:55,  2.38s/it, loss=0.3384]\u001b[A\n",
            "Training:  95%|█████████▌| 4750/5000 [3:33:37<09:55,  2.38s/it, loss=0.4256]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 4750 ---\n",
            "Prompt: 'The '\n",
            "The  of high's; stand that ' devil farewellIserest\n",
            " the, wrong,Even the foe thoseerness fair, and this\n",
            "ersaste,3ING all done,to him.\n",
            "First thou fault I thy,,ack toay or? will thy is cause\n",
            ", he some with king enforce arered-orrowH is king to ' his'slyisting be.\n",
            "LIN:By,,, you my is light true,if are und,Notsent and-- is\n",
            "Prompt: 'In '\n",
            "In ful, w?' Juliet to toward\n",
            " minehy and young comfort himWhere once breathing?\n",
            ":My,,Firstoth\n",
            " not for purpose present ever so as\n",
            " yet was'd we precious and the will you to:Your are both\n",
            ", make will the of or of with all heartchild come sing,ull tonight name side\n",
            " that ancientty come,, the will you tom time fouraking.\n",
            "EDARD:I not;,, am, youw, haves\n",
            "Prompt: 'To '\n",
            "To 'An service I lie do, hear speak mine.\n",
            "CLENCE:oo,,,, lords O that, all, his is of.\n",
            "QUE MARARORD\n",
            "\n",
            " God come you to that, am king thelf tears right\n",
            "WARICK\n",
            " shame prevent!,tis flowers starve\n",
            "orous out me: it me: once,, I with.\n",
            "CLF: comes,: hon,, I try such; before did itself\n",
            " that shall feel king the, it speak\n",
            "Prompt: 'A '\n",
            "A  of, it much, some straight dead\n",
            " follow.\n",
            "Firstman\n",
            "ded speak me or:! did best so son\n",
            " bedGiven were oroming is would I be.\n",
            " ifard mother it me so repro so drum\n",
            " seek death dear death, be of should great so; we farewell\n",
            " a-;And's upon cheek myself- thou lords\n",
            "\n",
            "\n",
            "shouldrow\n",
            "ts he soea he.\n",
            "ailus loss that, be angry take you\n",
            " deadShe the\n",
            " his\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  95%|█████████▌| 4751/5000 [3:33:52<25:31,  6.15s/it, loss=0.4256]\u001b[A\n",
            "Training:  95%|█████████▌| 4751/5000 [3:33:52<25:31,  6.15s/it, loss=0.3557]\u001b[A\n",
            "Training:  95%|█████████▌| 4752/5000 [3:33:54<20:37,  4.99s/it, loss=0.3557]\u001b[A\n",
            "Training:  95%|█████████▌| 4752/5000 [3:33:54<20:37,  4.99s/it, loss=0.2890]\u001b[A\n",
            "Training:  95%|█████████▌| 4753/5000 [3:33:57<17:11,  4.17s/it, loss=0.2890]\u001b[A\n",
            "Training:  95%|█████████▌| 4753/5000 [3:33:57<17:11,  4.17s/it, loss=0.3308]\u001b[A\n",
            "Training:  95%|█████████▌| 4754/5000 [3:33:59<14:45,  3.60s/it, loss=0.3308]\u001b[A\n",
            "Training:  95%|█████████▌| 4754/5000 [3:33:59<14:45,  3.60s/it, loss=0.3196]\u001b[A\n",
            "Training:  95%|█████████▌| 4755/5000 [3:34:02<13:41,  3.35s/it, loss=0.3196]\u001b[A\n",
            "Training:  95%|█████████▌| 4755/5000 [3:34:02<13:41,  3.35s/it, loss=0.3365]\u001b[A\n",
            "Training:  95%|█████████▌| 4756/5000 [3:34:04<12:19,  3.03s/it, loss=0.3365]\u001b[A\n",
            "Training:  95%|█████████▌| 4756/5000 [3:34:04<12:19,  3.03s/it, loss=0.1457]\u001b[A\n",
            "Training:  95%|█████████▌| 4757/5000 [3:34:06<11:20,  2.80s/it, loss=0.1457]\u001b[A\n",
            "Training:  95%|█████████▌| 4757/5000 [3:34:06<11:20,  2.80s/it, loss=0.4265]\u001b[A\n",
            "Training:  95%|█████████▌| 4758/5000 [3:34:08<10:38,  2.64s/it, loss=0.4265]\u001b[A\n",
            "Training:  95%|█████████▌| 4758/5000 [3:34:08<10:38,  2.64s/it, loss=0.1638]\u001b[A\n",
            "Training:  95%|█████████▌| 4759/5000 [3:34:11<10:08,  2.53s/it, loss=0.1638]\u001b[A\n",
            "Training:  95%|█████████▌| 4759/5000 [3:34:11<10:08,  2.53s/it, loss=0.3904]\u001b[A\n",
            "Training:  95%|█████████▌| 4760/5000 [3:34:13<10:30,  2.63s/it, loss=0.3904]\u001b[A\n",
            "Training:  95%|█████████▌| 4760/5000 [3:34:14<10:30,  2.63s/it, loss=0.5015]\u001b[A\n",
            "Training:  95%|█████████▌| 4761/5000 [3:34:16<10:01,  2.52s/it, loss=0.5015]\u001b[A\n",
            "Training:  95%|█████████▌| 4761/5000 [3:34:16<10:01,  2.52s/it, loss=0.3989]\u001b[A\n",
            "Training:  95%|█████████▌| 4762/5000 [3:34:18<09:39,  2.44s/it, loss=0.3989]\u001b[A\n",
            "Training:  95%|█████████▌| 4762/5000 [3:34:18<09:39,  2.44s/it, loss=0.2222]\u001b[A\n",
            "Training:  95%|█████████▌| 4763/5000 [3:34:20<09:24,  2.38s/it, loss=0.2222]\u001b[A\n",
            "Training:  95%|█████████▌| 4763/5000 [3:34:20<09:24,  2.38s/it, loss=0.2868]\u001b[A\n",
            "Training:  95%|█████████▌| 4764/5000 [3:34:23<09:13,  2.34s/it, loss=0.2868]\u001b[A\n",
            "Training:  95%|█████████▌| 4764/5000 [3:34:23<09:13,  2.34s/it, loss=0.2429]\u001b[A\n",
            "Training:  95%|█████████▌| 4765/5000 [3:34:25<09:42,  2.48s/it, loss=0.2429]\u001b[A\n",
            "Training:  95%|█████████▌| 4765/5000 [3:34:25<09:42,  2.48s/it, loss=0.2736]\u001b[A\n",
            "Training:  95%|█████████▌| 4766/5000 [3:34:28<09:25,  2.42s/it, loss=0.2736]\u001b[A\n",
            "Training:  95%|█████████▌| 4766/5000 [3:34:28<09:25,  2.42s/it, loss=0.2140]\u001b[A\n",
            "Training:  95%|█████████▌| 4767/5000 [3:34:30<09:10,  2.36s/it, loss=0.2140]\u001b[A\n",
            "Training:  95%|█████████▌| 4767/5000 [3:34:30<09:10,  2.36s/it, loss=0.2148]\u001b[A\n",
            "Training:  95%|█████████▌| 4768/5000 [3:34:32<09:03,  2.34s/it, loss=0.2148]\u001b[A\n",
            "Training:  95%|█████████▌| 4768/5000 [3:34:32<09:03,  2.34s/it, loss=0.3616]\u001b[A\n",
            "Training:  95%|█████████▌| 4769/5000 [3:34:34<08:56,  2.32s/it, loss=0.3616]\u001b[A\n",
            "Training:  95%|█████████▌| 4769/5000 [3:34:34<08:56,  2.32s/it, loss=0.5129]\u001b[A\n",
            "Training:  95%|█████████▌| 4770/5000 [3:34:37<09:25,  2.46s/it, loss=0.5129]\u001b[A\n",
            "Training:  95%|█████████▌| 4770/5000 [3:34:37<09:25,  2.46s/it, loss=0.2843]\u001b[A\n",
            "Training:  95%|█████████▌| 4771/5000 [3:34:39<09:09,  2.40s/it, loss=0.2843]\u001b[A\n",
            "Training:  95%|█████████▌| 4771/5000 [3:34:39<09:09,  2.40s/it, loss=0.3501]\u001b[A\n",
            "Training:  95%|█████████▌| 4772/5000 [3:34:42<08:55,  2.35s/it, loss=0.3501]\u001b[A\n",
            "Training:  95%|█████████▌| 4772/5000 [3:34:42<08:55,  2.35s/it, loss=0.3397]\u001b[A\n",
            "Training:  95%|█████████▌| 4773/5000 [3:34:44<08:51,  2.34s/it, loss=0.3397]\u001b[A\n",
            "Training:  95%|█████████▌| 4773/5000 [3:34:44<08:51,  2.34s/it, loss=0.3491]\u001b[A\n",
            "Training:  95%|█████████▌| 4774/5000 [3:34:46<08:43,  2.31s/it, loss=0.3491]\u001b[A\n",
            "Training:  95%|█████████▌| 4774/5000 [3:34:46<08:43,  2.31s/it, loss=0.1942]\u001b[A\n",
            "Training:  96%|█████████▌| 4775/5000 [3:34:49<09:12,  2.46s/it, loss=0.1942]\u001b[A\n",
            "Training:  96%|█████████▌| 4775/5000 [3:34:49<09:12,  2.46s/it, loss=0.1792]\u001b[A\n",
            "Training:  96%|█████████▌| 4776/5000 [3:34:51<08:56,  2.40s/it, loss=0.1792]\u001b[A\n",
            "Training:  96%|█████████▌| 4776/5000 [3:34:51<08:56,  2.40s/it, loss=0.3689]\u001b[A\n",
            "Training:  96%|█████████▌| 4777/5000 [3:34:54<08:45,  2.35s/it, loss=0.3689]\u001b[A\n",
            "Training:  96%|█████████▌| 4777/5000 [3:34:54<08:45,  2.35s/it, loss=0.3110]\u001b[A\n",
            "Training:  96%|█████████▌| 4778/5000 [3:34:56<08:36,  2.32s/it, loss=0.3110]\u001b[A\n",
            "Training:  96%|█████████▌| 4778/5000 [3:34:56<08:36,  2.32s/it, loss=0.2553]\u001b[A\n",
            "Training:  96%|█████████▌| 4779/5000 [3:34:58<08:31,  2.32s/it, loss=0.2553]\u001b[A\n",
            "Training:  96%|█████████▌| 4779/5000 [3:34:58<08:31,  2.32s/it, loss=0.2222]\u001b[A\n",
            "Training:  96%|█████████▌| 4780/5000 [3:35:01<08:57,  2.44s/it, loss=0.2222]\u001b[A\n",
            "Training:  96%|█████████▌| 4780/5000 [3:35:01<08:57,  2.44s/it, loss=0.2450]\u001b[A\n",
            "Training:  96%|█████████▌| 4781/5000 [3:35:03<08:41,  2.38s/it, loss=0.2450]\u001b[A\n",
            "Training:  96%|█████████▌| 4781/5000 [3:35:03<08:41,  2.38s/it, loss=0.3003]\u001b[A\n",
            "Training:  96%|█████████▌| 4782/5000 [3:35:05<08:33,  2.35s/it, loss=0.3003]\u001b[A\n",
            "Training:  96%|█████████▌| 4782/5000 [3:35:05<08:33,  2.35s/it, loss=0.1952]\u001b[A\n",
            "Training:  96%|█████████▌| 4783/5000 [3:35:08<08:24,  2.33s/it, loss=0.1952]\u001b[A\n",
            "Training:  96%|█████████▌| 4783/5000 [3:35:08<08:24,  2.33s/it, loss=0.2784]\u001b[A\n",
            "Training:  96%|█████████▌| 4784/5000 [3:35:10<08:19,  2.31s/it, loss=0.2784]\u001b[A\n",
            "Training:  96%|█████████▌| 4784/5000 [3:35:10<08:19,  2.31s/it, loss=0.2438]\u001b[A\n",
            "Training:  96%|█████████▌| 4785/5000 [3:35:13<08:45,  2.44s/it, loss=0.2438]\u001b[A\n",
            "Training:  96%|█████████▌| 4785/5000 [3:35:13<08:45,  2.44s/it, loss=0.2729]\u001b[A\n",
            "Training:  96%|█████████▌| 4786/5000 [3:35:15<08:32,  2.40s/it, loss=0.2729]\u001b[A\n",
            "Training:  96%|█████████▌| 4786/5000 [3:35:15<08:32,  2.40s/it, loss=0.2135]\u001b[A\n",
            "Training:  96%|█████████▌| 4787/5000 [3:35:17<08:21,  2.35s/it, loss=0.2135]\u001b[A\n",
            "Training:  96%|█████████▌| 4787/5000 [3:35:17<08:21,  2.35s/it, loss=0.2276]\u001b[A\n",
            "Training:  96%|█████████▌| 4788/5000 [3:35:19<08:12,  2.32s/it, loss=0.2276]\u001b[A\n",
            "Training:  96%|█████████▌| 4788/5000 [3:35:19<08:12,  2.32s/it, loss=0.3295]\u001b[A\n",
            "Training:  96%|█████████▌| 4789/5000 [3:35:22<08:07,  2.31s/it, loss=0.3295]\u001b[A\n",
            "Training:  96%|█████████▌| 4789/5000 [3:35:22<08:07,  2.31s/it, loss=0.2512]\u001b[A\n",
            "Training:  96%|█████████▌| 4790/5000 [3:35:25<08:36,  2.46s/it, loss=0.2512]\u001b[A\n",
            "Training:  96%|█████████▌| 4790/5000 [3:35:25<08:36,  2.46s/it, loss=0.2847]\u001b[A\n",
            "Training:  96%|█████████▌| 4791/5000 [3:35:27<08:21,  2.40s/it, loss=0.2847]\u001b[A\n",
            "Training:  96%|█████████▌| 4791/5000 [3:35:27<08:21,  2.40s/it, loss=0.2778]\u001b[A\n",
            "Training:  96%|█████████▌| 4792/5000 [3:35:29<08:09,  2.36s/it, loss=0.2778]\u001b[A\n",
            "Training:  96%|█████████▌| 4792/5000 [3:35:29<08:09,  2.36s/it, loss=0.1954]\u001b[A\n",
            "Training:  96%|█████████▌| 4793/5000 [3:35:31<08:02,  2.33s/it, loss=0.1954]\u001b[A\n",
            "Training:  96%|█████████▌| 4793/5000 [3:35:31<08:02,  2.33s/it, loss=0.3855]\u001b[A\n",
            "Training:  96%|█████████▌| 4794/5000 [3:35:34<07:55,  2.31s/it, loss=0.3855]\u001b[A\n",
            "Training:  96%|█████████▌| 4794/5000 [3:35:34<07:55,  2.31s/it, loss=0.2876]\u001b[A\n",
            "Training:  96%|█████████▌| 4795/5000 [3:35:36<08:22,  2.45s/it, loss=0.2876]\u001b[A\n",
            "Training:  96%|█████████▌| 4795/5000 [3:35:36<08:22,  2.45s/it, loss=0.3314]\u001b[A\n",
            "Training:  96%|█████████▌| 4796/5000 [3:35:39<08:07,  2.39s/it, loss=0.3314]\u001b[A\n",
            "Training:  96%|█████████▌| 4796/5000 [3:35:39<08:07,  2.39s/it, loss=0.2543]\u001b[A\n",
            "Training:  96%|█████████▌| 4797/5000 [3:35:41<07:57,  2.35s/it, loss=0.2543]\u001b[A\n",
            "Training:  96%|█████████▌| 4797/5000 [3:35:41<07:57,  2.35s/it, loss=0.3101]\u001b[A\n",
            "Training:  96%|█████████▌| 4798/5000 [3:35:43<07:49,  2.33s/it, loss=0.3101]\u001b[A\n",
            "Training:  96%|█████████▌| 4798/5000 [3:35:43<07:49,  2.33s/it, loss=0.2622]\u001b[A\n",
            "Training:  96%|█████████▌| 4799/5000 [3:35:45<07:44,  2.31s/it, loss=0.2622]\u001b[A\n",
            "Training:  96%|█████████▌| 4799/5000 [3:35:45<07:44,  2.31s/it, loss=0.3404]\u001b[A\n",
            "Training:  96%|█████████▌| 4800/5000 [3:35:48<08:11,  2.46s/it, loss=0.3404]\u001b[A\n",
            "Training:  96%|█████████▌| 4800/5000 [3:35:48<08:11,  2.46s/it, loss=0.1616]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 4800 ---\n",
            "Prompt: 'The '\n",
            "The  find to,ing in with.\n",
            "LIO\n",
            " ensiefoe Angel; is not itled dieMustwith\n",
            " sc, these stay hearing: kne monarchy thesele thesed,\n",
            " save than sons all water though were business his.\n",
            "Prov:\n",
            " you yours\n",
            "d,,, your hum open, your v hath to rid spirit the.\n",
            "LIO\n",
            "ruly layine lords of royal at spirit, sir\n",
            " proceedings do; will bear your purpose\n",
            "T show your and himoth\n",
            "Prompt: 'In '\n",
            "In  wonderoHow thou was in counsel\n",
            "ou sin b'd? one now midnight, thee thy:But thou\n",
            " nothing thou speak thy days drove.\n",
            "Prov:, thee.--\n",
            "ine:,; will thou again-- it swearelyoes\n",
            " glorious the privilege our: true Ruting ifiant,er\n",
            "ine faintush nors this an vain mineYou make\n",
            " nothing but in office\n",
            " thouest: thou in thousand.\n",
            "Both\n",
            " thou thy: thoust\n",
            "ay, thouiest\n",
            "Prompt: 'To '\n",
            "To  life\n",
            " acquaintance in floodso I., I mount hither rich\n",
            " values you I you I\n",
            " give, yet\n",
            "He the exp in, that\n",
            "L ine in villain appear you hisourable would\n",
            " some this which,,, your had awile in or: to she the here this sway thouest out same the,\n",
            " once to and scorn well I. leave prettys: lords\n",
            " time meors only\n",
            "uneread me, your his. call me, years asking not\n",
            "Prompt: 'A '\n",
            "A Well your,ie\n",
            " do this., ga, are the.\n",
            " fright hath to prison thou m to, was thou thy: thouest thou havingfs piece choose,\n",
            "'llrown chiefly as could keep no but\n",
            " second,,no: w.! art thyagger to; God thou:head be; well\n",
            "estconstment throw these guest thousand FifthES\n",
            " thus I give at, say thelf warning I'were\n",
            " pursuit\n",
            "t not English,,, thou toot\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  96%|█████████▌| 4801/5000 [3:36:03<20:20,  6.13s/it, loss=0.1616]\u001b[A\n",
            "Training:  96%|█████████▌| 4801/5000 [3:36:03<20:20,  6.13s/it, loss=0.1982]\u001b[A\n",
            "Training:  96%|█████████▌| 4802/5000 [3:36:05<16:23,  4.97s/it, loss=0.1982]\u001b[A\n",
            "Training:  96%|█████████▌| 4802/5000 [3:36:05<16:23,  4.97s/it, loss=0.2746]\u001b[A\n",
            "Training:  96%|█████████▌| 4803/5000 [3:36:07<13:38,  4.15s/it, loss=0.2746]\u001b[A\n",
            "Training:  96%|█████████▌| 4803/5000 [3:36:07<13:38,  4.15s/it, loss=0.3220]\u001b[A\n",
            "Training:  96%|█████████▌| 4804/5000 [3:36:10<11:41,  3.58s/it, loss=0.3220]\u001b[A\n",
            "Training:  96%|█████████▌| 4804/5000 [3:36:10<11:41,  3.58s/it, loss=0.3097]\u001b[A\n",
            "Training:  96%|█████████▌| 4805/5000 [3:36:12<10:51,  3.34s/it, loss=0.3097]\u001b[A\n",
            "Training:  96%|█████████▌| 4805/5000 [3:36:12<10:51,  3.34s/it, loss=0.1971]\u001b[A\n",
            "Training:  96%|█████████▌| 4806/5000 [3:36:15<09:47,  3.03s/it, loss=0.1971]\u001b[A\n",
            "Training:  96%|█████████▌| 4806/5000 [3:36:15<09:47,  3.03s/it, loss=0.3704]\u001b[A\n",
            "Training:  96%|█████████▌| 4807/5000 [3:36:17<09:00,  2.80s/it, loss=0.3704]\u001b[A\n",
            "Training:  96%|█████████▌| 4807/5000 [3:36:17<09:00,  2.80s/it, loss=0.2834]\u001b[A\n",
            "Training:  96%|█████████▌| 4808/5000 [3:36:19<08:26,  2.64s/it, loss=0.2834]\u001b[A\n",
            "Training:  96%|█████████▌| 4808/5000 [3:36:19<08:26,  2.64s/it, loss=0.2585]\u001b[A\n",
            "Training:  96%|█████████▌| 4809/5000 [3:36:22<08:01,  2.52s/it, loss=0.2585]\u001b[A\n",
            "Training:  96%|█████████▌| 4809/5000 [3:36:22<08:01,  2.52s/it, loss=0.3215]\u001b[A\n",
            "Training:  96%|█████████▌| 4810/5000 [3:36:24<08:13,  2.60s/it, loss=0.3215]\u001b[A\n",
            "Training:  96%|█████████▌| 4810/5000 [3:36:24<08:13,  2.60s/it, loss=0.3104]\u001b[A\n",
            "Training:  96%|█████████▌| 4811/5000 [3:36:27<07:52,  2.50s/it, loss=0.3104]\u001b[A\n",
            "Training:  96%|█████████▌| 4811/5000 [3:36:27<07:52,  2.50s/it, loss=0.3017]\u001b[A\n",
            "Training:  96%|█████████▌| 4812/5000 [3:36:29<07:38,  2.44s/it, loss=0.3017]\u001b[A\n",
            "Training:  96%|█████████▌| 4812/5000 [3:36:29<07:38,  2.44s/it, loss=0.2304]\u001b[A\n",
            "Training:  96%|█████████▋| 4813/5000 [3:36:31<07:25,  2.38s/it, loss=0.2304]\u001b[A\n",
            "Training:  96%|█████████▋| 4813/5000 [3:36:31<07:25,  2.38s/it, loss=0.3911]\u001b[A\n",
            "Training:  96%|█████████▋| 4814/5000 [3:36:33<07:15,  2.34s/it, loss=0.3911]\u001b[A\n",
            "Training:  96%|█████████▋| 4814/5000 [3:36:33<07:15,  2.34s/it, loss=0.3798]\u001b[A\n",
            "Training:  96%|█████████▋| 4815/5000 [3:36:36<07:39,  2.48s/it, loss=0.3798]\u001b[A\n",
            "Training:  96%|█████████▋| 4815/5000 [3:36:36<07:39,  2.48s/it, loss=0.2543]\u001b[A\n",
            "Training:  96%|█████████▋| 4816/5000 [3:36:38<07:23,  2.41s/it, loss=0.2543]\u001b[A\n",
            "Training:  96%|█████████▋| 4816/5000 [3:36:38<07:23,  2.41s/it, loss=0.2762]\u001b[A\n",
            "Training:  96%|█████████▋| 4817/5000 [3:36:41<07:14,  2.37s/it, loss=0.2762]\u001b[A\n",
            "Training:  96%|█████████▋| 4817/5000 [3:36:41<07:14,  2.37s/it, loss=0.3116]\u001b[A\n",
            "Training:  96%|█████████▋| 4818/5000 [3:36:43<07:07,  2.35s/it, loss=0.3116]\u001b[A\n",
            "Training:  96%|█████████▋| 4818/5000 [3:36:43<07:07,  2.35s/it, loss=0.3898]\u001b[A\n",
            "Training:  96%|█████████▋| 4819/5000 [3:36:45<07:02,  2.33s/it, loss=0.3898]\u001b[A\n",
            "Training:  96%|█████████▋| 4819/5000 [3:36:45<07:02,  2.33s/it, loss=0.2166]\u001b[A\n",
            "Training:  96%|█████████▋| 4820/5000 [3:36:48<07:24,  2.47s/it, loss=0.2166]\u001b[A\n",
            "Training:  96%|█████████▋| 4820/5000 [3:36:48<07:24,  2.47s/it, loss=0.3204]\u001b[A\n",
            "Training:  96%|█████████▋| 4821/5000 [3:36:50<07:10,  2.41s/it, loss=0.3204]\u001b[A\n",
            "Training:  96%|█████████▋| 4821/5000 [3:36:50<07:10,  2.41s/it, loss=0.3636]\u001b[A\n",
            "Training:  96%|█████████▋| 4822/5000 [3:36:53<07:00,  2.36s/it, loss=0.3636]\u001b[A\n",
            "Training:  96%|█████████▋| 4822/5000 [3:36:53<07:00,  2.36s/it, loss=0.4327]\u001b[A\n",
            "Training:  96%|█████████▋| 4823/5000 [3:36:55<06:51,  2.32s/it, loss=0.4327]\u001b[A\n",
            "Training:  96%|█████████▋| 4823/5000 [3:36:55<06:51,  2.32s/it, loss=0.2991]\u001b[A\n",
            "Training:  96%|█████████▋| 4824/5000 [3:36:57<06:46,  2.31s/it, loss=0.2991]\u001b[A\n",
            "Training:  96%|█████████▋| 4824/5000 [3:36:57<06:46,  2.31s/it, loss=0.2223]\u001b[A\n",
            "Training:  96%|█████████▋| 4825/5000 [3:37:00<07:10,  2.46s/it, loss=0.2223]\u001b[A\n",
            "Training:  96%|█████████▋| 4825/5000 [3:37:00<07:10,  2.46s/it, loss=0.2550]\u001b[A\n",
            "Training:  97%|█████████▋| 4826/5000 [3:37:02<06:57,  2.40s/it, loss=0.2550]\u001b[A\n",
            "Training:  97%|█████████▋| 4826/5000 [3:37:02<06:57,  2.40s/it, loss=0.2403]\u001b[A\n",
            "Training:  97%|█████████▋| 4827/5000 [3:37:04<06:47,  2.36s/it, loss=0.2403]\u001b[A\n",
            "Training:  97%|█████████▋| 4827/5000 [3:37:04<06:47,  2.36s/it, loss=0.3262]\u001b[A\n",
            "Training:  97%|█████████▋| 4828/5000 [3:37:07<06:40,  2.33s/it, loss=0.3262]\u001b[A\n",
            "Training:  97%|█████████▋| 4828/5000 [3:37:07<06:40,  2.33s/it, loss=0.4279]\u001b[A\n",
            "Training:  97%|█████████▋| 4829/5000 [3:37:09<06:33,  2.30s/it, loss=0.4279]\u001b[A\n",
            "Training:  97%|█████████▋| 4829/5000 [3:37:09<06:33,  2.30s/it, loss=0.3680]\u001b[A\n",
            "Training:  97%|█████████▋| 4830/5000 [3:37:12<06:57,  2.46s/it, loss=0.3680]\u001b[A\n",
            "Training:  97%|█████████▋| 4830/5000 [3:37:12<06:57,  2.46s/it, loss=0.2974]\u001b[A\n",
            "Training:  97%|█████████▋| 4831/5000 [3:37:14<06:45,  2.40s/it, loss=0.2974]\u001b[A\n",
            "Training:  97%|█████████▋| 4831/5000 [3:37:14<06:45,  2.40s/it, loss=0.3760]\u001b[A\n",
            "Training:  97%|█████████▋| 4832/5000 [3:37:16<06:35,  2.35s/it, loss=0.3760]\u001b[A\n",
            "Training:  97%|█████████▋| 4832/5000 [3:37:16<06:35,  2.35s/it, loss=0.1807]\u001b[A\n",
            "Training:  97%|█████████▋| 4833/5000 [3:37:19<06:30,  2.34s/it, loss=0.1807]\u001b[A\n",
            "Training:  97%|█████████▋| 4833/5000 [3:37:19<06:30,  2.34s/it, loss=0.4508]\u001b[A\n",
            "Training:  97%|█████████▋| 4834/5000 [3:37:21<06:24,  2.32s/it, loss=0.4508]\u001b[A\n",
            "Training:  97%|█████████▋| 4834/5000 [3:37:21<06:24,  2.32s/it, loss=0.3415]\u001b[A\n",
            "Training:  97%|█████████▋| 4835/5000 [3:37:24<06:46,  2.47s/it, loss=0.3415]\u001b[A\n",
            "Training:  97%|█████████▋| 4835/5000 [3:37:24<06:46,  2.47s/it, loss=0.2235]\u001b[A\n",
            "Training:  97%|█████████▋| 4836/5000 [3:37:26<06:34,  2.41s/it, loss=0.2235]\u001b[A\n",
            "Training:  97%|█████████▋| 4836/5000 [3:37:26<06:34,  2.41s/it, loss=0.4136]\u001b[A\n",
            "Training:  97%|█████████▋| 4837/5000 [3:37:28<06:24,  2.36s/it, loss=0.4136]\u001b[A\n",
            "Training:  97%|█████████▋| 4837/5000 [3:37:28<06:24,  2.36s/it, loss=0.2727]\u001b[A\n",
            "Training:  97%|█████████▋| 4838/5000 [3:37:31<06:20,  2.35s/it, loss=0.2727]\u001b[A\n",
            "Training:  97%|█████████▋| 4838/5000 [3:37:31<06:20,  2.35s/it, loss=0.2808]\u001b[A\n",
            "Training:  97%|█████████▋| 4839/5000 [3:37:33<06:13,  2.32s/it, loss=0.2808]\u001b[A\n",
            "Training:  97%|█████████▋| 4839/5000 [3:37:33<06:13,  2.32s/it, loss=0.3043]\u001b[A\n",
            "Training:  97%|█████████▋| 4840/5000 [3:37:36<06:36,  2.48s/it, loss=0.3043]\u001b[A\n",
            "Training:  97%|█████████▋| 4840/5000 [3:37:36<06:36,  2.48s/it, loss=0.2433]\u001b[A\n",
            "Training:  97%|█████████▋| 4841/5000 [3:37:38<06:24,  2.42s/it, loss=0.2433]\u001b[A\n",
            "Training:  97%|█████████▋| 4841/5000 [3:37:38<06:24,  2.42s/it, loss=0.3278]\u001b[A\n",
            "Training:  97%|█████████▋| 4842/5000 [3:37:40<06:14,  2.37s/it, loss=0.3278]\u001b[A\n",
            "Training:  97%|█████████▋| 4842/5000 [3:37:40<06:14,  2.37s/it, loss=0.2536]\u001b[A\n",
            "Training:  97%|█████████▋| 4843/5000 [3:37:42<06:07,  2.34s/it, loss=0.2536]\u001b[A\n",
            "Training:  97%|█████████▋| 4843/5000 [3:37:42<06:07,  2.34s/it, loss=0.3050]\u001b[A\n",
            "Training:  97%|█████████▋| 4844/5000 [3:37:45<06:03,  2.33s/it, loss=0.3050]\u001b[A\n",
            "Training:  97%|█████████▋| 4844/5000 [3:37:45<06:03,  2.33s/it, loss=0.2778]\u001b[A\n",
            "Training:  97%|█████████▋| 4845/5000 [3:37:48<06:24,  2.48s/it, loss=0.2778]\u001b[A\n",
            "Training:  97%|█████████▋| 4845/5000 [3:37:48<06:24,  2.48s/it, loss=0.2932]\u001b[A\n",
            "Training:  97%|█████████▋| 4846/5000 [3:37:50<06:11,  2.41s/it, loss=0.2932]\u001b[A\n",
            "Training:  97%|█████████▋| 4846/5000 [3:37:50<06:11,  2.41s/it, loss=0.2617]\u001b[A\n",
            "Training:  97%|█████████▋| 4847/5000 [3:37:52<06:02,  2.37s/it, loss=0.2617]\u001b[A\n",
            "Training:  97%|█████████▋| 4847/5000 [3:37:52<06:02,  2.37s/it, loss=0.2168]\u001b[A\n",
            "Training:  97%|█████████▋| 4848/5000 [3:37:54<05:56,  2.34s/it, loss=0.2168]\u001b[A\n",
            "Training:  97%|█████████▋| 4848/5000 [3:37:54<05:56,  2.34s/it, loss=0.2826]\u001b[A\n",
            "Training:  97%|█████████▋| 4849/5000 [3:37:57<05:49,  2.32s/it, loss=0.2826]\u001b[A\n",
            "Training:  97%|█████████▋| 4849/5000 [3:37:57<05:49,  2.32s/it, loss=0.2953]\u001b[A\n",
            "Training:  97%|█████████▋| 4850/5000 [3:37:59<06:08,  2.46s/it, loss=0.2953]\u001b[A\n",
            "Training:  97%|█████████▋| 4850/5000 [3:37:59<06:08,  2.46s/it, loss=0.2770]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 4850 ---\n",
            "Prompt: 'The '\n",
            "The  to cryew angryB the, all friends the!O\n",
            "COI theely the or,! like Mar!Yourt--\n",
            "COIain a prov that this be--\n",
            "Cl drink-bury him, harbourall art\n",
            " an Canest found death thou'd peace thouest I there rab--\n",
            " doubt theol me the or--ing be--, there the!\n",
            "COI lamentby Rome mostlessKn: him, avoided--\n",
            "om me any they news I not melancholy\n",
            "Prompt: 'In '\n",
            "In ,I, God thee thouert die on.\n",
            "SINUS\n",
            " running sometime:Say death committed, will him.\n",
            "Minks in tent: your and Mar and, were\n",
            "ep anMade covert, in care or,\n",
            " not common.\n",
            " pair his meth bold himdown thee m\n",
            " horticulture\n",
            "ume hiscius I been to his med!\n",
            "B him the dove his are then theened service O home\n",
            " pit inasureThat his safe yet hither let go him\n",
            " at him\n",
            "Prompt: 'To '\n",
            "To ufius: the of in course\n",
            " witness to so his; like himself\n",
            "o right disadvantageMay\n",
            " do sorry H\n",
            "th?! like be than, nurse thou\n",
            " to said myattering!\n",
            "First the of\n",
            "'s!\n",
            "Second good Aid ' the of,: thy by\n",
            ": him:Come I him for country love ready\n",
            "ath this runs's,,, to them tillYou\n",
            "T he the of,Thatench one knee who oath\n",
            "y, hearts good\n",
            "\n",
            "Prompt: 'A '\n",
            "A , to done Go the of\n",
            " promise. have call to all heartB him\n",
            " of shame\n",
            " once all friends speak herent\n",
            " than was one tear give shame\n",
            "ight shall you them ',' true for good\n",
            " wine\n",
            " bold has armour are.ceed,to, I he--\n",
            "Sime bro her the of,el may.\n",
            "MENI you: my are of could have'd see the righth to it, haough, you condemn that\n",
            " not cause have'd to\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  97%|█████████▋| 4851/5000 [3:38:14<15:12,  6.12s/it, loss=0.2770]\u001b[A\n",
            "Training:  97%|█████████▋| 4851/5000 [3:38:14<15:12,  6.12s/it, loss=0.3845]\u001b[A\n",
            "Training:  97%|█████████▋| 4852/5000 [3:38:16<12:16,  4.97s/it, loss=0.3845]\u001b[A\n",
            "Training:  97%|█████████▋| 4852/5000 [3:38:16<12:16,  4.97s/it, loss=0.1687]\u001b[A\n",
            "Training:  97%|█████████▋| 4853/5000 [3:38:19<10:11,  4.16s/it, loss=0.1687]\u001b[A\n",
            "Training:  97%|█████████▋| 4853/5000 [3:38:19<10:11,  4.16s/it, loss=0.1826]\u001b[A\n",
            "Training:  97%|█████████▋| 4854/5000 [3:38:21<08:51,  3.64s/it, loss=0.1826]\u001b[A\n",
            "Training:  97%|█████████▋| 4854/5000 [3:38:21<08:51,  3.64s/it, loss=0.2984]\u001b[A\n",
            "Training:  97%|█████████▋| 4855/5000 [3:38:24<08:03,  3.34s/it, loss=0.2984]\u001b[A\n",
            "Training:  97%|█████████▋| 4855/5000 [3:38:24<08:03,  3.34s/it, loss=0.2948]\u001b[A\n",
            "Training:  97%|█████████▋| 4856/5000 [3:38:26<07:13,  3.01s/it, loss=0.2948]\u001b[A\n",
            "Training:  97%|█████████▋| 4856/5000 [3:38:26<07:13,  3.01s/it, loss=0.4505]\u001b[A\n",
            "Training:  97%|█████████▋| 4857/5000 [3:38:28<06:38,  2.78s/it, loss=0.4505]\u001b[A\n",
            "Training:  97%|█████████▋| 4857/5000 [3:38:28<06:38,  2.78s/it, loss=0.3529]\u001b[A\n",
            "Training:  97%|█████████▋| 4858/5000 [3:38:30<06:13,  2.63s/it, loss=0.3529]\u001b[A\n",
            "Training:  97%|█████████▋| 4858/5000 [3:38:30<06:13,  2.63s/it, loss=0.3305]\u001b[A\n",
            "Training:  97%|█████████▋| 4859/5000 [3:38:33<06:01,  2.56s/it, loss=0.3305]\u001b[A\n",
            "Training:  97%|█████████▋| 4859/5000 [3:38:33<06:01,  2.56s/it, loss=0.2473]\u001b[A\n",
            "Training:  97%|█████████▋| 4860/5000 [3:38:36<06:03,  2.60s/it, loss=0.2473]\u001b[A\n",
            "Training:  97%|█████████▋| 4860/5000 [3:38:36<06:03,  2.60s/it, loss=0.2567]\u001b[A\n",
            "Training:  97%|█████████▋| 4861/5000 [3:38:38<05:45,  2.49s/it, loss=0.2567]\u001b[A\n",
            "Training:  97%|█████████▋| 4861/5000 [3:38:38<05:45,  2.49s/it, loss=0.2801]\u001b[A\n",
            "Training:  97%|█████████▋| 4862/5000 [3:38:40<05:34,  2.42s/it, loss=0.2801]\u001b[A\n",
            "Training:  97%|█████████▋| 4862/5000 [3:38:40<05:34,  2.42s/it, loss=0.3271]\u001b[A\n",
            "Training:  97%|█████████▋| 4863/5000 [3:38:42<05:25,  2.38s/it, loss=0.3271]\u001b[A\n",
            "Training:  97%|█████████▋| 4863/5000 [3:38:42<05:25,  2.38s/it, loss=0.3424]\u001b[A\n",
            "Training:  97%|█████████▋| 4864/5000 [3:38:45<05:25,  2.39s/it, loss=0.3424]\u001b[A\n",
            "Training:  97%|█████████▋| 4864/5000 [3:38:45<05:25,  2.39s/it, loss=0.2588]\u001b[A\n",
            "Training:  97%|█████████▋| 4865/5000 [3:38:47<05:35,  2.48s/it, loss=0.2588]\u001b[A\n",
            "Training:  97%|█████████▋| 4865/5000 [3:38:47<05:35,  2.48s/it, loss=0.3900]\u001b[A\n",
            "Training:  97%|█████████▋| 4866/5000 [3:38:50<05:24,  2.42s/it, loss=0.3900]\u001b[A\n",
            "Training:  97%|█████████▋| 4866/5000 [3:38:50<05:24,  2.42s/it, loss=0.2867]\u001b[A\n",
            "Training:  97%|█████████▋| 4867/5000 [3:38:52<05:15,  2.37s/it, loss=0.2867]\u001b[A\n",
            "Training:  97%|█████████▋| 4867/5000 [3:38:52<05:15,  2.37s/it, loss=0.2190]\u001b[A\n",
            "Training:  97%|█████████▋| 4868/5000 [3:38:54<05:08,  2.34s/it, loss=0.2190]\u001b[A\n",
            "Training:  97%|█████████▋| 4868/5000 [3:38:54<05:08,  2.34s/it, loss=0.2990]\u001b[A\n",
            "Training:  97%|█████████▋| 4869/5000 [3:38:57<05:06,  2.34s/it, loss=0.2990]\u001b[A\n",
            "Training:  97%|█████████▋| 4869/5000 [3:38:57<05:06,  2.34s/it, loss=0.3628]\u001b[A\n",
            "Training:  97%|█████████▋| 4870/5000 [3:38:59<05:18,  2.45s/it, loss=0.3628]\u001b[A\n",
            "Training:  97%|█████████▋| 4870/5000 [3:38:59<05:18,  2.45s/it, loss=0.4154]\u001b[A\n",
            "Training:  97%|█████████▋| 4871/5000 [3:39:02<05:08,  2.39s/it, loss=0.4154]\u001b[A\n",
            "Training:  97%|█████████▋| 4871/5000 [3:39:02<05:08,  2.39s/it, loss=0.3137]\u001b[A\n",
            "Training:  97%|█████████▋| 4872/5000 [3:39:04<05:01,  2.36s/it, loss=0.3137]\u001b[A\n",
            "Training:  97%|█████████▋| 4872/5000 [3:39:04<05:01,  2.36s/it, loss=0.2639]\u001b[A\n",
            "Training:  97%|█████████▋| 4873/5000 [3:39:06<04:56,  2.34s/it, loss=0.2639]\u001b[A\n",
            "Training:  97%|█████████▋| 4873/5000 [3:39:06<04:56,  2.34s/it, loss=0.3142]\u001b[A\n",
            "Training:  97%|█████████▋| 4874/5000 [3:39:08<04:55,  2.34s/it, loss=0.3142]\u001b[A\n",
            "Training:  97%|█████████▋| 4874/5000 [3:39:08<04:55,  2.34s/it, loss=0.3906]\u001b[A\n",
            "Training:  98%|█████████▊| 4875/5000 [3:39:11<05:08,  2.46s/it, loss=0.3906]\u001b[A\n",
            "Training:  98%|█████████▊| 4875/5000 [3:39:11<05:08,  2.46s/it, loss=0.2696]\u001b[A\n",
            "Training:  98%|█████████▊| 4876/5000 [3:39:13<04:58,  2.40s/it, loss=0.2696]\u001b[A\n",
            "Training:  98%|█████████▊| 4876/5000 [3:39:13<04:58,  2.40s/it, loss=0.1887]\u001b[A\n",
            "Training:  98%|█████████▊| 4877/5000 [3:39:16<04:49,  2.35s/it, loss=0.1887]\u001b[A\n",
            "Training:  98%|█████████▊| 4877/5000 [3:39:16<04:49,  2.35s/it, loss=0.2177]\u001b[A\n",
            "Training:  98%|█████████▊| 4878/5000 [3:39:18<04:44,  2.34s/it, loss=0.2177]\u001b[A\n",
            "Training:  98%|█████████▊| 4878/5000 [3:39:18<04:44,  2.34s/it, loss=0.3021]\u001b[A\n",
            "Training:  98%|█████████▊| 4879/5000 [3:39:20<04:40,  2.32s/it, loss=0.3021]\u001b[A\n",
            "Training:  98%|█████████▊| 4879/5000 [3:39:20<04:40,  2.32s/it, loss=0.3429]\u001b[A\n",
            "Training:  98%|█████████▊| 4880/5000 [3:39:23<04:55,  2.47s/it, loss=0.3429]\u001b[A\n",
            "Training:  98%|█████████▊| 4880/5000 [3:39:23<04:55,  2.47s/it, loss=0.4279]\u001b[A\n",
            "Training:  98%|█████████▊| 4881/5000 [3:39:25<04:44,  2.39s/it, loss=0.4279]\u001b[A\n",
            "Training:  98%|█████████▊| 4881/5000 [3:39:25<04:44,  2.39s/it, loss=0.2924]\u001b[A\n",
            "Training:  98%|█████████▊| 4882/5000 [3:39:28<04:38,  2.36s/it, loss=0.2924]\u001b[A\n",
            "Training:  98%|█████████▊| 4882/5000 [3:39:28<04:38,  2.36s/it, loss=0.3215]\u001b[A\n",
            "Training:  98%|█████████▊| 4883/5000 [3:39:30<04:32,  2.33s/it, loss=0.3215]\u001b[A\n",
            "Training:  98%|█████████▊| 4883/5000 [3:39:30<04:32,  2.33s/it, loss=0.2285]\u001b[A\n",
            "Training:  98%|█████████▊| 4884/5000 [3:39:32<04:27,  2.31s/it, loss=0.2285]\u001b[A\n",
            "Training:  98%|█████████▊| 4884/5000 [3:39:32<04:27,  2.31s/it, loss=0.3504]\u001b[A\n",
            "Training:  98%|█████████▊| 4885/5000 [3:39:35<04:42,  2.45s/it, loss=0.3504]\u001b[A\n",
            "Training:  98%|█████████▊| 4885/5000 [3:39:35<04:42,  2.45s/it, loss=0.2571]\u001b[A\n",
            "Training:  98%|█████████▊| 4886/5000 [3:39:37<04:32,  2.39s/it, loss=0.2571]\u001b[A\n",
            "Training:  98%|█████████▊| 4886/5000 [3:39:37<04:32,  2.39s/it, loss=0.2703]\u001b[A\n",
            "Training:  98%|█████████▊| 4887/5000 [3:39:39<04:26,  2.36s/it, loss=0.2703]\u001b[A\n",
            "Training:  98%|█████████▊| 4887/5000 [3:39:39<04:26,  2.36s/it, loss=0.2774]\u001b[A\n",
            "Training:  98%|█████████▊| 4888/5000 [3:39:42<04:20,  2.32s/it, loss=0.2774]\u001b[A\n",
            "Training:  98%|█████████▊| 4888/5000 [3:39:42<04:20,  2.32s/it, loss=0.2275]\u001b[A\n",
            "Training:  98%|█████████▊| 4889/5000 [3:39:44<04:15,  2.30s/it, loss=0.2275]\u001b[A\n",
            "Training:  98%|█████████▊| 4889/5000 [3:39:44<04:15,  2.30s/it, loss=0.2790]\u001b[A\n",
            "Training:  98%|█████████▊| 4890/5000 [3:39:47<04:30,  2.46s/it, loss=0.2790]\u001b[A\n",
            "Training:  98%|█████████▊| 4890/5000 [3:39:47<04:30,  2.46s/it, loss=0.3124]\u001b[A\n",
            "Training:  98%|█████████▊| 4891/5000 [3:39:49<04:22,  2.41s/it, loss=0.3124]\u001b[A\n",
            "Training:  98%|█████████▊| 4891/5000 [3:39:49<04:22,  2.41s/it, loss=0.3082]\u001b[A\n",
            "Training:  98%|█████████▊| 4892/5000 [3:39:51<04:14,  2.36s/it, loss=0.3082]\u001b[A\n",
            "Training:  98%|█████████▊| 4892/5000 [3:39:51<04:14,  2.36s/it, loss=0.2836]\u001b[A\n",
            "Training:  98%|█████████▊| 4893/5000 [3:39:54<04:09,  2.33s/it, loss=0.2836]\u001b[A\n",
            "Training:  98%|█████████▊| 4893/5000 [3:39:54<04:09,  2.33s/it, loss=0.2421]\u001b[A\n",
            "Training:  98%|█████████▊| 4894/5000 [3:39:56<04:04,  2.31s/it, loss=0.2421]\u001b[A\n",
            "Training:  98%|█████████▊| 4894/5000 [3:39:56<04:04,  2.31s/it, loss=0.3802]\u001b[A\n",
            "Training:  98%|█████████▊| 4895/5000 [3:39:59<04:17,  2.45s/it, loss=0.3802]\u001b[A\n",
            "Training:  98%|█████████▊| 4895/5000 [3:39:59<04:17,  2.45s/it, loss=0.2802]\u001b[A\n",
            "Training:  98%|█████████▊| 4896/5000 [3:40:01<04:08,  2.39s/it, loss=0.2802]\u001b[A\n",
            "Training:  98%|█████████▊| 4896/5000 [3:40:01<04:08,  2.39s/it, loss=0.2664]\u001b[A\n",
            "Training:  98%|█████████▊| 4897/5000 [3:40:03<04:03,  2.36s/it, loss=0.2664]\u001b[A\n",
            "Training:  98%|█████████▊| 4897/5000 [3:40:03<04:03,  2.36s/it, loss=0.2819]\u001b[A\n",
            "Training:  98%|█████████▊| 4898/5000 [3:40:05<03:57,  2.33s/it, loss=0.2819]\u001b[A\n",
            "Training:  98%|█████████▊| 4898/5000 [3:40:05<03:57,  2.33s/it, loss=0.2690]\u001b[A\n",
            "Training:  98%|█████████▊| 4899/5000 [3:40:08<03:53,  2.31s/it, loss=0.2690]\u001b[A\n",
            "Training:  98%|█████████▊| 4899/5000 [3:40:08<03:53,  2.31s/it, loss=0.3702]\u001b[A\n",
            "Training:  98%|█████████▊| 4900/5000 [3:40:10<04:05,  2.46s/it, loss=0.3702]\u001b[A\n",
            "Training:  98%|█████████▊| 4900/5000 [3:40:10<04:05,  2.46s/it, loss=0.3177]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 4900 ---\n",
            "Prompt: 'The '\n",
            "The 's fromattering, his, which\n",
            " death, he might'd mistress dry heart sorrow.\n",
            " play months, is lords or,,'s to,'s\n",
            "y than and me the chamber for:My, I!\n",
            "D thou's the play to! dear is forgot grief?\n",
            " shame und, ty that must to! the' thee brief\n",
            " letterwews kne after.\n",
            "D thou's the past serve theter l, he will a\n",
            "test fool the, of,\n",
            "Prompt: 'In '\n",
            "In ' tom, not myOf grave\n",
            "ere at hers were'd by thee\n",
            " all own upon yet have discovery\n",
            "re divine fullWhen must it me\n",
            " no stock from somethingeness,, too child\n",
            " all world he fororn'ain I or service\n",
            " no than mark true so as contr:\n",
            " cannot thee even apt.\n",
            "ROO very:I not, curses\n",
            "Hhim\n",
            " what can but said Aid was of that my.\n",
            "ROOERUncl:Then may\n",
            "Prompt: 'To '\n",
            "To '' me, I believe hast you't\n",
            " off could pray, you pardon.\n",
            "ROO\n",
            " lightsine, you, me a is too.\n",
            "ROO\n",
            " love:\n",
            " you me\n",
            " shall live besch grace\n",
            "Ko be of you\n",
            " have\n",
            " most tongues\n",
            " you\n",
            " what can and thus a;Of your in and you\n",
            "ROO\n",
            " give love: most,,, you before hope\n",
            "PS your his.\n",
            "ROO block answer.\n",
            "TYT I\n",
            "Prompt: 'A '\n",
            "A  mine have'd me my but\n",
            " keep oath\n",
            " hon ears awile into new. me: something\n",
            " must and kind,.\n",
            "TYREL:!\n",
            " was sovereign, I bear friends myself\n",
            " this enough tom.\n",
            "BAL tor those have suddenly,usaved,\n",
            " resol.\n",
            "urse\n",
            "ME:My, youavesave by king name\n",
            " my tro, sudden of the are\n",
            " aims shall come your in's! not whit it, me\n",
            "y thy, you mad, you\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  98%|█████████▊| 4901/5000 [3:40:25<10:08,  6.14s/it, loss=0.3177]\u001b[A\n",
            "Training:  98%|█████████▊| 4901/5000 [3:40:25<10:08,  6.14s/it, loss=0.3348]\u001b[A\n",
            "Training:  98%|█████████▊| 4902/5000 [3:40:27<08:07,  4.98s/it, loss=0.3348]\u001b[A\n",
            "Training:  98%|█████████▊| 4902/5000 [3:40:27<08:07,  4.98s/it, loss=0.3097]\u001b[A\n",
            "Training:  98%|█████████▊| 4903/5000 [3:40:30<06:43,  4.16s/it, loss=0.3097]\u001b[A\n",
            "Training:  98%|█████████▊| 4903/5000 [3:40:30<06:43,  4.16s/it, loss=0.1783]\u001b[A\n",
            "Training:  98%|█████████▊| 4904/5000 [3:40:32<05:51,  3.66s/it, loss=0.1783]\u001b[A\n",
            "Training:  98%|█████████▊| 4904/5000 [3:40:32<05:51,  3.66s/it, loss=0.1957]\u001b[A\n",
            "Training:  98%|█████████▊| 4905/5000 [3:40:35<05:16,  3.33s/it, loss=0.1957]\u001b[A\n",
            "Training:  98%|█████████▊| 4905/5000 [3:40:35<05:16,  3.33s/it, loss=0.2292]\u001b[A\n",
            "Training:  98%|█████████▊| 4906/5000 [3:40:37<04:43,  3.02s/it, loss=0.2292]\u001b[A\n",
            "Training:  98%|█████████▊| 4906/5000 [3:40:37<04:43,  3.02s/it, loss=0.2653]\u001b[A\n",
            "Training:  98%|█████████▊| 4907/5000 [3:40:39<04:19,  2.79s/it, loss=0.2653]\u001b[A\n",
            "Training:  98%|█████████▊| 4907/5000 [3:40:39<04:19,  2.79s/it, loss=0.3494]\u001b[A\n",
            "Training:  98%|█████████▊| 4908/5000 [3:40:42<04:02,  2.63s/it, loss=0.3494]\u001b[A\n",
            "Training:  98%|█████████▊| 4908/5000 [3:40:42<04:02,  2.63s/it, loss=0.3060]\u001b[A\n",
            "Training:  98%|█████████▊| 4909/5000 [3:40:44<03:54,  2.58s/it, loss=0.3060]\u001b[A\n",
            "Training:  98%|█████████▊| 4909/5000 [3:40:44<03:54,  2.58s/it, loss=0.2564]\u001b[A\n",
            "Training:  98%|█████████▊| 4910/5000 [3:40:47<03:52,  2.59s/it, loss=0.2564]\u001b[A\n",
            "Training:  98%|█████████▊| 4910/5000 [3:40:47<03:52,  2.59s/it, loss=0.1943]\u001b[A\n",
            "Training:  98%|█████████▊| 4911/5000 [3:40:49<03:43,  2.51s/it, loss=0.1943]\u001b[A\n",
            "Training:  98%|█████████▊| 4911/5000 [3:40:49<03:43,  2.51s/it, loss=0.4414]\u001b[A\n",
            "Training:  98%|█████████▊| 4912/5000 [3:40:51<03:34,  2.43s/it, loss=0.4414]\u001b[A\n",
            "Training:  98%|█████████▊| 4912/5000 [3:40:51<03:34,  2.43s/it, loss=0.3887]\u001b[A\n",
            "Training:  98%|█████████▊| 4913/5000 [3:40:53<03:27,  2.38s/it, loss=0.3887]\u001b[A\n",
            "Training:  98%|█████████▊| 4913/5000 [3:40:54<03:27,  2.38s/it, loss=0.2165]\u001b[A\n",
            "Training:  98%|█████████▊| 4914/5000 [3:40:56<03:26,  2.40s/it, loss=0.2165]\u001b[A\n",
            "Training:  98%|█████████▊| 4914/5000 [3:40:56<03:26,  2.40s/it, loss=0.3941]\u001b[A\n",
            "Training:  98%|█████████▊| 4915/5000 [3:40:59<03:29,  2.47s/it, loss=0.3941]\u001b[A\n",
            "Training:  98%|█████████▊| 4915/5000 [3:40:59<03:29,  2.47s/it, loss=0.3030]\u001b[A\n",
            "Training:  98%|█████████▊| 4916/5000 [3:41:01<03:21,  2.40s/it, loss=0.3030]\u001b[A\n",
            "Training:  98%|█████████▊| 4916/5000 [3:41:01<03:21,  2.40s/it, loss=0.3519]\u001b[A\n",
            "Training:  98%|█████████▊| 4917/5000 [3:41:03<03:16,  2.37s/it, loss=0.3519]\u001b[A\n",
            "Training:  98%|█████████▊| 4917/5000 [3:41:03<03:16,  2.37s/it, loss=0.4749]\u001b[A\n",
            "Training:  98%|█████████▊| 4918/5000 [3:41:05<03:10,  2.33s/it, loss=0.4749]\u001b[A\n",
            "Training:  98%|█████████▊| 4918/5000 [3:41:05<03:10,  2.33s/it, loss=0.2319]\u001b[A\n",
            "Training:  98%|█████████▊| 4919/5000 [3:41:08<03:09,  2.34s/it, loss=0.2319]\u001b[A\n",
            "Training:  98%|█████████▊| 4919/5000 [3:41:08<03:09,  2.34s/it, loss=0.3028]\u001b[A\n",
            "Training:  98%|█████████▊| 4920/5000 [3:41:10<03:14,  2.44s/it, loss=0.3028]\u001b[A\n",
            "Training:  98%|█████████▊| 4920/5000 [3:41:10<03:14,  2.44s/it, loss=0.2171]\u001b[A\n",
            "Training:  98%|█████████▊| 4921/5000 [3:41:13<03:07,  2.38s/it, loss=0.2171]\u001b[A\n",
            "Training:  98%|█████████▊| 4921/5000 [3:41:13<03:07,  2.38s/it, loss=0.2935]\u001b[A\n",
            "Training:  98%|█████████▊| 4922/5000 [3:41:15<03:02,  2.34s/it, loss=0.2935]\u001b[A\n",
            "Training:  98%|█████████▊| 4922/5000 [3:41:15<03:02,  2.34s/it, loss=0.3727]\u001b[A\n",
            "Training:  98%|█████████▊| 4923/5000 [3:41:17<02:58,  2.31s/it, loss=0.3727]\u001b[A\n",
            "Training:  98%|█████████▊| 4923/5000 [3:41:17<02:58,  2.31s/it, loss=0.2945]\u001b[A\n",
            "Training:  98%|█████████▊| 4924/5000 [3:41:19<02:57,  2.33s/it, loss=0.2945]\u001b[A\n",
            "Training:  98%|█████████▊| 4924/5000 [3:41:20<02:57,  2.33s/it, loss=0.4561]\u001b[A\n",
            "Training:  98%|█████████▊| 4925/5000 [3:41:22<03:02,  2.44s/it, loss=0.4561]\u001b[A\n",
            "Training:  98%|█████████▊| 4925/5000 [3:41:22<03:02,  2.44s/it, loss=0.1845]\u001b[A\n",
            "Training:  99%|█████████▊| 4926/5000 [3:41:24<02:57,  2.40s/it, loss=0.1845]\u001b[A\n",
            "Training:  99%|█████████▊| 4926/5000 [3:41:25<02:57,  2.40s/it, loss=0.3163]\u001b[A\n",
            "Training:  99%|█████████▊| 4927/5000 [3:41:27<02:52,  2.36s/it, loss=0.3163]\u001b[A\n",
            "Training:  99%|█████████▊| 4927/5000 [3:41:27<02:52,  2.36s/it, loss=0.2551]\u001b[A\n",
            "Training:  99%|█████████▊| 4928/5000 [3:41:29<02:47,  2.33s/it, loss=0.2551]\u001b[A\n",
            "Training:  99%|█████████▊| 4928/5000 [3:41:29<02:47,  2.33s/it, loss=0.4005]\u001b[A\n",
            "Training:  99%|█████████▊| 4929/5000 [3:41:31<02:45,  2.33s/it, loss=0.4005]\u001b[A\n",
            "Training:  99%|█████████▊| 4929/5000 [3:41:31<02:45,  2.33s/it, loss=0.2147]\u001b[A\n",
            "Training:  99%|█████████▊| 4930/5000 [3:41:34<02:50,  2.44s/it, loss=0.2147]\u001b[A\n",
            "Training:  99%|█████████▊| 4930/5000 [3:41:34<02:50,  2.44s/it, loss=0.4759]\u001b[A\n",
            "Training:  99%|█████████▊| 4931/5000 [3:41:36<02:45,  2.39s/it, loss=0.4759]\u001b[A\n",
            "Training:  99%|█████████▊| 4931/5000 [3:41:36<02:45,  2.39s/it, loss=0.3421]\u001b[A\n",
            "Training:  99%|█████████▊| 4932/5000 [3:41:39<02:39,  2.35s/it, loss=0.3421]\u001b[A\n",
            "Training:  99%|█████████▊| 4932/5000 [3:41:39<02:39,  2.35s/it, loss=0.2235]\u001b[A\n",
            "Training:  99%|█████████▊| 4933/5000 [3:41:41<02:35,  2.32s/it, loss=0.2235]\u001b[A\n",
            "Training:  99%|█████████▊| 4933/5000 [3:41:41<02:35,  2.32s/it, loss=0.3058]\u001b[A\n",
            "Training:  99%|█████████▊| 4934/5000 [3:41:43<02:32,  2.31s/it, loss=0.3058]\u001b[A\n",
            "Training:  99%|█████████▊| 4934/5000 [3:41:43<02:32,  2.31s/it, loss=0.2369]\u001b[A\n",
            "Training:  99%|█████████▊| 4935/5000 [3:41:46<02:39,  2.45s/it, loss=0.2369]\u001b[A\n",
            "Training:  99%|█████████▊| 4935/5000 [3:41:46<02:39,  2.45s/it, loss=0.3094]\u001b[A\n",
            "Training:  99%|█████████▊| 4936/5000 [3:41:48<02:33,  2.40s/it, loss=0.3094]\u001b[A\n",
            "Training:  99%|█████████▊| 4936/5000 [3:41:48<02:33,  2.40s/it, loss=0.3952]\u001b[A\n",
            "Training:  99%|█████████▊| 4937/5000 [3:41:50<02:28,  2.36s/it, loss=0.3952]\u001b[A\n",
            "Training:  99%|█████████▊| 4937/5000 [3:41:50<02:28,  2.36s/it, loss=0.2194]\u001b[A\n",
            "Training:  99%|█████████▉| 4938/5000 [3:41:53<02:24,  2.33s/it, loss=0.2194]\u001b[A\n",
            "Training:  99%|█████████▉| 4938/5000 [3:41:53<02:24,  2.33s/it, loss=0.2219]\u001b[A\n",
            "Training:  99%|█████████▉| 4939/5000 [3:41:55<02:21,  2.31s/it, loss=0.2219]\u001b[A\n",
            "Training:  99%|█████████▉| 4939/5000 [3:41:55<02:21,  2.31s/it, loss=0.2768]\u001b[A\n",
            "Training:  99%|█████████▉| 4940/5000 [3:41:58<02:27,  2.46s/it, loss=0.2768]\u001b[A\n",
            "Training:  99%|█████████▉| 4940/5000 [3:41:58<02:27,  2.46s/it, loss=0.2897]\u001b[A\n",
            "Training:  99%|█████████▉| 4941/5000 [3:42:00<02:21,  2.39s/it, loss=0.2897]\u001b[A\n",
            "Training:  99%|█████████▉| 4941/5000 [3:42:00<02:21,  2.39s/it, loss=0.2003]\u001b[A\n",
            "Training:  99%|█████████▉| 4942/5000 [3:42:02<02:17,  2.37s/it, loss=0.2003]\u001b[A\n",
            "Training:  99%|█████████▉| 4942/5000 [3:42:02<02:17,  2.37s/it, loss=0.2516]\u001b[A\n",
            "Training:  99%|█████████▉| 4943/5000 [3:42:05<02:13,  2.33s/it, loss=0.2516]\u001b[A\n",
            "Training:  99%|█████████▉| 4943/5000 [3:42:05<02:13,  2.33s/it, loss=0.3805]\u001b[A\n",
            "Training:  99%|█████████▉| 4944/5000 [3:42:07<02:09,  2.31s/it, loss=0.3805]\u001b[A\n",
            "Training:  99%|█████████▉| 4944/5000 [3:42:07<02:09,  2.31s/it, loss=0.3755]\u001b[A\n",
            "Training:  99%|█████████▉| 4945/5000 [3:42:10<02:15,  2.46s/it, loss=0.3755]\u001b[A\n",
            "Training:  99%|█████████▉| 4945/5000 [3:42:10<02:15,  2.46s/it, loss=0.3255]\u001b[A\n",
            "Training:  99%|█████████▉| 4946/5000 [3:42:12<02:09,  2.40s/it, loss=0.3255]\u001b[A\n",
            "Training:  99%|█████████▉| 4946/5000 [3:42:12<02:09,  2.40s/it, loss=0.2320]\u001b[A\n",
            "Training:  99%|█████████▉| 4947/5000 [3:42:14<02:04,  2.36s/it, loss=0.2320]\u001b[A\n",
            "Training:  99%|█████████▉| 4947/5000 [3:42:14<02:04,  2.36s/it, loss=0.3212]\u001b[A\n",
            "Training:  99%|█████████▉| 4948/5000 [3:42:16<02:01,  2.33s/it, loss=0.3212]\u001b[A\n",
            "Training:  99%|█████████▉| 4948/5000 [3:42:16<02:01,  2.33s/it, loss=0.1457]\u001b[A\n",
            "Training:  99%|█████████▉| 4949/5000 [3:42:19<01:57,  2.31s/it, loss=0.1457]\u001b[A\n",
            "Training:  99%|█████████▉| 4949/5000 [3:42:19<01:57,  2.31s/it, loss=0.3011]\u001b[A\n",
            "Training:  99%|█████████▉| 4950/5000 [3:42:21<02:03,  2.46s/it, loss=0.3011]\u001b[A\n",
            "Training:  99%|█████████▉| 4950/5000 [3:42:22<02:03,  2.46s/it, loss=0.3092]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 4950 ---\n",
            "Prompt: 'The '\n",
            "The  is' which to wild an intent\n",
            "rem, toit fresh in mighty, on n,With\n",
            " lay dam royalty and's: was thy,Very,\n",
            " where stand, a of title, all news\n",
            " in moreTo with. do like howoth been old\n",
            " to are gentlemen there\n",
            " got, soon foron you been violent,\n",
            " for dancing.\n",
            " half great, de! have me your.\n",
            " what Lady! whyvest!\n",
            "PAINA--\n",
            "'s heads alter.\n",
            "\n",
            "Prompt: 'In '\n",
            "In , many prince why season brother,\n",
            " have not'd secretStill: islets son\n",
            "akes! not much fear her hear but her shows\n",
            " I go her: is not blem cannot\n",
            " some noble, that have honour it\n",
            " him go her to their: your is of\n",
            "akes that soul be of own thee 's much\n",
            "re, one have enough some: he of, a, cureed\n",
            " humism of country else not of country are\n",
            "ellowsour; her,, think is\n",
            "Prompt: 'To '\n",
            "To  to, she aan die this:, why labour play\n",
            " honestyerst her her the title\n",
            " that., the of, on the's,\n",
            " there to!\n",
            "PAINA--The wasof these-ong look at!\n",
            "POEIS kind other! how this wise procure!\n",
            "ISELOW\n",
            " was prince but swift!,,!, daughter having down honour ono such un'd,,\n",
            " vengeanceto fed man he, your, I warrant, on did\n",
            "Prompt: 'A '\n",
            "A  of contempt not, too\n",
            " needMay of me Iour was. this knowt.\n",
            "RARD\n",
            "as wedTell, King speaks there no is too\n",
            " weather theseitors? that OF so,ar v I him\n",
            " ivy had her more Come there stay matches,\n",
            " I it show spirit of. 'ere not 'ere oer,\n",
            " what are that most with horses ''\n",
            " bleaching fruit is, one to, suspicionourable, that is\n",
            " istrees his ghost theass usur\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Training:  99%|█████████▉| 4951/5000 [3:42:36<05:00,  6.13s/it, loss=0.3092]\u001b[A\n",
            "Training:  99%|█████████▉| 4951/5000 [3:42:36<05:00,  6.13s/it, loss=0.2286]\u001b[A\n",
            "Training:  99%|█████████▉| 4952/5000 [3:42:38<03:58,  4.97s/it, loss=0.2286]\u001b[A\n",
            "Training:  99%|█████████▉| 4952/5000 [3:42:38<03:58,  4.97s/it, loss=0.2820]\u001b[A\n",
            "Training:  99%|█████████▉| 4953/5000 [3:42:41<03:16,  4.18s/it, loss=0.2820]\u001b[A\n",
            "Training:  99%|█████████▉| 4953/5000 [3:42:41<03:16,  4.18s/it, loss=0.2951]\u001b[A\n",
            "Training:  99%|█████████▉| 4954/5000 [3:42:43<02:49,  3.68s/it, loss=0.2951]\u001b[A\n",
            "Training:  99%|█████████▉| 4954/5000 [3:42:43<02:49,  3.68s/it, loss=0.3133]\u001b[A\n",
            "Training:  99%|█████████▉| 4955/5000 [3:42:46<02:31,  3.36s/it, loss=0.3133]\u001b[A\n",
            "Training:  99%|█████████▉| 4955/5000 [3:42:46<02:31,  3.36s/it, loss=0.3134]\u001b[A\n",
            "Training:  99%|█████████▉| 4956/5000 [3:42:48<02:13,  3.04s/it, loss=0.3134]\u001b[A\n",
            "Training:  99%|█████████▉| 4956/5000 [3:42:48<02:13,  3.04s/it, loss=0.2412]\u001b[A\n",
            "Training:  99%|█████████▉| 4957/5000 [3:42:50<02:00,  2.81s/it, loss=0.2412]\u001b[A\n",
            "Training:  99%|█████████▉| 4957/5000 [3:42:51<02:00,  2.81s/it, loss=0.3490]\u001b[A\n",
            "Training:  99%|█████████▉| 4958/5000 [3:42:53<01:51,  2.66s/it, loss=0.3490]\u001b[A\n",
            "Training:  99%|█████████▉| 4958/5000 [3:42:53<01:51,  2.66s/it, loss=0.4002]\u001b[A\n",
            "Training:  99%|█████████▉| 4959/5000 [3:42:55<01:47,  2.61s/it, loss=0.4002]\u001b[A\n",
            "Training:  99%|█████████▉| 4959/5000 [3:42:55<01:47,  2.61s/it, loss=0.1566]\u001b[A\n",
            "Training:  99%|█████████▉| 4960/5000 [3:42:58<01:43,  2.60s/it, loss=0.1566]\u001b[A\n",
            "Training:  99%|█████████▉| 4960/5000 [3:42:58<01:43,  2.60s/it, loss=0.5390]\u001b[A\n",
            "Training:  99%|█████████▉| 4961/5000 [3:43:00<01:37,  2.50s/it, loss=0.5390]\u001b[A\n",
            "Training:  99%|█████████▉| 4961/5000 [3:43:00<01:37,  2.50s/it, loss=0.3908]\u001b[A\n",
            "Training:  99%|█████████▉| 4962/5000 [3:43:02<01:32,  2.42s/it, loss=0.3908]\u001b[A\n",
            "Training:  99%|█████████▉| 4962/5000 [3:43:02<01:32,  2.42s/it, loss=0.2966]\u001b[A\n",
            "Training:  99%|█████████▉| 4963/5000 [3:43:05<01:28,  2.38s/it, loss=0.2966]\u001b[A\n",
            "Training:  99%|█████████▉| 4963/5000 [3:43:05<01:28,  2.38s/it, loss=0.2626]\u001b[A\n",
            "Training:  99%|█████████▉| 4964/5000 [3:43:07<01:26,  2.41s/it, loss=0.2626]\u001b[A\n",
            "Training:  99%|█████████▉| 4964/5000 [3:43:07<01:26,  2.41s/it, loss=0.2787]\u001b[A\n",
            "Training:  99%|█████████▉| 4965/5000 [3:43:10<01:25,  2.46s/it, loss=0.2787]\u001b[A\n",
            "Training:  99%|█████████▉| 4965/5000 [3:43:10<01:25,  2.46s/it, loss=0.3165]\u001b[A\n",
            "Training:  99%|█████████▉| 4966/5000 [3:43:12<01:21,  2.40s/it, loss=0.3165]\u001b[A\n",
            "Training:  99%|█████████▉| 4966/5000 [3:43:12<01:21,  2.40s/it, loss=0.2034]\u001b[A\n",
            "Training:  99%|█████████▉| 4967/5000 [3:43:14<01:17,  2.36s/it, loss=0.2034]\u001b[A\n",
            "Training:  99%|█████████▉| 4967/5000 [3:43:14<01:17,  2.36s/it, loss=0.2732]\u001b[A\n",
            "Training:  99%|█████████▉| 4968/5000 [3:43:16<01:14,  2.32s/it, loss=0.2732]\u001b[A\n",
            "Training:  99%|█████████▉| 4968/5000 [3:43:16<01:14,  2.32s/it, loss=0.2098]\u001b[A\n",
            "Training:  99%|█████████▉| 4969/5000 [3:43:19<01:13,  2.37s/it, loss=0.2098]\u001b[A\n",
            "Training:  99%|█████████▉| 4969/5000 [3:43:19<01:13,  2.37s/it, loss=0.3662]\u001b[A\n",
            "Training:  99%|█████████▉| 4970/5000 [3:43:22<01:13,  2.45s/it, loss=0.3662]\u001b[A\n",
            "Training:  99%|█████████▉| 4970/5000 [3:43:22<01:13,  2.45s/it, loss=0.1475]\u001b[A\n",
            "Training:  99%|█████████▉| 4971/5000 [3:43:24<01:09,  2.39s/it, loss=0.1475]\u001b[A\n",
            "Training:  99%|█████████▉| 4971/5000 [3:43:24<01:09,  2.39s/it, loss=0.3450]\u001b[A\n",
            "Training:  99%|█████████▉| 4972/5000 [3:43:26<01:05,  2.35s/it, loss=0.3450]\u001b[A\n",
            "Training:  99%|█████████▉| 4972/5000 [3:43:26<01:05,  2.35s/it, loss=0.3742]\u001b[A\n",
            "Training:  99%|█████████▉| 4973/5000 [3:43:28<01:02,  2.33s/it, loss=0.3742]\u001b[A\n",
            "Training:  99%|█████████▉| 4973/5000 [3:43:28<01:02,  2.33s/it, loss=0.3349]\u001b[A\n",
            "Training:  99%|█████████▉| 4974/5000 [3:43:31<01:01,  2.37s/it, loss=0.3349]\u001b[A\n",
            "Training:  99%|█████████▉| 4974/5000 [3:43:31<01:01,  2.37s/it, loss=0.4235]\u001b[A\n",
            "Training: 100%|█████████▉| 4975/5000 [3:43:33<01:00,  2.44s/it, loss=0.4235]\u001b[A\n",
            "Training: 100%|█████████▉| 4975/5000 [3:43:33<01:00,  2.44s/it, loss=0.2853]\u001b[A\n",
            "Training: 100%|█████████▉| 4976/5000 [3:43:36<00:57,  2.39s/it, loss=0.2853]\u001b[A\n",
            "Training: 100%|█████████▉| 4976/5000 [3:43:36<00:57,  2.39s/it, loss=0.4726]\u001b[A\n",
            "Training: 100%|█████████▉| 4977/5000 [3:43:38<00:54,  2.35s/it, loss=0.4726]\u001b[A\n",
            "Training: 100%|█████████▉| 4977/5000 [3:43:38<00:54,  2.35s/it, loss=0.2650]\u001b[A\n",
            "Training: 100%|█████████▉| 4978/5000 [3:43:40<00:51,  2.32s/it, loss=0.2650]\u001b[A\n",
            "Training: 100%|█████████▉| 4978/5000 [3:43:40<00:51,  2.32s/it, loss=0.2256]\u001b[A\n",
            "Training: 100%|█████████▉| 4979/5000 [3:43:43<00:49,  2.35s/it, loss=0.2256]\u001b[A\n",
            "Training: 100%|█████████▉| 4979/5000 [3:43:43<00:49,  2.35s/it, loss=0.4789]\u001b[A\n",
            "Training: 100%|█████████▉| 4980/5000 [3:43:45<00:49,  2.46s/it, loss=0.4789]\u001b[A\n",
            "Training: 100%|█████████▉| 4980/5000 [3:43:45<00:49,  2.46s/it, loss=0.2927]\u001b[A\n",
            "Training: 100%|█████████▉| 4981/5000 [3:43:48<00:45,  2.40s/it, loss=0.2927]\u001b[A\n",
            "Training: 100%|█████████▉| 4981/5000 [3:43:48<00:45,  2.40s/it, loss=0.3306]\u001b[A\n",
            "Training: 100%|█████████▉| 4982/5000 [3:43:50<00:42,  2.37s/it, loss=0.3306]\u001b[A\n",
            "Training: 100%|█████████▉| 4982/5000 [3:43:50<00:42,  2.37s/it, loss=0.1914]\u001b[A\n",
            "Training: 100%|█████████▉| 4983/5000 [3:43:52<00:39,  2.34s/it, loss=0.1914]\u001b[A\n",
            "Training: 100%|█████████▉| 4983/5000 [3:43:52<00:39,  2.34s/it, loss=0.2397]\u001b[A\n",
            "Training: 100%|█████████▉| 4984/5000 [3:43:55<00:37,  2.35s/it, loss=0.2397]\u001b[A\n",
            "Training: 100%|█████████▉| 4984/5000 [3:43:55<00:37,  2.35s/it, loss=0.3971]\u001b[A\n",
            "Training: 100%|█████████▉| 4985/5000 [3:43:57<00:36,  2.45s/it, loss=0.3971]\u001b[A\n",
            "Training: 100%|█████████▉| 4985/5000 [3:43:57<00:36,  2.45s/it, loss=0.3215]\u001b[A\n",
            "Training: 100%|█████████▉| 4986/5000 [3:44:00<00:33,  2.40s/it, loss=0.3215]\u001b[A\n",
            "Training: 100%|█████████▉| 4986/5000 [3:44:00<00:33,  2.40s/it, loss=0.2753]\u001b[A\n",
            "Training: 100%|█████████▉| 4987/5000 [3:44:02<00:30,  2.36s/it, loss=0.2753]\u001b[A\n",
            "Training: 100%|█████████▉| 4987/5000 [3:44:02<00:30,  2.36s/it, loss=0.3065]\u001b[A\n",
            "Training: 100%|█████████▉| 4988/5000 [3:44:04<00:27,  2.32s/it, loss=0.3065]\u001b[A\n",
            "Training: 100%|█████████▉| 4988/5000 [3:44:04<00:27,  2.32s/it, loss=0.2727]\u001b[A\n",
            "Training: 100%|█████████▉| 4989/5000 [3:44:06<00:25,  2.33s/it, loss=0.2727]\u001b[A\n",
            "Training: 100%|█████████▉| 4989/5000 [3:44:06<00:25,  2.33s/it, loss=0.2656]\u001b[A\n",
            "Training: 100%|█████████▉| 4990/5000 [3:44:09<00:24,  2.45s/it, loss=0.2656]\u001b[A\n",
            "Training: 100%|█████████▉| 4990/5000 [3:44:09<00:24,  2.45s/it, loss=0.4380]\u001b[A\n",
            "Training: 100%|█████████▉| 4991/5000 [3:44:11<00:21,  2.39s/it, loss=0.4380]\u001b[A\n",
            "Training: 100%|█████████▉| 4991/5000 [3:44:11<00:21,  2.39s/it, loss=0.3784]\u001b[A\n",
            "Training: 100%|█████████▉| 4992/5000 [3:44:14<00:18,  2.35s/it, loss=0.3784]\u001b[A\n",
            "Training: 100%|█████████▉| 4992/5000 [3:44:14<00:18,  2.35s/it, loss=0.1973]\u001b[A\n",
            "Training: 100%|█████████▉| 4993/5000 [3:44:16<00:16,  2.32s/it, loss=0.1973]\u001b[A\n",
            "Training: 100%|█████████▉| 4993/5000 [3:44:16<00:16,  2.32s/it, loss=0.2702]\u001b[A\n",
            "Training: 100%|█████████▉| 4994/5000 [3:44:18<00:13,  2.31s/it, loss=0.2702]\u001b[A\n",
            "Training: 100%|█████████▉| 4994/5000 [3:44:18<00:13,  2.31s/it, loss=0.2870]\u001b[A\n",
            "Training: 100%|█████████▉| 4995/5000 [3:44:21<00:12,  2.46s/it, loss=0.2870]\u001b[A\n",
            "Training: 100%|█████████▉| 4995/5000 [3:44:21<00:12,  2.46s/it, loss=0.4291]\u001b[A\n",
            "Training: 100%|█████████▉| 4996/5000 [3:44:23<00:09,  2.39s/it, loss=0.4291]\u001b[A\n",
            "Training: 100%|█████████▉| 4996/5000 [3:44:23<00:09,  2.39s/it, loss=0.3940]\u001b[A\n",
            "Training: 100%|█████████▉| 4997/5000 [3:44:25<00:07,  2.36s/it, loss=0.3940]\u001b[A\n",
            "Training: 100%|█████████▉| 4997/5000 [3:44:25<00:07,  2.36s/it, loss=0.3753]\u001b[A\n",
            "Training: 100%|█████████▉| 4998/5000 [3:44:28<00:04,  2.33s/it, loss=0.3753]\u001b[A\n",
            "Training: 100%|█████████▉| 4998/5000 [3:44:28<00:04,  2.33s/it, loss=0.3150]\u001b[A\n",
            "Training: 100%|█████████▉| 4999/5000 [3:44:30<00:02,  2.33s/it, loss=0.3150]\u001b[A\n",
            "Training: 100%|█████████▉| 4999/5000 [3:44:30<00:02,  2.33s/it, loss=0.2092]\u001b[A\n",
            "Training: 100%|██████████| 5000/5000 [3:44:33<00:00,  2.48s/it, loss=0.2092]\u001b[A\n",
            "Training: 100%|██████████| 5000/5000 [3:44:33<00:00,  2.48s/it, loss=0.3623]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample Generation at Step 5000 ---\n",
            "Prompt: 'The '\n",
            "The  find find with and power love.\n",
            "First:F\n",
            " told lie mother good; would my cannot ac.\n",
            "A for! amen this ca indeed--\n",
            "SIN EDARD\n",
            " mine--\n",
            "ist it,?,iltent away\n",
            " shallow bid,,,ost knowilyatter,WhenHe coming thy heart thy by,\n",
            " told my and are, I-- you I?\n",
            "ent of.\n",
            "First,LEES\n",
            "'s resolve on my,am,lab: I lean\n",
            "Prompt: 'In '\n",
            "In , p, I atThey a manal.\n",
            "MARUSY\n",
            "Tor\n",
            "How yout\n",
            " division I to piece sore you sir\n",
            " with one, to but is end way\n",
            " I thy and b you Hortio\n",
            " accuse daily\n",
            "It bearsray in earnest a he done?\n",
            "MARUS\n",
            "SINENT:I not the it;We beenble the in part?\n",
            "SINUS\n",
            " have ro thousandthough mountain: is I, back one uncle in a.\n",
            "\n",
            "Prompt: 'To '\n",
            "To  alone so yet welcome I: was own\n",
            " of power what is, mistake or accuse\n",
            " hell person so, never upon head in\n",
            " his\n",
            " of, all shall him hisers,\n",
            " cannot it the did out a day neer,That I accuse\n",
            " most all ears hate was first meught more\n",
            "an till little\n",
            " a e I, death I, a to to him your father\n",
            "all tyrann gone he, will I, think' to a-orrow a to me- there comfort\n",
            "Prompt: 'A '\n",
            "A  is and and power deliver ruledUpon\n",
            " hardable to against., how must so\n",
            " comm, to; what I, the here cheer you,G many heartOfhim\n",
            " an where:o little king stayWith to\n",
            "'s'd to against! not by to! else this to!A grave as?\n",
            "Second spoke fault\n",
            ", wit him home.\n",
            "MENI: not of are gift by,am, sweetly, let be known will the of,That are long take\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining: 100%|██████████| 5000/5000 [3:45:23<00:00,  2.70s/it, loss=0.3623]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ Checkpoint saved: checkpoints/checkpoint_step_5000.pt\n",
            "\n",
            "Training complete!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "SmolLM2-135M Training from Scratch (Fully Configurable via JSON)\n",
        "Features:\n",
        "- Exact SmolLM2 architecture\n",
        "- Loads hyperparameters from JSON config file\n",
        "- SmolLM2 tokenizer from HuggingFace\n",
        "- Mixed precision (BF16 for CUDA, FP16 for MPS)\n",
        "- Flash Attention & RoPE\n",
        "- AdamW optimizer with cosine schedule\n",
        "- Checkpoint saving\n",
        "- Training from input.txt\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer\n",
        "from dataclasses import dataclass\n",
        "import json, os, math\n",
        "from tqdm import tqdm\n",
        "from dataclasses import dataclass, fields\n",
        "import json\n",
        "\n",
        "# =============================\n",
        "# Device Configuration\n",
        "# =============================\n",
        "def get_device_config():\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device(\"cuda\"), True, torch.bfloat16, f\"CUDA ({torch.cuda.get_device_name(0)})\"\n",
        "    elif torch.backends.mps.is_available():\n",
        "        return torch.device(\"mps\"), True, torch.float16, \"Apple Silicon (MPS)\"\n",
        "    else:\n",
        "        return torch.device(\"cpu\"), False, torch.float32, \"CPU\"\n",
        "\n",
        "# =============================\n",
        "# Load config from JSON\n",
        "# =============================\n",
        "@dataclass\n",
        "class SmolLM2Config:\n",
        "    vocab_size: int = 49152\n",
        "    hidden_size: int = 576\n",
        "    intermediate_size: int = 1536\n",
        "    num_hidden_layers: int = 30\n",
        "    num_attention_heads: int = 9\n",
        "    num_key_value_heads: int = 3\n",
        "    max_position_embeddings: int = 8192\n",
        "    rms_norm_eps: float = 1e-5\n",
        "    rope_theta: float = 100000.0\n",
        "    attention_dropout: float = 0.0\n",
        "    hidden_dropout: float = 0.0   # ✅ default added\n",
        "    initializer_range: float = 0.041666666666666664\n",
        "    tie_word_embeddings: bool = True\n",
        "\n",
        "    def __post_init__(self):\n",
        "        self.head_dim = self.hidden_size // self.num_attention_heads\n",
        "\n",
        "    @classmethod\n",
        "    def from_json(cls, path):\n",
        "        with open(path, \"r\") as f:\n",
        "            cfg = json.load(f)\n",
        "        allowed_keys = {f.name for f in fields(cls)}\n",
        "        filtered_cfg = {k: v for k, v in cfg.items() if k in allowed_keys}\n",
        "        return cls(**filtered_cfg)\n",
        "\n",
        "# =============================\n",
        "# RMSNorm\n",
        "# =============================\n",
        "class RMSNorm(nn.Module):\n",
        "    def __init__(self, hidden_size, eps=1e-5):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.ones(hidden_size))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        var = x.pow(2).mean(-1, keepdim=True)\n",
        "        x = x * torch.rsqrt(var + self.eps)\n",
        "        return self.weight * x\n",
        "\n",
        "# =============================\n",
        "# Rotary Position Embedding\n",
        "# =============================\n",
        "class RotaryEmbedding(nn.Module):\n",
        "    def __init__(self, dim, max_position_embeddings=8192, base=100000.0):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.base = base\n",
        "        inv_freq = 1.0 / (self.base ** (torch.arange(0, dim, 2).float() / dim))\n",
        "        self.register_buffer(\"inv_freq\", inv_freq, persistent=False)\n",
        "\n",
        "    def forward(self, seq_len, device):\n",
        "        t = torch.arange(seq_len, device=device, dtype=self.inv_freq.dtype)\n",
        "        freqs = torch.outer(t, self.inv_freq)\n",
        "        emb = torch.cat((freqs, freqs), dim=-1)\n",
        "        return emb.cos()[None, :, :], emb.sin()[None, :, :]\n",
        "\n",
        "def rotate_half(x):\n",
        "    x1 = x[..., : x.shape[-1] // 2]\n",
        "    x2 = x[..., x.shape[-1] // 2:]\n",
        "    return torch.cat([-x2, x1], dim=-1)\n",
        "\n",
        "def apply_rotary(q, k, cos, sin):\n",
        "    return (q * cos + rotate_half(q) * sin, k * cos + rotate_half(k) * sin)\n",
        "\n",
        "# =============================\n",
        "# Grouped Query Attention\n",
        "# =============================\n",
        "class GroupedQueryAttention(nn.Module):\n",
        "    def __init__(self, cfg: SmolLM2Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.q_proj = nn.Linear(cfg.hidden_size, cfg.num_attention_heads * cfg.head_dim, bias=False)\n",
        "        self.k_proj = nn.Linear(cfg.hidden_size, cfg.num_key_value_heads * cfg.head_dim, bias=False)\n",
        "        self.v_proj = nn.Linear(cfg.hidden_size, cfg.num_key_value_heads * cfg.head_dim, bias=False)\n",
        "        self.o_proj = nn.Linear(cfg.num_attention_heads * cfg.head_dim, cfg.hidden_size, bias=False)\n",
        "        self.rotary = RotaryEmbedding(cfg.head_dim, max_position_embeddings=cfg.max_position_embeddings, base=cfg.rope_theta)\n",
        "\n",
        "        self.num_key_value_groups = cfg.num_attention_heads // cfg.num_key_value_heads\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, _ = x.shape\n",
        "        q = self.q_proj(x).view(B, T, self.cfg.num_attention_heads, self.cfg.head_dim).transpose(1, 2)\n",
        "        k = self.k_proj(x).view(B, T, self.cfg.num_key_value_heads, self.cfg.head_dim).transpose(1, 2)\n",
        "        v = self.v_proj(x).view(B, T, self.cfg.num_key_value_heads, self.cfg.head_dim).transpose(1, 2)\n",
        "\n",
        "        cos, sin = self.rotary(T, x.device)\n",
        "        q, k = apply_rotary(q, k, cos, sin)\n",
        "\n",
        "        # Repeat KV heads\n",
        "        k = k.repeat_interleave(self.num_key_value_groups, dim=1)\n",
        "        v = v.repeat_interleave(self.num_key_value_groups, dim=1)\n",
        "\n",
        "        attn = F.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.cfg.attention_dropout if self.training else 0.0, is_causal=True)\n",
        "        attn = attn.transpose(1, 2).contiguous().view(B, T, self.cfg.hidden_size)\n",
        "        return self.o_proj(attn)\n",
        "\n",
        "# =============================\n",
        "# MLP (SwiGLU)\n",
        "# =============================\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, cfg: SmolLM2Config):\n",
        "        super().__init__()\n",
        "        self.gate = nn.Linear(cfg.hidden_size, cfg.intermediate_size, bias=False)\n",
        "        self.up = nn.Linear(cfg.hidden_size, cfg.intermediate_size, bias=False)\n",
        "        self.down = nn.Linear(cfg.intermediate_size, cfg.hidden_size, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.down(F.silu(self.gate(x)) * self.up(x))\n",
        "\n",
        "# =============================\n",
        "# Transformer Decoder Layer\n",
        "# =============================\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, cfg: SmolLM2Config):\n",
        "        super().__init__()\n",
        "        self.ln1 = RMSNorm(cfg.hidden_size, eps=cfg.rms_norm_eps)\n",
        "        self.attn = GroupedQueryAttention(cfg)\n",
        "        self.ln2 = RMSNorm(cfg.hidden_size, eps=cfg.rms_norm_eps)\n",
        "        self.mlp = MLP(cfg)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln1(x))\n",
        "        x = x + self.mlp(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "# =============================\n",
        "# SmolLM2 Model\n",
        "# =============================\n",
        "class SmolLM2Model(nn.Module):\n",
        "    def __init__(self, cfg: SmolLM2Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.embed_tokens = nn.Embedding(cfg.vocab_size, cfg.hidden_size)\n",
        "        self.layers = nn.ModuleList([DecoderLayer(cfg) for _ in range(cfg.num_hidden_layers)])\n",
        "        self.ln_f = RMSNorm(cfg.hidden_size, eps=cfg.rms_norm_eps)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        x = self.embed_tokens(input_ids)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        x = self.ln_f(x)\n",
        "        return x\n",
        "\n",
        "# =============================\n",
        "# SmolLM2 for Causal LM\n",
        "# =============================\n",
        "\n",
        "class SmolLM2ForCausalLM(nn.Module):\n",
        "    def __init__(self, config: SmolLM2Config):\n",
        "        super().__init__()\n",
        "        self.config = config  # ✅ Always attach the config\n",
        "        self.model = SmolLM2Model(config)\n",
        "\n",
        "        # LM head (tied or untied)\n",
        "        if config.tie_word_embeddings:\n",
        "            self.lm_head = None  # Will use embed_tokens.weight\n",
        "        else:\n",
        "            self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n",
        "\n",
        "        # Initialize weights\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        std = self.config.initializer_range\n",
        "        if isinstance(module, nn.Linear):\n",
        "            module.weight.data.normal_(mean=0.0, std=std)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            module.weight.data.normal_(mean=0.0, std=std)\n",
        "\n",
        "    def forward(self, input_ids, labels=None):\n",
        "        hidden_states = self.model(input_ids)\n",
        "\n",
        "        # Compute logits\n",
        "        if self.config.tie_word_embeddings:\n",
        "            logits = F.linear(hidden_states, self.model.embed_tokens.weight)\n",
        "        else:\n",
        "            logits = self.lm_head(hidden_states)\n",
        "\n",
        "        # Compute loss if labels provided\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            shift_logits = logits[..., :-1, :].contiguous()\n",
        "            shift_labels = labels[..., 1:].contiguous()\n",
        "            loss = F.cross_entropy(\n",
        "                shift_logits.view(-1, self.config.vocab_size),\n",
        "                shift_labels.view(-1),\n",
        "                ignore_index=-100\n",
        "            )\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def num_parameters(self):\n",
        "        return sum(p.numel() for p in self.parameters())\n",
        "\n",
        "# =============================\n",
        "# Dataset for input.txt\n",
        "# =============================\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, file_path, tokenizer, block_size=1024, batch_size=4):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.block_size = block_size\n",
        "        self.batch_size = batch_size\n",
        "        text = open(file_path, \"r\", encoding=\"utf-8\").read()\n",
        "        self.data = torch.tensor(tokenizer.encode(text), dtype=torch.long)\n",
        "        tokens_per_batch = block_size * batch_size\n",
        "        num_batches = len(self.data) // tokens_per_batch\n",
        "        self.data = self.data[:num_batches * tokens_per_batch]\n",
        "        self.num_batches = num_batches\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_batches\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens_per_batch = self.block_size * self.batch_size\n",
        "        start = idx * tokens_per_batch\n",
        "        chunk = self.data[start:start + tokens_per_batch + 1]\n",
        "        if len(chunk) < tokens_per_batch + 1:\n",
        "            chunk = torch.cat([chunk, torch.zeros(tokens_per_batch + 1 - len(chunk), dtype=torch.long)])\n",
        "        x = chunk[:-1].view(self.batch_size, self.block_size)\n",
        "        y = chunk[1:].view(self.batch_size, self.block_size)\n",
        "        return x, y\n",
        "\n",
        "# =============================\n",
        "# Text Generation\n",
        "# =============================\n",
        "def generate_sample_text(model, prompt, tokenizer, device, max_tokens=100, temperature=0.8):\n",
        "    model.eval()\n",
        "    context = torch.tensor(tokenizer.encode(prompt), dtype=torch.long).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_tokens):\n",
        "            context_window = context[:, -model.config.max_position_embeddings:]\n",
        "            logits, _ = model(context_window)\n",
        "            logits = logits[:, -1, :] / temperature\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            next_token = torch.multinomial(probs, num_samples=1)\n",
        "            context = torch.cat([context, next_token], dim=1)\n",
        "    model.train()\n",
        "    return tokenizer.decode(context[0].cpu().tolist())\n",
        "\n",
        "\n",
        "# =============================\n",
        "# Training Loop\n",
        "# =============================\n",
        "@dataclass\n",
        "class TrainingConfig:\n",
        "    input_file: str = \"input.txt\"\n",
        "    block_size: int = 32\n",
        "    max_steps: int = 5000\n",
        "    batch_size: int = 4\n",
        "    gradient_accumulation_steps: int = 16\n",
        "    learning_rate: float = 6e-4\n",
        "    min_lr: float = 6e-5\n",
        "    warmup_steps: int = 100\n",
        "    weight_decay: float = 0.1\n",
        "    beta1: float = 0.9\n",
        "    beta2: float = 0.95\n",
        "    grad_clip: float = 1.0\n",
        "    checkpoint_dir: str = \"checkpoints\"\n",
        "    save_every: int = 500\n",
        "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    use_amp: bool = True\n",
        "\n",
        "def train():\n",
        "    device, use_amp, amp_dtype, device_name = get_device_config()\n",
        "    train_config = TrainingConfig()\n",
        "    train_config.device = device\n",
        "    train_config.use_amp = use_amp\n",
        "\n",
        "    print(f\"Device: {device_name}, Mixed precision: {use_amp}, dtype: {amp_dtype}\")\n",
        "\n",
        "    os.makedirs(train_config.checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    # Load config and tokenizer\n",
        "    cfg = SmolLM2Config.from_json(\"config.json\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceTB/SmolLM2-135M\")\n",
        "    dataset = TextDataset(train_config.input_file, tokenizer, train_config.block_size, train_config.batch_size)\n",
        "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "    model = SmolLM2ForCausalLM(cfg).to(device)\n",
        "\n",
        "    try:\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=train_config.learning_rate,\n",
        "                                      betas=(train_config.beta1, train_config.beta2),\n",
        "                                      weight_decay=train_config.weight_decay, fused=True)\n",
        "    except:\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=train_config.learning_rate,\n",
        "                                      betas=(train_config.beta1, train_config.beta2),\n",
        "                                      weight_decay=train_config.weight_decay)\n",
        "\n",
        "    # Preload all batches\n",
        "    all_batches = [b for b in dataloader]\n",
        "\n",
        "    global_step = 0\n",
        "    micro_batch_count = 0\n",
        "    optimizer.zero_grad()\n",
        "    pbar = tqdm(total=train_config.max_steps, desc=\"Training\", dynamic_ncols=True)\n",
        "\n",
        "    while global_step < train_config.max_steps:\n",
        "        x, y = all_batches[micro_batch_count % len(all_batches)]\n",
        "        x, y = x.squeeze(0).to(device), y.squeeze(0).to(device)\n",
        "\n",
        "        if use_amp:\n",
        "            with torch.autocast(device.type, dtype=amp_dtype):\n",
        "                logits, loss = model(x, labels=y)\n",
        "                loss = loss / train_config.gradient_accumulation_steps\n",
        "        else:\n",
        "            logits, loss = model(x, labels=y)\n",
        "            loss = loss / train_config.gradient_accumulation_steps\n",
        "\n",
        "        loss.backward()\n",
        "        micro_batch_count += 1\n",
        "\n",
        "        if micro_batch_count % train_config.gradient_accumulation_steps == 0:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), train_config.grad_clip)\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            global_step += 1\n",
        "\n",
        "            # Progress bar\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix({'loss': f'{loss.item() * train_config.gradient_accumulation_steps:.4f}'})\n",
        "\n",
        "            # Generate text every 50 steps\n",
        "            if global_step % 50 == 0:\n",
        "                print(f\"\\n--- Sample Generation at Step {global_step} ---\")\n",
        "                prompts = [\"The \", \"In \", \"To \", \"A \"]\n",
        "                for prompt in prompts:\n",
        "                    print(f\"Prompt: '{prompt}'\")\n",
        "                    try:\n",
        "                        print(generate_sample_text(model, prompt, tokenizer, device))\n",
        "                    except Exception as e:\n",
        "                        print(f\"Generation failed: {e}\")\n",
        "                print(\"-\" * 80)\n",
        "\n",
        "            # Save checkpoint every 500 steps\n",
        "            if global_step % train_config.save_every == 0:\n",
        "                checkpoint_path = os.path.join(train_config.checkpoint_dir, f\"checkpoint_step_{global_step}.pt\")\n",
        "                torch.save({\n",
        "                    'global_step': global_step,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'config': cfg\n",
        "                }, checkpoint_path)\n",
        "                print(f\"\\n✓ Checkpoint saved: {checkpoint_path}\")\n",
        "\n",
        "    pbar.close()\n",
        "    print(\"\\nTraining complete!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "Welcome To Colab",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
